module.exports = [
"[project]/node_modules/@remotion/media-parser/dist/aac-codecprivate.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mapAudioObjectTypeToCodecString = exports.parseAacCodecPrivate = exports.createAacCodecPrivate = exports.getSampleRateFromSampleFrequencyIndex = void 0;
const getSampleRateFromSampleFrequencyIndex = (samplingFrequencyIndex)=>{
    switch(samplingFrequencyIndex){
        case 0:
            return 96000;
        case 1:
            return 88200;
        case 2:
            return 64000;
        case 3:
            return 48000;
        case 4:
            return 44100;
        case 5:
            return 32000;
        case 6:
            return 24000;
        case 7:
            return 22050;
        case 8:
            return 16000;
        case 9:
            return 12000;
        case 10:
            return 11025;
        case 11:
            return 8000;
        case 12:
            return 7350;
        default:
            throw new Error(`Unexpected sampling frequency index ${samplingFrequencyIndex}`);
    }
};
exports.getSampleRateFromSampleFrequencyIndex = getSampleRateFromSampleFrequencyIndex;
// codec private, for example [17, 144]
// audioObjectType = 2 = 'AAC LC'
// samplingFrequencyIndex = 3 = '48000 Hz'
// channelConfiguration = 2 = '2 channels'
/**
 * bytes 17,144: 00010 001 | 1 0010 000
                 ^^^^^ ^^^   ^ ^^^^ ^
                 |     |       |    | padding
                 |     |       |
                 |     |       +-- channelConfiguration (2)
                 |     +-- samplingFrequencyIndex (3)
                 +-- audioConfigType (2)
  */ // https://wiki.multimedia.cx/index.php/MPEG-4_Audio#Channel_Configurations
const getConfigForSampleRate = (sampleRate)=>{
    if (sampleRate === 96000) {
        return 0;
    }
    if (sampleRate === 88200) {
        return 1;
    }
    if (sampleRate === 64000) {
        return 2;
    }
    if (sampleRate === 48000) {
        return 3;
    }
    if (sampleRate === 44100) {
        return 4;
    }
    if (sampleRate === 32000) {
        return 5;
    }
    if (sampleRate === 24000) {
        return 6;
    }
    if (sampleRate === 22050) {
        return 7;
    }
    if (sampleRate === 16000) {
        return 8;
    }
    if (sampleRate === 12000) {
        return 9;
    }
    if (sampleRate === 11025) {
        return 10;
    }
    if (sampleRate === 8000) {
        return 11;
    }
    if (sampleRate === 7350) {
        return 12;
    }
    throw new Error(`Unexpected sample rate ${sampleRate}`);
};
const createAacCodecPrivate = ({ audioObjectType, sampleRate, channelConfiguration, codecPrivate })=>{
    if (codecPrivate !== null && codecPrivate.length > 2) {
        // Video submitted
        // submitted by Yossi Elkrief
        // TOOD: Check if we are now parsing correctly
        return codecPrivate;
    }
    const bits = `${audioObjectType.toString(2).padStart(5, '0')}${getConfigForSampleRate(sampleRate).toString(2).padStart(4, '0')}${channelConfiguration.toString(2).padStart(4, '0')}000`;
    if (bits.length !== 16) {
        throw new Error('Invalid AAC codec private ' + bits.length);
    }
    if (channelConfiguration === 0 || channelConfiguration > 7) {
        throw new Error('Invalid channel configuration ' + channelConfiguration);
    }
    const firstByte = parseInt(bits.slice(0, 8), 2);
    const secondByte = parseInt(bits.slice(8, 16), 2);
    return new Uint8Array([
        firstByte,
        secondByte
    ]);
};
exports.createAacCodecPrivate = createAacCodecPrivate;
const parseAacCodecPrivate = (bytes)=>{
    if (bytes.length < 2) {
        throw new Error('Invalid AAC codec private length');
    }
    const bits = [
        ...bytes
    ].map((b)=>b.toString(2).padStart(8, '0')).join('');
    let offset = 0;
    const audioObjectType = parseInt(bits.slice(offset, offset + 5), 2);
    offset += 5;
    const samplingFrequencyIndex = parseInt(bits.slice(offset, offset + 4), 2);
    offset += 4;
    if (samplingFrequencyIndex === 0xf) {
        offset += 24;
    }
    const channelConfiguration = parseInt(bits.slice(offset, offset + 4), 2);
    offset += 4;
    if (audioObjectType === 5) {
        const extensionSamplingFrequencyIndex = parseInt(bits.slice(offset, offset + 4), 2);
        offset += 4;
        const newAudioObjectType = parseInt(bits.slice(offset, offset + 5), 2);
        offset += 5;
        return {
            audioObjectType: newAudioObjectType,
            sampleRate: (0, exports.getSampleRateFromSampleFrequencyIndex)(extensionSamplingFrequencyIndex),
            channelConfiguration
        };
    }
    const sampleRate = (0, exports.getSampleRateFromSampleFrequencyIndex)(samplingFrequencyIndex);
    return {
        audioObjectType,
        sampleRate,
        channelConfiguration
    };
};
exports.parseAacCodecPrivate = parseAacCodecPrivate;
const mapAudioObjectTypeToCodecString = (audioObjectType)=>{
    /**
 * 	1.	1 - mp4a.40.2: MPEG-4 AAC LC (Low Complexity)
    2.	2 - mp4a.40.5: MPEG-4 AAC HE (High Efficiency)
    3.	3 - mp4a.40.29: MPEG-4 AAC HEv2 (High Efficiency v2)
    4.	4 - mp4a.40.1: MPEG-4 AAC Main
    5.	5 - mp4a.40.3: MPEG-4 AAC SSR (Scalable Sample Rate)
    6.	6 - mp4a.40.4: MPEG-4 AAC LTP (Long Term Prediction)
    7.	17 - mp4a.40.17: MPEG-4 AAC LD (Low Delay)
    8.	23 - mp4a.40.23: MPEG-4 AAC ELD (Enhanced Low Delay)
 */ switch(audioObjectType){
        case 1:
            return 'mp4a.40.2';
        case 2:
            return 'mp4a.40.5';
        case 3:
            return 'mp4a.40.29';
        case 4:
            return 'mp4a.40.1';
        case 5:
            return 'mp4a.40.3';
        case 6:
            return 'mp4a.40.4';
        case 17:
            return 'mp4a.40.17';
        case 23:
            return 'mp4a.40.23';
        default:
            throw new Error(`Unexpected audio object type ${audioObjectType}`);
    }
};
exports.mapAudioObjectTypeToCodecString = mapAudioObjectTypeToCodecString;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/ftyp.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseFtyp = void 0;
const parseFtyp = ({ iterator, size, offset })=>{
    const majorBrand = iterator.getByteString(4, false);
    const minorVersion = iterator.getFourByteNumber();
    const types = (size - iterator.counter.getOffset()) / 4;
    const compatibleBrands = [];
    for(let i = 0; i < types; i++){
        compatibleBrands.push(iterator.getByteString(4, false).trim());
    }
    const offsetAtEnd = iterator.counter.getOffset();
    return {
        type: 'ftyp-box',
        majorBrand,
        minorVersion,
        compatibleBrands,
        offset,
        boxSize: offsetAtEnd - offset
    };
};
exports.parseFtyp = parseFtyp;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/all-segments.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.range = exports.primaries = exports.matrixCoefficients = exports.transferCharacteristics = exports.color = exports.trackUID = exports.trackNumber = exports.tags = exports.tagSegment = exports.flagLacing = exports.displayUnit = exports.displayHeight = exports.displayWidth = exports.bitDepth = exports.interlaced = exports.alphaMode = exports.channels = exports.samplingFrequency = exports.tagTrackUidType = exports.titleType = exports.infoType = exports.writingApp = exports.timestampScale = exports.duration = exports.muxingApp = exports.heightType = exports.widthType = exports.trackType = exports.codecID = exports.voidHeader = exports.seekHead = exports.seek = exports.seekPosition = exports.maxCache = exports.minCache = exports._name = exports.seekId = exports.matroskaHeader = exports.docTypeReadVersion = exports.docTypeVersion = exports.docType = exports.ebmlMaxSizeLength = exports.ebmlMaxIdLength = exports.ebmlReadVersion = exports.ebmlVersion = exports.getSegmentName = exports.knownIdsWithThreeLength = exports.knownIdsWithTwoLength = exports.knownIdsWithOneLength = exports.matroskaElements = void 0;
exports.ebmlMap = exports.tagStringType = exports.tagNameType = exports.simpleTagType = exports.targetsType = exports.cluster = exports.segment = exports.blockGroup = exports.simpleBlock = exports.block = exports.timestampEntry = exports.tracks = exports.trackEntry = exports.trackTimestampScale = exports.codecName = exports.blockElement = exports.blockDurationSegment = exports.referenceBlock = exports.flagDefault = exports.videoSegment = exports.audioSegment = exports.maxBlockAdditionIdSegment = exports.blockAdditionsSegment = exports.codecPrivate = exports.defaultDuration = exports.language = exports.ChromaSitingVert = exports.ChromaSitingHorz = void 0;
exports.matroskaElements = {
    Header: '0x1a45dfa3',
    EBMLMaxIDLength: '0x42f2',
    EBMLVersion: '0x4286',
    EBMLReadVersion: '0x42f7',
    EBMLMaxSizeLength: '0x42f3',
    DocType: '0x4282',
    DocTypeVersion: '0x4287',
    DocTypeReadVersion: '0x4285',
    Segment: '0x18538067',
    SeekHead: '0x114d9b74',
    Seek: '0x4dbb',
    SeekID: '0x53ab',
    SeekPosition: '0x53ac',
    Info: '0x1549a966',
    SegmentUUID: '0x73a4',
    SegmentFilename: '0x7384',
    PrevUUID: '0x3cb923',
    PrevFilename: '0x3c83ab',
    NextUUID: '0x3eb923',
    NextFilename: '0x3e83bb',
    SegmentFamily: '0x4444',
    ChapterTranslate: '0x6924',
    ChapterTranslateID: '0x69a5',
    ChapterTranslateCodec: '0x69bf',
    ChapterTranslateEditionUID: '0x69fc',
    TimestampScale: '0x2ad7b1',
    Duration: '0x4489',
    DateUTC: '0x4461',
    Title: '0x7ba9',
    MuxingApp: '0x4d80',
    WritingApp: '0x5741',
    Cluster: '0x1f43b675',
    Timestamp: '0xe7',
    SilentTracks: '0x5854',
    SilentTrackNumber: '0x58d7',
    Position: '0xa7',
    PrevSize: '0xab',
    SimpleBlock: '0xa3',
    BlockGroup: '0xa0',
    Block: '0xa1',
    BlockVirtual: '0xa2',
    BlockAdditions: '0x75a1',
    BlockMore: '0xa6',
    BlockAdditional: '0xa5',
    BlockAddID: '0xee',
    BlockDuration: '0x9b',
    ReferencePriority: '0xfa',
    ReferenceBlock: '0xfb',
    ReferenceVirtual: '0xfd',
    CodecState: '0xa4',
    DiscardPadding: '0x75a2',
    Slices: '0x8e',
    TimeSlice: '0xe8',
    LaceNumber: '0xcc',
    FrameNumber: '0xcd',
    BlockAdditionID: '0xcb',
    Delay: '0xce',
    SliceDuration: '0xcf',
    ReferenceFrame: '0xc8',
    ReferenceOffset: '0xc9',
    ReferenceTimestamp: '0xca',
    EncryptedBlock: '0xaf',
    Tracks: '0x1654ae6b',
    TrackEntry: '0xae',
    TrackNumber: '0xd7',
    TrackUID: '0x73c5',
    TrackType: '0x83',
    FlagEnabled: '0xb9',
    FlagDefault: '0x88',
    FlagForced: '0x55aa',
    FlagHearingImpaired: '0x55ab',
    FlagVisualImpaired: '0x55ac',
    FlagTextDescriptions: '0x55ad',
    FlagOriginal: '0x55ae',
    FlagCommentary: '0x55af',
    FlagLacing: '0x9c',
    MinCache: '0x6de7',
    MaxCache: '0x6df8',
    DefaultDuration: '0x23e383',
    DefaultDecodedFieldDuration: '0x234e7a',
    TrackTimestampScale: '0x23314f',
    TrackOffset: '0x537f',
    MaxBlockAdditionID: '0x55ee',
    BlockAdditionMapping: '0x41e4',
    BlockAddIDValue: '0x41f0',
    BlockAddIDName: '0x41a4',
    BlockAddIDType: '0x41e7',
    BlockAddIDExtraData: '0x41ed',
    Name: '0x536e',
    Language: '0x22b59c',
    LanguageBCP47: '0x22b59d',
    CodecID: '0x86',
    CodecPrivate: '0x63a2',
    CodecName: '0x258688',
    AttachmentLink: '0x7446',
    CodecSettings: '0x3a9697',
    CodecInfoURL: '0x3b4040',
    CodecDownloadURL: '0x26b240',
    CodecDecodeAll: '0xaa',
    TrackOverlay: '0x6fab',
    CodecDelay: '0x56aa',
    SeekPreRoll: '0x56bb',
    TrackTranslate: '0x6624',
    TrackTranslateTrackID: '0x66a5',
    TrackTranslateCodec: '0x66bf',
    TrackTranslateEditionUID: '0x66fc',
    Video: '0xe0',
    FlagInterlaced: '0x9a',
    FieldOrder: '0x9d',
    StereoMode: '0x53b8',
    AlphaMode: '0x53c0',
    OldStereoMode: '0x53b9',
    PixelWidth: '0xb0',
    PixelHeight: '0xba',
    PixelCropBottom: '0x54aa',
    PixelCropTop: '0x54bb',
    PixelCropLeft: '0x54cc',
    PixelCropRight: '0x54dd',
    DisplayWidth: '0x54b0',
    DisplayHeight: '0x54ba',
    DisplayUnit: '0x54b2',
    AspectRatioType: '0x54b3',
    UncompressedFourCC: '0x2eb524',
    GammaValue: '0x2fb523',
    FrameRate: '0x2383e3',
    Colour: '0x55b0',
    MatrixCoefficients: '0x55b1',
    BitsPerChannel: '0x55b2',
    ChromaSubsamplingHorz: '0x55b3',
    ChromaSubsamplingVert: '0x55b4',
    CbSubsamplingHorz: '0x55b5',
    CbSubsamplingVert: '0x55b6',
    ChromaSitingHorz: '0x55b7',
    ChromaSitingVert: '0x55b8',
    Range: '0x55b9',
    TransferCharacteristics: '0x55ba',
    Primaries: '0x55bb',
    MaxCLL: '0x55bc',
    MaxFALL: '0x55bd',
    MasteringMetadata: '0x55d0',
    PrimaryRChromaticityX: '0x55d1',
    PrimaryRChromaticityY: '0x55d2',
    PrimaryGChromaticityX: '0x55d3',
    PrimaryGChromaticityY: '0x55d4',
    PrimaryBChromaticityX: '0x55d5',
    PrimaryBChromaticityY: '0x55d6',
    WhitePointChromaticityX: '0x55d7',
    WhitePointChromaticityY: '0x55d8',
    LuminanceMax: '0x55d9',
    LuminanceMin: '0x55da',
    Projection: '0x7670',
    ProjectionType: '0x7671',
    ProjectionPrivate: '0x7672',
    ProjectionPoseYaw: '0x7673',
    ProjectionPosePitch: '0x7674',
    ProjectionPoseRoll: '0x7675',
    Audio: '0xe1',
    SamplingFrequency: '0xb5',
    OutputSamplingFrequency: '0x78b5',
    Channels: '0x9f',
    ChannelPositions: '0x7d7b',
    BitDepth: '0x6264',
    Emphasis: '0x52f1',
    TrackOperation: '0xe2',
    TrackCombinePlanes: '0xe3',
    TrackPlane: '0xe4',
    TrackPlaneUID: '0xe5',
    TrackPlaneType: '0xe6',
    TrackJoinBlocks: '0xe9',
    TrackJoinUID: '0xed',
    TrickTrackUID: '0xc0',
    TrickTrackSegmentUID: '0xc1',
    TrickTrackFlag: '0xc6',
    TrickMasterTrackUID: '0xc7',
    TrickMasterTrackSegmentUID: '0xc4',
    ContentEncodings: '0x6d80',
    ContentEncoding: '0x6240',
    ContentEncodingOrder: '0x5031',
    ContentEncodingScope: '0x5032',
    ContentEncodingType: '0x5033',
    ContentCompression: '0x5034',
    ContentCompAlgo: '0x4254',
    ContentCompSettings: '0x4255',
    ContentEncryption: '0x5035',
    ContentEncAlgo: '0x47e1',
    ContentEncKeyID: '0x47e2',
    ContentEncAESSettings: '0x47e7',
    AESSettingsCipherMode: '0x47e8',
    ContentSignature: '0x47e3',
    ContentSigKeyID: '0x47e4',
    ContentSigAlgo: '0x47e5',
    ContentSigHashAlgo: '0x47e6',
    Cues: '0x1c53bb6b',
    CuePoint: '0xbb',
    CueTime: '0xb3',
    CueTrackPositions: '0xb7',
    CueTrack: '0xf7',
    CueClusterPosition: '0xf1',
    CueRelativePosition: '0xf0',
    CueDuration: '0xb2',
    CueBlockNumber: '0x5378',
    CueCodecState: '0xea',
    CueReference: '0xdb',
    CueRefTime: '0x96',
    CueRefCluster: '0x97',
    CueRefNumber: '0x535f',
    CueRefCodecState: '0xeb',
    Attachments: '0x1941a469',
    AttachedFile: '0x61a7',
    FileDescription: '0x467e',
    FileName: '0x466e',
    FileMediaType: '0x4660',
    FileData: '0x465c',
    FileUID: '0x46ae',
    FileReferral: '0x4675',
    FileUsedStartTime: '0x4661',
    FileUsedEndTime: '0x4662',
    Chapters: '0x1043a770',
    EditionEntry: '0x45b9',
    EditionUID: '0x45bc',
    EditionFlagHidden: '0x45bd',
    EditionFlagDefault: '0x45db',
    EditionFlagOrdered: '0x45dd',
    EditionDisplay: '0x4520',
    EditionString: '0x4521',
    EditionLanguageIETF: '0x45e4',
    ChapterAtom: '0xb6',
    ChapterUID: '0x73c4',
    ChapterStringUID: '0x5654',
    ChapterTimeStart: '0x91',
    ChapterTimeEnd: '0x92',
    ChapterFlagHidden: '0x98',
    ChapterFlagEnabled: '0x4598',
    ChapterSegmentUUID: '0x6e67',
    ChapterSkipType: '0x4588',
    ChapterSegmentEditionUID: '0x6ebc',
    ChapterPhysicalEquiv: '0x63c3',
    ChapterTrack: '0x8f',
    ChapterTrackUID: '0x89',
    ChapterDisplay: '0x80',
    ChapString: '0x85',
    ChapLanguage: '0x437c',
    ChapLanguageBCP47: '0x437d',
    ChapCountry: '0x437e',
    ChapProcess: '0x6944',
    ChapProcessCodecID: '0x6955',
    ChapProcessPrivate: '0x450d',
    ChapProcessCommand: '0x6911',
    ChapProcessTime: '0x6922',
    ChapProcessData: '0x6933',
    Tags: '0x1254c367',
    Tag: '0x7373',
    Targets: '0x63c0',
    TargetTypeValue: '0x68ca',
    TargetType: '0x63ca',
    TagTrackUID: '0x63c5',
    TagEditionUID: '0x63c9',
    TagChapterUID: '0x63c4',
    TagAttachmentUID: '0x63c6',
    SimpleTag: '0x67c8',
    TagName: '0x45a3',
    TagLanguage: '0x447a',
    TagLanguageBCP47: '0x447b',
    TagDefault: '0x4484',
    TagDefaultBogus: '0x44b4',
    TagString: '0x4487',
    TagBinary: '0x4485',
    Void: '0xec',
    Crc32: '0xbf'
};
const matroskaIds = Object.values(exports.matroskaElements);
exports.knownIdsWithOneLength = matroskaIds.filter((id)=>id.length === 4);
exports.knownIdsWithTwoLength = matroskaIds.filter((id)=>id.length === 6);
exports.knownIdsWithThreeLength = matroskaIds.filter((id)=>id.length === 8);
const getSegmentName = (id)=>{
    var _a;
    return (_a = Object.entries(exports.matroskaElements).find(([, value])=>value === id)) === null || _a === void 0 ? void 0 : _a[0];
};
exports.getSegmentName = getSegmentName;
exports.ebmlVersion = {
    name: 'EBMLVersion',
    type: 'uint'
};
exports.ebmlReadVersion = {
    name: 'EBMLReadVersion',
    type: 'uint'
};
exports.ebmlMaxIdLength = {
    name: 'EBMLMaxIDLength',
    type: 'uint'
};
exports.ebmlMaxSizeLength = {
    name: 'EBMLMaxSizeLength',
    type: 'uint'
};
exports.docType = {
    name: 'DocType',
    type: 'string'
};
exports.docTypeVersion = {
    name: 'DocTypeVersion',
    type: 'uint'
};
exports.docTypeReadVersion = {
    name: 'DocTypeReadVersion',
    type: 'uint'
};
const voidEbml = {
    name: 'Void',
    type: 'uint8array'
};
exports.matroskaHeader = {
    name: 'Header',
    type: 'children'
};
exports.seekId = {
    name: 'SeekID',
    type: 'hex-string'
};
exports._name = {
    name: 'Name',
    type: 'string'
};
exports.minCache = {
    name: 'MinCache',
    type: 'uint'
};
exports.maxCache = {
    name: 'MaxCache',
    type: 'uint'
};
exports.seekPosition = {
    name: 'SeekPosition',
    type: 'uint'
};
exports.seek = {
    name: 'Seek',
    type: 'children'
};
exports.seekHead = {
    name: 'SeekHead',
    type: 'children'
};
exports.voidHeader = {
    name: 'Void',
    type: 'uint8array'
};
exports.codecID = {
    name: 'CodecID',
    type: 'string'
};
exports.trackType = {
    name: 'TrackType',
    type: 'uint'
};
exports.widthType = {
    name: 'PixelWidth',
    type: 'uint'
};
exports.heightType = {
    name: 'PixelHeight',
    type: 'uint'
};
exports.muxingApp = {
    name: 'MuxingApp',
    type: 'string'
};
exports.duration = {
    name: 'Duration',
    type: 'float'
};
exports.timestampScale = {
    name: 'TimestampScale',
    type: 'uint'
};
exports.writingApp = {
    name: 'WritingApp',
    type: 'string'
};
exports.infoType = {
    name: 'Info',
    type: 'children'
};
exports.titleType = {
    name: 'Title',
    type: 'string'
};
exports.tagTrackUidType = {
    name: 'TagTrackUID',
    type: 'hex-string'
};
exports.samplingFrequency = {
    name: 'SamplingFrequency',
    type: 'float'
};
exports.channels = {
    name: 'Channels',
    type: 'uint'
};
exports.alphaMode = {
    name: 'AlphaMode',
    type: 'uint'
};
exports.interlaced = {
    name: 'FlagInterlaced',
    type: 'uint'
};
exports.bitDepth = {
    name: 'BitDepth',
    type: 'uint'
};
exports.displayWidth = {
    name: 'DisplayWidth',
    type: 'uint'
};
exports.displayHeight = {
    name: 'DisplayHeight',
    type: 'uint'
};
exports.displayUnit = {
    name: 'DisplayUnit',
    type: 'uint'
};
exports.flagLacing = {
    name: 'FlagLacing',
    type: 'uint'
};
exports.tagSegment = {
    name: 'Tag',
    type: 'children'
};
exports.tags = {
    name: 'Tags',
    type: 'children'
};
exports.trackNumber = {
    name: 'TrackNumber',
    type: 'uint'
};
exports.trackUID = {
    name: 'TrackUID',
    type: 'hex-string'
};
exports.color = {
    name: 'Colour',
    type: 'children'
};
exports.transferCharacteristics = {
    name: 'TransferCharacteristics',
    type: 'uint'
};
exports.matrixCoefficients = {
    name: 'MatrixCoefficients',
    type: 'uint'
};
exports.primaries = {
    name: 'Primaries',
    type: 'uint'
};
exports.range = {
    name: 'Range',
    type: 'uint'
};
exports.ChromaSitingHorz = {
    name: 'ChromaSitingHorz',
    type: 'uint'
};
exports.ChromaSitingVert = {
    name: 'ChromaSitingVert',
    type: 'uint'
};
exports.language = {
    name: 'Language',
    type: 'string'
};
exports.defaultDuration = {
    name: 'DefaultDuration',
    type: 'uint'
};
exports.codecPrivate = {
    name: 'CodecPrivate',
    type: 'uint8array'
};
exports.blockAdditionsSegment = {
    name: 'BlockAdditions',
    type: 'uint8array'
};
exports.maxBlockAdditionIdSegment = {
    name: 'MaxBlockAdditionID',
    type: 'uint'
};
exports.audioSegment = {
    name: 'Audio',
    type: 'children'
};
exports.videoSegment = {
    name: 'Video',
    type: 'children'
};
exports.flagDefault = {
    name: 'FlagDefault',
    type: 'uint'
};
exports.referenceBlock = {
    name: 'ReferenceBlock',
    type: 'uint'
};
exports.blockDurationSegment = {
    name: 'BlockDuration',
    type: 'uint'
};
exports.blockElement = {
    name: 'Block',
    type: 'uint8array'
};
exports.codecName = {
    name: 'CodecName',
    type: 'string'
};
exports.trackTimestampScale = {
    name: 'TrackTimestampScale',
    type: 'float'
};
exports.trackEntry = {
    name: 'TrackEntry',
    type: 'children'
};
exports.tracks = {
    name: 'Tracks',
    type: 'children'
};
exports.timestampEntry = {
    name: 'Timestamp',
    type: 'uint'
};
exports.block = {
    name: 'Block',
    type: 'uint8array'
};
exports.simpleBlock = {
    name: 'SimpleBlock',
    type: 'uint8array'
};
exports.blockGroup = {
    name: 'BlockGroup',
    type: 'children'
};
exports.segment = {
    name: 'Segment',
    type: 'children'
};
exports.cluster = {
    name: 'Cluster',
    type: 'children'
};
exports.targetsType = {
    name: 'Targets',
    type: 'children'
};
exports.simpleTagType = {
    name: 'SimpleTag',
    type: 'children'
};
exports.tagNameType = {
    name: 'TagName',
    type: 'string'
};
exports.tagStringType = {
    name: 'TagString',
    type: 'string'
};
exports.ebmlMap = {
    [exports.matroskaElements.Header]: exports.matroskaHeader,
    [exports.matroskaElements.DocType]: exports.docType,
    [exports.matroskaElements.Targets]: exports.targetsType,
    [exports.matroskaElements.SimpleTag]: exports.simpleTagType,
    [exports.matroskaElements.TagName]: exports.tagNameType,
    [exports.matroskaElements.TagString]: exports.tagStringType,
    [exports.matroskaElements.DocTypeVersion]: exports.docTypeVersion,
    [exports.matroskaElements.DocTypeReadVersion]: exports.docTypeReadVersion,
    [exports.matroskaElements.EBMLVersion]: exports.ebmlVersion,
    [exports.matroskaElements.EBMLReadVersion]: exports.ebmlReadVersion,
    [exports.matroskaElements.EBMLMaxIDLength]: exports.ebmlMaxIdLength,
    [exports.matroskaElements.EBMLMaxSizeLength]: exports.ebmlMaxSizeLength,
    [exports.matroskaElements.Void]: voidEbml,
    [exports.matroskaElements.Cues]: {
        name: 'Cues',
        type: 'children'
    },
    [exports.matroskaElements.CuePoint]: {
        name: 'CuePoint',
        type: 'children'
    },
    [exports.matroskaElements.CueTime]: {
        name: 'CueTime',
        type: 'uint'
    },
    [exports.matroskaElements.CueTrackPositions]: {
        name: 'CueTrackPositions',
        type: 'children'
    },
    [exports.matroskaElements.CueClusterPosition]: {
        name: 'CueClusterPosition',
        type: 'uint'
    },
    [exports.matroskaElements.CueRelativePosition]: {
        name: 'CueRelativePosition',
        type: 'uint'
    },
    [exports.matroskaElements.CueBlockNumber]: {
        name: 'CueBlockNumber',
        type: 'uint'
    },
    [exports.matroskaElements.CueTrack]: {
        name: 'CueTrack',
        type: 'uint'
    },
    [exports.matroskaElements.DateUTC]: {
        name: 'DateUTC',
        type: 'uint8array'
    },
    [exports.matroskaElements.TrackTimestampScale]: exports.trackTimestampScale,
    [exports.matroskaElements.CodecDelay]: {
        name: 'CodecDelay',
        type: 'uint8array'
    },
    [exports.matroskaElements.SeekPreRoll]: {
        name: 'SeekPreRoll',
        type: 'uint8array'
    },
    [exports.matroskaElements.DiscardPadding]: {
        name: 'DiscardPadding',
        type: 'uint8array'
    },
    [exports.matroskaElements.OutputSamplingFrequency]: {
        name: 'OutputSamplingFrequency',
        type: 'uint8array'
    },
    [exports.matroskaElements.CodecName]: exports.codecName,
    [exports.matroskaElements.Position]: {
        name: 'Position',
        type: 'uint8array'
    },
    [exports.matroskaElements.SliceDuration]: {
        name: 'SliceDuration',
        type: 'uint8array'
    },
    [exports.matroskaElements.TagTrackUID]: exports.tagTrackUidType,
    [exports.matroskaElements.SeekHead]: exports.seekHead,
    [exports.matroskaElements.Seek]: exports.seek,
    [exports.matroskaElements.SeekID]: exports.seekId,
    [exports.matroskaElements.Name]: exports._name,
    [exports.matroskaElements.MinCache]: exports.minCache,
    [exports.matroskaElements.MaxCache]: exports.maxCache,
    [exports.matroskaElements.SeekPosition]: exports.seekPosition,
    [exports.matroskaElements.Crc32]: {
        name: 'Crc32',
        type: 'uint8array'
    },
    [exports.matroskaElements.MuxingApp]: exports.muxingApp,
    [exports.matroskaElements.WritingApp]: {
        name: 'WritingApp',
        type: 'string'
    },
    [exports.matroskaElements.SegmentUUID]: {
        name: 'SegmentUUID',
        type: 'string'
    },
    [exports.matroskaElements.Duration]: exports.duration,
    [exports.matroskaElements.CodecID]: {
        name: 'CodecID',
        type: 'string'
    },
    [exports.matroskaElements.TrackType]: exports.trackType,
    [exports.matroskaElements.PixelWidth]: exports.widthType,
    [exports.matroskaElements.PixelHeight]: exports.heightType,
    [exports.matroskaElements.TimestampScale]: exports.timestampScale,
    [exports.matroskaElements.Info]: exports.infoType,
    [exports.matroskaElements.Title]: exports.titleType,
    [exports.matroskaElements.SamplingFrequency]: exports.samplingFrequency,
    [exports.matroskaElements.Channels]: exports.channels,
    [exports.matroskaElements.AlphaMode]: exports.alphaMode,
    [exports.matroskaElements.FlagInterlaced]: exports.interlaced,
    [exports.matroskaElements.BitDepth]: exports.bitDepth,
    [exports.matroskaElements.DisplayHeight]: exports.displayHeight,
    [exports.matroskaElements.DisplayWidth]: exports.displayWidth,
    [exports.matroskaElements.DisplayUnit]: exports.displayUnit,
    [exports.matroskaElements.FlagLacing]: exports.flagLacing,
    [exports.matroskaElements.Tags]: exports.tags,
    [exports.matroskaElements.Tag]: exports.tagSegment,
    [exports.matroskaElements.TrackNumber]: exports.trackNumber,
    [exports.matroskaElements.TrackUID]: exports.trackUID,
    [exports.matroskaElements.Colour]: exports.color,
    [exports.matroskaElements.Language]: exports.language,
    [exports.matroskaElements.DefaultDuration]: exports.defaultDuration,
    [exports.matroskaElements.CodecPrivate]: exports.codecPrivate,
    [exports.matroskaElements.BlockDuration]: exports.blockDurationSegment,
    [exports.matroskaElements.BlockAdditions]: exports.blockAdditionsSegment,
    [exports.matroskaElements.MaxBlockAdditionID]: exports.maxBlockAdditionIdSegment,
    [exports.matroskaElements.Audio]: exports.audioSegment,
    [exports.matroskaElements.Video]: exports.videoSegment,
    [exports.matroskaElements.FlagDefault]: exports.flagDefault,
    [exports.matroskaElements.ReferenceBlock]: exports.referenceBlock,
    [exports.matroskaElements.TrackEntry]: exports.trackEntry,
    [exports.matroskaElements.Timestamp]: {
        name: 'Timestamp',
        type: 'uint'
    },
    [exports.matroskaElements.Tracks]: exports.tracks,
    [exports.matroskaElements.Block]: exports.block,
    [exports.matroskaElements.SimpleBlock]: exports.simpleBlock,
    [exports.matroskaElements.BlockGroup]: exports.blockGroup,
    [exports.matroskaElements.Segment]: {
        name: 'Segment',
        type: 'children'
    },
    [exports.matroskaElements.Cluster]: {
        name: 'Cluster',
        type: 'children'
    },
    [exports.matroskaElements.TransferCharacteristics]: exports.transferCharacteristics,
    [exports.matroskaElements.MatrixCoefficients]: exports.matrixCoefficients,
    [exports.matroskaElements.Primaries]: exports.primaries,
    [exports.matroskaElements.Range]: exports.range,
    [exports.matroskaElements.ChromaSitingHorz]: exports.ChromaSitingHorz,
    [exports.matroskaElements.ChromaSitingVert]: exports.ChromaSitingVert
};
}),
"[project]/node_modules/@remotion/media-parser/dist/file-types/detect-file-type.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isM3u = exports.isFlac = exports.isAac = exports.isMp3 = exports.isTransportStream = exports.isIsoBaseMedia = exports.isWebm = exports.isRiffWave = exports.isRiffAvi = exports.matchesPattern = void 0;
const webmPattern = new Uint8Array([
    0x1a,
    0x45,
    0xdf,
    0xa3
]);
const matchesPattern = (pattern)=>{
    return (data)=>{
        return pattern.every((value, index)=>data[index] === value);
    };
};
exports.matchesPattern = matchesPattern;
const isRiffAvi = (data)=>{
    const riffPattern = new Uint8Array([
        0x52,
        0x49,
        0x46,
        0x46
    ]);
    if (!(0, exports.matchesPattern)(riffPattern)(data.subarray(0, 4))) {
        return false;
    }
    const fileType = data.subarray(8, 12);
    const aviPattern = new Uint8Array([
        0x41,
        0x56,
        0x49,
        0x20
    ]);
    return (0, exports.matchesPattern)(aviPattern)(fileType);
};
exports.isRiffAvi = isRiffAvi;
const isRiffWave = (data)=>{
    const riffPattern = new Uint8Array([
        0x52,
        0x49,
        0x46,
        0x46
    ]);
    if (!(0, exports.matchesPattern)(riffPattern)(data.subarray(0, 4))) {
        return false;
    }
    const fileType = data.subarray(8, 12);
    const wavePattern = new Uint8Array([
        0x57,
        0x41,
        0x56,
        0x45
    ]);
    return (0, exports.matchesPattern)(wavePattern)(fileType);
};
exports.isRiffWave = isRiffWave;
const isWebm = (data)=>{
    return (0, exports.matchesPattern)(webmPattern)(data.subarray(0, 4));
};
exports.isWebm = isWebm;
const isIsoBaseMedia = (data)=>{
    const isoBaseMediaMp4Pattern = new TextEncoder().encode('ftyp');
    return (0, exports.matchesPattern)(isoBaseMediaMp4Pattern)(data.subarray(4, 8));
};
exports.isIsoBaseMedia = isIsoBaseMedia;
const isTransportStream = (data)=>{
    return data[0] === 0x47 && data[188] === 0x47;
};
exports.isTransportStream = isTransportStream;
const isMp3 = (data)=>{
    const mpegPattern = new Uint8Array([
        0xff,
        0xf3
    ]);
    const mpegPattern2 = new Uint8Array([
        0xff,
        0xfb
    ]);
    const id3v4Pattern = new Uint8Array([
        0x49,
        0x44,
        0x33,
        4
    ]);
    const id3v3Pattern = new Uint8Array([
        0x49,
        0x44,
        0x33,
        3
    ]);
    const id3v2Pattern = new Uint8Array([
        0x49,
        0x44,
        0x33,
        2
    ]);
    const subarray = data.subarray(0, 4);
    return (0, exports.matchesPattern)(mpegPattern)(subarray) || (0, exports.matchesPattern)(mpegPattern2)(subarray) || (0, exports.matchesPattern)(id3v4Pattern)(subarray) || (0, exports.matchesPattern)(id3v3Pattern)(subarray) || (0, exports.matchesPattern)(id3v2Pattern)(subarray);
};
exports.isMp3 = isMp3;
const isAac = (data)=>{
    const aacPattern = new Uint8Array([
        0xff,
        0xf1
    ]);
    return (0, exports.matchesPattern)(aacPattern)(data.subarray(0, 2));
};
exports.isAac = isAac;
const isFlac = (data)=>{
    const flacPattern = new Uint8Array([
        0x66,
        0x4c,
        0x61,
        0x43
    ]);
    return (0, exports.matchesPattern)(flacPattern)(data.subarray(0, 4));
};
exports.isFlac = isFlac;
const isM3u = (data)=>{
    return new TextDecoder('utf-8').decode(data.slice(0, 7)) === '#EXTM3U';
};
exports.isM3u = isM3u;
}),
"[project]/node_modules/@remotion/media-parser/dist/file-types/bmp.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isBmp = void 0;
const detect_file_type_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/detect-file-type.js [app-route] (ecmascript)");
function getBmpDimensions(bmpData) {
    if (bmpData.length < 26) {
        return null;
    }
    const view = new DataView(bmpData.buffer, bmpData.byteOffset);
    return {
        width: view.getUint32(18, true),
        height: Math.abs(view.getInt32(22, true))
    };
}
const isBmp = (data)=>{
    const bmpPattern = new Uint8Array([
        0x42,
        0x4d
    ]);
    if ((0, detect_file_type_1.matchesPattern)(bmpPattern)(data.subarray(0, 2))) {
        const bmp = getBmpDimensions(data);
        return {
            dimensions: bmp,
            type: 'bmp'
        };
    }
    return null;
};
exports.isBmp = isBmp;
}),
"[project]/node_modules/@remotion/media-parser/dist/file-types/gif.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isGif = void 0;
const detect_file_type_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/detect-file-type.js [app-route] (ecmascript)");
const getGifDimensions = (data)=>{
    const view = new DataView(data.buffer, data.byteOffset);
    const width = view.getUint16(6, true);
    const height = view.getUint16(8, true);
    return {
        width,
        height
    };
};
const isGif = (data)=>{
    const gifPattern = new Uint8Array([
        0x47,
        0x49,
        0x46,
        0x38
    ]);
    if ((0, detect_file_type_1.matchesPattern)(gifPattern)(data.subarray(0, 4))) {
        return {
            type: 'gif',
            dimensions: getGifDimensions(data)
        };
    }
    return null;
};
exports.isGif = isGif;
}),
"[project]/node_modules/@remotion/media-parser/dist/file-types/jpeg.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isJpeg = void 0;
exports.getJpegDimensions = getJpegDimensions;
const detect_file_type_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/detect-file-type.js [app-route] (ecmascript)");
function getJpegDimensions(data) {
    let offset = 0;
    // Helper function to read a 16-bit big-endian integer
    function readUint16BE(o) {
        return data[o] << 8 | data[o + 1];
    }
    // Skip the Start of Image (SOI) marker
    if (readUint16BE(offset) !== 0xffd8) {
        return null; // Not a valid JPEG file
    }
    offset += 2;
    while(offset < data.length){
        if (data[offset] === 0xff) {
            const marker = data[offset + 1];
            if (marker === 0xc0 || marker === 0xc2) {
                // SOF0 or SOF2
                const height = readUint16BE(offset + 5);
                const width = readUint16BE(offset + 7);
                return {
                    width,
                    height
                };
            }
            const length = readUint16BE(offset + 2);
            offset += length + 2; // Move to the next marker
        } else {
            offset++;
        }
    }
    return null; // Return null if dimensions are not found
}
const isJpeg = (data)=>{
    const jpegPattern = new Uint8Array([
        0xff,
        0xd8
    ]);
    const jpeg = (0, detect_file_type_1.matchesPattern)(jpegPattern)(data.subarray(0, 2));
    if (!jpeg) {
        return null;
    }
    const dim = getJpegDimensions(data);
    return {
        dimensions: dim,
        type: 'jpeg'
    };
};
exports.isJpeg = isJpeg;
}),
"[project]/node_modules/@remotion/media-parser/dist/file-types/pdf.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isPdf = void 0;
const detect_file_type_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/detect-file-type.js [app-route] (ecmascript)");
const isPdf = (data)=>{
    if (data.length < 4) {
        return null;
    }
    const pdfPattern = new Uint8Array([
        0x25,
        0x50,
        0x44,
        0x46
    ]);
    return (0, detect_file_type_1.matchesPattern)(pdfPattern)(data.subarray(0, 4)) ? {
        type: 'pdf'
    } : null;
};
exports.isPdf = isPdf;
}),
"[project]/node_modules/@remotion/media-parser/dist/file-types/png.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isPng = void 0;
exports.getPngDimensions = getPngDimensions;
const detect_file_type_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/detect-file-type.js [app-route] (ecmascript)");
function getPngDimensions(pngData) {
    if (pngData.length < 24) {
        // PNG header (8) + IHDR chunk (16) minimum
        return null;
    }
    const view = new DataView(pngData.buffer, pngData.byteOffset);
    // Check PNG signature
    const pngSignature = [
        137,
        80,
        78,
        71,
        13,
        10,
        26,
        10
    ];
    for(let i = 0; i < 8; i++){
        if (pngData[i] !== pngSignature[i]) {
            return null;
        }
    }
    return {
        width: view.getUint32(16, false),
        height: view.getUint32(20, false)
    };
}
const isPng = (data)=>{
    const pngPattern = new Uint8Array([
        0x89,
        0x50,
        0x4e,
        0x47
    ]);
    if ((0, detect_file_type_1.matchesPattern)(pngPattern)(data.subarray(0, 4))) {
        const png = getPngDimensions(data);
        return {
            dimensions: png,
            type: 'png'
        };
    }
    return null;
};
exports.isPng = isPng;
}),
"[project]/node_modules/@remotion/media-parser/dist/file-types/webp.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isWebp = void 0;
const detect_file_type_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/detect-file-type.js [app-route] (ecmascript)");
function getWebPDimensions(bytes) {
    // Check if we have enough bytes for a basic WebP header
    if (bytes.length < 30) {
        return null;
    }
    // Check WebP file signature
    // "RIFF" signature (52 49 46 46) and "WEBP" signature (57 45 42 50)
    if (bytes[0] !== 0x52 || // R
    bytes[1] !== 0x49 || // I
    bytes[2] !== 0x46 || // F
    bytes[3] !== 0x46 || // F
    bytes[8] !== 0x57 || // W
    bytes[9] !== 0x45 || // E
    bytes[10] !== 0x42 || // B
    bytes[11] !== 0x50 // P
    ) {
        return null;
    }
    // Check for VP8 bitstream
    if (bytes[12] === 0x56 && bytes[13] === 0x50 && bytes[14] === 0x38) {
        // VP8 format
        if (bytes[15] === 0x20) {
            // Simple VP8 format
            return {
                width: bytes[26] | bytes[27] << 8 & 0x3fff,
                height: bytes[28] | bytes[29] << 8 & 0x3fff
            };
        }
    }
    // Check for VP8L (lossless) bitstream
    if (bytes[12] === 0x56 && bytes[13] === 0x50 && bytes[14] === 0x38 && bytes[15] === 0x4c) {
        return {
            width: 1 + (bytes[21] | (bytes[22] & 0x3f) << 8),
            height: 1 + ((bytes[22] & 0xc0) >> 6 | bytes[23] << 2 | (bytes[24] & 0x0f) << 10)
        };
    }
    // Check for VP8X (extended) bitstream
    if (bytes[12] === 0x56 && bytes[13] === 0x50 && bytes[14] === 0x38 && bytes[15] === 0x58) {
        return {
            width: 1 + (bytes[24] | bytes[25] << 8 | bytes[26] << 16),
            height: 1 + (bytes[27] | bytes[28] << 8 | bytes[29] << 16)
        };
    }
    return null;
}
const isWebp = (data)=>{
    const webpPattern = new Uint8Array([
        0x52,
        0x49,
        0x46,
        0x46
    ]);
    if ((0, detect_file_type_1.matchesPattern)(webpPattern)(data.subarray(0, 4))) {
        return {
            type: 'webp',
            dimensions: getWebPDimensions(data)
        };
    }
    return null;
};
exports.isWebp = isWebp;
}),
"[project]/node_modules/@remotion/media-parser/dist/file-types/index.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.detectFileType = void 0;
const bmp_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/bmp.js [app-route] (ecmascript)");
const detect_file_type_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/detect-file-type.js [app-route] (ecmascript)");
const gif_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/gif.js [app-route] (ecmascript)");
const jpeg_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/jpeg.js [app-route] (ecmascript)");
const pdf_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/pdf.js [app-route] (ecmascript)");
const png_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/png.js [app-route] (ecmascript)");
const webp_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/webp.js [app-route] (ecmascript)");
const detectFileType = (data)=>{
    if ((0, detect_file_type_1.isRiffWave)(data)) {
        return {
            type: 'wav'
        };
    }
    if ((0, detect_file_type_1.isRiffAvi)(data)) {
        return {
            type: 'riff'
        };
    }
    if ((0, detect_file_type_1.isAac)(data)) {
        return {
            type: 'aac'
        };
    }
    if ((0, detect_file_type_1.isFlac)(data)) {
        return {
            type: 'flac'
        };
    }
    if ((0, detect_file_type_1.isM3u)(data)) {
        return {
            type: 'm3u'
        };
    }
    const webp = (0, webp_1.isWebp)(data);
    if (webp) {
        return webp;
    }
    if ((0, detect_file_type_1.isWebm)(data)) {
        return {
            type: 'webm'
        };
    }
    if ((0, detect_file_type_1.isIsoBaseMedia)(data)) {
        return {
            type: 'iso-base-media'
        };
    }
    if ((0, detect_file_type_1.isTransportStream)(data)) {
        return {
            type: 'transport-stream'
        };
    }
    if ((0, detect_file_type_1.isMp3)(data)) {
        return {
            type: 'mp3'
        };
    }
    const gif = (0, gif_1.isGif)(data);
    if (gif) {
        return gif;
    }
    const png = (0, png_1.isPng)(data);
    if (png) {
        return png;
    }
    const pdf = (0, pdf_1.isPdf)(data);
    if (pdf) {
        return pdf;
    }
    const bmp = (0, bmp_1.isBmp)(data);
    if (bmp) {
        return bmp;
    }
    const jpeg = (0, jpeg_1.isJpeg)(data);
    if (jpeg) {
        return jpeg;
    }
    return {
        type: 'unknown'
    };
};
exports.detectFileType = detectFileType;
}),
"[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Log = exports.isEqualOrBelowLogLevel = exports.logLevels = void 0;
/* eslint-disable no-console */ exports.logLevels = [
    'trace',
    'verbose',
    'info',
    'warn',
    'error'
];
const getNumberForLogLevel = (level)=>{
    return exports.logLevels.indexOf(level);
};
const isEqualOrBelowLogLevel = (currentLevel, level)=>{
    return getNumberForLogLevel(currentLevel) <= getNumberForLogLevel(level);
};
exports.isEqualOrBelowLogLevel = isEqualOrBelowLogLevel;
exports.Log = {
    trace: (logLevel, ...args)=>{
        if ((0, exports.isEqualOrBelowLogLevel)(logLevel, 'trace')) {
            return console.log(...args);
        }
    },
    verbose: (logLevel, ...args)=>{
        if ((0, exports.isEqualOrBelowLogLevel)(logLevel, 'verbose')) {
            return console.log(...args);
        }
    },
    info: (logLevel, ...args)=>{
        if ((0, exports.isEqualOrBelowLogLevel)(logLevel, 'info')) {
            return console.log(...args);
        }
    },
    warn: (logLevel, ...args)=>{
        if ((0, exports.isEqualOrBelowLogLevel)(logLevel, 'warn')) {
            return console.warn(...args);
        }
    },
    error: (...args)=>{
        return console.error(...args);
    }
};
}),
"[project]/node_modules/@remotion/media-parser/dist/iterator/polyfilled-arraybuffer.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.ResizableBuffer = void 0;
class ResizableBuffer {
    constructor(buffer){
        this.buffer = buffer;
        this.uintarray = new Uint8Array(buffer);
    }
    resize(newLength) {
        if (typeof this.buffer.resize === 'function') {
            this.buffer.resize(newLength);
        } else {
            const newBuffer = new ArrayBuffer(newLength);
            new Uint8Array(newBuffer).set(new Uint8Array(this.buffer).subarray(0, Math.min(this.buffer.byteLength, newLength)));
            this.buffer = newBuffer;
            this.uintarray = new Uint8Array(newBuffer);
        }
    }
}
exports.ResizableBuffer = ResizableBuffer;
}),
"[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-manager.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.bufferManager = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const polyfilled_arraybuffer_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/polyfilled-arraybuffer.js [app-route] (ecmascript)");
const makeBufferWithMaxBytes = (initialData, maxBytes)=>{
    const maxByteLength = Math.min(maxBytes, 2 ** 31);
    try {
        const buf = new ArrayBuffer(initialData.byteLength, {
            maxByteLength
        });
        return new polyfilled_arraybuffer_1.ResizableBuffer(buf);
    } catch (e) {
        // Cloudflare Workers have a limit of 128MB max array buffer size
        if (e instanceof RangeError && maxBytes > 2 ** 27) {
            return new polyfilled_arraybuffer_1.ResizableBuffer(new ArrayBuffer(initialData.byteLength, {
                maxByteLength: 2 ** 27
            }));
        }
        throw e;
    }
};
const bufferManager = ({ initialData, maxBytes, counter, logLevel })=>{
    const buf = makeBufferWithMaxBytes(initialData, maxBytes);
    if (!buf.buffer.resize) {
        log_1.Log.warn(logLevel, '`ArrayBuffer.resize` is not supported in this Runtime. Using slow polyfill.');
    }
    buf.uintarray.set(initialData);
    let view = new DataView(buf.uintarray.buffer);
    const destroy = ()=>{
        buf.uintarray = new Uint8Array(0);
        buf.resize(0);
    };
    const flushBytesRead = (force, mode)=>{
        const bytesToRemove = counter.getDiscardedOffset();
        // Only do this operation if it is really worth it ðŸ˜‡
        // let's set the threshold to 3MB
        if (bytesToRemove < 3000000 && !force) {
            return {
                bytesRemoved: 0,
                removedData: null
            };
        }
        // Don't remove if the data is not even available
        if (view.byteLength < bytesToRemove && !force) {
            return {
                bytesRemoved: 0,
                removedData: null
            };
        }
        counter.discardBytes(bytesToRemove);
        const removedData = mode === 'download' ? buf.uintarray.slice(0, bytesToRemove) : null;
        const newData = buf.uintarray.slice(bytesToRemove);
        buf.uintarray.set(newData);
        buf.resize(newData.byteLength);
        view = new DataView(buf.uintarray.buffer);
        return {
            bytesRemoved: bytesToRemove,
            removedData
        };
    };
    const skipTo = (offset)=>{
        const becomesSmaller = offset < counter.getOffset();
        if (becomesSmaller) {
            const toDecrement = counter.getOffset() - offset;
            if (toDecrement > counter.getDiscardedOffset()) {
                throw new Error('Cannot count backwards, data has already been flushed');
            }
            counter.decrement(toDecrement);
        }
        const currentOffset = counter.getOffset();
        counter.increment(offset - currentOffset);
    };
    const addData = (newData)=>{
        const oldLength = buf.buffer.byteLength;
        const newLength = oldLength + newData.byteLength;
        if (newLength < oldLength) {
            throw new Error('Cannot decrement size');
        }
        if (newLength > (maxBytes !== null && maxBytes !== void 0 ? maxBytes : Infinity)) {
            throw new Error(`Exceeded maximum byte length ${maxBytes} with ${newLength}`);
        }
        buf.resize(newLength);
        buf.uintarray = new Uint8Array(buf.buffer);
        buf.uintarray.set(newData, oldLength);
        view = new DataView(buf.uintarray.buffer);
    };
    const replaceData = (newData, seekTo)=>{
        buf.resize(newData.byteLength);
        buf.uintarray = new Uint8Array(buf.buffer);
        buf.uintarray.set(newData);
        view = new DataView(buf.uintarray.buffer);
        counter.setDiscardedOffset(seekTo);
        // reset counter to 0
        counter.decrement(counter.getOffset());
        // seek to the new position
        counter.increment(seekTo);
    };
    return {
        getView: ()=>view,
        getUint8Array: ()=>buf.uintarray,
        destroy,
        addData,
        skipTo,
        removeBytesRead: flushBytesRead,
        replaceData
    };
};
exports.bufferManager = bufferManager;
}),
"[project]/node_modules/@remotion/media-parser/dist/iterator/offset-counter.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makeOffsetCounter = void 0;
const makeOffsetCounter = (initial)=>{
    let offset = initial;
    let discardedBytes = 0;
    return {
        getOffset: ()=>offset,
        discardBytes: (bytes)=>{
            discardedBytes += bytes;
        },
        increment: (bytes)=>{
            if (bytes < 0) {
                throw new Error('Cannot increment by a negative amount: ' + bytes);
            }
            offset += bytes;
        },
        getDiscardedBytes: ()=>discardedBytes,
        setDiscardedOffset: (bytes)=>{
            discardedBytes = bytes;
        },
        getDiscardedOffset: ()=>offset - discardedBytes,
        decrement: (bytes)=>{
            if (bytes < 0) {
                throw new Error('Cannot decrement by a negative amount: ' + bytes);
            }
            offset -= bytes;
        }
    };
};
exports.makeOffsetCounter = makeOffsetCounter;
}),
"[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getArrayBufferIterator = void 0;
/* eslint-disable @typescript-eslint/no-use-before-define */ const all_segments_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/all-segments.js [app-route] (ecmascript)");
const file_types_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/file-types/index.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const buffer_manager_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-manager.js [app-route] (ecmascript)");
const offset_counter_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/offset-counter.js [app-route] (ecmascript)");
const getArrayBufferIterator = ({ initialData, maxBytes, logLevel })=>{
    const counter = (0, offset_counter_1.makeOffsetCounter)(0);
    const { getUint8Array, getView, addData, destroy, removeBytesRead, skipTo, replaceData } = (0, buffer_manager_1.bufferManager)({
        initialData,
        maxBytes,
        counter,
        logLevel
    });
    const startCheckpoint = ()=>{
        const checkpoint = counter.getOffset();
        return {
            returnToCheckpoint: ()=>{
                counter.decrement(counter.getOffset() - checkpoint);
            }
        };
    };
    const getSlice = (amount)=>{
        const value = getUint8Array().slice(counter.getDiscardedOffset(), counter.getDiscardedOffset() + amount);
        counter.increment(value.length);
        return value;
    };
    const discard = (length)=>{
        counter.increment(length);
    };
    const readUntilNullTerminator = ()=>{
        const bytes = [];
        let byte;
        while((byte = getUint8()) !== 0){
            bytes.push(byte);
        }
        counter.decrement(1);
        return new TextDecoder().decode(new Uint8Array(bytes));
    };
    const readUntilLineEnd = ()=>{
        const bytes = [];
        // 10 is "\n"
        while(true){
            if (bytesRemaining() === 0) {
                return null;
            }
            const byte = getUint8();
            bytes.push(byte);
            if (byte === 10) {
                break;
            }
        }
        const str = new TextDecoder().decode(new Uint8Array(bytes)).trim();
        return str;
    };
    const getUint8 = ()=>{
        const val = getView().getUint8(counter.getDiscardedOffset());
        counter.increment(1);
        return val;
    };
    const getEightByteNumber = (littleEndian = false)=>{
        if (littleEndian) {
            const one = getUint8();
            const two = getUint8();
            const three = getUint8();
            const four = getUint8();
            const five = getUint8();
            const six = getUint8();
            const seven = getUint8();
            const eight = getUint8();
            return (eight << 56 | seven << 48 | six << 40 | five << 32 | four << 24 | three << 16 | two << 8 | one) >>> 0;
        }
        function byteArrayToBigInt(byteArray) {
            let result = BigInt(0);
            for(let i = 0; i < byteArray.length; i++){
                result = (result << BigInt(8)) + BigInt(byteArray[i]);
            }
            return result;
        }
        const bigInt = byteArrayToBigInt([
            getUint8(),
            getUint8(),
            getUint8(),
            getUint8(),
            getUint8(),
            getUint8(),
            getUint8(),
            getUint8()
        ]);
        return Number(bigInt);
    };
    const getFourByteNumber = ()=>{
        const unsigned = getUint8() << 24 | getUint8() << 16 | getUint8() << 8 | getUint8();
        return unsigned >>> 0;
    };
    const getPaddedFourByteNumber = ()=>{
        let lastInt = 128;
        while(lastInt = getUint8(), lastInt === 128){
        // Do nothing
        }
        return lastInt;
    };
    const getUint32 = ()=>{
        const val = getView().getUint32(counter.getDiscardedOffset());
        counter.increment(4);
        return val;
    };
    const getSyncSafeInt32 = ()=>{
        const val = getView().getUint32(counter.getDiscardedOffset());
        counter.increment(4);
        return (val & 0x7f000000) >> 3 | (val & 0x007f0000) >> 2 | (val & 0x00007f00) >> 1 | val & 0x0000007f;
    };
    const getUint64 = (littleEndian = false)=>{
        const val = getView().getBigUint64(counter.getDiscardedOffset(), littleEndian);
        counter.increment(8);
        return val;
    };
    const getInt64 = (littleEndian = false)=>{
        const val = getView().getBigInt64(counter.getDiscardedOffset(), littleEndian);
        counter.increment(8);
        return val;
    };
    const startBox = (size)=>{
        const startOffset = counter.getOffset();
        return {
            discardRest: ()=>discard(size - (counter.getOffset() - startOffset)),
            expectNoMoreBytes: ()=>{
                const remaining = size - (counter.getOffset() - startOffset);
                if (remaining !== 0) {
                    throw new Error('expected 0 bytes, got ' + remaining);
                }
            }
        };
    };
    const getUint32Le = ()=>{
        const val = getView().getUint32(counter.getDiscardedOffset(), true);
        counter.increment(4);
        return val;
    };
    const getInt32Le = ()=>{
        const val = getView().getInt32(counter.getDiscardedOffset(), true);
        counter.increment(4);
        return val;
    };
    const getInt32 = ()=>{
        const val = getView().getInt32(counter.getDiscardedOffset());
        counter.increment(4);
        return val;
    };
    const bytesRemaining = ()=>{
        return getUint8Array().byteLength - counter.getDiscardedOffset();
    };
    const readExpGolomb = ()=>{
        if (!bitReadingMode) {
            throw new Error('Not in bit reading mode');
        }
        let zerosCount = 0;
        // Step 1: Count the number of leading zeros
        while(getBits(1) === 0){
            zerosCount++;
        }
        // Step 2: Read the suffix
        let suffix = 0;
        for(let i = 0; i < zerosCount; i++){
            suffix = suffix << 1 | getBits(1);
        }
        // Step 3: Calculate the value
        return (1 << zerosCount) - 1 + suffix;
    };
    const peekB = (length)=>{
        log_1.Log.info('info', [
            ...getSlice(length)
        ].map((b)=>b.toString(16).padStart(2, '0')));
        counter.decrement(length);
    };
    const peekD = (length)=>{
        log_1.Log.info('info', [
            ...getSlice(length)
        ].map((b)=>b.toString(16).padStart(2, '0')));
        counter.decrement(length);
    };
    const leb128 = ()=>{
        let result = 0;
        let shift = 0;
        let byte;
        do {
            byte = getBits(8);
            result |= (byte & 0x7f) << shift;
            shift += 7;
        }while (byte >= 0x80) // Continue if the high bit is set
        return result;
    };
    let bitIndex = 0;
    const stopReadingBits = ()=>{
        bitIndex = 0;
        bitReadingMode = false;
    };
    let byteToShift = 0;
    let bitReadingMode = false;
    const startReadingBits = ()=>{
        bitReadingMode = true;
        byteToShift = getUint8();
    };
    // https://www.rfc-editor.org/rfc/rfc9639.html#name-coded-number
    const getFlacCodecNumber = ()=>{
        let ones = 0;
        let bits = 0;
        // eslint-disable-next-line no-constant-binary-expression
        while((++bits || true) && getBits(1) === 1){
            ones++;
        }
        if (ones === 0) {
            return getBits(7);
        }
        const bitArray = [];
        const firstByteBits = 8 - ones - 1;
        for(let i = 0; i < firstByteBits; i++){
            bitArray.unshift(getBits(1));
        }
        const extraBytes = ones - 1;
        for(let i = 0; i < extraBytes; i++){
            for(let j = 0; j < 8; j++){
                const val = getBits(1);
                if (j < 2) {
                    continue;
                }
                bitArray.unshift(val);
            }
        }
        const encoded = bitArray.reduce((acc, bit, index)=>{
            return acc | bit << index;
        }, 0);
        return encoded;
    };
    const getBits = (bits)=>{
        let result = 0;
        let bitsCollected = 0;
        while(bitsCollected < bits){
            if (bitIndex >= 8) {
                bitIndex = 0;
                byteToShift = getUint8();
            }
            const remainingBitsInByte = 8 - bitIndex;
            const bitsToReadNow = Math.min(bits - bitsCollected, remainingBitsInByte);
            const mask = (1 << bitsToReadNow) - 1;
            const shift = remainingBitsInByte - bitsToReadNow;
            result <<= bitsToReadNow;
            result |= byteToShift >> shift & mask;
            bitsCollected += bitsToReadNow;
            bitIndex += bitsToReadNow;
        }
        return result;
    };
    return {
        startReadingBits,
        stopReadingBits,
        skipTo,
        addData,
        counter,
        peekB,
        peekD,
        getBits,
        bytesRemaining,
        leb128,
        removeBytesRead,
        discard,
        getEightByteNumber,
        getFourByteNumber,
        getSlice,
        getAtom: ()=>{
            const atom = getSlice(4);
            return new TextDecoder().decode(atom);
        },
        detectFileType: ()=>{
            return (0, file_types_1.detectFileType)(getUint8Array());
        },
        getPaddedFourByteNumber,
        getMatroskaSegmentId: ()=>{
            if (bytesRemaining() === 0) {
                return null;
            }
            const first = getSlice(1);
            const firstOneString = `0x${Array.from(new Uint8Array(first)).map((b)=>{
                return b.toString(16).padStart(2, '0');
            }).join('')}`;
            // Catch void block
            // https://www.matroska.org/technical/elements.html
            if (all_segments_1.knownIdsWithOneLength.includes(firstOneString)) {
                return firstOneString;
            }
            if (bytesRemaining() === 0) {
                return null;
            }
            const firstTwo = getSlice(1);
            const firstTwoString = `${firstOneString}${Array.from(new Uint8Array(firstTwo)).map((b)=>{
                return b.toString(16).padStart(2, '0');
            }).join('')}`;
            if (all_segments_1.knownIdsWithTwoLength.includes(firstTwoString)) {
                return firstTwoString;
            }
            if (bytesRemaining() === 0) {
                return null;
            }
            const firstThree = getSlice(1);
            const firstThreeString = `${firstTwoString}${Array.from(new Uint8Array(firstThree)).map((b)=>{
                return b.toString(16).padStart(2, '0');
            }).join('')}`;
            if (all_segments_1.knownIdsWithThreeLength.includes(firstThreeString)) {
                return firstThreeString;
            }
            if (bytesRemaining() === 0) {
                return null;
            }
            const segmentId = getSlice(1);
            return `${firstThreeString}${Array.from(new Uint8Array(segmentId)).map((b)=>{
                return b.toString(16).padStart(2, '0');
            }).join('')}`;
        },
        getVint: ()=>{
            if (bytesRemaining() === 0) {
                return null;
            }
            const firstByte = getUint8();
            const totalLength = firstByte;
            if (totalLength === 0) {
                return 0;
            }
            // Calculate the actual length of the data based on the first set bit
            let actualLength = 0;
            while((totalLength >> 7 - actualLength & 0x01) === 0){
                actualLength++;
            }
            if (bytesRemaining() < actualLength) {
                return null;
            }
            const slice = getSlice(actualLength);
            const d = [
                firstByte,
                ...Array.from(new Uint8Array(slice))
            ];
            actualLength += 1; // Include the first byte set as 1
            // Combine the numbers to form the integer value
            let value = 0;
            // Mask the first byte properly then start combining
            value = totalLength & 0xff >> actualLength;
            for(let i = 1; i < actualLength; i++){
                value = value << 8 | d[i];
            }
            // Livestreamed segments sometimes have a Cluster length of 0xFFFFFFFFFFFFFF
            // which we parse as -1
            // this should be treated as Infinity
            if (value === -1) {
                return Infinity;
            }
            return value;
        },
        getUint8,
        getEBML: ()=>{
            const val = getUint8();
            // https://darkcoding.net/software/reading-mediarecorders-webm-opus-output/#:~:text=The%20first%20four%20bytes%20(%201A,%E2%80%93%20read%20on%20for%20why).
            // You drop the initial 0 bits and the first 1 bit to get the value. 0x81 is 0b10000001, so there are zero inital 0 bits, meaning length one byte, and the value is 1. The 0x9F value for length of the EBML header we saw earlier is 0b10011111, still one byte, value is 0b0011111, which is 31 (the python repl is very helpful for these conversions).
            const actualValue = val & 0x7f; // 0x7F is binary 01111111, which masks out the first bit
            return actualValue;
        },
        getInt8: ()=>{
            const val = getView().getInt8(counter.getDiscardedOffset());
            counter.increment(1);
            return val;
        },
        getUint16: ()=>{
            const val = getView().getUint16(counter.getDiscardedOffset());
            counter.increment(2);
            return val;
        },
        getUint16Le: ()=>{
            const val = getView().getUint16(counter.getDiscardedOffset(), true);
            counter.increment(2);
            return val;
        },
        getUint24: ()=>{
            const val1 = getView().getUint8(counter.getDiscardedOffset());
            const val2 = getView().getUint8(counter.getDiscardedOffset() + 1);
            const val3 = getView().getUint8(counter.getDiscardedOffset() + 2);
            counter.increment(3);
            return val1 << 16 | val2 << 8 | val3;
        },
        getInt24: ()=>{
            const val1 = getView().getInt8(counter.getDiscardedOffset());
            const val2 = getView().getUint8(counter.getDiscardedOffset() + 1);
            const val3 = getView().getUint8(counter.getDiscardedOffset() + 2);
            counter.increment(3);
            return val1 << 16 | val2 << 8 | val3;
        },
        getInt16: ()=>{
            const val = getView().getInt16(counter.getDiscardedOffset());
            counter.increment(2);
            return val;
        },
        getUint32,
        getUint64,
        getInt64,
        // https://developer.apple.com/documentation/quicktime-file-format/sound_sample_description_version_1
        // A 32-bit unsigned fixed-point number (16.16) that indicates the rate at which the sound samples were obtained.
        getFixedPointUnsigned1616Number: ()=>{
            const val = getUint32();
            return val / 2 ** 16;
        },
        getFixedPointSigned1616Number: ()=>{
            const val = getInt32();
            return val / 2 ** 16;
        },
        getFixedPointSigned230Number: ()=>{
            const val = getInt32();
            return val / 2 ** 30;
        },
        getPascalString: ()=>{
            const val = getSlice(32);
            return [
                ...Array.from(new Uint8Array(val))
            ];
        },
        getUint (length) {
            const bytes = getSlice(length);
            const numbers = [
                ...Array.from(new Uint8Array(bytes))
            ];
            return numbers.reduce((acc, byte, index)=>acc + (byte << 8 * (numbers.length - index - 1)), 0);
        },
        getByteString (length, trimTrailingZeroes) {
            let bytes = getSlice(length);
            // This file has trailing zeroes throughout
            // https://github.com/remotion-dev/remotion/issues/4668#issuecomment-2561904068
            // eslint-disable-next-line no-unmodified-loop-condition
            while(trimTrailingZeroes && bytes[bytes.length - 1] === 0){
                bytes = bytes.slice(0, -1);
            }
            return new TextDecoder().decode(bytes).trim();
        },
        planBytes: (size)=>{
            const currentOffset = counter.getOffset();
            return {
                discardRest: ()=>{
                    const toDiscard = size - (counter.getOffset() - currentOffset);
                    if (toDiscard < 0) {
                        throw new Error('read too many bytes');
                    }
                    return getSlice(toDiscard);
                }
            };
        },
        getFloat64: ()=>{
            const val = getView().getFloat64(counter.getDiscardedOffset());
            counter.increment(8);
            return val;
        },
        readUntilNullTerminator,
        getFloat32: ()=>{
            const val = getView().getFloat32(counter.getDiscardedOffset());
            counter.increment(4);
            return val;
        },
        getUint32Le,
        getInt32Le,
        getInt32,
        destroy,
        startBox,
        readExpGolomb,
        startCheckpoint,
        getFlacCodecNumber,
        readUntilLineEnd,
        getSyncSafeInt32,
        replaceData
    };
};
exports.getArrayBufferIterator = getArrayBufferIterator;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/to-date.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.toUnixTimestamp = void 0;
const toUnixTimestamp = (value)=>{
    if (value === 0) {
        return null;
    }
    const baseDate = new Date('1904-01-01T00:00:00Z');
    return Math.floor(value + baseDate.getTime() / 1000) * 1000;
};
exports.toUnixTimestamp = toUnixTimestamp;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/moov/mvhd.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMvhd = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const to_date_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/to-date.js [app-route] (ecmascript)");
const parseMvhd = ({ iterator, offset, size })=>{
    const version = iterator.getUint8();
    // Flags, we discard them
    iterator.discard(3);
    const creationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
    const modificationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
    const timeScale = iterator.getUint32();
    const durationInUnits = version === 1 ? iterator.getUint64() : iterator.getUint32();
    const durationInSeconds = Number(durationInUnits) / timeScale;
    const rateArray = iterator.getSlice(4);
    const rateView = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: rateArray,
        maxBytes: rateArray.length,
        logLevel: 'error'
    });
    const rate = rateView.getInt8() * 10 + rateView.getInt8() + rateView.getInt8() * 0.1 + rateView.getInt8() * 0.01;
    const volumeArray = iterator.getSlice(2);
    const volumeView = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: volumeArray,
        maxBytes: volumeArray.length,
        logLevel: 'error'
    });
    const volume = volumeView.getInt8() + volumeView.getInt8() * 0.1;
    // reserved 16bit
    iterator.discard(2);
    // reserved 32bit x2
    iterator.discard(4);
    iterator.discard(4);
    // matrix
    const matrix = [
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned230Number(),
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned230Number(),
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned230Number()
    ];
    // pre-defined
    iterator.discard(4 * 6);
    // next track id
    const nextTrackId = iterator.getUint32();
    volumeView.destroy();
    const bytesRemaining = size - (iterator.counter.getOffset() - offset);
    if (bytesRemaining !== 0) {
        throw new Error('expected 0 bytes ' + bytesRemaining);
    }
    return {
        creationTime: (0, to_date_1.toUnixTimestamp)(Number(creationTime)),
        modificationTime: (0, to_date_1.toUnixTimestamp)(Number(modificationTime)),
        timeScale,
        durationInUnits: Number(durationInUnits),
        durationInSeconds,
        rate,
        volume,
        matrix: matrix,
        nextTrackId,
        type: 'mvhd-box',
        boxSize: size,
        offset
    };
};
exports.parseMvhd = parseMvhd;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/avc/codec-string.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getCodecStringFromSpsAndPps = void 0;
const getCodecStringFromSpsAndPps = (sps)=>{
    return `avc1.${sps.spsData.profile.toString(16).padStart(2, '0')}${sps.spsData.compatibility.toString(16).padStart(2, '0')}${sps.spsData.level.toString(16).padStart(2, '0')}`;
};
exports.getCodecStringFromSpsAndPps = getCodecStringFromSpsAndPps;
}),
"[project]/node_modules/@remotion/media-parser/dist/combine-uint8-arrays.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.combineUint8Arrays = void 0;
const combineUint8Arrays = (arrays)=>{
    if (arrays.length === 0) {
        return new Uint8Array([]);
    }
    if (arrays.length === 1) {
        return arrays[0];
    }
    let totalLength = 0;
    for (const array of arrays){
        totalLength += array.length;
    }
    const result = new Uint8Array(totalLength);
    let offset = 0;
    for (const array of arrays){
        result.set(array, offset);
        offset += array.length;
    }
    return result;
};
exports.combineUint8Arrays = combineUint8Arrays;
}),
"[project]/node_modules/@remotion/media-parser/dist/truthy.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.truthy = truthy;
function truthy(value) {
    return Boolean(value);
}
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/avc/create-sps-pps-data.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.createSpsPpsData = void 0;
const combine_uint8_arrays_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/combine-uint8-arrays.js [app-route] (ecmascript)");
const truthy_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/truthy.js [app-route] (ecmascript)");
function serializeUint16(value) {
    const buffer = new ArrayBuffer(2);
    const view = new DataView(buffer);
    view.setUint16(0, value);
    return new Uint8Array(buffer);
}
const createSpsPpsData = (avc1Profile)=>{
    return (0, combine_uint8_arrays_1.combineUint8Arrays)([
        new Uint8Array([
            // https://gist.github.com/uupaa/8493378ec15f644a3d2b
            1,
            avc1Profile.sps.spsData.profile,
            avc1Profile.sps.spsData.compatibility,
            avc1Profile.sps.spsData.level,
            0xff,
            0xe1
        ]),
        // sequence parameter set length
        serializeUint16(avc1Profile.sps.sps.length),
        // sequence parameter set
        avc1Profile.sps.sps,
        // num of PPS
        new Uint8Array([
            0x01
        ]),
        // picture parameter set length
        serializeUint16(avc1Profile.pps.pps.length),
        // PPS
        avc1Profile.pps.pps,
        // if AVCProfileIndication != 66 && AVCProfileIndication != 77 && AVCProfileIndication != 88
        [
            66,
            77,
            88
        ].some((b)=>avc1Profile.sps.spsData.profile === b) ? null : /**
             *  reserved	63 (0x3F)
                    chroma_format	1, '4:2:0'
                    reserved	31 (0x1F)
                    bit_depth_luma_minus8	0
                    reserved	31 (0x1F)
                    bit_depth_chroma_minus8	0
                    numOfSequenceParameterSetExt	0
             */ new Uint8Array([
            0xfd,
            0xf8,
            0xf8,
            0
        ])
    ].filter(truthy_1.truthy));
};
exports.createSpsPpsData = createSpsPpsData;
}),
"[project]/node_modules/@remotion/media-parser/dist/add-avc-profile-to-track.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.addAvcProfileToTrack = void 0;
const codec_string_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/codec-string.js [app-route] (ecmascript)");
const create_sps_pps_data_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/create-sps-pps-data.js [app-route] (ecmascript)");
const addAvcProfileToTrack = (track, avc1Profile)=>{
    if (avc1Profile === null) {
        return track;
    }
    return {
        ...track,
        codec: (0, codec_string_1.getCodecStringFromSpsAndPps)(avc1Profile.sps),
        codecData: {
            type: 'avc-sps-pps',
            data: (0, create_sps_pps_data_1.createSpsPpsData)(avc1Profile)
        },
        // description should be undefined, since this signals to WebCodecs that
        // the codec is in Annex B format, which is the case for AVI files
        // https://www.w3.org/TR/webcodecs-avc-codec-registration/#videodecoderconfig-description
        // ChatGPT 4.1: "Great question! The format of the H.264/AVC bitstream inside a â .avi file is almost always in the "Annex B" format"
        // (description is probably already undefined at this point, just writing this to be explicit)
        description: undefined
    };
};
exports.addAvcProfileToTrack = addAvcProfileToTrack;
}),
"[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.registerVideoTrackWhenProfileIsAvailable = exports.registerAudioTrack = exports.registerVideoTrack = void 0;
const add_avc_profile_to_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/add-avc-profile-to-track.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const registerVideoTrack = async ({ track, container, logLevel, onVideoTrack, registerVideoSampleCallback, tracks })=>{
    if (tracks.getTracks().find((t)=>t.trackId === track.trackId)) {
        log_1.Log.trace(logLevel, `Track ${track.trackId} already registered, skipping`);
        return null;
    }
    if (track.type !== 'video') {
        throw new Error('Expected video track');
    }
    tracks.addTrack(track);
    if (!onVideoTrack) {
        return null;
    }
    const callback = await onVideoTrack({
        track,
        container
    });
    await registerVideoSampleCallback(track.trackId, callback !== null && callback !== void 0 ? callback : null);
    return callback;
};
exports.registerVideoTrack = registerVideoTrack;
const registerAudioTrack = async ({ track, container, tracks, logLevel, onAudioTrack, registerAudioSampleCallback })=>{
    if (tracks.getTracks().find((t)=>t.trackId === track.trackId)) {
        log_1.Log.trace(logLevel, `Track ${track.trackId} already registered, skipping`);
        return null;
    }
    if (track.type !== 'audio') {
        throw new Error('Expected audio track');
    }
    tracks.addTrack(track);
    if (!onAudioTrack) {
        return null;
    }
    const callback = await onAudioTrack({
        track,
        container
    });
    await registerAudioSampleCallback(track.trackId, callback !== null && callback !== void 0 ? callback : null);
    return callback;
};
exports.registerAudioTrack = registerAudioTrack;
const registerVideoTrackWhenProfileIsAvailable = ({ state, track, container })=>{
    state.riff.registerOnAvcProfileCallback(async (profile)=>{
        await (0, exports.registerVideoTrack)({
            track: (0, add_avc_profile_to_track_1.addAvcProfileToTrack)(track, profile),
            container,
            logLevel: state.logLevel,
            onVideoTrack: state.onVideoTrack,
            registerVideoSampleCallback: state.callbacks.registerVideoSampleCallback,
            tracks: state.callbacks.tracks
        });
    });
};
exports.registerVideoTrackWhenProfileIsAvailable = registerVideoTrackWhenProfileIsAvailable;
}),
"[project]/node_modules/@remotion/media-parser/dist/skip.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makeFetchMoreData = exports.makeSkip = void 0;
const makeSkip = (skipTo)=>({
        action: 'skip',
        skipTo
    });
exports.makeSkip = makeSkip;
const makeFetchMoreData = (bytesNeeded)=>({
        action: 'fetch-more-data',
        bytesNeeded
    });
exports.makeFetchMoreData = makeFetchMoreData;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/elst.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseElst = void 0;
const parseElst = ({ iterator, size, offset })=>{
    const { discardRest } = iterator.startBox(size - 8);
    const version = iterator.getUint8();
    const flags = iterator.getUint24();
    const entryCount = iterator.getUint32();
    const entries = [];
    for(let i = 0; i < entryCount; i++){
        const editDuration = Number(version === 1 ? iterator.getUint64() : iterator.getUint32());
        const mediaTime = Number(version === 1 ? iterator.getUint64() : iterator.getInt32());
        const mediaRateInteger = iterator.getUint16();
        const mediaRateFraction = iterator.getUint16();
        entries.push({
            editDuration,
            mediaTime,
            mediaRateInteger,
            mediaRateFraction
        });
    }
    discardRest();
    const result = {
        type: 'elst-box',
        version,
        flags,
        entries,
        boxSize: size,
        offset
    };
    return result;
};
exports.parseElst = parseElst;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/esds/decoder-specific-config.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseDecoderSpecificConfig = void 0;
const parseDecoderSpecificConfig = (iterator)=>{
    const layerTag = iterator.getUint8();
    const layerSize = iterator.getPaddedFourByteNumber();
    const start = iterator.counter.getOffset();
    if (layerTag !== 5) {
        iterator.discard(layerSize);
        return {
            type: 'unknown-decoder-specific-config'
        };
    }
    // https://csclub.uwaterloo.ca/~pbarfuss/ISO14496-3-2009.pdf
    // 1.6.2.1 AudioSpecificConfig
    const bytes = iterator.getSlice(layerSize);
    iterator.counter.decrement(layerSize);
    iterator.startReadingBits();
    const audioObjectType = iterator.getBits(5);
    const samplingFrequencyIndex = iterator.getBits(4);
    if (samplingFrequencyIndex === 0xf) {
        iterator.getBits(24);
    }
    const channelConfiguration = iterator.getBits(4);
    iterator.stopReadingBits();
    const read = iterator.counter.getOffset() - start;
    if (read < layerSize) {
        iterator.discard(layerSize - read);
    }
    return {
        type: 'mp4a-specific-config',
        audioObjectType,
        samplingFrequencyIndex,
        channelConfiguration,
        asBytes: bytes
    };
};
exports.parseDecoderSpecificConfig = parseDecoderSpecificConfig;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/esds/esds-descriptors.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseDescriptors = exports.processDescriptor = void 0;
const decoder_specific_config_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/esds/decoder-specific-config.js [app-route] (ecmascript)");
const mapToObjectAudioIndicator = (num)=>{
    // https://chromium.googlesource.com/chromium/src/media/+/master/formats/mp4/es_descriptor.h
    // http://netmedia.zju.edu.cn/multimedia2013/mpeg-4/ISO%20IEC%2014496-1%20MPEG-4%20System%20Standard.pdf
    // Page 42, table 8
    if (num === 0x40) {
        return 'aac';
    }
    if (num === 0x6b) {
        return 'mp3';
    }
    return 'unknown';
};
const processDescriptor = ({ iterator })=>{
    const tag = iterator.getUint8();
    if (tag === 4) {
        const size = iterator.getPaddedFourByteNumber();
        const initialOffset = iterator.counter.getOffset();
        const objectTypeIndication = iterator.getUint8();
        iterator.startReadingBits();
        const streamType = iterator.getBits(6);
        const upStream = iterator.getBits(1);
        // reserved
        iterator.getBits(1);
        const bufferSizeDB = iterator.getBits(24);
        iterator.stopReadingBits();
        const maxBitrate = iterator.getUint32();
        const avgBitrate = iterator.getUint32();
        const decoderSpecificConfigs = [];
        while(size - (iterator.counter.getOffset() - initialOffset) > 0){
            const decoderSpecificConfig = (0, decoder_specific_config_1.parseDecoderSpecificConfig)(iterator);
            decoderSpecificConfigs.push(decoderSpecificConfig);
        }
        return {
            descriptor: {
                type: 'decoder-config-descriptor',
                objectTypeIndication: mapToObjectAudioIndicator(objectTypeIndication),
                asNumber: objectTypeIndication,
                bufferSizeDB,
                streamType,
                upStream,
                avgBitrate,
                maxBitrate,
                decoderSpecificConfigs
            }
        };
    }
    if (tag === 6) {
        const size = iterator.getPaddedFourByteNumber();
        iterator.discard(size);
        return {
            descriptor: {
                type: 'sl-config-descriptor'
            }
        };
    }
    return {
        descriptor: null
    };
};
exports.processDescriptor = processDescriptor;
const parseDescriptors = (iterator, maxBytes)=>{
    const descriptors = [];
    const initialOffset = iterator.counter.getOffset();
    while(iterator.bytesRemaining() > 0 && iterator.counter.getOffset() - initialOffset < maxBytes){
        const { descriptor } = (0, exports.processDescriptor)({
            iterator
        });
        if (descriptor) {
            descriptors.push(descriptor);
        } else {
            break;
        }
    }
    return descriptors;
};
exports.parseDescriptors = parseDescriptors;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/esds/esds.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseEsds = void 0;
const esds_descriptors_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/esds/esds-descriptors.js [app-route] (ecmascript)");
const parseEsds = ({ data, size, fileOffset })=>{
    const version = data.getUint8();
    // Flags, we discard them
    data.discard(3);
    const tag = data.getUint8();
    const sizeOfInstance = data.getPaddedFourByteNumber();
    const esId = data.getUint16();
    // disard 1 byte, currently unknown
    data.discard(1);
    const remaining = size - (data.counter.getOffset() - fileOffset);
    const descriptors = (0, esds_descriptors_1.parseDescriptors)(data, remaining);
    const remainingNow = size - (data.counter.getOffset() - fileOffset);
    data.discard(remainingNow);
    return {
        type: 'esds-box',
        version,
        tag,
        sizeOfInstance,
        esId,
        descriptors
    };
};
exports.parseEsds = parseEsds;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/precomputed-moof.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.deduplicateMoofBoxesByOffset = exports.toMoofBox = exports.precomputedMoofState = void 0;
// Note: May be duplicated!
const precomputedMoofState = ()=>{
    let moofBoxes = [];
    return {
        getMoofBoxes: ()=>moofBoxes,
        setMoofBoxes: (boxes)=>{
            moofBoxes = boxes;
        }
    };
};
exports.precomputedMoofState = precomputedMoofState;
const toMoofBox = (box)=>{
    if (box.type !== 'regular-box') {
        throw new Error('expected regular bpx');
    }
    return {
        offset: box.offset,
        trafBoxes: box.children.filter((c)=>c.type === 'regular-box' && c.boxType === 'traf'),
        size: box.boxSize
    };
};
exports.toMoofBox = toMoofBox;
const deduplicateMoofBoxesByOffset = (moofBoxes)=>{
    return moofBoxes.filter((m, i, arr)=>i === arr.findIndex((t)=>t.offset === m.offset));
};
exports.deduplicateMoofBoxesByOffset = deduplicateMoofBoxesByOffset;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getElstBox = exports.getTrakBoxByTrackId = exports.getTfraBoxes = exports.getTfraBoxesFromMfraBoxChildren = exports.getTrexBoxes = exports.getMvexBox = exports.getTrunBoxes = exports.getTfhdBox = exports.getTfdtBox = exports.getStssBox = exports.getStscBox = exports.getStszBox = exports.getCttsBox = exports.getSttsBox = exports.getStcoBox = exports.getVideoDescriptors = exports.getStsdBox = exports.getStblBox = exports.getMdhdBox = exports.getMdiaBox = exports.getTkhdBox = exports.getTraks = exports.getMvhdBox = exports.getMoofBoxes = exports.getMoovBoxFromState = exports.getMoovFromFromIsoStructure = exports.getFtypBox = void 0;
const precomputed_moof_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/precomputed-moof.js [app-route] (ecmascript)");
const getFtypBox = (segments)=>{
    const ftypBox = segments.find((s)=>s.type === 'ftyp-box');
    if (!ftypBox || ftypBox.type !== 'ftyp-box') {
        return null;
    }
    return ftypBox;
};
exports.getFtypBox = getFtypBox;
const getMoovFromFromIsoStructure = (structure)=>{
    const moovBox = structure.boxes.find((s)=>s.type === 'moov-box');
    if (!moovBox || moovBox.type !== 'moov-box') {
        return null;
    }
    return moovBox;
};
exports.getMoovFromFromIsoStructure = getMoovFromFromIsoStructure;
const getMoovBoxFromState = ({ structureState, isoState, mp4HeaderSegment, mayUsePrecomputed })=>{
    const got = isoState.moov.getMoovBoxAndPrecomputed();
    if (got && (mayUsePrecomputed || !got.precomputed)) {
        return got.moovBox;
    }
    if (mp4HeaderSegment) {
        return (0, exports.getMoovFromFromIsoStructure)(mp4HeaderSegment);
    }
    const structure = structureState.getIsoStructure();
    return (0, exports.getMoovFromFromIsoStructure)(structure);
};
exports.getMoovBoxFromState = getMoovBoxFromState;
const getMoofBoxes = (main)=>{
    const moofBoxes = main.filter((s)=>s.type === 'regular-box' && s.boxType === 'moof');
    return moofBoxes.map((m)=>(0, precomputed_moof_1.toMoofBox)(m));
};
exports.getMoofBoxes = getMoofBoxes;
const getMvhdBox = (moovBox)=>{
    const mvHdBox = moovBox.children.find((s)=>s.type === 'mvhd-box');
    if (!mvHdBox || mvHdBox.type !== 'mvhd-box') {
        return null;
    }
    return mvHdBox;
};
exports.getMvhdBox = getMvhdBox;
const getTraks = (moovBox)=>{
    return moovBox.children.filter((s)=>s.type === 'trak-box');
};
exports.getTraks = getTraks;
const getTkhdBox = (trakBox)=>{
    const tkhdBox = trakBox.children.find((s)=>s.type === 'tkhd-box');
    return tkhdBox;
};
exports.getTkhdBox = getTkhdBox;
const getMdiaBox = (trakBox)=>{
    const mdiaBox = trakBox.children.find((s)=>s.type === 'regular-box' && s.boxType === 'mdia');
    if (!mdiaBox || mdiaBox.type !== 'regular-box') {
        return null;
    }
    return mdiaBox;
};
exports.getMdiaBox = getMdiaBox;
const getMdhdBox = (trakBox)=>{
    const mdiaBox = (0, exports.getMdiaBox)(trakBox);
    if (!mdiaBox) {
        return null;
    }
    const mdhdBox = mdiaBox.children.find((c)=>c.type === 'mdhd-box');
    return mdhdBox;
};
exports.getMdhdBox = getMdhdBox;
const getStblBox = (trakBox)=>{
    const mdiaBox = (0, exports.getMdiaBox)(trakBox);
    if (!mdiaBox) {
        return null;
    }
    const minfBox = mdiaBox.children.find((s)=>s.type === 'regular-box' && s.boxType === 'minf');
    if (!minfBox || minfBox.type !== 'regular-box') {
        return null;
    }
    const stblBox = minfBox.children.find((s)=>s.type === 'regular-box' && s.boxType === 'stbl');
    if (!stblBox || stblBox.type !== 'regular-box') {
        return null;
    }
    return stblBox;
};
exports.getStblBox = getStblBox;
const getStsdBox = (trakBox)=>{
    const stblBox = (0, exports.getStblBox)(trakBox);
    if (!stblBox || stblBox.type !== 'regular-box') {
        return null;
    }
    const stsdBox = stblBox.children.find((s)=>s.type === 'stsd-box');
    return stsdBox;
};
exports.getStsdBox = getStsdBox;
const getVideoDescriptors = (trakBox)=>{
    var _a;
    const stsdBox = (0, exports.getStsdBox)(trakBox);
    if (!stsdBox) {
        return null;
    }
    const descriptors = stsdBox.samples.map((s)=>{
        return s.type === 'video' ? s.descriptors.map((d)=>{
            return d.type === 'avcc-box' ? d.privateData : d.type === 'hvcc-box' ? d.privateData : null;
        }) : [];
    });
    return (_a = descriptors.flat(1).filter(Boolean)[0]) !== null && _a !== void 0 ? _a : null;
};
exports.getVideoDescriptors = getVideoDescriptors;
const getStcoBox = (trakBox)=>{
    const stblBox = (0, exports.getStblBox)(trakBox);
    if (!stblBox || stblBox.type !== 'regular-box') {
        return null;
    }
    const stcoBox = stblBox.children.find((s)=>s.type === 'stco-box');
    return stcoBox;
};
exports.getStcoBox = getStcoBox;
const getSttsBox = (trakBox)=>{
    const stblBox = (0, exports.getStblBox)(trakBox);
    if (!stblBox || stblBox.type !== 'regular-box') {
        return null;
    }
    const sttsBox = stblBox.children.find((s)=>s.type === 'stts-box');
    return sttsBox;
};
exports.getSttsBox = getSttsBox;
const getCttsBox = (trakBox)=>{
    const stblBox = (0, exports.getStblBox)(trakBox);
    if (!stblBox || stblBox.type !== 'regular-box') {
        return null;
    }
    const cttsBox = stblBox.children.find((s)=>s.type === 'ctts-box');
    return cttsBox;
};
exports.getCttsBox = getCttsBox;
const getStszBox = (trakBox)=>{
    const stblBox = (0, exports.getStblBox)(trakBox);
    if (!stblBox || stblBox.type !== 'regular-box') {
        return null;
    }
    const stszBox = stblBox.children.find((s)=>s.type === 'stsz-box');
    return stszBox;
};
exports.getStszBox = getStszBox;
const getStscBox = (trakBox)=>{
    const stblBox = (0, exports.getStblBox)(trakBox);
    if (!stblBox || stblBox.type !== 'regular-box') {
        return null;
    }
    const stcoBox = stblBox.children.find((b)=>b.type === 'stsc-box');
    return stcoBox;
};
exports.getStscBox = getStscBox;
const getStssBox = (trakBox)=>{
    const stblBox = (0, exports.getStblBox)(trakBox);
    if (!stblBox || stblBox.type !== 'regular-box') {
        return null;
    }
    const stssBox = stblBox.children.find((b)=>b.type === 'stss-box');
    return stssBox;
};
exports.getStssBox = getStssBox;
const getTfdtBox = (segment)=>{
    if (segment.type !== 'regular-box' || segment.boxType !== 'traf') {
        throw new Error('Expected traf-box');
    }
    const tfhdBox = segment.children.find((c)=>c.type === 'tfdt-box');
    if (!tfhdBox || tfhdBox.type !== 'tfdt-box') {
        throw new Error('Expected tfhd-box');
    }
    return tfhdBox;
};
exports.getTfdtBox = getTfdtBox;
const getTfhdBox = (segment)=>{
    if (segment.type !== 'regular-box' || segment.boxType !== 'traf') {
        throw new Error('Expected traf-box');
    }
    const tfhdBox = segment.children.find((c)=>c.type === 'tfhd-box');
    if (!tfhdBox || tfhdBox.type !== 'tfhd-box') {
        throw new Error('Expected tfhd-box');
    }
    return tfhdBox;
};
exports.getTfhdBox = getTfhdBox;
const getTrunBoxes = (segment)=>{
    if (segment.type !== 'regular-box' || segment.boxType !== 'traf') {
        throw new Error('Expected traf-box');
    }
    const trunBoxes = segment.children.filter((c)=>c.type === 'trun-box');
    return trunBoxes;
};
exports.getTrunBoxes = getTrunBoxes;
const getMvexBox = (moovAtom)=>{
    const mvexBox = moovAtom.children.find((s)=>s.type === 'regular-box' && s.boxType === 'mvex');
    if (!mvexBox || mvexBox.type !== 'regular-box') {
        return null;
    }
    return mvexBox;
};
exports.getMvexBox = getMvexBox;
const getTrexBoxes = (moovAtom)=>{
    const mvexBox = (0, exports.getMvexBox)(moovAtom);
    if (!mvexBox) {
        return [];
    }
    const trexBoxes = mvexBox.children.filter((c)=>c.type === 'trex-box');
    return trexBoxes;
};
exports.getTrexBoxes = getTrexBoxes;
const getTfraBoxesFromMfraBoxChildren = (mfraBoxChildren)=>{
    const tfraBoxes = mfraBoxChildren.filter((b)=>b.type === 'tfra-box');
    return tfraBoxes;
};
exports.getTfraBoxesFromMfraBoxChildren = getTfraBoxesFromMfraBoxChildren;
const getTfraBoxes = (structure)=>{
    const mfraBox = structure.find((b)=>b.type === 'regular-box' && b.boxType === 'mfra');
    if (!mfraBox) {
        return [];
    }
    return (0, exports.getTfraBoxesFromMfraBoxChildren)(mfraBox.children);
};
exports.getTfraBoxes = getTfraBoxes;
const getTrakBoxByTrackId = (moovBox, trackId)=>{
    var _a;
    const trakBoxes = (0, exports.getTraks)(moovBox);
    return (_a = trakBoxes.find((t)=>{
        const tkhd = (0, exports.getTkhdBox)(t);
        if (!tkhd) {
            return false;
        }
        return tkhd.trackId === trackId;
    })) !== null && _a !== void 0 ? _a : null;
};
exports.getTrakBoxByTrackId = getTrakBoxByTrackId;
const getElstBox = (trakBox)=>{
    const edtsBox = trakBox.children.find((s)=>s.type === 'regular-box' && s.boxType === 'edts');
    if (!edtsBox || edtsBox.type !== 'regular-box') {
        return null;
    }
    const elstBox = edtsBox.children.find((s)=>s.type === 'elst-box');
    return elstBox;
};
exports.getElstBox = getElstBox;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mdat/get-editlist.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.findTrackMediaTimeOffsetInTrackTimescale = exports.findTrackStartTimeInSeconds = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const findTrackStartTimeInSeconds = ({ movieTimeScale, trakBox })=>{
    const elstBox = (0, traversal_1.getElstBox)(trakBox);
    if (!elstBox) {
        return 0;
    }
    const { entries } = elstBox;
    let dwellTime = 0;
    for (const entry of entries){
        const { editDuration, mediaTime } = entry;
        if (mediaTime !== -1) {
            continue;
        }
        dwellTime += editDuration;
    }
    return dwellTime / movieTimeScale;
};
exports.findTrackStartTimeInSeconds = findTrackStartTimeInSeconds;
const findTrackMediaTimeOffsetInTrackTimescale = ({ trakBox })=>{
    const elstBox = (0, traversal_1.getElstBox)(trakBox);
    if (!elstBox) {
        return 0;
    }
    const { entries } = elstBox;
    let dwellTime = 0;
    for (const entry of entries){
        const { mediaTime } = entry;
        if (mediaTime === -1) {
            continue;
        }
        dwellTime += mediaTime;
    }
    return dwellTime;
};
exports.findTrackMediaTimeOffsetInTrackTimescale = findTrackMediaTimeOffsetInTrackTimescale;
}),
"[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.WEBCODECS_TIMESCALE = void 0;
exports.WEBCODECS_TIMESCALE = 1000000;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/timescale.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.MEDIA_PARSER_RIFF_TIMESCALE = void 0;
exports.MEDIA_PARSER_RIFF_TIMESCALE = 1000000;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/traversal.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getStrhBox = exports.getStrlBoxes = exports.getAvihBox = exports.getHdlrBox = exports.isRiffAvi = void 0;
const isRiffAvi = (structure)=>{
    return structure.boxes.some((box)=>box.type === 'riff-header' && box.fileType === 'AVI');
};
exports.isRiffAvi = isRiffAvi;
const getHdlrBox = (structure)=>{
    return structure.boxes.find((box)=>box.type === 'list-box' && box.listType === 'hdrl');
};
exports.getHdlrBox = getHdlrBox;
const getAvihBox = (structure)=>{
    const hdlrBox = (0, exports.getHdlrBox)(structure);
    if (!hdlrBox) {
        return null;
    }
    return hdlrBox.children.find((box)=>box.type === 'avih-box');
};
exports.getAvihBox = getAvihBox;
const getStrlBoxes = (structure)=>{
    const hdlrBox = (0, exports.getHdlrBox)(structure);
    if (!hdlrBox) {
        return [];
    }
    return hdlrBox.children.filter((box)=>box.type === 'list-box' && box.listType === 'strl');
};
exports.getStrlBoxes = getStrlBoxes;
const getStrhBox = (strlBoxChildren)=>{
    return strlBoxChildren.find((box)=>box.type === 'strh-box');
};
exports.getStrhBox = getStrhBox;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/get-tracks-from-avi.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasAllTracksFromAvi = exports.getTracksFromAvi = exports.makeAviVideoTrack = exports.makeAviAudioTrack = exports.getNumberOfTracks = exports.TO_BE_OVERRIDDEN_LATER = void 0;
const add_avc_profile_to_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/add-avc-profile-to-track.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/timescale.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/traversal.js [app-route] (ecmascript)");
exports.TO_BE_OVERRIDDEN_LATER = 'to-be-overriden-later';
const getNumberOfTracks = (structure)=>{
    const avihBox = (0, traversal_1.getAvihBox)(structure);
    if (avihBox) {
        return avihBox.streams;
    }
    throw new Error('No avih box found');
};
exports.getNumberOfTracks = getNumberOfTracks;
const makeAviAudioTrack = ({ strf, index })=>{
    // 255 = AAC
    if (strf.formatTag !== 255) {
        throw new Error(`Unsupported audio format ${strf.formatTag}`);
    }
    return {
        type: 'audio',
        codec: 'mp4a.40.2',
        codecData: {
            type: 'aac-config',
            data: new Uint8Array([
                18,
                16
            ])
        },
        codecEnum: 'aac',
        description: new Uint8Array([
            18,
            16
        ]),
        numberOfChannels: strf.numberOfChannels,
        sampleRate: strf.sampleRate,
        originalTimescale: timescale_1.MEDIA_PARSER_RIFF_TIMESCALE,
        trackId: index,
        startInSeconds: 0,
        timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
        trackMediaTimeOffsetInTrackTimescale: 0
    };
};
exports.makeAviAudioTrack = makeAviAudioTrack;
const makeAviVideoTrack = ({ strh, strf, index })=>{
    if (strh.handler !== 'H264') {
        throw new Error(`Unsupported video codec ${strh.handler}`);
    }
    return {
        codecData: null,
        codec: exports.TO_BE_OVERRIDDEN_LATER,
        codecEnum: 'h264',
        codedHeight: strf.height,
        codedWidth: strf.width,
        width: strf.width,
        height: strf.height,
        type: 'video',
        displayAspectHeight: strf.height,
        originalTimescale: timescale_1.MEDIA_PARSER_RIFF_TIMESCALE,
        description: undefined,
        m3uStreamFormat: null,
        trackId: index,
        colorSpace: {
            fullRange: null,
            matrix: null,
            primaries: null,
            transfer: null
        },
        advancedColor: {
            fullRange: null,
            matrix: null,
            primaries: null,
            transfer: null
        },
        displayAspectWidth: strf.width,
        rotation: 0,
        sampleAspectRatio: {
            numerator: 1,
            denominator: 1
        },
        fps: strh.rate / strh.scale,
        startInSeconds: 0,
        timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
        trackMediaTimeOffsetInTrackTimescale: 0
    };
};
exports.makeAviVideoTrack = makeAviVideoTrack;
const getTracksFromAvi = (structure, state)=>{
    const tracks = [];
    const boxes = (0, traversal_1.getStrlBoxes)(structure);
    let i = 0;
    for (const box of boxes){
        const strh = (0, traversal_1.getStrhBox)(box.children);
        if (!strh) {
            continue;
        }
        const { strf } = strh;
        if (strf.type === 'strf-box-video') {
            tracks.push((0, add_avc_profile_to_track_1.addAvcProfileToTrack)((0, exports.makeAviVideoTrack)({
                strh,
                strf,
                index: i
            }), state.riff.getAvcProfile()));
        } else if (strh.fccType === 'auds') {
            tracks.push((0, exports.makeAviAudioTrack)({
                strf,
                index: i
            }));
        } else {
            throw new Error(`Unsupported track type ${strh.fccType}`);
        }
        i++;
    }
    return tracks;
};
exports.getTracksFromAvi = getTracksFromAvi;
const hasAllTracksFromAvi = (state)=>{
    try {
        const structure = state.structure.getRiffStructure();
        const numberOfTracks = (0, exports.getNumberOfTracks)(structure);
        const tracks = (0, exports.getTracksFromAvi)(structure, state);
        return tracks.length === numberOfTracks && !tracks.find((t)=>t.type === 'video' && t.codec === exports.TO_BE_OVERRIDDEN_LATER);
    } catch (_a) {
        return false;
    }
};
exports.hasAllTracksFromAvi = hasAllTracksFromAvi;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/traversal.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getStreamForId = exports.getProgramForId = exports.findProgramMapTableOrThrow = exports.findProgramMapOrNull = void 0;
const findProgramAssociationTableOrThrow = (structure)=>{
    const box = structure.boxes.find((b)=>b.type === 'transport-stream-pat-box');
    if (!box) {
        throw new Error('No PAT box found');
    }
    return box;
};
const findProgramMapOrNull = (structure)=>{
    const box = structure.boxes.find((b)=>b.type === 'transport-stream-pmt-box');
    if (!box) {
        return null;
    }
    return box;
};
exports.findProgramMapOrNull = findProgramMapOrNull;
const findProgramMapTableOrThrow = (structure)=>{
    const box = (0, exports.findProgramMapOrNull)(structure);
    if (!box) {
        throw new Error('No PMT box found');
    }
    return box;
};
exports.findProgramMapTableOrThrow = findProgramMapTableOrThrow;
const getProgramForId = (structure, packetIdentifier)=>{
    const box = findProgramAssociationTableOrThrow(structure);
    const entry = box.pat.find((e)=>e.programMapIdentifier === packetIdentifier);
    return entry !== null && entry !== void 0 ? entry : null;
};
exports.getProgramForId = getProgramForId;
const getStreamForId = (structure, packetIdentifier)=>{
    const box = (0, exports.findProgramMapTableOrThrow)(structure);
    const entry = box.streams.find((e)=>e.pid === packetIdentifier);
    return entry !== null && entry !== void 0 ? entry : null;
};
exports.getStreamForId = getStreamForId;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/get-tracks.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasAllTracksFromTransportStream = exports.getTracksFromTransportStream = exports.filterStreamsBySupportedTypes = void 0;
const truthy_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/truthy.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/traversal.js [app-route] (ecmascript)");
const filterStreamsBySupportedTypes = (streams)=>{
    return streams.filter((stream)=>stream.streamType === 27 || stream.streamType === 15);
};
exports.filterStreamsBySupportedTypes = filterStreamsBySupportedTypes;
const getTracksFromTransportStream = (parserState)=>{
    const structure = parserState.structure.getTsStructure();
    const programMapTable = (0, traversal_1.findProgramMapTableOrThrow)(structure);
    const parserTracks = parserState.callbacks.tracks.getTracks();
    const mapped = (0, exports.filterStreamsBySupportedTypes)(programMapTable.streams).map((stream)=>{
        return parserTracks.find((track)=>track.trackId === stream.pid);
    }).filter(truthy_1.truthy);
    if (mapped.length !== (0, exports.filterStreamsBySupportedTypes)(programMapTable.streams).length) {
        throw new Error('Not all tracks found');
    }
    return mapped;
};
exports.getTracksFromTransportStream = getTracksFromTransportStream;
const hasAllTracksFromTransportStream = (parserState)=>{
    try {
        (0, exports.getTracksFromTransportStream)(parserState);
        return true;
    } catch (_a) {
        return false;
    }
};
exports.hasAllTracksFromTransportStream = hasAllTracksFromTransportStream;
}),
"[project]/node_modules/@remotion/media-parser/dist/make-hvc1-codec-strings.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getHvc1CodecString = void 0;
const getHvc1CodecString = (data)=>{
    const configurationVersion = data.getUint8();
    if (configurationVersion !== 1) {
        throw new Error(`Unsupported HVCC version ${configurationVersion}`);
    }
    const generalProfileSpaceTierFlagAndIdc = data.getUint8();
    let generalProfileCompatibility = data.getUint32();
    //  unsigned int(2) general_profile_space;
    // 	unsigned int(1) general_tier_flag;
    //	unsigned int(5) general_profile_idc;
    const generalProfileSpace = generalProfileSpaceTierFlagAndIdc >> 6;
    const generalTierFlag = (generalProfileSpaceTierFlagAndIdc & 0x20) >> 5;
    const generalProfileIdc = generalProfileSpaceTierFlagAndIdc & 0x1f;
    // general_constraint_indicator_flags(48)
    const generalConstraintIndicator = data.getSlice(6);
    const generalLevelIdc = data.getUint8();
    let profileId = 0;
    for(let i = 0; i < 32; i++){
        profileId |= generalProfileCompatibility & 1;
        if (i === 31) break;
        profileId <<= 1;
        generalProfileCompatibility >>= 1;
    }
    const profileSpaceChar = generalProfileSpace === 0 ? '' : generalProfileSpace === 1 ? 'A' : generalProfileSpace === 2 ? 'B' : 'C';
    const generalTierChar = generalTierFlag === 0 ? 'L' : 'H';
    let hasByte = false;
    let generalConstraintString = '';
    for(let i = 5; i >= 0; i--){
        if (generalConstraintIndicator[i] || hasByte) {
            generalConstraintString = generalConstraintIndicator[i].toString(16) + generalConstraintString;
            hasByte = true;
        }
    }
    return `${profileSpaceChar}${generalProfileIdc.toString(16)}.${profileId.toString(16)}.${generalTierChar}${generalLevelIdc}${generalConstraintString ? '.' : ''}${generalConstraintString}`;
};
exports.getHvc1CodecString = getHvc1CodecString;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/color-to-webcodecs-colors.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mediaParserAdvancedColorToWebCodecsColor = void 0;
const mediaParserAdvancedColorToWebCodecsColor = (color)=>{
    return {
        transfer: color.transfer,
        matrix: color.matrix,
        primaries: color.primaries,
        fullRange: color.fullRange
    };
};
exports.mediaParserAdvancedColorToWebCodecsColor = mediaParserAdvancedColorToWebCodecsColor;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/av1-codec-private.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseAv1PrivateData = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const parseAv1PrivateData = (data, colrAtom)=>{
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: data,
        maxBytes: data.byteLength,
        logLevel: 'error'
    });
    iterator.startReadingBits();
    if (iterator.getBits(1) !== 1) {
        iterator.destroy();
        throw new Error('Expected av1 private data to be version 1');
    }
    const version = iterator.getBits(7);
    if (version !== 1) {
        iterator.destroy();
        throw new Error(`Expected av1 private data to be version 1, got ${version}`);
    }
    let str = 'av01.';
    // https://aomediacodec.github.io/av1-isobmff/#codecsparam
    const seqProfile = iterator.getBits(3);
    // Profile
    str += seqProfile;
    str += '.';
    const seq_level_idx = iterator.getBits(5);
    const seq_tier_0 = iterator.getBits(1);
    // Level
    // The level parameter value SHALL equal the first level value indicated by seq_level_idx in the Sequence Header OBU
    str += String(seq_level_idx).padStart(2, '0');
    str += seq_tier_0 ? 'H' : 'M';
    str += '.';
    // bitDepth
    // The bitDepth parameter value SHALL equal the value of BitDepth variable as defined in [AV1] derived from the Sequence Header OBU
    const high_bitdepth = iterator.getBits(1);
    const twelve_bit = iterator.getBits(1);
    const bitDepth = high_bitdepth && seqProfile === 2 ? twelve_bit ? 12 : 10 : high_bitdepth ? 10 : 8;
    str += bitDepth.toString().padStart(2, '0');
    str += '.';
    // monochrome
    // The monochrome parameter value, represented by a single digit decimal, SHALL equal the value of mono_chrome in the Sequence Header OBU
    const mono_chrome = iterator.getBits(1);
    str += mono_chrome ? '1' : '0';
    str += '.';
    // The chromaSubsampling parameter value, represented by a three-digit decimal,
    // SHALL have its first digit equal to subsampling_x
    const subsampling_x = iterator.getBits(1);
    str += subsampling_x ? '1' : '0';
    // and its second digit equal to subsampling_y.
    const subsampling_y = iterator.getBits(1);
    str += subsampling_y ? '1' : '0';
    // If both subsampling_x and subsampling_y are set to 1, then the third digit SHALL be equal to chroma_sample_position, otherwise it SHALL be set to 0
    const chroma_sample_position = iterator.getBits(2);
    str += subsampling_x && subsampling_y ? chroma_sample_position === 1 ? '1' : '0' : '0';
    str += '.';
    if (colrAtom && colrAtom.colorType === 'transfer-characteristics') {
        str += colrAtom.primaries.toString().padStart(2, '0');
        str += '.';
        str += colrAtom.transfer.toString().padStart(2, '0');
        str += '.';
        str += colrAtom.matrixIndex.toString().padStart(2, '0');
        str += '.';
        str += colrAtom.fullRangeFlag ? '1' : '0';
    } else {
        // Otherwise, the color_description_present_flag is set to 0 in the Sequence Header OBU. The colorPrimaries, transferCharacteristics, and matrixCoefficients parameter values SHOULD be set to the default values below.
        // colorPrimaries 01 (ITU-R BT.709)
        str += '01';
        str += '.';
        // transferCharacteristics 01 (ITU-R BT.709)
        str += '01';
        str += '.';
        // matrixCoefficients 00 (ITU-R BT.709)
        str += '01';
        str += '.';
        // videoFullRangeFlag 0 (studio swing representation)
        str += '0';
    }
    // If the codecs parameter string ends with ".0.110.01.01.01.0" (containing all the default values below), that trailing part of the string SHOULD be omitted.
    const suffix = '.0.110.01.01.01.0';
    if (str.endsWith(suffix)) {
        str = str.slice(0, -suffix.length);
    }
    iterator.destroy();
    return str;
};
exports.parseAv1PrivateData = parseAv1PrivateData;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/avc/color.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getPrimariesFromIndex = exports.getTransferCharacteristicsFromIndex = exports.getMatrixCoefficientsFromIndex = void 0;
const getMatrixCoefficientsFromIndex = (index)=>{
    if (index === 0) {
        return 'rgb';
    }
    if (index === 1) {
        return 'bt709';
    }
    if (index === 5) {
        return 'bt470bg';
    }
    if (index === 6) {
        return 'smpte170m';
    }
    if (index === 9) {
        return 'bt2020-ncl';
    }
    return null;
};
exports.getMatrixCoefficientsFromIndex = getMatrixCoefficientsFromIndex;
// https://w3c.github.io/webcodecs/#videotransfercharacteristics
// But we may support more than that
const getTransferCharacteristicsFromIndex = (index)=>{
    if (index === 1) {
        return 'bt709';
    }
    if (index === 6) {
        return 'smpte170m';
    }
    if (index === 8) {
        return 'linear';
    }
    if (index === 13) {
        return 'iec61966-2-1';
    }
    if (index === 16) {
        return 'pq';
    }
    if (index === 18) {
        return 'hlg';
    }
    return null;
};
exports.getTransferCharacteristicsFromIndex = getTransferCharacteristicsFromIndex;
const getPrimariesFromIndex = (index)=>{
    if (index === 1) {
        return 'bt709';
    }
    if (index === 5) {
        return 'bt470bg';
    }
    if (index === 6) {
        return 'smpte170m';
    }
    if (index === 9) {
        return 'bt2020';
    }
    if (index === 12) {
        return 'smpte432';
    }
    return null;
};
exports.getPrimariesFromIndex = getPrimariesFromIndex;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/traversal.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getClusterSegment = exports.getPrivateData = exports.getBitDepth = exports.getNumberOfChannels = exports.getSampleRate = exports.getAudioSegment = exports.getVideoSegment = exports.getTimescaleSegment = exports.getTrackWithUid = exports.getTracksSegment = exports.getDisplayWidthSegment = exports.getHeightSegment = exports.getWidthSegment = exports.getTrackTypeSegment = exports.getDisplayHeightSegment = exports.getRangeSegment = exports.getPrimariesSegment = exports.getMatrixCoefficientsSegment = exports.getTransferCharacteristicsSegment = exports.getColourSegment = exports.getCodecSegment = exports.getTrackId = exports.getTrackByNumber = exports.getTrackTimestampScale = exports.getTrackCodec = exports.getTrackNumber = exports.getMainSegment = void 0;
const getMainSegment = (segments)=>{
    var _a;
    return (_a = segments.find((s)=>s.type === 'Segment')) !== null && _a !== void 0 ? _a : null;
};
exports.getMainSegment = getMainSegment;
const getTrackNumber = (track)=>{
    var _a;
    const child = track.value.find((b)=>b.type === 'TrackNumber');
    return (_a = child === null || child === void 0 ? void 0 : child.value) !== null && _a !== void 0 ? _a : null;
};
exports.getTrackNumber = getTrackNumber;
const getTrackCodec = (track)=>{
    const child = track.value.find((b)=>b.type === 'CodecID');
    return child !== null && child !== void 0 ? child : null;
};
exports.getTrackCodec = getTrackCodec;
const getTrackTimestampScale = (track)=>{
    const child = track.value.find((b)=>b.type === 'TrackTimestampScale');
    if (!child) {
        return null;
    }
    if (child.type !== 'TrackTimestampScale') {
        throw new Error('Expected TrackTimestampScale');
    }
    return child.value;
};
exports.getTrackTimestampScale = getTrackTimestampScale;
const getTrackByNumber = (tracks, id)=>{
    return tracks.find((track)=>{
        const trackNumber = (0, exports.getTrackNumber)(track);
        return (trackNumber === null || trackNumber === void 0 ? void 0 : trackNumber.value) === id;
    });
};
exports.getTrackByNumber = getTrackByNumber;
const getTrackId = (track)=>{
    const trackId = track.value.find((b)=>b.type === 'TrackNumber');
    if (!trackId || trackId.type !== 'TrackNumber') {
        throw new Error('Expected track number segment');
    }
    return trackId.value.value;
};
exports.getTrackId = getTrackId;
const getCodecSegment = (track)=>{
    const codec = track.value.find((b)=>b.type === 'CodecID');
    if (!codec || codec.type !== 'CodecID') {
        return null;
    }
    return codec;
};
exports.getCodecSegment = getCodecSegment;
const getColourSegment = (track)=>{
    const videoSegment = (0, exports.getVideoSegment)(track);
    if (!videoSegment) {
        return null;
    }
    const colour = videoSegment.value.find((b)=>b.type === 'Colour');
    if (!colour || colour.type !== 'Colour') {
        return null;
    }
    return colour;
};
exports.getColourSegment = getColourSegment;
const getTransferCharacteristicsSegment = (color)=>{
    if (!color || color.type !== 'Colour') {
        return null;
    }
    const box = color.value.find((b)=>b.type === 'TransferCharacteristics');
    if (!box || box.type !== 'TransferCharacteristics') {
        return null;
    }
    return box;
};
exports.getTransferCharacteristicsSegment = getTransferCharacteristicsSegment;
const getMatrixCoefficientsSegment = (color)=>{
    if (!color || color.type !== 'Colour') {
        return null;
    }
    const box = color.value.find((b)=>b.type === 'MatrixCoefficients');
    if (!box || box.type !== 'MatrixCoefficients') {
        return null;
    }
    return box;
};
exports.getMatrixCoefficientsSegment = getMatrixCoefficientsSegment;
const getPrimariesSegment = (color)=>{
    if (!color || color.type !== 'Colour') {
        return null;
    }
    const box = color.value.find((b)=>b.type === 'Primaries');
    if (!box || box.type !== 'Primaries') {
        return null;
    }
    return box;
};
exports.getPrimariesSegment = getPrimariesSegment;
const getRangeSegment = (color)=>{
    if (!color || color.type !== 'Colour') {
        return null;
    }
    const box = color.value.find((b)=>b.type === 'Range');
    if (!box || box.type !== 'Range') {
        return null;
    }
    return box;
};
exports.getRangeSegment = getRangeSegment;
const getDisplayHeightSegment = (track)=>{
    const videoSegment = (0, exports.getVideoSegment)(track);
    if (!videoSegment) {
        return null;
    }
    const displayHeight = videoSegment.value.find((b)=>b.type === 'DisplayHeight');
    if (!displayHeight || displayHeight.type !== 'DisplayHeight') {
        return null;
    }
    return displayHeight;
};
exports.getDisplayHeightSegment = getDisplayHeightSegment;
const getTrackTypeSegment = (track)=>{
    const trackType = track.value.find((b)=>b.type === 'TrackType');
    if (!trackType || trackType.type !== 'TrackType') {
        return null;
    }
    return trackType;
};
exports.getTrackTypeSegment = getTrackTypeSegment;
const getWidthSegment = (track)=>{
    const videoSegment = (0, exports.getVideoSegment)(track);
    if (!videoSegment) {
        return null;
    }
    const width = videoSegment.value.find((b)=>b.type === 'PixelWidth');
    if (!width || width.type !== 'PixelWidth') {
        return null;
    }
    return width;
};
exports.getWidthSegment = getWidthSegment;
const getHeightSegment = (track)=>{
    const videoSegment = (0, exports.getVideoSegment)(track);
    if (!videoSegment) {
        return null;
    }
    const height = videoSegment.value.find((b)=>b.type === 'PixelHeight');
    if (!height || height.type !== 'PixelHeight') {
        return null;
    }
    return height;
};
exports.getHeightSegment = getHeightSegment;
const getDisplayWidthSegment = (track)=>{
    const videoSegment = (0, exports.getVideoSegment)(track);
    if (!videoSegment) {
        return null;
    }
    const displayWidth = videoSegment.value.find((b)=>b.type === 'DisplayWidth');
    if (!displayWidth || displayWidth.type !== 'DisplayWidth') {
        return null;
    }
    return displayWidth;
};
exports.getDisplayWidthSegment = getDisplayWidthSegment;
const getTracksSegment = (segment)=>{
    const tracksSegment = segment.value.find((b)=>b.type === 'Tracks');
    if (!tracksSegment) {
        return null;
    }
    return tracksSegment;
};
exports.getTracksSegment = getTracksSegment;
const getTrackWithUid = (segment, trackUid)=>{
    var _a, _b;
    const tracksSegment = (0, exports.getTracksSegment)(segment);
    if (!tracksSegment) {
        return null;
    }
    const trackEntries = tracksSegment.value.filter((t)=>t.type === 'TrackEntry');
    const trackEntry = trackEntries.find((entry)=>{
        return entry === null || entry === void 0 ? void 0 : entry.value.find((t)=>t.type === 'TrackUID' && t.value === trackUid);
    });
    if (!trackEntry) {
        return null;
    }
    return (_b = (_a = trackEntry.value.find((t)=>t.type === 'TrackNumber')) === null || _a === void 0 ? void 0 : _a.value.value) !== null && _b !== void 0 ? _b : null;
};
exports.getTrackWithUid = getTrackWithUid;
const getTimescaleSegment = (segment)=>{
    const infoSegment = segment.value.find((b)=>b.type === 'Info');
    if (!infoSegment || infoSegment.type !== 'Info') {
        return null;
    }
    const timescale = infoSegment.value.find((b)=>b.type === 'TimestampScale');
    if (!timescale || timescale.type !== 'TimestampScale') {
        return null;
    }
    return timescale;
};
exports.getTimescaleSegment = getTimescaleSegment;
const getVideoSegment = (track)=>{
    const videoSegment = track.value.find((b)=>b.type === 'Video');
    if (!videoSegment || videoSegment.type !== 'Video') {
        return null;
    }
    return videoSegment !== null && videoSegment !== void 0 ? videoSegment : null;
};
exports.getVideoSegment = getVideoSegment;
const getAudioSegment = (track)=>{
    const audioSegment = track.value.find((b)=>b.type === 'Audio');
    if (!audioSegment || audioSegment.type !== 'Audio') {
        return null;
    }
    return audioSegment !== null && audioSegment !== void 0 ? audioSegment : null;
};
exports.getAudioSegment = getAudioSegment;
const getSampleRate = (track)=>{
    const audioSegment = (0, exports.getAudioSegment)(track);
    if (!audioSegment) {
        return null;
    }
    const samplingFrequency = audioSegment.value.find((b)=>b.type === 'SamplingFrequency');
    if (!samplingFrequency || samplingFrequency.type !== 'SamplingFrequency') {
        return null;
    }
    return samplingFrequency.value.value;
};
exports.getSampleRate = getSampleRate;
const getNumberOfChannels = (track)=>{
    const audioSegment = (0, exports.getAudioSegment)(track);
    if (!audioSegment) {
        throw new Error('Could not find audio segment');
    }
    const channels = audioSegment.value.find((b)=>b.type === 'Channels');
    if (!channels || channels.type !== 'Channels') {
        return 1;
    }
    return channels.value.value;
};
exports.getNumberOfChannels = getNumberOfChannels;
const getBitDepth = (track)=>{
    const audioSegment = (0, exports.getAudioSegment)(track);
    if (!audioSegment) {
        return null;
    }
    const bitDepth = audioSegment.value.find((b)=>b.type === 'BitDepth');
    if (!bitDepth || bitDepth.type !== 'BitDepth') {
        return null;
    }
    return bitDepth.value.value;
};
exports.getBitDepth = getBitDepth;
const getPrivateData = (track)=>{
    const privateData = track.value.find((b)=>b.type === 'CodecPrivate');
    if (!privateData || privateData.type !== 'CodecPrivate') {
        return null;
    }
    return privateData.value;
};
exports.getPrivateData = getPrivateData;
const getClusterSegment = (segment)=>{
    const clusterSegment = segment.value.find((b)=>b.type === 'Cluster');
    return clusterSegment !== null && clusterSegment !== void 0 ? clusterSegment : null;
};
exports.getClusterSegment = getClusterSegment;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/color.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseColorSegment = void 0;
const color_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/color.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/traversal.js [app-route] (ecmascript)");
const parseColorSegment = (colourSegment)=>{
    const transferCharacteristics = (0, traversal_1.getTransferCharacteristicsSegment)(colourSegment);
    const matrixCoefficients = (0, traversal_1.getMatrixCoefficientsSegment)(colourSegment);
    const primaries = (0, traversal_1.getPrimariesSegment)(colourSegment);
    const range = (0, traversal_1.getRangeSegment)(colourSegment);
    return {
        transfer: transferCharacteristics ? (0, color_1.getTransferCharacteristicsFromIndex)(transferCharacteristics.value.value) : null,
        matrix: matrixCoefficients ? (0, color_1.getMatrixCoefficientsFromIndex)(matrixCoefficients.value.value) : null,
        primaries: primaries ? (0, color_1.getPrimariesFromIndex)(primaries.value.value) : null,
        fullRange: (transferCharacteristics === null || transferCharacteristics === void 0 ? void 0 : transferCharacteristics.value.value) && (matrixCoefficients === null || matrixCoefficients === void 0 ? void 0 : matrixCoefficients.value.value) ? null : range ? Boolean(range === null || range === void 0 ? void 0 : range.value.value) : null
    };
};
exports.parseColorSegment = parseColorSegment;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/description.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getAudioDescription = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/traversal.js [app-route] (ecmascript)");
const getAudioDescription = (track)=>{
    const codec = (0, traversal_1.getCodecSegment)(track);
    if (!codec || codec.value !== 'A_VORBIS') {
        return undefined;
    }
    // how to parse vorbis private
    // https://github.com/google/ExoPlayer/blob/dd430f7053a1a3958deea3ead6a0565150c06bfc/library/extractor/src/main/java/com/google/android/exoplayer2/extractor/mkv/MatroskaExtractor.java#L2466
    const privateData = (0, traversal_1.getPrivateData)(track);
    if (!privateData) {
        return undefined;
    }
    if (privateData[0] !== 2) {
        throw new Error('Expected vorbis private data version 2');
    }
    let offset = 1;
    let vorbisInfoLength = 0;
    let vorbisSkipLength = 0;
    while((privateData[offset] & 0xff) === 0xff){
        vorbisInfoLength += 0xff;
        offset++;
    }
    vorbisInfoLength += privateData[offset++] & 0xff;
    while((privateData[offset] & 0xff) === 0xff){
        vorbisSkipLength += 0xff;
        offset++;
    }
    vorbisSkipLength += privateData[offset++] & 0xff;
    if (privateData[offset] !== 0x01) {
        throw new Error('Error parsing vorbis codec private');
    }
    const vorbisInfo = privateData.slice(offset, offset + vorbisInfoLength);
    offset += vorbisInfoLength;
    if (privateData[offset] !== 0x03) {
        throw new Error('Error parsing vorbis codec private');
    }
    const vorbisComments = privateData.slice(offset, offset + vorbisSkipLength);
    offset += vorbisSkipLength;
    if (privateData[offset] !== 0x05) {
        throw new Error('Error parsing vorbis codec private');
    }
    const vorbisBooks = privateData.slice(offset);
    const bufferIterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: vorbisInfo.slice(0),
        maxBytes: vorbisInfo.length,
        logLevel: 'error'
    });
    // type
    bufferIterator.getUint8();
    // vorbis
    const vorbis = bufferIterator.getByteString(6, false);
    if (vorbis !== 'vorbis') {
        throw new Error('Error parsing vorbis codec private');
    }
    const vorbisVersion = bufferIterator.getUint32Le();
    if (vorbisVersion !== 0) {
        throw new Error('Error parsing vorbis codec private');
    }
    const vorbisDescription = new Uint8Array([
        // constructing the vorbis description
        // This format consists in the page_segments field
        /**
         * The number of segment entries to appear in the segment table.
         * The maximum number of 255 segments (255 bytes each) sets the maximum possible physical page size at 65307 bytes or just under 64kB (thus we know that a header corrupted so as destroy sizing/alignment information will not cause a runaway bitstream.
         * We'll read in the page according to the corrupted size information that's guaranteed to be a reasonable size regardless, notice the checksum mismatch, drop sync and then look for recapture).
         */ 2,
        // followed by the segment_table field
        // offset of the comments table
        vorbisInfo.length,
        // offset of the codebooks table
        vorbisComments.length,
        // followed by the three Vorbis header packets,
        // respectively the identification header,
        ...vorbisInfo,
        // the comments header,
        ...vorbisComments,
        // and the setup header, in this order, as described in section 4.2 of [VORBIS].
        ...vorbisBooks
    ]);
    return vorbisDescription;
};
exports.getAudioDescription = getAudioDescription;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/track-entry.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.trackTypeToString = void 0;
const trackTypeToString = (trackType)=>{
    switch(trackType){
        case 1:
            return 'video';
        case 2:
            return 'audio';
        case 3:
            return 'complex';
        case 4:
            return 'subtitle';
        case 5:
            return 'button';
        case 6:
            return 'control';
        case 7:
            return 'metadata';
        default:
            throw new Error(`Unknown track type: ${trackType}`);
    }
};
exports.trackTypeToString = trackTypeToString;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/make-track.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getTrack = exports.getMatroskaAudioCodecEnum = exports.NO_CODEC_PRIVATE_SHOULD_BE_DERIVED_FROM_SPS = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const make_hvc1_codec_strings_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/make-hvc1-codec-strings.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const color_to_webcodecs_colors_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/color-to-webcodecs-colors.js [app-route] (ecmascript)");
const av1_codec_private_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/av1-codec-private.js [app-route] (ecmascript)");
const color_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/color.js [app-route] (ecmascript)");
const description_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/description.js [app-route] (ecmascript)");
const track_entry_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/track-entry.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/traversal.js [app-route] (ecmascript)");
exports.NO_CODEC_PRIVATE_SHOULD_BE_DERIVED_FROM_SPS = 'no-codec-private-should-be-derived-from-sps';
const getDescription = (track)=>{
    const codec = (0, traversal_1.getCodecSegment)(track);
    if (!codec) {
        return undefined;
    }
    if (codec.value === 'V_MPEG4/ISO/AVC' || codec.value === 'V_MPEGH/ISO/HEVC') {
        const priv = (0, traversal_1.getPrivateData)(track);
        if (priv) {
            return priv;
        }
    }
    return undefined;
};
const getMatroskaVideoCodecEnum = ({ codecSegment: codec })=>{
    if (codec.value === 'V_VP8') {
        return 'vp8';
    }
    if (codec.value === 'V_VP9') {
        return 'vp9';
    }
    if (codec.value === 'V_MPEG4/ISO/AVC') {
        return 'h264';
    }
    if (codec.value === 'V_AV1') {
        return 'av1';
    }
    if (codec.value === 'V_MPEGH/ISO/HEVC') {
        return 'h265';
    }
    throw new Error(`Unknown codec: ${codec.value}`);
};
const getMatroskaVideoCodecString = ({ track, codecSegment: codec })=>{
    if (codec.value === 'V_VP8') {
        return 'vp8';
    }
    if (codec.value === 'V_VP9') {
        const priv = (0, traversal_1.getPrivateData)(track);
        if (priv) {
            throw new Error('@remotion/media-parser cannot handle the private data for VP9. Do you have an example file you could send so we can implement it? https://remotion.dev/report');
        }
        return 'vp09.00.10.08';
    }
    if (codec.value === 'V_MPEG4/ISO/AVC') {
        const priv = (0, traversal_1.getPrivateData)(track);
        if (priv) {
            return `avc1.${priv[1].toString(16).padStart(2, '0')}${priv[2].toString(16).padStart(2, '0')}${priv[3].toString(16).padStart(2, '0')}`;
        }
        return exports.NO_CODEC_PRIVATE_SHOULD_BE_DERIVED_FROM_SPS;
    }
    if (codec.value === 'V_MPEGH/ISO/HEVC') {
        const priv = (0, traversal_1.getPrivateData)(track);
        const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
            initialData: priv,
            maxBytes: priv.length,
            logLevel: 'error'
        });
        return 'hvc1.' + (0, make_hvc1_codec_strings_1.getHvc1CodecString)(iterator);
    }
    if (codec.value === 'V_AV1') {
        const priv = (0, traversal_1.getPrivateData)(track);
        if (!priv) {
            throw new Error('Expected private data in AV1 track');
        }
        return (0, av1_codec_private_1.parseAv1PrivateData)(priv, null);
    }
    throw new Error(`Unknown codec: ${codec.value}`);
};
const getMatroskaAudioCodecEnum = ({ track })=>{
    const codec = (0, traversal_1.getCodecSegment)(track);
    if (!codec) {
        throw new Error('Expected codec segment');
    }
    if (codec.value === 'A_OPUS') {
        return 'opus';
    }
    if (codec.value === 'A_VORBIS') {
        return 'vorbis';
    }
    if (codec.value === 'A_PCM/INT/LIT') {
        // https://github.com/ietf-wg-cellar/matroska-specification/issues/142#issuecomment-330004950
        // Audio samples MUST be considered as signed values, except if the audio bit depth is 8 which MUST be interpreted as unsigned values.
        const bitDepth = (0, traversal_1.getBitDepth)(track);
        if (bitDepth === null) {
            throw new Error('Expected bit depth');
        }
        if (bitDepth === 8) {
            return 'pcm-u8';
        }
        if (bitDepth === 16) {
            return 'pcm-s16';
        }
        if (bitDepth === 24) {
            return 'pcm-s24';
        }
        throw new Error('Unknown audio format');
    }
    if (codec.value === 'A_AAC') {
        return `aac`;
    }
    if (codec.value === 'A_MPEG/L3') {
        return 'mp3';
    }
    throw new Error(`Unknown codec: ${codec.value}`);
};
exports.getMatroskaAudioCodecEnum = getMatroskaAudioCodecEnum;
const getMatroskaAudioCodecString = (track)=>{
    const codec = (0, traversal_1.getCodecSegment)(track);
    if (!codec) {
        throw new Error('Expected codec segment');
    }
    if (codec.value === 'A_OPUS') {
        return 'opus';
    }
    if (codec.value === 'A_VORBIS') {
        return 'vorbis';
    }
    if (codec.value === 'A_PCM/INT/LIT') {
        // https://github.com/ietf-wg-cellar/matroska-specification/issues/142#issuecomment-330004950
        // Audio samples MUST be considered as signed values, except if the audio bit depth is 8 which MUST be interpreted as unsigned values.
        const bitDepth = (0, traversal_1.getBitDepth)(track);
        if (bitDepth === null) {
            throw new Error('Expected bit depth');
        }
        if (bitDepth === 8) {
            return 'pcm-u8';
        }
        return 'pcm-s' + bitDepth;
    }
    if (codec.value === 'A_AAC') {
        const priv = (0, traversal_1.getPrivateData)(track);
        const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
            initialData: priv,
            maxBytes: priv.length,
            logLevel: 'error'
        });
        iterator.startReadingBits();
        /**
         * ChatGPT
         * 	â–ª	The first 5 bits represent the AOT.
                â–ª	Common values:
                â—¦	1 for AAC Main
                â—¦	2 for AAC LC (Low Complexity)
                â—¦	3 for AAC SSR (Scalable Sample Rate)
                â—¦	4 for AAC LTP (Long Term Prediction)
                â—¦	5 for SBR (Spectral Band Replication)
                â—¦	29 for HE-AAC (which uses SBR with AAC LC)
         */ /**
         * Fully qualified codec:
         * This codec has multiple possible codec strings:
            "mp4a.40.2" â€” MPEG-4 AAC LC
            "mp4a.40.02" â€” MPEG-4 AAC LC, leading 0 for Aud-OTI compatibility
            "mp4a.40.5" â€” MPEG-4 HE-AAC v1 (AAC LC + SBR)
            "mp4a.40.05" â€” MPEG-4 HE-AAC v1 (AAC LC + SBR), leading 0 for Aud-OTI compatibility
            "mp4a.40.29" â€” MPEG-4 HE-AAC v2 (AAC LC + SBR + PS)
            "mp4a.67" â€” MPEG-2 AAC LC
        */ const profile = iterator.getBits(5);
        iterator.stopReadingBits();
        iterator.destroy();
        return `mp4a.40.${profile.toString().padStart(2, '0')}`;
    }
    if (codec.value === 'A_MPEG/L3') {
        return 'mp3';
    }
    throw new Error(`Unknown codec: ${codec.value}`);
};
const getTrack = ({ timescale, track })=>{
    const trackType = (0, traversal_1.getTrackTypeSegment)(track);
    if (!trackType) {
        throw new Error('Expected track type segment');
    }
    const trackId = (0, traversal_1.getTrackId)(track);
    if ((0, track_entry_1.trackTypeToString)(trackType.value.value) === 'video') {
        const width = (0, traversal_1.getWidthSegment)(track);
        if (width === null) {
            throw new Error('Expected width segment');
        }
        const height = (0, traversal_1.getHeightSegment)(track);
        if (height === null) {
            throw new Error('Expected height segment');
        }
        const displayHeight = (0, traversal_1.getDisplayHeightSegment)(track);
        const displayWidth = (0, traversal_1.getDisplayWidthSegment)(track);
        const codec = (0, traversal_1.getCodecSegment)(track);
        if (!codec) {
            return null;
        }
        const codecPrivate = (0, traversal_1.getPrivateData)(track);
        const codecString = getMatroskaVideoCodecString({
            track,
            codecSegment: codec
        });
        const colour = (0, traversal_1.getColourSegment)(track);
        if (!codecString) {
            return null;
        }
        const codecEnum = getMatroskaVideoCodecEnum({
            codecSegment: codec
        });
        const codecData = codecPrivate === null ? null : codecEnum === 'h264' ? {
            type: 'avc-sps-pps',
            data: codecPrivate
        } : codecEnum === 'av1' ? {
            type: 'av1c-data',
            data: codecPrivate
        } : codecEnum === 'h265' ? {
            type: 'hvcc-data',
            data: codecPrivate
        } : codecEnum === 'vp8' ? {
            type: 'unknown-data',
            data: codecPrivate
        } : codecEnum === 'vp9' ? {
            type: 'unknown-data',
            data: codecPrivate
        } : null;
        const advancedColor = colour ? (0, color_1.parseColorSegment)(colour) : {
            fullRange: null,
            matrix: null,
            primaries: null,
            transfer: null
        };
        return {
            m3uStreamFormat: null,
            type: 'video',
            trackId,
            codec: codecString,
            description: getDescription(track),
            height: displayHeight ? displayHeight.value.value : height.value.value,
            width: displayWidth ? displayWidth.value.value : width.value.value,
            sampleAspectRatio: {
                numerator: 1,
                denominator: 1
            },
            originalTimescale: timescale,
            codedHeight: height.value.value,
            codedWidth: width.value.value,
            displayAspectHeight: displayHeight ? displayHeight.value.value : height.value.value,
            displayAspectWidth: displayWidth ? displayWidth.value.value : width.value.value,
            rotation: 0,
            codecData,
            colorSpace: (0, color_to_webcodecs_colors_1.mediaParserAdvancedColorToWebCodecsColor)(advancedColor),
            advancedColor,
            codecEnum,
            fps: null,
            startInSeconds: 0,
            timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
            trackMediaTimeOffsetInTrackTimescale: 0
        };
    }
    if ((0, track_entry_1.trackTypeToString)(trackType.value.value) === 'audio') {
        const sampleRate = (0, traversal_1.getSampleRate)(track);
        const numberOfChannels = (0, traversal_1.getNumberOfChannels)(track);
        const codecPrivate = (0, traversal_1.getPrivateData)(track);
        if (sampleRate === null) {
            throw new Error('Could not find sample rate or number of channels');
        }
        const codecString = getMatroskaAudioCodecString(track);
        return {
            type: 'audio',
            trackId,
            codec: codecString,
            originalTimescale: timescale,
            numberOfChannels,
            sampleRate,
            description: (0, description_1.getAudioDescription)(track),
            codecData: codecPrivate ? codecString === 'opus' ? {
                type: 'ogg-identification',
                data: codecPrivate
            } : {
                type: 'unknown-data',
                data: codecPrivate
            } : null,
            codecEnum: (0, exports.getMatroskaAudioCodecEnum)({
                track
            }),
            startInSeconds: 0,
            timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
            trackMediaTimeOffsetInTrackTimescale: 0
        };
    }
    return null;
};
exports.getTrack = getTrack;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/get-ready-tracks.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.matroskaHasTracks = exports.getTracksFromMatroska = void 0;
const codec_string_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/codec-string.js [app-route] (ecmascript)");
const make_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/make-track.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/traversal.js [app-route] (ecmascript)");
const getTracksFromMatroska = ({ structureState, webmState })=>{
    const structure = structureState.getMatroskaStructure();
    const mainSegment = (0, traversal_1.getMainSegment)(structure.boxes);
    if (!mainSegment) {
        throw new Error('No main segment');
    }
    const tracksSegment = (0, traversal_1.getTracksSegment)(mainSegment);
    if (!tracksSegment) {
        throw new Error('No tracks segment');
    }
    const resolvedTracks = [];
    const missingInfo = [];
    for (const trackEntrySegment of tracksSegment.value){
        if (trackEntrySegment.type === 'Crc32') {
            continue;
        }
        if (trackEntrySegment.type !== 'TrackEntry') {
            throw new Error('Expected track entry segment');
        }
        const track = (0, make_track_1.getTrack)({
            track: trackEntrySegment,
            timescale: webmState.getTimescale()
        });
        if (!track) {
            continue;
        }
        if (track.codec === make_track_1.NO_CODEC_PRIVATE_SHOULD_BE_DERIVED_FROM_SPS) {
            const avc = webmState.getAvcProfileForTrackNumber(track.trackId);
            if (avc) {
                resolvedTracks.push({
                    ...track,
                    codec: (0, codec_string_1.getCodecStringFromSpsAndPps)(avc)
                });
            } else {
                missingInfo.push(track);
            }
        } else {
            resolvedTracks.push(track);
        }
    }
    return {
        missingInfo,
        resolved: resolvedTracks
    };
};
exports.getTracksFromMatroska = getTracksFromMatroska;
const matroskaHasTracks = ({ structureState, webmState })=>{
    const structure = structureState.getMatroskaStructure();
    const mainSegment = (0, traversal_1.getMainSegment)(structure.boxes);
    if (!mainSegment) {
        return false;
    }
    return (0, traversal_1.getTracksSegment)(mainSegment) !== null && (0, exports.getTracksFromMatroska)({
        structureState,
        webmState
    }).missingInfo.length === 0;
};
exports.matroskaHasTracks = matroskaHasTracks;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getTracks = exports.defaultHasallTracks = exports.defaultGetTracks = exports.getTracksFromIsoBaseMedia = exports.getTracksFromMoovBox = exports.getHasTracks = exports.isoBaseMediaHasTracks = exports.getNumberOfTracks = void 0;
const make_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/make-track.js [app-route] (ecmascript)");
const get_editlist_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mdat/get-editlist.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const get_tracks_from_avi_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/get-tracks-from-avi.js [app-route] (ecmascript)");
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/get-tracks.js [app-route] (ecmascript)");
const get_ready_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/get-ready-tracks.js [app-route] (ecmascript)");
const getNumberOfTracks = (moovBox)=>{
    const mvHdBox = (0, traversal_1.getMvhdBox)(moovBox);
    if (!mvHdBox) {
        return 0;
    }
    return mvHdBox.nextTrackId - 1;
};
exports.getNumberOfTracks = getNumberOfTracks;
const isoBaseMediaHasTracks = (state, mayUsePrecomputed)=>{
    var _a, _b;
    return Boolean((0, traversal_1.getMoovBoxFromState)({
        structureState: state.structure,
        isoState: state.iso,
        mp4HeaderSegment: (_b = (_a = state.m3uPlaylistContext) === null || _a === void 0 ? void 0 : _a.mp4HeaderSegment) !== null && _b !== void 0 ? _b : null,
        mayUsePrecomputed
    }));
};
exports.isoBaseMediaHasTracks = isoBaseMediaHasTracks;
const getHasTracks = (state, mayUsePrecomputed)=>{
    const structure = state.structure.getStructure();
    if (structure.type === 'matroska') {
        return (0, get_ready_tracks_1.matroskaHasTracks)({
            structureState: state.structure,
            webmState: state.webm
        });
    }
    if (structure.type === 'iso-base-media') {
        return (0, exports.isoBaseMediaHasTracks)(state, mayUsePrecomputed);
    }
    if (structure.type === 'riff') {
        return (0, get_tracks_from_avi_1.hasAllTracksFromAvi)(state);
    }
    if (structure.type === 'transport-stream') {
        return (0, get_tracks_1.hasAllTracksFromTransportStream)(state);
    }
    if (structure.type === 'mp3') {
        return state.callbacks.tracks.getTracks().length > 0;
    }
    if (structure.type === 'wav') {
        return state.callbacks.tracks.hasAllTracks();
    }
    if (structure.type === 'aac') {
        return state.callbacks.tracks.hasAllTracks();
    }
    if (structure.type === 'flac') {
        return state.callbacks.tracks.hasAllTracks();
    }
    if (structure.type === 'm3u') {
        return state.callbacks.tracks.hasAllTracks();
    }
    throw new Error('Unknown container ' + structure);
};
exports.getHasTracks = getHasTracks;
const getCategorizedTracksFromMatroska = (state)=>{
    const { resolved } = (0, get_ready_tracks_1.getTracksFromMatroska)({
        structureState: state.structure,
        webmState: state.webm
    });
    return resolved;
};
const getTracksFromMoovBox = (moovBox)=>{
    const mediaParserTracks = [];
    const tracks = (0, traversal_1.getTraks)(moovBox);
    for (const trakBox of tracks){
        const mvhdBox = (0, traversal_1.getMvhdBox)(moovBox);
        if (!mvhdBox) {
            throw new Error('Mvhd box is not found');
        }
        const startTime = (0, get_editlist_1.findTrackStartTimeInSeconds)({
            movieTimeScale: mvhdBox.timeScale,
            trakBox
        });
        const track = (0, make_track_1.makeBaseMediaTrack)(trakBox, startTime);
        if (!track) {
            continue;
        }
        mediaParserTracks.push(track);
    }
    return mediaParserTracks;
};
exports.getTracksFromMoovBox = getTracksFromMoovBox;
const getTracksFromIsoBaseMedia = ({ mayUsePrecomputed, structure, isoState, m3uPlaylistContext })=>{
    var _a;
    const moovBox = (0, traversal_1.getMoovBoxFromState)({
        structureState: structure,
        isoState,
        mp4HeaderSegment: (_a = m3uPlaylistContext === null || m3uPlaylistContext === void 0 ? void 0 : m3uPlaylistContext.mp4HeaderSegment) !== null && _a !== void 0 ? _a : null,
        mayUsePrecomputed
    });
    if (!moovBox) {
        return [];
    }
    return (0, exports.getTracksFromMoovBox)(moovBox);
};
exports.getTracksFromIsoBaseMedia = getTracksFromIsoBaseMedia;
const defaultGetTracks = (parserState)=>{
    const tracks = parserState.callbacks.tracks.getTracks();
    if (tracks.length === 0) {
        throw new Error('No tracks found');
    }
    return tracks;
};
exports.defaultGetTracks = defaultGetTracks;
const defaultHasallTracks = (parserState)=>{
    try {
        (0, exports.defaultGetTracks)(parserState);
        return true;
    } catch (_a) {
        return false;
    }
};
exports.defaultHasallTracks = defaultHasallTracks;
const getTracks = (state, mayUsePrecomputed)=>{
    const structure = state.structure.getStructure();
    if (structure.type === 'matroska') {
        return getCategorizedTracksFromMatroska(state);
    }
    if (structure.type === 'iso-base-media') {
        return (0, exports.getTracksFromIsoBaseMedia)({
            isoState: state.iso,
            m3uPlaylistContext: state.m3uPlaylistContext,
            structure: state.structure,
            mayUsePrecomputed
        });
    }
    if (structure.type === 'riff') {
        return (0, get_tracks_from_avi_1.getTracksFromAvi)(structure, state);
    }
    if (structure.type === 'transport-stream') {
        return (0, get_tracks_1.getTracksFromTransportStream)(state);
    }
    if (structure.type === 'mp3' || structure.type === 'wav' || structure.type === 'flac' || structure.type === 'aac' || structure.type === 'm3u') {
        return (0, exports.defaultGetTracks)(state);
    }
    throw new Error(`Unknown container${structure}`);
};
exports.getTracks = getTracks;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-audio-codec.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getAudioCodecFromTrack = exports.getAudioCodecStringFromTrak = exports.isTwosAudioCodec = exports.isIn24AudioCodec = exports.isLpcmAudioCodec = exports.getAudioCodecFromTrak = exports.getSampleRate = exports.getNumberOfChannelsFromTrak = exports.getCodecPrivateFromTrak = exports.hasAudioCodec = exports.getAudioCodec = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const getAudioCodec = (parserState)=>{
    const tracks = (0, get_tracks_1.getTracks)(parserState, true);
    if (tracks.length === 0) {
        throw new Error('No tracks yet');
    }
    const audioTrack = tracks.find((t)=>t.type === 'audio');
    if (!audioTrack) {
        return null;
    }
    if (audioTrack.type === 'audio') {
        return audioTrack.codecEnum;
    }
    return null;
};
exports.getAudioCodec = getAudioCodec;
const hasAudioCodec = (state)=>{
    return (0, get_tracks_1.getHasTracks)(state, true);
};
exports.hasAudioCodec = hasAudioCodec;
const getCodecSpecificatorFromEsdsBox = ({ child })=>{
    const descriptor = child.descriptors.find((d)=>d.type === 'decoder-config-descriptor');
    if (!descriptor) {
        throw new Error('No decoder-config-descriptor');
    }
    if (descriptor.type !== 'decoder-config-descriptor') {
        throw new Error('Expected decoder-config-descriptor');
    }
    if (descriptor.asNumber !== 0x40) {
        return {
            primary: descriptor.asNumber,
            secondary: null,
            description: undefined
        };
    }
    const audioSpecificConfig = descriptor.decoderSpecificConfigs.find((d)=>{
        return d.type === 'mp4a-specific-config' ? d : null;
    });
    if (!audioSpecificConfig || audioSpecificConfig.type !== 'mp4a-specific-config') {
        throw new Error('No audio-specific-config');
    }
    return {
        primary: descriptor.asNumber,
        secondary: audioSpecificConfig.audioObjectType,
        description: audioSpecificConfig.asBytes
    };
};
const getCodecPrivateFromTrak = (trakBox)=>{
    const stsdBox = (0, traversal_1.getStsdBox)(trakBox);
    if (!stsdBox) {
        return null;
    }
    const audioSample = stsdBox.samples.find((s)=>s.type === 'audio');
    if (!audioSample || audioSample.type !== 'audio') {
        return null;
    }
    const esds = audioSample.children.find((b)=>b.type === 'esds-box');
    if (!esds || esds.type !== 'esds-box') {
        return null;
    }
    const decoderConfigDescriptor = esds.descriptors.find((d)=>d.type === 'decoder-config-descriptor');
    if (!decoderConfigDescriptor) {
        return null;
    }
    const mp4a = decoderConfigDescriptor.decoderSpecificConfigs.find((d)=>d.type === 'mp4a-specific-config');
    if (!mp4a) {
        return null;
    }
    return {
        type: 'aac-config',
        data: mp4a.asBytes
    };
};
exports.getCodecPrivateFromTrak = getCodecPrivateFromTrak;
const onSample = (sample, children)=>{
    const child = children.find((c)=>c.type === 'esds-box');
    if (child && child.type === 'esds-box') {
        const ret = getCodecSpecificatorFromEsdsBox({
            child
        });
        return {
            format: sample.format,
            primarySpecificator: ret.primary,
            secondarySpecificator: ret.secondary,
            description: ret.description
        };
    }
    return {
        format: sample.format,
        primarySpecificator: null,
        secondarySpecificator: null,
        description: undefined
    };
};
const getNumberOfChannelsFromTrak = (trak)=>{
    const stsdBox = (0, traversal_1.getStsdBox)(trak);
    if (!stsdBox) {
        return null;
    }
    const sample = stsdBox.samples.find((s)=>s.type === 'audio');
    if (!sample || sample.type !== 'audio') {
        return null;
    }
    return sample.numberOfChannels;
};
exports.getNumberOfChannelsFromTrak = getNumberOfChannelsFromTrak;
const getSampleRate = (trak)=>{
    const stsdBox = (0, traversal_1.getStsdBox)(trak);
    if (!stsdBox) {
        return null;
    }
    const sample = stsdBox.samples.find((s)=>s.type === 'audio');
    if (!sample || sample.type !== 'audio') {
        return null;
    }
    return sample.sampleRate;
};
exports.getSampleRate = getSampleRate;
const getAudioCodecFromTrak = (trak)=>{
    const stsdBox = (0, traversal_1.getStsdBox)(trak);
    if (!stsdBox) {
        return null;
    }
    const sample = stsdBox.samples.find((s)=>s.type === 'audio');
    if (!sample || sample.type !== 'audio') {
        return null;
    }
    const waveBox = sample.children.find((b)=>b.type === 'regular-box' && b.boxType === 'wave');
    if (waveBox && waveBox.type === 'regular-box' && waveBox.boxType === 'wave') {
        const esdsSample = onSample(sample, waveBox.children);
        if ("TURBOPACK compile-time truthy", 1) {
            return esdsSample;
        }
    }
    const ret = onSample(sample, sample.children);
    if ("TURBOPACK compile-time truthy", 1) {
        return ret;
    }
    //TURBOPACK unreachable
    ;
};
exports.getAudioCodecFromTrak = getAudioCodecFromTrak;
const isLpcmAudioCodec = (trak)=>{
    var _a;
    return ((_a = (0, exports.getAudioCodecFromTrak)(trak)) === null || _a === void 0 ? void 0 : _a.format) === 'lpcm';
};
exports.isLpcmAudioCodec = isLpcmAudioCodec;
const isIn24AudioCodec = (trak)=>{
    var _a;
    return ((_a = (0, exports.getAudioCodecFromTrak)(trak)) === null || _a === void 0 ? void 0 : _a.format) === 'in24';
};
exports.isIn24AudioCodec = isIn24AudioCodec;
const isTwosAudioCodec = (trak)=>{
    var _a;
    return ((_a = (0, exports.getAudioCodecFromTrak)(trak)) === null || _a === void 0 ? void 0 : _a.format) === 'twos';
};
exports.isTwosAudioCodec = isTwosAudioCodec;
const getAudioCodecStringFromTrak = (trak)=>{
    const codec = (0, exports.getAudioCodecFromTrak)(trak);
    if (!codec) {
        throw new Error('Expected codec');
    }
    if (codec.format === 'lpcm') {
        return {
            codecString: 'pcm-s16',
            description: codec.description ? {
                type: 'unknown-data',
                data: codec.description
            } : undefined
        };
    }
    if (codec.format === 'twos') {
        return {
            codecString: 'pcm-s16',
            description: codec.description ? {
                type: 'unknown-data',
                data: codec.description
            } : undefined
        };
    }
    if (codec.format === 'in24') {
        return {
            codecString: 'pcm-s24',
            description: codec.description ? {
                type: 'unknown-data',
                data: codec.description
            } : undefined
        };
    }
    const codecStringWithoutMp3Exception = [
        codec.format,
        codec.primarySpecificator ? codec.primarySpecificator.toString(16) : null,
        codec.secondarySpecificator ? codec.secondarySpecificator.toString().padStart(2, '0') : null
    ].filter(Boolean).join('.');
    // Really, MP3? ðŸ˜”
    const codecString = codecStringWithoutMp3Exception.toLowerCase() === 'mp4a.6b' || codecStringWithoutMp3Exception.toLowerCase() === 'mp4a.69' ? 'mp3' // or "mp4a.6B" would also work, with the uppercasing, but mp3 is probably more obvious
     : codecStringWithoutMp3Exception;
    if (codecString === 'mp3') {
        return {
            codecString,
            description: codec.description ? {
                type: 'unknown-data',
                data: codec.description
            } : undefined
        };
    }
    if (codecString.startsWith('mp4a.')) {
        return {
            codecString,
            description: codec.description ? {
                type: 'aac-config',
                data: codec.description
            } : undefined
        };
    }
    return {
        codecString,
        description: codec.description ? {
            type: 'unknown-data',
            data: codec.description
        } : undefined
    };
};
exports.getAudioCodecStringFromTrak = getAudioCodecStringFromTrak;
const getAudioCodecFromAudioCodecInfo = (codec)=>{
    if (codec.format === 'twos') {
        return 'pcm-s16';
    }
    if (codec.format === 'in24') {
        return 'pcm-s24';
    }
    if (codec.format === 'lpcm') {
        return 'pcm-s16';
    }
    if (codec.format === 'sowt') {
        return 'aiff';
    }
    if (codec.format === 'ac-3') {
        return 'ac3';
    }
    if (codec.format === 'Opus') {
        return 'opus';
    }
    if (codec.format === 'mp4a') {
        if (codec.primarySpecificator === 0x40) {
            return 'aac';
        }
        if (codec.primarySpecificator === 0x6b) {
            return 'mp3';
        }
        if (codec.primarySpecificator === null) {
            return 'aac';
        }
        throw new Error('Unknown mp4a codec: ' + codec.primarySpecificator);
    }
    throw new Error(`Unknown audio format: ${codec.format}`);
};
const getAudioCodecFromTrack = (track)=>{
    const audioSample = (0, exports.getAudioCodecFromTrak)(track);
    if (!audioSample) {
        throw new Error('Could not find audio sample');
    }
    return getAudioCodecFromAudioCodecInfo(audioSample);
};
exports.getAudioCodecFromTrack = getAudioCodecFromTrack;
}),
"[project]/node_modules/@remotion/media-parser/dist/is-audio-structure.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isAudioStructure = void 0;
const isAudioStructure = (structure)=>{
    if (structure.type === 'mp3') {
        return true;
    }
    if (structure.type === 'wav') {
        return true;
    }
    if (structure.type === 'aac') {
        return true;
    }
    if (structure.type === 'flac') {
        return true;
    }
    if (structure.type === 'iso-base-media') {
        return false;
    }
    if (structure.type === 'matroska') {
        return false;
    }
    if (structure.type === 'transport-stream') {
        return false;
    }
    if (structure.type === 'riff') {
        return false;
    }
    if (structure.type === 'm3u') {
        return false;
    }
    throw new Error(`Unhandled structure type: ${structure}`);
};
exports.isAudioStructure = isAudioStructure;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-fps.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasFps = exports.hasFpsSuitedForSlowFps = exports.getFps = exports.getFpsFromMp4TrakBox = exports.getTimescaleAndDuration = exports.trakBoxContainsVideo = exports.trakBoxContainsAudio = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const traversal_2 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/traversal.js [app-route] (ecmascript)");
const is_audio_structure_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/is-audio-structure.js [app-route] (ecmascript)");
const calculateFps = ({ sttsBox, timeScale, durationInSamples })=>{
    let totalSamples = 0;
    for (const sample of sttsBox.sampleDistribution){
        totalSamples += sample.sampleCount;
    }
    if (totalSamples === 0) {
        return null;
    }
    const durationInSeconds = durationInSamples / timeScale;
    const fps = totalSamples / durationInSeconds;
    return fps;
};
const trakBoxContainsAudio = (trakBox)=>{
    const stsd = (0, traversal_1.getStsdBox)(trakBox);
    if (!stsd) {
        return false;
    }
    const videoSample = stsd.samples.find((s)=>s.type === 'audio');
    if (!videoSample || videoSample.type !== 'audio') {
        return false;
    }
    return true;
};
exports.trakBoxContainsAudio = trakBoxContainsAudio;
const trakBoxContainsVideo = (trakBox)=>{
    const stsd = (0, traversal_1.getStsdBox)(trakBox);
    if (!stsd) {
        return false;
    }
    const videoSample = stsd.samples.find((s)=>s.type === 'video');
    if (!videoSample || videoSample.type !== 'video') {
        return false;
    }
    return true;
};
exports.trakBoxContainsVideo = trakBoxContainsVideo;
const getTimescaleAndDuration = (trakBox)=>{
    const mdhdBox = (0, traversal_1.getMdhdBox)(trakBox);
    if (mdhdBox) {
        return {
            timescale: mdhdBox.timescale,
            duration: mdhdBox.duration
        };
    }
    return null;
};
exports.getTimescaleAndDuration = getTimescaleAndDuration;
const getFpsFromMp4TrakBox = (trakBox)=>{
    const timescaleAndDuration = (0, exports.getTimescaleAndDuration)(trakBox);
    if (!timescaleAndDuration) {
        return null;
    }
    const sttsBox = (0, traversal_1.getSttsBox)(trakBox);
    if (!sttsBox) {
        return null;
    }
    return calculateFps({
        sttsBox,
        timeScale: timescaleAndDuration.timescale,
        durationInSamples: timescaleAndDuration.duration
    });
};
exports.getFpsFromMp4TrakBox = getFpsFromMp4TrakBox;
const getFpsFromIsoMaseMedia = (state)=>{
    var _a, _b;
    const moovBox = (0, traversal_1.getMoovBoxFromState)({
        structureState: state.structure,
        isoState: state.iso,
        mp4HeaderSegment: (_b = (_a = state.m3uPlaylistContext) === null || _a === void 0 ? void 0 : _a.mp4HeaderSegment) !== null && _b !== void 0 ? _b : null,
        mayUsePrecomputed: true
    });
    if (!moovBox) {
        return null;
    }
    const trackBoxes = (0, traversal_1.getTraks)(moovBox);
    const trackBox = trackBoxes.find(exports.trakBoxContainsVideo);
    if (!trackBox) {
        return null;
    }
    return (0, exports.getFpsFromMp4TrakBox)(trackBox);
};
const getFpsFromAvi = (structure)=>{
    const strl = (0, traversal_2.getStrlBoxes)(structure);
    for (const s of strl){
        const strh = (0, traversal_2.getStrhBox)(s.children);
        if (!strh) {
            throw new Error('No strh box');
        }
        if (strh.fccType === 'auds') {
            continue;
        }
        return strh.rate;
    }
    return null;
};
const getFps = (state)=>{
    const segments = state.structure.getStructure();
    if (segments.type === 'iso-base-media') {
        return getFpsFromIsoMaseMedia(state);
    }
    if (segments.type === 'riff') {
        return getFpsFromAvi(segments);
    }
    // People need to get it from slowFps
    if (segments.type === 'matroska') {
        return null;
    }
    // People need to get it from slowFps
    if (segments.type === 'transport-stream') {
        return null;
    }
    // Same as m3u8
    if (segments.type === 'm3u') {
        return null;
    }
    if (segments.type === 'mp3' || segments.type === 'wav' || segments.type === 'flac' || segments.type === 'aac') {
        return null;
    }
    throw new Error('Cannot get fps, not implemented: ' + segments);
};
exports.getFps = getFps;
const hasFpsSuitedForSlowFps = (state)=>{
    try {
        return (0, exports.getFps)(state) !== null;
    } catch (_a) {
        return false;
    }
};
exports.hasFpsSuitedForSlowFps = hasFpsSuitedForSlowFps;
const hasFps = (state)=>{
    // Matroska and Transport stream has no FPS metadata
    // Not bothering to parse
    // Users should use `slowFps` field
    // same goes for audio
    const structure = state.structure.getStructure();
    if ((0, is_audio_structure_1.isAudioStructure)(structure)) {
        return true;
    }
    if (structure.type === 'matroska') {
        return true;
    }
    if (structure.type === 'transport-stream') {
        return true;
    }
    if (structure.type === 'm3u') {
        return true;
    }
    return (0, exports.hasFpsSuitedForSlowFps)(state);
};
exports.hasFps = hasFps;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-sample-aspect-ratio.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getDisplayAspectRatio = exports.applyAspectRatios = exports.applyTkhdBox = exports.getColrBox = exports.getSampleAspectRatio = exports.getHvccBox = exports.getPaspBox = exports.getAv1CBox = exports.getVpccBox = exports.getAvccBox = exports.getStsdVideoConfig = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const getStsdVideoConfig = (trakBox)=>{
    const stsdBox = (0, traversal_1.getStsdBox)(trakBox);
    if (!stsdBox) {
        return null;
    }
    const videoConfig = stsdBox.samples.find((s)=>s.type === 'video');
    if (!videoConfig || videoConfig.type !== 'video') {
        return null;
    }
    return videoConfig;
};
exports.getStsdVideoConfig = getStsdVideoConfig;
const getAvccBox = (trakBox)=>{
    const videoConfig = (0, exports.getStsdVideoConfig)(trakBox);
    if (!videoConfig) {
        return null;
    }
    const avccBox = videoConfig.descriptors.find((c)=>c.type === 'avcc-box');
    if (!avccBox || avccBox.type !== 'avcc-box') {
        return null;
    }
    return avccBox;
};
exports.getAvccBox = getAvccBox;
const getVpccBox = (trakBox)=>{
    const videoConfig = (0, exports.getStsdVideoConfig)(trakBox);
    if (!videoConfig) {
        return null;
    }
    const vpccBox = videoConfig.descriptors.find((c)=>c.type === 'vpcc-box');
    if (!vpccBox || vpccBox.type !== 'vpcc-box') {
        return null;
    }
    return vpccBox;
};
exports.getVpccBox = getVpccBox;
const getAv1CBox = (trakBox)=>{
    const videoConfig = (0, exports.getStsdVideoConfig)(trakBox);
    if (!videoConfig) {
        return null;
    }
    const av1cBox = videoConfig.descriptors.find((c)=>c.type === 'av1C-box');
    if (!av1cBox || av1cBox.type !== 'av1C-box') {
        return null;
    }
    return av1cBox;
};
exports.getAv1CBox = getAv1CBox;
const getPaspBox = (trakBox)=>{
    const videoConfig = (0, exports.getStsdVideoConfig)(trakBox);
    if (!videoConfig) {
        return null;
    }
    const paspBox = videoConfig.descriptors.find((c)=>c.type === 'pasp-box');
    if (!paspBox || paspBox.type !== 'pasp-box') {
        return null;
    }
    return paspBox;
};
exports.getPaspBox = getPaspBox;
const getHvccBox = (trakBox)=>{
    const videoConfig = (0, exports.getStsdVideoConfig)(trakBox);
    if (!videoConfig) {
        return null;
    }
    const hvccBox = videoConfig.descriptors.find((c)=>c.type === 'hvcc-box');
    if (!hvccBox || hvccBox.type !== 'hvcc-box') {
        return null;
    }
    return hvccBox;
};
exports.getHvccBox = getHvccBox;
const getSampleAspectRatio = (trakBox)=>{
    const paspBox = (0, exports.getPaspBox)(trakBox);
    if (!paspBox) {
        return {
            numerator: 1,
            denominator: 1
        };
    }
    return {
        numerator: paspBox.hSpacing,
        denominator: paspBox.vSpacing
    };
};
exports.getSampleAspectRatio = getSampleAspectRatio;
const getColrBox = (videoSample)=>{
    const colrBox = videoSample.descriptors.find((c)=>c.type === 'colr-box');
    if (!colrBox || colrBox.type !== 'colr-box') {
        return null;
    }
    return colrBox;
};
exports.getColrBox = getColrBox;
const applyTkhdBox = (aspectRatioApplied, tkhdBox)=>{
    if (tkhdBox === null || tkhdBox.rotation === 0) {
        return {
            displayAspectWidth: aspectRatioApplied.width,
            displayAspectHeight: aspectRatioApplied.height,
            width: aspectRatioApplied.width,
            height: aspectRatioApplied.height,
            rotation: 0
        };
    }
    return {
        width: tkhdBox.width,
        height: tkhdBox.height,
        rotation: tkhdBox.rotation,
        displayAspectWidth: aspectRatioApplied.width,
        displayAspectHeight: aspectRatioApplied.height
    };
};
exports.applyTkhdBox = applyTkhdBox;
const applyAspectRatios = ({ dimensions, sampleAspectRatio, displayAspectRatio })=>{
    if (displayAspectRatio.numerator === 0) {
        return dimensions;
    }
    if (displayAspectRatio.denominator === 0) {
        return dimensions;
    }
    const newWidth = Math.round(dimensions.width * sampleAspectRatio.numerator / sampleAspectRatio.denominator);
    const newHeight = Math.floor(newWidth / (displayAspectRatio.numerator / displayAspectRatio.denominator));
    return {
        width: Math.floor(newWidth),
        height: newHeight
    };
};
exports.applyAspectRatios = applyAspectRatios;
function gcd(a, b) {
    return b === 0 ? a : gcd(b, a % b);
}
function reduceFraction(numerator, denominator) {
    const greatestCommonDivisor = gcd(Math.abs(numerator), Math.abs(denominator));
    return {
        numerator: numerator / greatestCommonDivisor,
        denominator: denominator / greatestCommonDivisor
    };
}
const getDisplayAspectRatio = ({ sampleAspectRatio, nativeDimensions })=>{
    const num = Math.round(nativeDimensions.width * sampleAspectRatio.numerator);
    const den = Math.round(nativeDimensions.height * sampleAspectRatio.denominator);
    return reduceFraction(num, den);
};
exports.getDisplayAspectRatio = getDisplayAspectRatio;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-video-codec.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getVideoCodecString = exports.getIsoBmColrConfig = exports.getVideoPrivateData = exports.hasVideoCodec = exports.getVideoCodec = void 0;
const color_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/color.js [app-route] (ecmascript)");
const av1_codec_private_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/av1-codec-private.js [app-route] (ecmascript)");
const get_sample_aspect_ratio_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-sample-aspect-ratio.js [app-route] (ecmascript)");
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const getVideoCodec = (state)=>{
    var _a, _b;
    const track = (0, get_tracks_1.getTracks)(state, true);
    return (_b = (_a = track.find((t)=>t.type === 'video')) === null || _a === void 0 ? void 0 : _a.codecEnum) !== null && _b !== void 0 ? _b : null;
};
exports.getVideoCodec = getVideoCodec;
const hasVideoCodec = (state)=>{
    return (0, get_tracks_1.getHasTracks)(state, true);
};
exports.hasVideoCodec = hasVideoCodec;
const getVideoPrivateData = (trakBox)=>{
    const videoSample = (0, get_sample_aspect_ratio_1.getStsdVideoConfig)(trakBox);
    const avccBox = (0, get_sample_aspect_ratio_1.getAvccBox)(trakBox);
    const hvccBox = (0, get_sample_aspect_ratio_1.getHvccBox)(trakBox);
    const av1cBox = (0, get_sample_aspect_ratio_1.getAv1CBox)(trakBox);
    if (!videoSample) {
        return null;
    }
    if (avccBox) {
        return {
            type: 'avc-sps-pps',
            data: avccBox.privateData
        };
    }
    if (hvccBox) {
        return {
            type: 'hvcc-data',
            data: hvccBox.privateData
        };
    }
    if (av1cBox) {
        return {
            type: 'av1c-data',
            data: av1cBox.privateData
        };
    }
    return null;
};
exports.getVideoPrivateData = getVideoPrivateData;
const getIsoBmColrConfig = (trakBox)=>{
    const videoSample = (0, get_sample_aspect_ratio_1.getStsdVideoConfig)(trakBox);
    if (!videoSample) {
        return null;
    }
    const colrAtom = (0, get_sample_aspect_ratio_1.getColrBox)(videoSample);
    if (!colrAtom) {
        return null;
    }
    // TODO: Not doing anything with a in ICC color profile yet
    if (colrAtom.colorType !== 'transfer-characteristics') {
        return null;
    }
    // https://github.com/bbc/qtff-parameter-editor
    return {
        fullRange: colrAtom.fullRangeFlag,
        matrix: (0, color_1.getMatrixCoefficientsFromIndex)(colrAtom.matrixIndex),
        primaries: (0, color_1.getPrimariesFromIndex)(colrAtom.primaries),
        transfer: (0, color_1.getTransferCharacteristicsFromIndex)(colrAtom.transfer)
    };
};
exports.getIsoBmColrConfig = getIsoBmColrConfig;
const getVideoCodecString = (trakBox)=>{
    const videoSample = (0, get_sample_aspect_ratio_1.getStsdVideoConfig)(trakBox);
    const avccBox = (0, get_sample_aspect_ratio_1.getAvccBox)(trakBox);
    if (!videoSample) {
        return null;
    }
    if (avccBox) {
        return `${videoSample.format}.${avccBox.configurationString}`;
    }
    const hvccBox = (0, get_sample_aspect_ratio_1.getHvccBox)(trakBox);
    if (hvccBox) {
        return `${videoSample.format}.${hvccBox.configurationString}`;
    }
    const av1cBox = (0, get_sample_aspect_ratio_1.getAv1CBox)(trakBox);
    if (av1cBox) {
        const colrAtom = (0, get_sample_aspect_ratio_1.getColrBox)(videoSample);
        return (0, av1_codec_private_1.parseAv1PrivateData)(av1cBox.privateData, colrAtom);
    }
    const vpccBox = (0, get_sample_aspect_ratio_1.getVpccBox)(trakBox);
    if (vpccBox) {
        return `${videoSample.format}.${vpccBox.codecString}`;
    }
    return videoSample.format;
};
exports.getVideoCodecString = getVideoCodecString;
}),
"[project]/node_modules/@remotion/media-parser/dist/normalize-video-rotation.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.normalizeVideoRotation = void 0;
const normalizeVideoRotation = (rotation)=>{
    return (rotation % 360 + 360) % 360;
};
exports.normalizeVideoRotation = normalizeVideoRotation;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-actual-number-of-channels.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getActualDecoderParameters = void 0;
const aac_codecprivate_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/aac-codecprivate.js [app-route] (ecmascript)");
// Example video:	'https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/riverside.mp4';
// This video has `numberOfChannels = 2`, but the actual number of channels is `1` according to Codec Private.
// Therefore, prioritizing Codec Private over `numberOfChannels`.
const getActualDecoderParameters = ({ audioCodec, codecPrivate, numberOfChannels, sampleRate })=>{
    if (audioCodec !== 'aac') {
        return {
            numberOfChannels,
            sampleRate,
            codecPrivate
        };
    }
    if (codecPrivate === null) {
        return {
            numberOfChannels,
            sampleRate,
            codecPrivate
        };
    }
    if (codecPrivate.type !== 'aac-config') {
        throw new Error('Expected AAC codec private data');
    }
    const parsed = (0, aac_codecprivate_1.parseAacCodecPrivate)(codecPrivate.data);
    const actual = (0, aac_codecprivate_1.createAacCodecPrivate)({
        ...parsed,
        codecPrivate: codecPrivate.data
    });
    return {
        numberOfChannels: parsed.channelConfiguration,
        sampleRate: parsed.sampleRate,
        codecPrivate: {
            type: 'aac-config',
            data: actual
        }
    };
};
exports.getActualDecoderParameters = getActualDecoderParameters;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-video-codec-from-iso-track.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getVideoCodecFromIsoTrak = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const getVideoCodecFromIsoTrak = (trakBox)=>{
    const stsdBox = (0, traversal_1.getStsdBox)(trakBox);
    if (stsdBox && stsdBox.type === 'stsd-box') {
        const videoSample = stsdBox.samples.find((s)=>s.type === 'video');
        if (videoSample && videoSample.type === 'video') {
            if (videoSample.format === 'hvc1' || videoSample.format === 'hev1') {
                return 'h265';
            }
            if (videoSample.format === 'avc1') {
                return 'h264';
            }
            if (videoSample.format === 'av01') {
                return 'av1';
            }
            if (videoSample.format === 'vp09') {
                return 'vp9';
            }
            // ap4h: ProRes 4444
            if (videoSample.format === 'ap4h') {
                return 'prores';
            }
            // ap4x: ap4x: ProRes 4444 XQ
            if (videoSample.format === 'ap4x') {
                return 'prores';
            }
            // apch: ProRes 422 High Quality
            if (videoSample.format === 'apch') {
                return 'prores';
            }
            // apcn: ProRes 422 Standard Definition
            if (videoSample.format === 'apcn') {
                return 'prores';
            }
            // apcs: ProRes 422 LT
            if (videoSample.format === 'apcs') {
                return 'prores';
            }
            // apco: ProRes 422 Proxy
            if (videoSample.format === 'apco') {
                return 'prores';
            }
            // aprh: ProRes RAW High Quality
            if (videoSample.format === 'aprh') {
                return 'prores';
            }
            // aprn: ProRes RAW Standard Definition
            if (videoSample.format === 'aprn') {
                return 'prores';
            }
        }
    }
    throw new Error('Could not find video codec');
};
exports.getVideoCodecFromIsoTrak = getVideoCodecFromIsoTrak;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/make-track.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makeBaseMediaTrack = void 0;
const get_audio_codec_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-audio-codec.js [app-route] (ecmascript)");
const get_fps_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-fps.js [app-route] (ecmascript)");
const get_sample_aspect_ratio_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-sample-aspect-ratio.js [app-route] (ecmascript)");
const get_video_codec_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-video-codec.js [app-route] (ecmascript)");
const normalize_video_rotation_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/normalize-video-rotation.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const color_to_webcodecs_colors_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/color-to-webcodecs-colors.js [app-route] (ecmascript)");
const get_actual_number_of_channels_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-actual-number-of-channels.js [app-route] (ecmascript)");
const get_video_codec_from_iso_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-video-codec-from-iso-track.js [app-route] (ecmascript)");
const get_editlist_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mdat/get-editlist.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const makeBaseMediaTrack = (trakBox, startTimeInSeconds)=>{
    var _a, _b, _c, _d, _e;
    const tkhdBox = (0, traversal_1.getTkhdBox)(trakBox);
    const videoDescriptors = (0, traversal_1.getVideoDescriptors)(trakBox);
    const timescaleAndDuration = (0, get_fps_1.getTimescaleAndDuration)(trakBox);
    if (!tkhdBox) {
        throw new Error('Expected tkhd box in trak box');
    }
    if (!timescaleAndDuration) {
        throw new Error('Expected timescale and duration in trak box');
    }
    if ((0, get_fps_1.trakBoxContainsAudio)(trakBox)) {
        const numberOfChannels = (0, get_audio_codec_1.getNumberOfChannelsFromTrak)(trakBox);
        if (numberOfChannels === null) {
            throw new Error('Could not find number of channels');
        }
        const sampleRate = (0, get_audio_codec_1.getSampleRate)(trakBox);
        if (sampleRate === null) {
            throw new Error('Could not find sample rate');
        }
        const { codecString, description } = (0, get_audio_codec_1.getAudioCodecStringFromTrak)(trakBox);
        const codecPrivate = (_b = (_a = (0, get_audio_codec_1.getCodecPrivateFromTrak)(trakBox)) !== null && _a !== void 0 ? _a : description) !== null && _b !== void 0 ? _b : null;
        const codecEnum = (0, get_audio_codec_1.getAudioCodecFromTrack)(trakBox);
        const actual = (0, get_actual_number_of_channels_1.getActualDecoderParameters)({
            audioCodec: codecEnum,
            codecPrivate: codecPrivate !== null && codecPrivate !== void 0 ? codecPrivate : null,
            numberOfChannels,
            sampleRate
        });
        return {
            type: 'audio',
            trackId: tkhdBox.trackId,
            originalTimescale: timescaleAndDuration.timescale,
            codec: codecString,
            numberOfChannels: actual.numberOfChannels,
            sampleRate: actual.sampleRate,
            description: (_d = (_c = actual.codecPrivate) === null || _c === void 0 ? void 0 : _c.data) !== null && _d !== void 0 ? _d : undefined,
            codecData: actual.codecPrivate,
            codecEnum,
            startInSeconds: startTimeInSeconds,
            timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
            trackMediaTimeOffsetInTrackTimescale: (0, get_editlist_1.findTrackMediaTimeOffsetInTrackTimescale)({
                trakBox
            })
        };
    }
    if (!(0, get_fps_1.trakBoxContainsVideo)(trakBox)) {
        return {
            type: 'other',
            trackId: tkhdBox.trackId,
            originalTimescale: timescaleAndDuration.timescale,
            trakBox,
            startInSeconds: startTimeInSeconds,
            timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
            trackMediaTimeOffsetInTrackTimescale: (0, get_editlist_1.findTrackMediaTimeOffsetInTrackTimescale)({
                trakBox
            })
        };
    }
    const videoSample = (0, get_sample_aspect_ratio_1.getStsdVideoConfig)(trakBox);
    if (!videoSample) {
        throw new Error('No video sample');
    }
    const sampleAspectRatio = (0, get_sample_aspect_ratio_1.getSampleAspectRatio)(trakBox);
    const aspectRatioApplied = (0, get_sample_aspect_ratio_1.applyAspectRatios)({
        dimensions: videoSample,
        sampleAspectRatio,
        displayAspectRatio: (0, get_sample_aspect_ratio_1.getDisplayAspectRatio)({
            sampleAspectRatio,
            nativeDimensions: videoSample
        })
    });
    const { displayAspectHeight, displayAspectWidth, height, rotation, width } = (0, get_sample_aspect_ratio_1.applyTkhdBox)(aspectRatioApplied, tkhdBox);
    const codec = (0, get_video_codec_1.getVideoCodecString)(trakBox);
    if (!codec) {
        throw new Error('Could not find video codec');
    }
    const privateData = (0, get_video_codec_1.getVideoPrivateData)(trakBox);
    const advancedColor = (_e = (0, get_video_codec_1.getIsoBmColrConfig)(trakBox)) !== null && _e !== void 0 ? _e : {
        fullRange: null,
        matrix: null,
        primaries: null,
        transfer: null
    };
    const track = {
        m3uStreamFormat: null,
        type: 'video',
        trackId: tkhdBox.trackId,
        description: videoDescriptors !== null && videoDescriptors !== void 0 ? videoDescriptors : undefined,
        originalTimescale: timescaleAndDuration.timescale,
        codec,
        sampleAspectRatio: (0, get_sample_aspect_ratio_1.getSampleAspectRatio)(trakBox),
        width,
        height,
        codedWidth: videoSample.width,
        codedHeight: videoSample.height,
        // Repeating those keys because they get picked up by VideoDecoder
        displayAspectWidth,
        displayAspectHeight,
        rotation: (0, normalize_video_rotation_1.normalizeVideoRotation)(0 - rotation),
        codecData: privateData,
        colorSpace: (0, color_to_webcodecs_colors_1.mediaParserAdvancedColorToWebCodecsColor)(advancedColor),
        advancedColor,
        codecEnum: (0, get_video_codec_from_iso_track_1.getVideoCodecFromIsoTrak)(trakBox),
        fps: (0, get_fps_1.getFpsFromMp4TrakBox)(trakBox),
        startInSeconds: startTimeInSeconds,
        timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
        trackMediaTimeOffsetInTrackTimescale: (0, get_editlist_1.findTrackMediaTimeOffsetInTrackTimescale)({
            trakBox
        })
    };
    return track;
};
exports.makeBaseMediaTrack = makeBaseMediaTrack;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mdhd.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMdhd = void 0;
const parseMdhd = ({ data, size, fileOffset })=>{
    const version = data.getUint8();
    // flags, we discard them
    data.discard(3);
    // creation time
    const creationTime = version === 1 ? Number(data.getUint64()) : data.getUint32();
    // modification time
    const modificationTime = version === 1 ? Number(data.getUint64()) : data.getUint32();
    const timescale = data.getUint32();
    const duration = version === 1 ? data.getUint64() : data.getUint32();
    const language = data.getUint16();
    // quality
    const quality = data.getUint16();
    const remaining = size - (data.counter.getOffset() - fileOffset);
    if (remaining !== 0) {
        throw new Error(`Expected remaining bytes to be 0, got ${remaining}`);
    }
    return {
        type: 'mdhd-box',
        duration: Number(duration),
        timescale,
        version,
        language,
        quality,
        creationTime,
        modificationTime
    };
};
exports.parseMdhd = parseMdhd;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/meta/hdlr.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseHdlr = void 0;
const parseHdlr = ({ iterator, size, offset })=>{
    const box = iterator.startBox(size - 8);
    const version = iterator.getUint8();
    if (version !== 0) {
        throw new Error(`Unsupported hdlr version: ${version}`);
    }
    // version
    iterator.discard(3);
    // predefined
    iterator.discard(4);
    // type
    const hdlrType = iterator.getByteString(4, false);
    // component manufactor
    iterator.discard(4);
    // component flags
    iterator.discard(4);
    // component flags mask
    iterator.discard(4);
    // component name
    const componentName = iterator.readUntilNullTerminator();
    box.discardRest();
    return Promise.resolve({
        type: 'hdlr-box',
        boxSize: size,
        offset,
        hdlrType,
        componentName
    });
};
exports.parseHdlr = parseHdlr;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/meta/ilst.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseIlstBox = void 0;
// https://developer.apple.com/documentation/quicktime-file-format/well-known_types
const parseFromWellKnownType = (wellKnownType, iterator, size)=>{
    if (wellKnownType === 1) {
        const value = iterator.getByteString(size, false);
        return {
            type: 'text',
            value
        };
    }
    if (wellKnownType === 21) {
        if (size === 1) {
            return {
                type: 'number',
                value: iterator.getInt8()
            };
        }
        if (size === 2) {
            return {
                type: 'number',
                value: iterator.getInt16()
            };
        }
        if (size === 3) {
            return {
                type: 'number',
                value: iterator.getInt24()
            };
        }
        if (size === 4) {
            return {
                type: 'number',
                value: iterator.getInt32()
            };
        }
        if (size === 8) {
            return {
                type: 'number',
                value: Number(iterator.getInt64())
            };
        }
        throw new Error(`Weird size for number ${size}`);
    }
    if (wellKnownType === 22) {
        if (size === 1) {
            return {
                type: 'number',
                value: iterator.getUint8()
            };
        }
        if (size === 2) {
            return {
                type: 'number',
                value: iterator.getUint16()
            };
        }
        if (size === 3) {
            return {
                type: 'number',
                value: iterator.getUint24()
            };
        }
        if (size === 4) {
            return {
                type: 'number',
                value: iterator.getUint32()
            };
        }
        throw new Error(`Weird size for number ${size}`);
    }
    if (wellKnownType === 23) {
        if (size === 4) {
            return {
                type: 'number',
                value: iterator.getFloat32()
            };
        }
        if (size === 8) {
            return {
                type: 'number',
                value: iterator.getFloat64()
            };
        }
        throw new Error(`Weird size for number ${size}`);
    }
    iterator.discard(size);
    return {
        type: 'unknown',
        value: null
    };
};
const parseIlstBox = ({ iterator, size, offset })=>{
    const box = iterator.startBox(size - 8);
    const entries = [];
    while(iterator.counter.getOffset() < size + offset){
        // metadata size
        const metadataSize = iterator.getUint32();
        const index = iterator.getAtom();
        // this can be of a different type
        if (!index.startsWith('ï¿½') && !index.startsWith('\u0000')) {
            // "skip" as a number
            if (index === 'skip') {
                iterator.discard(metadataSize - 8);
                continue;
            }
            // "----" atom in m4a files
            // iTunes adds it for .m4a files
            // not very interesting data, so we don't parse them
            if (index === '----') {
                iterator.discard(metadataSize - 8);
                continue;
            }
            iterator.discard(metadataSize - 8);
            continue;
        }
        const innerSize = iterator.getUint32();
        const type = iterator.getAtom();
        const typeIndicator = iterator.getUint8();
        if (typeIndicator !== 0) {
            throw new Error('Expected type indicator to be 0');
        }
        const wellKnownType = iterator.getUint24();
        iterator.discard(4);
        const value = parseFromWellKnownType(wellKnownType, iterator, innerSize - 16);
        entries.push({
            index,
            type,
            wellKnownType,
            value
        });
    }
    box.discardRest();
    return {
        type: 'ilst-box',
        boxSize: size,
        offset,
        entries
    };
};
exports.parseIlstBox = parseIlstBox;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mfra/tfra.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseTfraBox = void 0;
const readTrafNumber = (iterator, lengthSizeOfTrafNum)=>{
    const uintTypeTrafNum = (lengthSizeOfTrafNum + 1) * 8;
    if (uintTypeTrafNum === 8) {
        return iterator.getUint8();
    }
    if (uintTypeTrafNum === 16) {
        return iterator.getUint16();
    }
    if (uintTypeTrafNum === 32) {
        return iterator.getUint32();
    }
    if (uintTypeTrafNum === 64) {
        return Number(iterator.getUint64());
    }
    throw new Error('Invalid traf number size');
};
const readTrunNumber = (iterator, lengthSizeOfTrunNum)=>{
    const uintTypeTrunNum = (lengthSizeOfTrunNum + 1) * 8;
    if (uintTypeTrunNum === 8) {
        return iterator.getUint8();
    }
    if (uintTypeTrunNum === 16) {
        return iterator.getUint16();
    }
    if (uintTypeTrunNum === 32) {
        return iterator.getUint32();
    }
    if (uintTypeTrunNum === 64) {
        return Number(iterator.getUint64());
    }
    throw new Error('Invalid trun number size');
};
const readSampleNumber = (iterator, lengthSizeOfSampleNum)=>{
    const uintTypeSampleNum = (lengthSizeOfSampleNum + 1) * 8;
    if (uintTypeSampleNum === 8) {
        return iterator.getUint8();
    }
    if (uintTypeSampleNum === 16) {
        return iterator.getUint16();
    }
    if (uintTypeSampleNum === 32) {
        return iterator.getUint32();
    }
    if (uintTypeSampleNum === 64) {
        return Number(iterator.getUint64());
    }
    throw new Error('Invalid sample number size');
};
const readTime = (iterator, version)=>{
    if (version === 1) {
        return Number(iterator.getUint64());
    }
    return iterator.getUint32();
};
const readMoofOffset = (iterator, version)=>{
    if (version === 1) {
        return Number(iterator.getUint64());
    }
    return iterator.getUint32();
};
const parseTfraBox = ({ iterator, size, offset })=>{
    const box = iterator.startBox(size - 8);
    const version = iterator.getUint8();
    // flags, we discard them
    iterator.discard(3);
    const trackId = iterator.getUint32();
    iterator.getUint24();
    const tmpByte = iterator.getUint8();
    const lengthSizeOfTrafNum = tmpByte >> 4 & 0x3;
    const lengthSizeOfTrunNum = tmpByte >> 2 & 0x3;
    const lengthSizeOfSampleNum = tmpByte & 0x3;
    const numberOfEntries = iterator.getUint32();
    const entries = [];
    for(let i = 0; i < numberOfEntries; i++){
        const time = readTime(iterator, version);
        const moofOffset = readMoofOffset(iterator, version);
        const trafNumber = readTrafNumber(iterator, lengthSizeOfTrafNum);
        const trunNumber = readTrunNumber(iterator, lengthSizeOfTrunNum);
        const sampleNumber = readSampleNumber(iterator, lengthSizeOfSampleNum);
        entries.push({
            time,
            moofOffset,
            trafNumber,
            trunNumber,
            sampleNumber
        });
    }
    box.expectNoMoreBytes();
    return {
        offset,
        boxSize: size,
        type: 'tfra-box',
        entries,
        trackId
    };
};
exports.parseTfraBox = parseTfraBox;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/moov/moov.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMoov = void 0;
const get_children_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-children.js [app-route] (ecmascript)");
const parseMoov = async ({ offset, size, onlyIfMoovAtomExpected, iterator, logLevel, contentLength })=>{
    const children = await (0, get_children_1.getIsoBaseMediaChildren)({
        onlyIfMoovAtomExpected,
        size: size - 8,
        iterator,
        logLevel,
        contentLength
    });
    return {
        offset,
        boxSize: size,
        type: 'moov-box',
        children
    };
};
exports.parseMoov = parseMoov;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/moov/trex.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseTrex = void 0;
const parseTrex = ({ iterator, offset, size })=>{
    const box = iterator.startBox(size - 8);
    const version = iterator.getUint8();
    // Flags, we discard them
    iterator.discard(3);
    const trackId = iterator.getUint32();
    const defaultSampleDescriptionIndex = iterator.getUint32();
    const defaultSampleDuration = iterator.getUint32();
    const defaultSampleSize = iterator.getUint32();
    const defaultSampleFlags = iterator.getUint32();
    box.expectNoMoreBytes();
    return {
        type: 'trex-box',
        boxSize: size,
        offset,
        trackId,
        version,
        defaultSampleDescriptionIndex,
        defaultSampleDuration,
        defaultSampleSize,
        defaultSampleFlags
    };
};
exports.parseTrex = parseTrex;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/av1c.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseAv1C = void 0;
const parseAv1C = ({ data, size })=>{
    return {
        type: 'av1C-box',
        privateData: data.getSlice(size - 8)
    };
};
exports.parseAv1C = parseAv1C;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/avcc.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseAvcc = void 0;
const parseAvcc = ({ data, size })=>{
    const confVersion = data.getUint8();
    if (confVersion !== 1) {
        throw new Error(`Unsupported AVCC version ${confVersion}`);
    }
    const profile = data.getUint8();
    const profileCompatibility = data.getUint8();
    const level = data.getUint8();
    const str = `${profile.toString(16).padStart(2, '0')}${profileCompatibility.toString(16).padStart(2, '0')}${level.toString(16).padStart(2, '0')}`;
    data.counter.decrement(4);
    const privateData = data.getSlice(size - 8);
    return {
        type: 'avcc-box',
        privateData,
        configurationString: str
    };
};
exports.parseAvcc = parseAvcc;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/parse-icc-profile.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseIccProfile = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const parseIccProfile = (data)=>{
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: data,
        maxBytes: data.length,
        logLevel: 'error'
    });
    const size = iterator.getUint32();
    if (size !== data.length) {
        throw new Error('Invalid ICC profile size');
    }
    const preferredCMMType = iterator.getByteString(4, false);
    const profileVersion = iterator.getByteString(4, false);
    const profileDeviceClass = iterator.getByteString(4, false);
    const colorSpace = iterator.getByteString(4, false);
    const pcs = iterator.getByteString(4, false);
    const dateTime = iterator.getSlice(12);
    const signature = iterator.getByteString(4, false);
    if (signature !== 'acsp') {
        throw new Error('Invalid ICC profile signature');
    }
    const primaryPlatform = iterator.getByteString(4, false);
    const profileFlags = iterator.getUint32();
    const deviceManufacturer = iterator.getByteString(4, false);
    const deviceModel = iterator.getByteString(4, false);
    const deviceAttributes = iterator.getUint64();
    const renderingIntent = iterator.getUint32();
    const pcsIlluminant1 = iterator.getUint32();
    const pcsIlluminant2 = iterator.getUint32();
    const pcsIlluminant3 = iterator.getUint32();
    const profileCreator = iterator.getByteString(4, false);
    const profileId = iterator.getByteString(16, false);
    // reserved
    iterator.discard(28);
    const tagCount = iterator.getUint32();
    const entries = [];
    for(let i = 0; i < tagCount; i++){
        const entry = {
            tag: iterator.getByteString(4, false),
            offset: iterator.getUint32(),
            size: iterator.getUint32()
        };
        entries.push(entry);
    }
    let lastOffset = -1;
    let rXYZ = null;
    let gXYZ = null;
    let bXYZ = null;
    let whitePoint = null;
    for (const entry of entries){
        const found = data.slice(entry.offset, entry.offset + entry.size);
        if (entry.tag === 'rXYZ' || entry.tag === 'gXYZ' || entry.tag === 'bXYZ' || entry.tag === 'wtpt') {
            const it = (0, buffer_iterator_1.getArrayBufferIterator)({
                initialData: found,
                maxBytes: found.length,
                logLevel: 'error'
            });
            it.discard(4);
            const x = it.getInt32() / 65536;
            const y = it.getInt32() / 65536;
            const z = it.getInt32() / 65536;
            it.destroy();
            const point = {
                x,
                y,
                z
            };
            if (entry.tag === 'rXYZ') {
                rXYZ = point;
            } else if (entry.tag === 'gXYZ') {
                gXYZ = point;
            } else if (entry.tag === 'bXYZ') {
                bXYZ = point;
            } else if (entry.tag === 'wtpt') {
                whitePoint = point;
            }
        }
        if (lastOffset !== -1) {
            const bytesToAdvance = entry.offset - lastOffset;
            const bytesToGoBackwards = entry.size - bytesToAdvance;
            if (bytesToGoBackwards > 0) {
                iterator.counter.decrement(bytesToGoBackwards);
            }
        }
        lastOffset = entry.offset;
    }
    const profile = {
        size,
        preferredCMMType,
        profileVersion,
        profileDeviceClass,
        colorSpace,
        pcs,
        dateTime,
        signature,
        primaryPlatform,
        profileFlags,
        deviceManufacturer,
        deviceModel,
        deviceAttributes,
        renderingIntent,
        pcsIlluminant: [
            pcsIlluminant1 / 65536,
            pcsIlluminant2 / 65536,
            pcsIlluminant3 / 65536
        ],
        profileCreator,
        profileId,
        entries,
        bXYZ,
        gXYZ,
        rXYZ,
        whitePoint
    };
    iterator.destroy();
    return profile;
};
exports.parseIccProfile = parseIccProfile;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/colr.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseColorParameterBox = void 0;
const parse_icc_profile_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/parse-icc-profile.js [app-route] (ecmascript)");
const parseColorParameterBox = ({ iterator, size })=>{
    const byteString = iterator.getByteString(4, false);
    if (byteString === 'nclx') {
        const primaries = iterator.getUint16();
        const transfer = iterator.getUint16();
        const matrixIndex = iterator.getUint16();
        iterator.startReadingBits();
        const fullRangeFlag = Boolean(iterator.getBits(1));
        iterator.stopReadingBits();
        return {
            type: 'colr-box',
            colorType: 'transfer-characteristics',
            fullRangeFlag,
            matrixIndex,
            primaries,
            transfer
        };
    }
    if (byteString === 'nclc') {
        const primaries = iterator.getUint16();
        const transfer = iterator.getUint16();
        const matrixIndex = iterator.getUint16();
        return {
            type: 'colr-box',
            colorType: 'transfer-characteristics',
            fullRangeFlag: false,
            matrixIndex,
            primaries,
            transfer
        };
    }
    if (byteString === 'prof') {
        const profile = iterator.getSlice(size - 12);
        return {
            type: 'colr-box',
            colorType: 'icc-profile',
            profile,
            parsed: (0, parse_icc_profile_1.parseIccProfile)(profile)
        };
    }
    throw new Error('Unexpected box type ' + byteString);
};
exports.parseColorParameterBox = parseColorParameterBox;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/ctts.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseCtts = void 0;
const parseCtts = ({ iterator, offset, size })=>{
    const version = iterator.getUint8();
    if (version !== 0 && version !== 1) {
        throw new Error(`Unsupported CTTS version ${version}`);
    }
    const flags = iterator.getSlice(3);
    const entryCount = iterator.getUint32();
    const entries = [];
    for(let i = 0; i < entryCount; i++){
        const sampleCount = iterator.getUint32();
        // V1 = signed, V0 = unsigned
        // however some files are buggy
        // Let's do the same thing as mp4box
        // https://github.com/gpac/mp4box.js/blob/c6cc468145bc5b031b866446111f29c8b620dbe6/src/parsing/ctts.js#L2
        const sampleOffset = iterator.getInt32();
        entries.push({
            sampleCount,
            sampleOffset
        });
    }
    return {
        type: 'ctts-box',
        boxSize: size,
        offset,
        version,
        flags: [
            ...flags
        ],
        entryCount,
        entries
    };
};
exports.parseCtts = parseCtts;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/hvcc.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseHvcc = void 0;
const make_hvc1_codec_strings_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/make-hvc1-codec-strings.js [app-route] (ecmascript)");
const parseHvcc = ({ data, size, offset })=>{
    const privateData = data.getSlice(size - 8);
    data.counter.decrement(size - 8);
    const constraintString = (0, make_hvc1_codec_strings_1.getHvc1CodecString)(data);
    const remaining = size - (data.counter.getOffset() - offset);
    data.discard(remaining);
    return {
        type: 'hvcc-box',
        privateData,
        configurationString: constraintString
    };
};
exports.parseHvcc = parseHvcc;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/keys.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseKeys = void 0;
const parseKeys = ({ iterator, offset, size })=>{
    const box = iterator.startBox(size - 8);
    const version = iterator.getUint8();
    // flags
    iterator.discard(3);
    // entry_count
    const entryCount = iterator.getUint32();
    const entries = [];
    for(let i = 0; i < entryCount; i++){
        // key_size
        const keySize = iterator.getUint32();
        const namespace = iterator.getAtom();
        const value = iterator.getByteString(keySize - 8, false);
        // data
        const entry = {
            keySize,
            namespace,
            value
        };
        entries.push(entry);
    }
    box.discardRest();
    return {
        type: 'keys-box',
        boxSize: size,
        offset,
        version,
        entryCount,
        entries
    };
};
exports.parseKeys = parseKeys;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/mebx.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMebx = void 0;
const get_children_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-children.js [app-route] (ecmascript)");
const parseMebx = async ({ offset, size, iterator, logLevel, contentLength })=>{
    // reserved, 6 bit
    iterator.discard(6);
    const dataReferenceIndex = iterator.getUint16();
    const children = await (0, get_children_1.getIsoBaseMediaChildren)({
        iterator,
        size: size - 8,
        logLevel,
        onlyIfMoovAtomExpected: null,
        contentLength
    });
    return {
        type: 'mebx-box',
        boxSize: size,
        offset,
        dataReferenceIndex,
        format: 'mebx',
        children
    };
};
exports.parseMebx = parseMebx;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/pasp.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parsePasp = void 0;
const parsePasp = ({ iterator, offset, size })=>{
    const hSpacing = iterator.getUint32();
    const vSpacing = iterator.getUint32();
    const bytesRemainingInBox = size - (iterator.counter.getOffset() - offset);
    iterator.discard(bytesRemainingInBox);
    return {
        type: 'pasp-box',
        boxSize: size,
        offset,
        hSpacing,
        vSpacing
    };
};
exports.parsePasp = parsePasp;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stco.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseStco = void 0;
const parseStco = ({ iterator, offset, size, mode64Bit })=>{
    const version = iterator.getUint8();
    if (version !== 0) {
        throw new Error(`Unsupported STSD version ${version}`);
    }
    const flags = iterator.getSlice(3);
    const entryCount = iterator.getUint32();
    const entries = [];
    for(let i = 0; i < entryCount; i++){
        const bytesRemaining = size - (iterator.counter.getOffset() - offset);
        if (bytesRemaining < 4) {
            break;
        }
        entries.push(mode64Bit ? iterator.getUint64() : iterator.getUint32());
    }
    iterator.discard(size - (iterator.counter.getOffset() - offset));
    return {
        type: 'stco-box',
        boxSize: size,
        offset,
        version,
        flags: [
            ...flags
        ],
        entries,
        entryCount
    };
};
exports.parseStco = parseStco;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stsc.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseStsc = void 0;
const parseStsc = ({ iterator, offset, size })=>{
    const version = iterator.getUint8();
    if (version !== 0) {
        throw new Error(`Unsupported STSD version ${version}`);
    }
    const flags = iterator.getSlice(3);
    const entryCount = iterator.getUint32();
    const entries = new Map();
    for(let i = 0; i < entryCount; i++){
        const firstChunk = iterator.getUint32();
        const samplesPerChunk = iterator.getUint32();
        const sampleDescriptionIndex = iterator.getUint32();
        if (sampleDescriptionIndex !== 1) {
            throw new Error(`Expected sampleDescriptionIndex to be 1, but got ${sampleDescriptionIndex}`);
        }
        entries.set(firstChunk, samplesPerChunk);
    }
    return {
        type: 'stsc-box',
        boxSize: size,
        offset,
        version,
        flags: [
            ...flags
        ],
        entryCount,
        entries
    };
};
exports.parseStsc = parseStsc;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stsd.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseStsd = void 0;
const samples_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/samples.js [app-route] (ecmascript)");
const parseStsd = async ({ offset, size, iterator, logLevel, contentLength })=>{
    const version = iterator.getUint8();
    if (version !== 0) {
        throw new Error(`Unsupported STSD version ${version}`);
    }
    // flags, we discard them
    iterator.discard(3);
    const numberOfEntries = iterator.getUint32();
    const bytesRemainingInBox = size - (iterator.counter.getOffset() - offset);
    const boxes = await (0, samples_1.parseIsoFormatBoxes)({
        maxBytes: bytesRemainingInBox,
        logLevel,
        iterator,
        contentLength
    });
    if (boxes.length !== numberOfEntries) {
        throw new Error(`Expected ${numberOfEntries} sample descriptions, got ${boxes.length}`);
    }
    return {
        type: 'stsd-box',
        boxSize: size,
        offset,
        numberOfEntries,
        samples: boxes
    };
};
exports.parseStsd = parseStsd;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stss.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseStss = void 0;
const parseStss = ({ iterator, offset, boxSize })=>{
    const version = iterator.getUint8();
    if (version !== 0) {
        throw new Error(`Unsupported STSS version ${version}`);
    }
    const flags = iterator.getSlice(3);
    const sampleCount = iterator.getUint32();
    const sampleNumber = new Set();
    for(let i = 0; i < sampleCount; i++){
        sampleNumber.add(iterator.getUint32());
    }
    const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - offset);
    if (bytesRemainingInBox > 0) {
        iterator.discard(bytesRemainingInBox);
    }
    return {
        type: 'stss-box',
        version,
        flags: [
            ...flags
        ],
        sampleNumber,
        boxSize,
        offset
    };
};
exports.parseStss = parseStss;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stsz.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseStsz = void 0;
const parseStsz = ({ iterator, offset, size })=>{
    const version = iterator.getUint8();
    if (version !== 0) {
        throw new Error(`Unsupported STSD version ${version}`);
    }
    const flags = iterator.getSlice(3);
    const sampleSize = iterator.getUint32();
    const sampleCount = iterator.getUint32();
    if (sampleSize !== 0) {
        return {
            type: 'stsz-box',
            boxSize: size,
            offset,
            version,
            flags: [
                ...flags
            ],
            sampleCount,
            countType: 'fixed',
            sampleSize
        };
    }
    const samples = [];
    for(let i = 0; i < sampleCount; i++){
        const bytesRemaining = size - (iterator.counter.getOffset() - offset);
        if (bytesRemaining < 4) {
            break;
        }
        samples.push(iterator.getUint32());
    }
    iterator.discard(size - (iterator.counter.getOffset() - offset));
    return {
        type: 'stsz-box',
        boxSize: size,
        offset,
        version,
        flags: [
            ...flags
        ],
        sampleCount,
        countType: 'variable',
        entries: samples
    };
};
exports.parseStsz = parseStsz;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stts.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseStts = void 0;
const parseStts = ({ data, size, fileOffset })=>{
    const initialOffset = data.counter.getOffset();
    const initialCounter = initialOffset - fileOffset;
    const version = data.getUint8();
    if (version !== 0) {
        throw new Error(`Unsupported STTS version ${version}`);
    }
    // flags, we discard them
    data.discard(3);
    // entry count
    const entryCount = data.getUint32();
    const sampleDistributions = [];
    // entries
    for(let i = 0; i < entryCount; i++){
        const sampleCount = data.getUint32();
        const sampleDelta = data.getUint32();
        const sampleDistribution = {
            sampleCount,
            sampleDelta
        };
        sampleDistributions.push(sampleDistribution);
    }
    const bytesUsed = data.counter.getOffset() - initialOffset + initialCounter;
    if (bytesUsed !== size) {
        throw new Error(`Expected stts box to be ${size} bytes, but was ${bytesUsed} bytes`);
    }
    return {
        type: 'stts-box',
        sampleDistribution: sampleDistributions
    };
};
exports.parseStts = parseStts;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/vpcc.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseVpcc = void 0;
const getvp09ConfigurationString = ({ profile, level, bitDepth })=>{
    return `${String(profile).padStart(2, '0')}.${String(level).padStart(2, '0')}.${String(bitDepth).padStart(2, '0')}`;
};
const parseVpcc = ({ data, size })=>{
    const box = data.startBox(size - 8);
    const confVersion = data.getUint8();
    if (confVersion !== 1) {
        throw new Error(`Unsupported AVCC version ${confVersion}`);
    }
    data.discard(3); // flags
    const profile = data.getUint8();
    const level = data.getUint8();
    data.startReadingBits();
    const bitDepth = data.getBits(4);
    const chromaSubsampling = data.getBits(3);
    const videoFullRangeFlag = data.getBits(1);
    const videoColorPrimaries = data.getBits(8);
    const videoTransferCharacteristics = data.getBits(8);
    const videoMatrixCoefficients = data.getBits(8);
    data.stopReadingBits();
    const codecInitializationDataSize = data.getUint16();
    const codecInitializationData = data.getSlice(codecInitializationDataSize);
    box.expectNoMoreBytes();
    return {
        type: 'vpcc-box',
        profile,
        level,
        bitDepth,
        chromaSubsampling,
        videoFullRangeFlag,
        videoColorPrimaries,
        videoTransferCharacteristics,
        videoMatrixCoefficients,
        codecInitializationDataSize,
        codecInitializationData,
        codecString: getvp09ConfigurationString({
            profile,
            level,
            bitDepth
        })
    };
};
exports.parseVpcc = parseVpcc;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/tfdt.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseTfdt = void 0;
const parseTfdt = ({ iterator, size, offset })=>{
    const version = iterator.getUint8();
    iterator.discard(3);
    // Flags, discard them
    const num = version === 0 ? iterator.getUint32() : Number(iterator.getUint64());
    const bytesRemaining = size - (iterator.counter.getOffset() - offset);
    if (bytesRemaining !== 0) {
        throw new Error('expected 0 bytes ' + bytesRemaining);
    }
    return {
        type: 'tfdt-box',
        version,
        baseMediaDecodeTime: num,
        offset
    };
};
exports.parseTfdt = parseTfdt;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/tfhd.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getTfhd = void 0;
const getTfhd = ({ iterator, offset, size })=>{
    const version = iterator.getUint8();
    const flags = iterator.getUint24();
    const trackId = iterator.getUint32();
    const baseDataOffsetPresent = flags & 0x01;
    const baseDataOffset = baseDataOffsetPresent ? Number(iterator.getUint64()) : 0;
    const baseSampleDescriptionIndexPresent = flags & 0x02;
    const baseSampleDescriptionIndex = baseSampleDescriptionIndexPresent ? iterator.getUint32() : 0;
    const defaultSampleDurationPresent = flags & 0x08;
    const defaultSampleDuration = defaultSampleDurationPresent ? iterator.getUint32() : 0;
    const defaultSampleSizePresent = flags & 0x10;
    const defaultSampleSize = defaultSampleSizePresent ? iterator.getUint32() : 0;
    const defaultSampleFlagsPresent = flags & 0x20;
    const defaultSampleFlags = defaultSampleFlagsPresent ? iterator.getUint32() : 0;
    const bytesRemaining = size - (iterator.counter.getOffset() - offset);
    if (bytesRemaining !== 0) {
        throw new Error('expected 0 bytes ' + bytesRemaining);
    }
    return {
        type: 'tfhd-box',
        version,
        trackId,
        baseDataOffset,
        baseSampleDescriptionIndex,
        defaultSampleDuration,
        defaultSampleSize,
        defaultSampleFlags
    };
};
exports.getTfhd = getTfhd;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/tkhd.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseTkhd = void 0;
const to_date_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/to-date.js [app-route] (ecmascript)");
function getRotationAngleFromMatrix(matrix) {
    // Extract elements from the matrix
    const [a, b, c, d] = matrix;
    if (a === 0 && b === 0 && c === 0 && d === 0) {
        return 0;
    }
    // Check if the matrix is a valid rotation matrix
    if (Math.round(a * a + b * b) !== 1 || Math.round(c * c + d * d) !== 1) {
        throw new Error('The provided matrix is not a valid rotation matrix.');
    }
    // Calculate the angle using the atan2 function
    const angleRadians = Math.atan2(c, a); // atan2(sin(Î¸), cos(Î¸))
    const angleDegrees = angleRadians * (180 / Math.PI); // Convert radians to degrees
    return angleDegrees;
}
const applyRotation = ({ matrix, width, height })=>{
    const newWidth = matrix[0] * width + matrix[1] * height; // 0*3840 + 1*2160
    const newHeight = matrix[2] * width + matrix[3] * height; // -1*3840 + 0*2160
    return {
        width: Math.abs(newWidth),
        height: Math.abs(newHeight)
    };
};
const parseTkhd = ({ iterator, offset, size })=>{
    const version = iterator.getUint8();
    // Flags, we discard them
    iterator.discard(3);
    const creationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
    const modificationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
    const trackId = iterator.getUint32();
    // reserved
    iterator.discard(4);
    const duration = version === 1 ? iterator.getUint64() : iterator.getUint32();
    // reserved 2
    iterator.discard(4);
    // reserved 3
    iterator.discard(4);
    const layer = iterator.getUint16();
    const alternateGroup = iterator.getUint16();
    const volume = iterator.getUint16();
    // reserved 4
    iterator.discard(2);
    const matrix = [
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned230Number(),
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned230Number(),
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned1616Number(),
        iterator.getFixedPointSigned230Number()
    ];
    const rotationMatrix = [
        matrix[0],
        matrix[1],
        matrix[3],
        matrix[4]
    ];
    const widthWithoutRotationApplied = iterator.getFixedPointUnsigned1616Number();
    const heightWithoutRotationApplied = iterator.getFixedPointSigned1616Number();
    const { width, height } = applyRotation({
        matrix: rotationMatrix,
        width: widthWithoutRotationApplied,
        height: heightWithoutRotationApplied
    });
    const rotation = getRotationAngleFromMatrix(rotationMatrix);
    return {
        offset,
        boxSize: size,
        type: 'tkhd-box',
        creationTime: (0, to_date_1.toUnixTimestamp)(Number(creationTime)),
        modificationTime: (0, to_date_1.toUnixTimestamp)(Number(modificationTime)),
        trackId,
        duration: Number(duration),
        layer,
        alternateGroup,
        volume,
        matrix: matrix,
        width,
        height,
        version,
        rotation,
        unrotatedWidth: widthWithoutRotationApplied,
        unrotatedHeight: heightWithoutRotationApplied
    };
};
exports.parseTkhd = parseTkhd;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/trak/trak.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseTrak = void 0;
const get_children_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-children.js [app-route] (ecmascript)");
const parseTrak = async ({ size, offsetAtStart, iterator, logLevel, contentLength })=>{
    const children = await (0, get_children_1.getIsoBaseMediaChildren)({
        onlyIfMoovAtomExpected: null,
        size: size - 8,
        iterator,
        logLevel,
        contentLength
    });
    return {
        offset: offsetAtStart,
        boxSize: size,
        type: 'trak-box',
        children
    };
};
exports.parseTrak = parseTrak;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/trun.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseTrun = void 0;
const parseTrun = ({ iterator, offset, size })=>{
    const version = iterator.getUint8();
    if (version !== 0 && version !== 1) {
        throw new Error(`Unsupported TRUN version ${version}`);
    }
    const flags = iterator.getUint24();
    const sampleCount = iterator.getUint32();
    const dataOffset = flags & 0x01 ? iterator.getInt32() : null;
    const firstSampleFlags = flags & 0x04 ? iterator.getUint32() : null;
    const samples = [];
    for(let i = 0; i < sampleCount; i++){
        const sampleDuration = flags & 0x100 ? iterator.getUint32() : null;
        const sampleSize = flags & 0x200 ? iterator.getUint32() : null;
        const sampleFlags = flags & 0x400 ? iterator.getUint32() : null;
        const sampleCompositionTimeOffset = flags & 0x800 ? version === 0 ? iterator.getUint32() : iterator.getInt32() : null;
        samples.push({
            sampleDuration,
            sampleSize,
            sampleFlags,
            sampleCompositionTimeOffset
        });
    }
    const currentOffset = iterator.counter.getOffset();
    const left = size - (currentOffset - offset);
    if (left !== 0) {
        throw new Error(`Unexpected data left in TRUN box: ${left}`);
    }
    return {
        type: 'trun-box',
        version,
        sampleCount,
        dataOffset,
        firstSampleFlags,
        samples
    };
};
exports.parseTrun = parseTrun;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/process-box.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.processBox = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const skip_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/skip.js [app-route] (ecmascript)");
const elst_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/elst.js [app-route] (ecmascript)");
const esds_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/esds/esds.js [app-route] (ecmascript)");
const ftyp_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/ftyp.js [app-route] (ecmascript)");
const get_children_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-children.js [app-route] (ecmascript)");
const make_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/make-track.js [app-route] (ecmascript)");
const get_editlist_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mdat/get-editlist.js [app-route] (ecmascript)");
const mdhd_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mdhd.js [app-route] (ecmascript)");
const hdlr_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/meta/hdlr.js [app-route] (ecmascript)");
const ilst_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/meta/ilst.js [app-route] (ecmascript)");
const tfra_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mfra/tfra.js [app-route] (ecmascript)");
const moov_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/moov/moov.js [app-route] (ecmascript)");
const mvhd_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/moov/mvhd.js [app-route] (ecmascript)");
const trex_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/moov/trex.js [app-route] (ecmascript)");
const av1c_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/av1c.js [app-route] (ecmascript)");
const avcc_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/avcc.js [app-route] (ecmascript)");
const colr_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/colr.js [app-route] (ecmascript)");
const ctts_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/ctts.js [app-route] (ecmascript)");
const hvcc_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/hvcc.js [app-route] (ecmascript)");
const keys_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/keys.js [app-route] (ecmascript)");
const mebx_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/mebx.js [app-route] (ecmascript)");
const pasp_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/pasp.js [app-route] (ecmascript)");
const stco_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stco.js [app-route] (ecmascript)");
const stsc_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stsc.js [app-route] (ecmascript)");
const stsd_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stsd.js [app-route] (ecmascript)");
const stss_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stss.js [app-route] (ecmascript)");
const stsz_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stsz.js [app-route] (ecmascript)");
const stts_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stts.js [app-route] (ecmascript)");
const vpcc_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/vpcc.js [app-route] (ecmascript)");
const tfdt_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/tfdt.js [app-route] (ecmascript)");
const tfhd_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/tfhd.js [app-route] (ecmascript)");
const tkhd_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/tkhd.js [app-route] (ecmascript)");
const trak_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/trak/trak.js [app-route] (ecmascript)");
const trun_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/trun.js [app-route] (ecmascript)");
const processBox = async ({ iterator, logLevel, onlyIfMoovAtomExpected, onlyIfMdatAtomExpected, contentLength })=>{
    var _a, _b;
    const fileOffset = iterator.counter.getOffset();
    const { returnToCheckpoint } = iterator.startCheckpoint();
    const bytesRemaining = iterator.bytesRemaining();
    const startOff = iterator.counter.getOffset();
    const boxSizeRaw = iterator.getFourByteNumber();
    if (boxSizeRaw === 0) {
        return {
            type: 'box',
            box: {
                type: 'void-box',
                boxSize: 0
            }
        };
    }
    // If `boxSize === 1`, the 8 bytes after the box type are the size of the box.
    if (boxSizeRaw === 1 && iterator.bytesRemaining() < 12 || iterator.bytesRemaining() < 4) {
        iterator.counter.decrement(iterator.counter.getOffset() - fileOffset);
        throw new Error(`Expected box size of ${bytesRemaining}, got ${boxSizeRaw}. Incomplete boxes are not allowed.`);
    }
    const maxSize = contentLength - startOff;
    const boxType = iterator.getByteString(4, false);
    const boxSizeUnlimited = boxSizeRaw === 1 ? iterator.getEightByteNumber() : boxSizeRaw;
    const boxSize = Math.min(boxSizeUnlimited, maxSize);
    const headerLength = iterator.counter.getOffset() - startOff;
    if (boxType === 'mdat') {
        if (!onlyIfMdatAtomExpected) {
            return {
                type: 'nothing'
            };
        }
        const { mediaSectionState } = onlyIfMdatAtomExpected;
        mediaSectionState.addMediaSection({
            size: boxSize - headerLength,
            start: iterator.counter.getOffset()
        });
        return {
            type: 'nothing'
        };
    }
    if (bytesRemaining < boxSize) {
        returnToCheckpoint();
        return {
            type: 'fetch-more-data',
            bytesNeeded: (0, skip_1.makeFetchMoreData)(boxSize - bytesRemaining)
        };
    }
    if (boxType === 'ftyp') {
        return {
            type: 'box',
            box: (0, ftyp_1.parseFtyp)({
                iterator,
                size: boxSize,
                offset: fileOffset
            })
        };
    }
    if (boxType === 'elst') {
        return {
            type: 'box',
            box: (0, elst_1.parseElst)({
                iterator,
                size: boxSize,
                offset: fileOffset
            })
        };
    }
    if (boxType === 'colr') {
        return {
            type: 'box',
            box: (0, colr_1.parseColorParameterBox)({
                iterator,
                size: boxSize
            })
        };
    }
    if (boxType === 'mvhd') {
        const mvhdBox = (0, mvhd_1.parseMvhd)({
            iterator,
            offset: fileOffset,
            size: boxSize
        });
        if (!onlyIfMoovAtomExpected) {
            throw new Error('State is required');
        }
        onlyIfMoovAtomExpected.movieTimeScaleState.setTrackTimescale(mvhdBox.timeScale);
        return {
            type: 'box',
            box: mvhdBox
        };
    }
    if (boxType === 'tkhd') {
        return {
            type: 'box',
            box: (0, tkhd_1.parseTkhd)({
                iterator,
                offset: fileOffset,
                size: boxSize
            })
        };
    }
    if (boxType === 'trun') {
        return {
            type: 'box',
            box: (0, trun_1.parseTrun)({
                iterator,
                offset: fileOffset,
                size: boxSize
            })
        };
    }
    if (boxType === 'tfdt') {
        return {
            type: 'box',
            box: (0, tfdt_1.parseTfdt)({
                iterator,
                size: boxSize,
                offset: fileOffset
            })
        };
    }
    if (boxType === 'stsd') {
        return {
            type: 'box',
            box: await (0, stsd_1.parseStsd)({
                offset: fileOffset,
                size: boxSize,
                iterator,
                logLevel,
                contentLength
            })
        };
    }
    if (boxType === 'stsz') {
        return {
            type: 'box',
            box: (0, stsz_1.parseStsz)({
                iterator,
                offset: fileOffset,
                size: boxSize
            })
        };
    }
    if (boxType === 'stco' || boxType === 'co64') {
        return {
            type: 'box',
            box: (0, stco_1.parseStco)({
                iterator,
                offset: fileOffset,
                size: boxSize,
                mode64Bit: boxType === 'co64'
            })
        };
    }
    if (boxType === 'pasp') {
        return {
            type: 'box',
            box: (0, pasp_1.parsePasp)({
                iterator,
                offset: fileOffset,
                size: boxSize
            })
        };
    }
    if (boxType === 'stss') {
        return {
            type: 'box',
            box: (0, stss_1.parseStss)({
                iterator,
                offset: fileOffset,
                boxSize
            })
        };
    }
    if (boxType === 'ctts') {
        return {
            type: 'box',
            box: (0, ctts_1.parseCtts)({
                iterator,
                offset: fileOffset,
                size: boxSize
            })
        };
    }
    if (boxType === 'stsc') {
        return {
            type: 'box',
            box: (0, stsc_1.parseStsc)({
                iterator,
                offset: fileOffset,
                size: boxSize
            })
        };
    }
    if (boxType === 'mebx') {
        return {
            type: 'box',
            box: await (0, mebx_1.parseMebx)({
                offset: fileOffset,
                size: boxSize,
                iterator,
                logLevel,
                contentLength
            })
        };
    }
    if (boxType === 'hdlr') {
        return {
            type: 'box',
            box: await (0, hdlr_1.parseHdlr)({
                iterator,
                size: boxSize,
                offset: fileOffset
            })
        };
    }
    if (boxType === 'keys') {
        return {
            type: 'box',
            box: await (0, keys_1.parseKeys)({
                iterator,
                size: boxSize,
                offset: fileOffset
            })
        };
    }
    if (boxType === 'ilst') {
        return {
            type: 'box',
            box: await (0, ilst_1.parseIlstBox)({
                iterator,
                offset: fileOffset,
                size: boxSize
            })
        };
    }
    if (boxType === 'tfra') {
        return {
            type: 'box',
            box: await (0, tfra_1.parseTfraBox)({
                iterator,
                offset: fileOffset,
                size: boxSize
            })
        };
    }
    if (boxType === 'moov') {
        if (!onlyIfMoovAtomExpected) {
            throw new Error('State is required');
        }
        const { tracks, isoState } = onlyIfMoovAtomExpected;
        if (tracks.hasAllTracks()) {
            iterator.discard(boxSize - 8);
            return {
                type: 'nothing'
            };
        }
        if (isoState && isoState.moov.getMoovBoxAndPrecomputed() && !((_a = isoState.moov.getMoovBoxAndPrecomputed()) === null || _a === void 0 ? void 0 : _a.precomputed)) {
            log_1.Log.verbose(logLevel, 'Moov box already parsed, skipping');
            iterator.discard(boxSize - 8);
            return {
                type: 'nothing'
            };
        }
        const box = await (0, moov_1.parseMoov)({
            offset: fileOffset,
            size: boxSize,
            onlyIfMoovAtomExpected,
            iterator,
            logLevel,
            contentLength
        });
        tracks.setIsDone(logLevel);
        return {
            type: 'box',
            box
        };
    }
    if (boxType === 'trak') {
        if (!onlyIfMoovAtomExpected) {
            throw new Error('State is required');
        }
        const { tracks, onAudioTrack, onVideoTrack } = onlyIfMoovAtomExpected;
        const trakBox = await (0, trak_1.parseTrak)({
            size: boxSize,
            offsetAtStart: fileOffset,
            iterator,
            logLevel,
            contentLength
        });
        const movieTimeScale = onlyIfMoovAtomExpected.movieTimeScaleState.getTrackTimescale();
        if (movieTimeScale === null) {
            throw new Error('Movie timescale is not set');
        }
        const editList = (0, get_editlist_1.findTrackStartTimeInSeconds)({
            movieTimeScale,
            trakBox
        });
        const transformedTrack = (0, make_track_1.makeBaseMediaTrack)(trakBox, editList);
        if (transformedTrack && transformedTrack.type === 'video') {
            await (0, register_track_1.registerVideoTrack)({
                track: transformedTrack,
                container: 'mp4',
                logLevel,
                onVideoTrack,
                registerVideoSampleCallback: onlyIfMoovAtomExpected.registerVideoSampleCallback,
                tracks
            });
        }
        if (transformedTrack && transformedTrack.type === 'audio') {
            await (0, register_track_1.registerAudioTrack)({
                track: transformedTrack,
                container: 'mp4',
                registerAudioSampleCallback: onlyIfMoovAtomExpected.registerAudioSampleCallback,
                tracks,
                logLevel,
                onAudioTrack
            });
        }
        return {
            type: 'box',
            box: trakBox
        };
    }
    if (boxType === 'stts') {
        return {
            type: 'box',
            box: (0, stts_1.parseStts)({
                data: iterator,
                size: boxSize,
                fileOffset
            })
        };
    }
    if (boxType === 'avcC') {
        return {
            type: 'box',
            box: (0, avcc_1.parseAvcc)({
                data: iterator,
                size: boxSize
            })
        };
    }
    if (boxType === 'vpcC') {
        return {
            type: 'box',
            box: (0, vpcc_1.parseVpcc)({
                data: iterator,
                size: boxSize
            })
        };
    }
    if (boxType === 'av1C') {
        return {
            type: 'box',
            box: (0, av1c_1.parseAv1C)({
                data: iterator,
                size: boxSize
            })
        };
    }
    if (boxType === 'hvcC') {
        return {
            type: 'box',
            box: (0, hvcc_1.parseHvcc)({
                data: iterator,
                size: boxSize,
                offset: fileOffset
            })
        };
    }
    if (boxType === 'tfhd') {
        return {
            type: 'box',
            box: (0, tfhd_1.getTfhd)({
                iterator,
                offset: fileOffset,
                size: boxSize
            })
        };
    }
    if (boxType === 'mdhd') {
        return {
            type: 'box',
            box: (0, mdhd_1.parseMdhd)({
                data: iterator,
                size: boxSize,
                fileOffset
            })
        };
    }
    if (boxType === 'esds') {
        return {
            type: 'box',
            box: (0, esds_1.parseEsds)({
                data: iterator,
                size: boxSize,
                fileOffset
            })
        };
    }
    if (boxType === 'trex') {
        return {
            type: 'box',
            box: (0, trex_1.parseTrex)({
                iterator,
                offset: fileOffset,
                size: boxSize
            })
        };
    }
    if (boxType === 'moof') {
        await ((_b = onlyIfMoovAtomExpected === null || onlyIfMoovAtomExpected === void 0 ? void 0 : onlyIfMoovAtomExpected.isoState) === null || _b === void 0 ? void 0 : _b.mfra.triggerLoad());
    }
    if (boxType === 'mdia' || boxType === 'minf' || boxType === 'stbl' || boxType === 'udta' || boxType === 'moof' || boxType === 'dims' || boxType === 'meta' || boxType === 'wave' || boxType === 'traf' || boxType === 'mfra' || boxType === 'edts' || boxType === 'mvex' || boxType === 'stsb') {
        const children = await (0, get_children_1.getIsoBaseMediaChildren)({
            iterator,
            size: boxSize - 8,
            logLevel,
            onlyIfMoovAtomExpected,
            contentLength
        });
        return {
            type: 'box',
            box: {
                type: 'regular-box',
                boxType,
                boxSize,
                children,
                offset: fileOffset
            }
        };
    }
    iterator.discard(boxSize - 8);
    log_1.Log.verbose(logLevel, 'Unknown ISO Base Media Box:', boxType);
    return {
        type: 'box',
        box: {
            type: 'regular-box',
            boxType,
            boxSize,
            children: [],
            offset: fileOffset
        }
    };
};
exports.processBox = processBox;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-children.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getIsoBaseMediaChildren = void 0;
const process_box_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/process-box.js [app-route] (ecmascript)");
const getIsoBaseMediaChildren = async ({ size, iterator, logLevel, onlyIfMoovAtomExpected, contentLength })=>{
    const boxes = [];
    const initial = iterator.counter.getOffset();
    while(iterator.counter.getOffset() < size + initial){
        const parsed = await (0, process_box_1.processBox)({
            iterator,
            logLevel,
            onlyIfMoovAtomExpected,
            onlyIfMdatAtomExpected: null,
            contentLength
        });
        if (parsed.type !== 'box') {
            throw new Error('Expected box');
        }
        boxes.push(parsed.box);
    }
    if (iterator.counter.getOffset() > size + initial) {
        throw new Error(`read too many bytes - size: ${size}, read: ${iterator.counter.getOffset() - initial}. initial offset: ${initial}`);
    }
    return boxes;
};
exports.getIsoBaseMediaChildren = getIsoBaseMediaChildren;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/samples.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseIsoFormatBoxes = exports.processIsoFormatBox = void 0;
const get_children_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-children.js [app-route] (ecmascript)");
// https://developer.apple.com/documentation/quicktime-file-format/video_sample_description
const videoTags = [
    'cvid',
    'jpeg',
    'smc ',
    'rle ',
    'rpza',
    'kpcd',
    'png ',
    'mjpa',
    'mjpb',
    'SVQ1',
    'SVQ3',
    'mp4v',
    'avc1',
    'dvc ',
    'dvcp',
    'gif ',
    'h263',
    'tiff',
    'raw ',
    '2vuY',
    'yuv2',
    'v308',
    'v408',
    'v216',
    'v410',
    'v210',
    'hvc1',
    'hev1',
    'ap4h',
    'av01',
    'vp08',
    'vp09'
];
// https://developer.apple.com/documentation/quicktime-file-format/sound_sample_descriptions
const audioTags = [
    0x00000000,
    'NONE',
    'raw ',
    'twos',
    'sowt',
    'MAC3 ',
    'MAC6 ',
    'ima4',
    'fl32',
    'lpcm',
    'fl64',
    'in24',
    'in32',
    'ulaw',
    'alaw',
    0x6d730002,
    0x6d730011,
    'dvca',
    'QDMC',
    'QDM2',
    'Qclp',
    0x6d730055,
    '.mp3',
    'mp4a',
    'ac-3',
    'Opus'
];
const processIsoFormatBox = async ({ iterator, logLevel, contentLength })=>{
    const fileOffset = iterator.counter.getOffset();
    const bytesRemaining = iterator.bytesRemaining();
    const boxSize = iterator.getUint32();
    if (bytesRemaining < boxSize) {
        throw new Error(`Expected box size of ${bytesRemaining}, got ${boxSize}`);
    }
    const boxFormat = iterator.getAtom();
    const isVideo = videoTags.includes(boxFormat);
    const isAudio = audioTags.includes(boxFormat) || audioTags.includes(Number(boxFormat));
    // 6 reserved bytes
    iterator.discard(6);
    const dataReferenceIndex = iterator.getUint16();
    if (!isVideo && !isAudio) {
        const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);
        iterator.discard(bytesRemainingInBox);
        return {
            sample: {
                type: 'unknown',
                offset: fileOffset,
                dataReferenceIndex,
                size: boxSize,
                format: boxFormat
            }
        };
    }
    if (isAudio) {
        const version = iterator.getUint16();
        const revisionLevel = iterator.getUint16();
        const vendor = iterator.getSlice(4);
        if (version === 0) {
            const numberOfChannels = iterator.getUint16();
            const sampleSize = iterator.getUint16();
            const compressionId = iterator.getUint16();
            const packetSize = iterator.getUint16();
            const sampleRate = iterator.getFixedPointUnsigned1616Number();
            const children = await (0, get_children_1.getIsoBaseMediaChildren)({
                iterator,
                logLevel,
                size: boxSize - (iterator.counter.getOffset() - fileOffset),
                onlyIfMoovAtomExpected: null,
                contentLength
            });
            return {
                sample: {
                    format: boxFormat,
                    offset: fileOffset,
                    dataReferenceIndex,
                    version,
                    revisionLevel,
                    vendor: [
                        ...Array.from(new Uint8Array(vendor))
                    ],
                    size: boxSize,
                    type: 'audio',
                    numberOfChannels,
                    sampleSize,
                    compressionId,
                    packetSize,
                    sampleRate,
                    samplesPerPacket: null,
                    bytesPerPacket: null,
                    bytesPerFrame: null,
                    bitsPerSample: null,
                    children
                }
            };
        }
        if (version === 1) {
            const numberOfChannels = iterator.getUint16();
            const sampleSize = iterator.getUint16();
            const compressionId = iterator.getInt16();
            const packetSize = iterator.getUint16();
            const sampleRate = iterator.getFixedPointUnsigned1616Number();
            const samplesPerPacket = iterator.getUint32();
            const bytesPerPacket = iterator.getUint32();
            const bytesPerFrame = iterator.getUint32();
            const bytesPerSample = iterator.getUint32();
            const children = await (0, get_children_1.getIsoBaseMediaChildren)({
                iterator,
                logLevel,
                size: boxSize - (iterator.counter.getOffset() - fileOffset),
                onlyIfMoovAtomExpected: null,
                contentLength
            });
            return {
                sample: {
                    format: boxFormat,
                    offset: fileOffset,
                    dataReferenceIndex,
                    version,
                    revisionLevel,
                    vendor: [
                        ...Array.from(new Uint8Array(vendor))
                    ],
                    size: boxSize,
                    type: 'audio',
                    numberOfChannels,
                    sampleSize,
                    compressionId,
                    packetSize,
                    sampleRate,
                    samplesPerPacket,
                    bytesPerPacket,
                    bytesPerFrame,
                    bitsPerSample: bytesPerSample,
                    children
                }
            };
        }
        if (version === 2) {
            iterator.getUint16(); // always 3
            const sampleSize = iterator.getUint16();
            const compressionId = iterator.getUint16();
            const packetSize = iterator.getUint16();
            iterator.getFixedPointUnsigned1616Number(); // LQ sample rate;
            iterator.getUint32(); // ignore
            const higherSampleRate = iterator.getFloat64();
            const numAudioChannel = iterator.getUint32(); // ignore;
            iterator.getUint32(); // ignore, always 0x7F000000?
            const bitsPerChannel = iterator.getUint32();
            iterator.getUint32(); // ignore;
            const bytesPerFrame = iterator.getUint32();
            const samplesPerPacket = iterator.getUint32();
            const children = await (0, get_children_1.getIsoBaseMediaChildren)({
                iterator,
                logLevel,
                size: boxSize - (iterator.counter.getOffset() - fileOffset),
                onlyIfMoovAtomExpected: null,
                contentLength
            });
            return {
                sample: {
                    format: boxFormat,
                    offset: fileOffset,
                    dataReferenceIndex,
                    version,
                    revisionLevel,
                    vendor: [
                        ...Array.from(new Uint8Array(vendor))
                    ],
                    size: boxSize,
                    type: 'audio',
                    numberOfChannels: numAudioChannel,
                    sampleSize,
                    compressionId,
                    packetSize,
                    sampleRate: higherSampleRate,
                    samplesPerPacket,
                    bytesPerPacket: null,
                    bytesPerFrame,
                    bitsPerSample: bitsPerChannel,
                    children
                }
            };
        }
        throw new Error(`Unsupported version ${version}`);
    }
    if (isVideo) {
        const version = iterator.getUint16();
        const revisionLevel = iterator.getUint16();
        const vendor = iterator.getSlice(4);
        const temporalQuality = iterator.getUint32();
        const spacialQuality = iterator.getUint32();
        const width = iterator.getUint16();
        const height = iterator.getUint16();
        const horizontalResolution = iterator.getFixedPointUnsigned1616Number();
        const verticalResolution = iterator.getFixedPointUnsigned1616Number();
        const dataSize = iterator.getUint32();
        const frameCountPerSample = iterator.getUint16();
        const compressorName = iterator.getPascalString();
        const depth = iterator.getUint16();
        const colorTableId = iterator.getInt16();
        const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);
        const children = bytesRemainingInBox > 8 ? await (0, get_children_1.getIsoBaseMediaChildren)({
            onlyIfMoovAtomExpected: null,
            iterator,
            logLevel,
            size: bytesRemainingInBox,
            contentLength
        }) : (iterator.discard(bytesRemainingInBox), []);
        return {
            sample: {
                format: boxFormat,
                offset: fileOffset,
                dataReferenceIndex,
                version,
                revisionLevel,
                vendor: [
                    ...Array.from(new Uint8Array(vendor))
                ],
                size: boxSize,
                type: 'video',
                width,
                height,
                horizontalResolutionPpi: horizontalResolution,
                verticalResolutionPpi: verticalResolution,
                spacialQuality,
                temporalQuality,
                dataSize,
                frameCountPerSample,
                compressorName,
                depth,
                colorTableId,
                descriptors: children
            }
        };
    }
    throw new Error(`Unknown sample format ${boxFormat}`);
};
exports.processIsoFormatBox = processIsoFormatBox;
const parseIsoFormatBoxes = async ({ maxBytes, logLevel, iterator, contentLength })=>{
    const samples = [];
    const initialOffset = iterator.counter.getOffset();
    while(iterator.bytesRemaining() > 0 && iterator.counter.getOffset() - initialOffset < maxBytes){
        const { sample } = await (0, exports.processIsoFormatBox)({
            iterator,
            logLevel,
            contentLength
        });
        if (sample) {
            samples.push(sample);
        }
    }
    return samples;
};
exports.parseIsoFormatBoxes = parseIsoFormatBoxes;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/avc/parse-avc.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

// https://www.itu.int/rec/T-REC-H.264-202408-I/en
// Page 455
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseAvc = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const Extended_SAR = 255;
const getPoc = (iterator, sps, avcState, isReferencePicture)=>{
    const { pic_order_cnt_type, log2_max_pic_order_cnt_lsb_minus4 } = sps;
    if (pic_order_cnt_type !== 0) {
        return null;
    }
    const prevPicOrderCntLsb = avcState.getPrevPicOrderCntLsb();
    const prevPicOrderCntMsb = avcState.getPrevPicOrderCntMsb();
    if (log2_max_pic_order_cnt_lsb_minus4 === null) {
        throw new Error('log2_max_pic_order_cnt_lsb_minus4 is null');
    }
    const max_pic_order_cnt_lsb = 2 ** (log2_max_pic_order_cnt_lsb_minus4 + 4);
    const pic_order_cnt_lsb = iterator.getBits(log2_max_pic_order_cnt_lsb_minus4 + 4);
    let picOrderCntMsb;
    if (pic_order_cnt_lsb < prevPicOrderCntLsb && prevPicOrderCntLsb - pic_order_cnt_lsb >= max_pic_order_cnt_lsb / 2) {
        picOrderCntMsb = prevPicOrderCntMsb + max_pic_order_cnt_lsb;
    } else if (pic_order_cnt_lsb > prevPicOrderCntLsb && pic_order_cnt_lsb - prevPicOrderCntLsb > max_pic_order_cnt_lsb / 2) {
        picOrderCntMsb = prevPicOrderCntMsb - max_pic_order_cnt_lsb;
    } else {
        picOrderCntMsb = prevPicOrderCntMsb;
    }
    const poc = picOrderCntMsb + pic_order_cnt_lsb;
    if (isReferencePicture) {
        avcState.setPrevPicOrderCntLsb(pic_order_cnt_lsb);
        avcState.setPrevPicOrderCntMsb(picOrderCntMsb);
    }
    return poc;
};
const readVuiParameters = (iterator)=>{
    let sar_width = null;
    let sar_height = null;
    let overscan_appropriate_flag = null;
    let video_format = null;
    let video_full_range_flag = null;
    let colour_primaries = null;
    let transfer_characteristics = null;
    let matrix_coefficients = null;
    let chroma_sample_loc_type_top_field = null;
    let chroma_sample_loc_type_bottom_field = null;
    const aspect_ratio_info_present_flag = iterator.getBits(1);
    if (aspect_ratio_info_present_flag) {
        const aspect_ratio_idc = iterator.getBits(8);
        if (aspect_ratio_idc === Extended_SAR) {
            sar_width = iterator.getBits(16);
            sar_height = iterator.getBits(16);
        }
    }
    const overscan_info_present_flag = iterator.getBits(1);
    if (overscan_info_present_flag) {
        overscan_appropriate_flag = iterator.getBits(1);
    }
    const video_signal_type_present_flag = iterator.getBits(1);
    if (video_signal_type_present_flag) {
        video_format = iterator.getBits(3);
        video_full_range_flag = Boolean(iterator.getBits(1));
        const colour_description_present_flag = iterator.getBits(1);
        if (colour_description_present_flag) {
            colour_primaries = iterator.getBits(8);
            transfer_characteristics = iterator.getBits(8);
            matrix_coefficients = iterator.getBits(8);
        }
    }
    const chroma_loc_info_present_flag = iterator.getBits(1);
    if (chroma_loc_info_present_flag) {
        chroma_sample_loc_type_top_field = iterator.readExpGolomb();
        chroma_sample_loc_type_bottom_field = iterator.readExpGolomb();
    }
    return {
        sar_width,
        sar_height,
        overscan_appropriate_flag,
        chroma_sample_loc_type_bottom_field,
        chroma_sample_loc_type_top_field,
        colour_primaries,
        matrix_coefficients,
        transfer_characteristics,
        video_format,
        video_full_range_flag
    };
};
const readSps = (iterator)=>{
    const profile = iterator.getUint8();
    const compatibility = iterator.getUint8();
    const level = iterator.getUint8();
    iterator.startReadingBits();
    const seq_parameter_set_id = iterator.readExpGolomb();
    let separate_colour_plane_flag = null;
    let bit_depth_luma_minus8 = null;
    let bit_depth_chroma_minus8 = null;
    let qpprime_y_zero_transform_bypass_flag = null;
    let log2_max_frame_num_minus4 = null;
    let log2_max_pic_order_cnt_lsb_minus4 = null;
    let max_num_ref_frames = null;
    let gaps_in_frame_num_value_allowed_flag = null;
    let mb_adaptive_frame_field_flag = null;
    let direct_8x8_inference_flag = null;
    let frame_crop_left_offset = null;
    let frame_crop_right_offset = null;
    let frame_crop_top_offset = null;
    let frame_crop_bottom_offset = null;
    let vui_parameters = null;
    // Page 71
    if (profile === 100 || profile === 110 || profile === 122 || profile === 244 || profile === 44 || profile === 83 || profile === 86 || profile === 118 || profile === 128 || profile === 138 || profile === 139 || profile === 134 || profile === 135) {
        const chromaFormat = iterator.readExpGolomb();
        if (chromaFormat === 3) {
            separate_colour_plane_flag = iterator.getBits(1);
        }
        bit_depth_luma_minus8 = iterator.readExpGolomb();
        bit_depth_chroma_minus8 = iterator.readExpGolomb();
        qpprime_y_zero_transform_bypass_flag = iterator.getBits(1);
        const seq_scaling_matrix_present_flag = iterator.getBits(1);
        const seq_scaling_list_present_flag = [];
        if (seq_scaling_matrix_present_flag) {
            for(let i = 0; i < (chromaFormat !== 3 ? 8 : 12); i++){
                seq_scaling_list_present_flag[i] = iterator.getBits(1);
                if (seq_scaling_list_present_flag[i]) {
                    if (i < 6) {
                        // scaling_list not implemented
                        throw new Error('Not implemented');
                    } else {
                        // scaling_list not implemented
                        throw new Error('Not implemented');
                    }
                }
            }
        }
    }
    log2_max_frame_num_minus4 = iterator.readExpGolomb();
    const pic_order_cnt_type = iterator.readExpGolomb();
    if (pic_order_cnt_type === 0) {
        log2_max_pic_order_cnt_lsb_minus4 = iterator.readExpGolomb();
    } else if (pic_order_cnt_type === 1) {
        throw new Error('pic_order_cnt_type = 1 not implemented');
    }
    max_num_ref_frames = iterator.readExpGolomb();
    gaps_in_frame_num_value_allowed_flag = iterator.getBits(1);
    const pic_width_in_mbs_minus1 = iterator.readExpGolomb();
    const pic_height_in_map_units_minus1 = iterator.readExpGolomb();
    const frame_mbs_only_flag = iterator.getBits(1);
    if (!frame_mbs_only_flag) {
        mb_adaptive_frame_field_flag = iterator.getBits(1);
    }
    direct_8x8_inference_flag = iterator.getBits(1);
    const frame_cropping_flag = iterator.getBits(1);
    if (frame_cropping_flag) {
        frame_crop_left_offset = iterator.readExpGolomb();
        frame_crop_right_offset = iterator.readExpGolomb();
        frame_crop_top_offset = iterator.readExpGolomb();
        frame_crop_bottom_offset = iterator.readExpGolomb();
    }
    const vui_parameters_present_flag = iterator.getBits(1);
    if (vui_parameters_present_flag) {
        vui_parameters = readVuiParameters(iterator);
    }
    iterator.stopReadingBits();
    return {
        profile,
        compatibility,
        level,
        bit_depth_chroma_minus8,
        bit_depth_luma_minus8,
        gaps_in_frame_num_value_allowed_flag,
        log2_max_frame_num_minus4,
        log2_max_pic_order_cnt_lsb_minus4,
        max_num_ref_frames,
        pic_height_in_map_units_minus1,
        pic_width_in_mbs_minus1,
        qpprime_y_zero_transform_bypass_flag,
        separate_colour_plane_flag,
        seq_parameter_set_id,
        direct_8x8_inference_flag,
        frame_crop_bottom_offset,
        frame_crop_left_offset,
        frame_crop_right_offset,
        frame_crop_top_offset,
        mb_adaptive_frame_field_flag,
        vui_parameters,
        pic_order_cnt_type
    };
};
const findEnd = (buffer)=>{
    let zeroesInARow = 0;
    for(let i = 0; i < buffer.length; i++){
        const val = buffer[i];
        if (val === 0) {
            zeroesInARow++;
            continue;
        }
        if (zeroesInARow >= 2 && val === 1) {
            return i - zeroesInARow;
        }
        zeroesInARow = 0;
    }
    return null;
};
const inspect = (buffer, avcState)=>{
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: buffer,
        maxBytes: buffer.byteLength,
        logLevel: 'error'
    });
    iterator.startReadingBits();
    iterator.getBits(1); // forbidden_zero_bit
    const nal_ref_idc = iterator.getBits(2); // nal_ref_idc
    const isReferencePicture = nal_ref_idc !== 0;
    const type = iterator.getBits(5); // nal_unit_type
    if (type === 7) {
        iterator.stopReadingBits();
        const end = findEnd(buffer);
        const data = readSps(iterator);
        const sps = buffer.slice(0, end === null ? Infinity : end);
        avcState.setSps(data);
        if (isReferencePicture) {
            avcState.setPrevPicOrderCntLsb(0);
            avcState.setPrevPicOrderCntMsb(0);
        }
        return {
            spsData: data,
            sps,
            type: 'avc-profile'
        };
    }
    if (type === 5) {
        avcState.setPrevPicOrderCntLsb(0);
        avcState.setPrevPicOrderCntMsb(0);
        iterator.readExpGolomb(); // ignore first_mb_in_slice
        iterator.readExpGolomb(); // slice_type
        iterator.readExpGolomb(); // pic_parameter_set_id
        const sps = avcState.getSps();
        if (!sps) {
            throw new Error('SPS not found');
        }
        const numberOfBitsForFrameNum = sps.log2_max_frame_num_minus4 + 4;
        iterator.getBits(numberOfBitsForFrameNum); // frame_num
        iterator.readExpGolomb(); // idr_pic_id
        const { pic_order_cnt_type } = sps;
        let poc = null;
        if (pic_order_cnt_type === 0) {
            poc = getPoc(iterator, sps, avcState, isReferencePicture);
        }
        iterator.stopReadingBits();
        return {
            type: 'keyframe',
            poc
        };
    }
    if (type === 8) {
        iterator.stopReadingBits();
        const end = findEnd(buffer);
        const pps = buffer.slice(0, end === null ? Infinity : end);
        return {
            type: 'avc-pps',
            pps
        };
    }
    if (type === 1) {
        iterator.readExpGolomb(); // ignore first_mb_in_slice
        const slice_type = iterator.readExpGolomb();
        const isBidirectionalFrame = slice_type === 6;
        iterator.readExpGolomb(); // pic_parameter_set_id
        const sps = avcState.getSps();
        if (!sps) {
            throw new Error('SPS not found');
        }
        const numberOfBitsForFrameNum = sps.log2_max_frame_num_minus4 + 4;
        iterator.getBits(numberOfBitsForFrameNum); // frame_num
        const { pic_order_cnt_type } = sps;
        let poc = null;
        if (pic_order_cnt_type === 0) {
            poc = getPoc(iterator, sps, avcState, isReferencePicture);
        }
        iterator.stopReadingBits();
        return {
            type: 'delta-frame',
            isBidirectionalFrame,
            poc
        };
    }
    iterator.destroy();
    return null;
};
// https://stackoverflow.com/questions/24884827/possible-locations-for-sequence-picture-parameter-sets-for-h-264-stream
const parseAvc = (buffer, avcState)=>{
    let zeroesInARow = 0;
    const infos = [];
    for(let i = 0; i < buffer.length; i++){
        const val = buffer[i];
        if (val === 0) {
            zeroesInARow++;
            continue;
        }
        if (zeroesInARow >= 2 && val === 1) {
            zeroesInARow = 0;
            const info = inspect(buffer.slice(i + 1, i + 100), avcState);
            if (info) {
                infos.push(info);
                if (info.type === 'keyframe' || info.type === 'delta-frame') {
                    break;
                }
            }
        }
        if (val !== 1) {
            zeroesInARow = 0;
        }
    }
    return infos;
};
exports.parseAvc = parseAvc;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/block-simple-block-flags.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseBlockFlags = void 0;
const all_segments_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/all-segments.js [app-route] (ecmascript)");
const parseBlockFlags = (iterator, type)=>{
    if (type === all_segments_1.matroskaElements.Block) {
        iterator.startReadingBits();
        // Reserved
        iterator.getBits(4);
        const invisible = Boolean(iterator.getBits(1));
        const lacing = iterator.getBits(2);
        // unused
        iterator.getBits(1);
        iterator.stopReadingBits();
        return {
            invisible,
            lacing,
            keyframe: null
        };
    }
    if (type === all_segments_1.matroskaElements.SimpleBlock) {
        iterator.startReadingBits();
        const keyframe = Boolean(iterator.getBits(1));
        // Reserved
        iterator.getBits(3);
        const invisible = Boolean(iterator.getBits(1));
        const lacing = iterator.getBits(2);
        iterator.getBits(1);
        iterator.stopReadingBits();
        return {
            invisible,
            lacing,
            keyframe
        };
    }
    throw new Error('Unexpected type');
};
exports.parseBlockFlags = parseBlockFlags;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/get-sample-from-block.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSampleFromBlock = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const parse_avc_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/parse-avc.js [app-route] (ecmascript)");
const get_ready_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/get-ready-tracks.js [app-route] (ecmascript)");
const all_segments_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/all-segments.js [app-route] (ecmascript)");
const block_simple_block_flags_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/block-simple-block-flags.js [app-route] (ecmascript)");
const addAvcToTrackAndActivateTrackIfNecessary = async ({ partialVideoSample, codec, structureState, webmState, trackNumber, logLevel, callbacks, onVideoTrack, avcState })=>{
    if (codec !== 'V_MPEG4/ISO/AVC') {
        return;
    }
    const missingTracks = (0, get_ready_tracks_1.getTracksFromMatroska)({
        structureState,
        webmState
    }).missingInfo;
    if (missingTracks.length === 0) {
        return;
    }
    const parsed = (0, parse_avc_1.parseAvc)(partialVideoSample.data, avcState);
    for (const parse of parsed){
        if (parse.type === 'avc-profile') {
            webmState.setAvcProfileForTrackNumber(trackNumber, parse);
            const track = missingTracks.find((t)=>t.trackId === trackNumber);
            if (!track) {
                throw new Error('Could not find track ' + trackNumber);
            }
            const resolvedTracks = (0, get_ready_tracks_1.getTracksFromMatroska)({
                structureState,
                webmState
            }).resolved;
            const resolvedTrack = resolvedTracks.find((t)=>t.trackId === trackNumber);
            if (!resolvedTrack) {
                throw new Error('Could not find track ' + trackNumber);
            }
            await (0, register_track_1.registerVideoTrack)({
                track: resolvedTrack,
                container: 'webm',
                logLevel,
                onVideoTrack,
                registerVideoSampleCallback: callbacks.registerVideoSampleCallback,
                tracks: callbacks.tracks
            });
        }
    }
};
const getSampleFromBlock = async ({ ebml, webmState, offset, structureState, callbacks, logLevel, onVideoTrack, avcState })=>{
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: ebml.value,
        maxBytes: ebml.value.length,
        logLevel: 'error'
    });
    const trackNumber = iterator.getVint();
    if (trackNumber === null) {
        throw new Error('Not enough data to get track number, should not happen');
    }
    const timecodeRelativeToCluster = iterator.getInt16();
    const { keyframe } = (0, block_simple_block_flags_1.parseBlockFlags)(iterator, ebml.type === 'SimpleBlock' ? all_segments_1.matroskaElements.SimpleBlock : all_segments_1.matroskaElements.Block);
    const { codec, trackTimescale } = webmState.getTrackInfoByNumber(trackNumber);
    const clusterOffset = webmState.getTimestampOffsetForByteOffset(offset);
    const timescale = webmState.getTimescale();
    if (clusterOffset === undefined) {
        throw new Error('Could not find offset for byte offset ' + offset);
    }
    // https://github.com/hubblec4/Matroska-Chapters-Specs/blob/master/notes.md/#timestampscale
    // The TimestampScale Element is used to calculate the Raw Timestamp of a Block. The timestamp is obtained by adding the Block's timestamp to the Cluster's Timestamp Element, and then multiplying that result by the TimestampScale. The result will be the Block's Raw Timestamp in nanoseconds.
    const timecodeInNanoSeconds = (timecodeRelativeToCluster + clusterOffset) * timescale * (trackTimescale !== null && trackTimescale !== void 0 ? trackTimescale : 1);
    // Timecode should be in microseconds
    const timecodeInMicroseconds = timecodeInNanoSeconds / 1000;
    if (!codec) {
        throw new Error(`Could not find codec for track ${trackNumber}`);
    }
    const remainingNow = ebml.value.length - iterator.counter.getOffset();
    if (codec.startsWith('V_')) {
        const partialVideoSample = {
            data: iterator.getSlice(remainingNow),
            decodingTimestamp: timecodeInMicroseconds,
            duration: undefined,
            timestamp: timecodeInMicroseconds,
            offset
        };
        if (keyframe === null) {
            iterator.destroy();
            return {
                type: 'partial-video-sample',
                partialVideoSample,
                trackId: trackNumber,
                timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE
            };
        }
        await addAvcToTrackAndActivateTrackIfNecessary({
            codec,
            partialVideoSample,
            structureState,
            webmState,
            trackNumber,
            callbacks,
            logLevel,
            onVideoTrack,
            avcState
        });
        const sample = {
            ...partialVideoSample,
            type: keyframe ? 'key' : 'delta'
        };
        iterator.destroy();
        return {
            type: 'video-sample',
            videoSample: sample,
            trackId: trackNumber,
            timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE
        };
    }
    if (codec.startsWith('A_')) {
        const audioSample = {
            data: iterator.getSlice(remainingNow),
            timestamp: timecodeInMicroseconds,
            type: 'key',
            duration: undefined,
            decodingTimestamp: timecodeInMicroseconds,
            offset
        };
        iterator.destroy();
        return {
            type: 'audio-sample',
            audioSample,
            trackId: trackNumber,
            timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE
        };
    }
    iterator.destroy();
    return {
        type: 'no-sample'
    };
};
exports.getSampleFromBlock = getSampleFromBlock;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/parse-ebml.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.postprocessEbml = exports.parseEbml = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const get_sample_from_block_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/get-sample-from-block.js [app-route] (ecmascript)");
const make_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/make-track.js [app-route] (ecmascript)");
const all_segments_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/all-segments.js [app-route] (ecmascript)");
const parseEbml = async (iterator, statesForProcessing, logLevel)=>{
    const hex = iterator.getMatroskaSegmentId();
    if (hex === null) {
        throw new Error('Not enough bytes left to parse EBML - this should not happen');
    }
    const off = iterator.counter.getOffset();
    const size = iterator.getVint();
    const minVintWidth = iterator.counter.getOffset() - off;
    if (size === null) {
        throw new Error('Not enough bytes left to parse EBML - this should not happen');
    }
    const hasInMap = all_segments_1.ebmlMap[hex];
    if (!hasInMap) {
        log_1.Log.verbose(logLevel, `Unknown EBML hex ID ${JSON.stringify(hex)}`);
        iterator.discard(size);
        return null;
    }
    if (hasInMap.type === 'uint') {
        const beforeUintOffset = iterator.counter.getOffset();
        const value = size === 0 ? 0 : iterator.getUint(size);
        const { name } = hasInMap;
        return {
            // To work around TS limit
            type: name,
            value: {
                value,
                byteLength: iterator.counter.getOffset() - beforeUintOffset
            },
            minVintWidth
        };
    }
    if (hasInMap.type === 'string') {
        const value = iterator.getByteString(size, true);
        return {
            type: hasInMap.name,
            value,
            minVintWidth
        };
    }
    if (hasInMap.type === 'float') {
        const value = size === 0 ? 0.0 : size === 4 ? iterator.getFloat32() : iterator.getFloat64();
        return {
            type: hasInMap.name,
            value: {
                value,
                size: size === 4 ? '32' : '64'
            },
            minVintWidth
        };
    }
    if (hasInMap.type === 'hex-string') {
        return {
            type: hasInMap.name,
            value: '0x' + [
                ...iterator.getSlice(size)
            ].map((b)=>b.toString(16).padStart(2, '0')).join('').replace(new RegExp('^' + hex), ''),
            minVintWidth
        };
    }
    if (hasInMap.type === 'uint8array') {
        return {
            type: hasInMap.name,
            value: iterator.getSlice(size),
            minVintWidth
        };
    }
    if (hasInMap.type === 'children') {
        const children = [];
        const startOffset = iterator.counter.getOffset();
        while(true){
            if (size === 0) {
                break;
            }
            const offset = iterator.counter.getOffset();
            const value = await (0, exports.parseEbml)(iterator, statesForProcessing, logLevel);
            if (value) {
                const remapped = statesForProcessing ? await (0, exports.postprocessEbml)({
                    offset,
                    ebml: value,
                    statesForProcessing
                }) : value;
                children.push(remapped);
            }
            const offsetNow = iterator.counter.getOffset();
            if (offsetNow - startOffset > size) {
                throw new Error(`Offset ${offsetNow - startOffset} is larger than the length of the hex ${size}`);
            }
            if (offsetNow - startOffset === size) {
                break;
            }
        }
        return {
            type: hasInMap.name,
            value: children,
            minVintWidth
        };
    }
    // @ts-expect-error
    throw new Error(`Unknown segment type ${hasInMap.type}`);
};
exports.parseEbml = parseEbml;
const postprocessEbml = async ({ offset, ebml, statesForProcessing: { webmState, callbacks, logLevel, onAudioTrack, onVideoTrack, structureState, avcState } })=>{
    if (ebml.type === 'TimestampScale') {
        webmState.setTimescale(ebml.value.value);
    }
    if (ebml.type === 'Tracks') {
        callbacks.tracks.setIsDone(logLevel);
    }
    if (ebml.type === 'TrackEntry') {
        webmState.onTrackEntrySegment(ebml);
        const track = (0, make_track_1.getTrack)({
            track: ebml,
            timescale: webmState.getTimescale()
        });
        if (track && track.type === 'audio') {
            await (0, register_track_1.registerAudioTrack)({
                track,
                container: 'webm',
                registerAudioSampleCallback: callbacks.registerAudioSampleCallback,
                tracks: callbacks.tracks,
                logLevel,
                onAudioTrack
            });
        }
        if (track && track.type === 'video') {
            if (track.codec !== make_track_1.NO_CODEC_PRIVATE_SHOULD_BE_DERIVED_FROM_SPS) {
                await (0, register_track_1.registerVideoTrack)({
                    track,
                    container: 'webm',
                    logLevel,
                    onVideoTrack,
                    registerVideoSampleCallback: callbacks.registerVideoSampleCallback,
                    tracks: callbacks.tracks
                });
            }
        }
    }
    if (ebml.type === 'Timestamp') {
        webmState.setTimestampOffset(offset, ebml.value.value);
    }
    if (ebml.type === 'Block' || ebml.type === 'SimpleBlock') {
        const sample = await (0, get_sample_from_block_1.getSampleFromBlock)({
            ebml,
            webmState,
            offset,
            structureState,
            callbacks,
            logLevel,
            onVideoTrack,
            avcState
        });
        if (sample.type === 'video-sample') {
            await callbacks.onVideoSample({
                videoSample: sample.videoSample,
                trackId: sample.trackId
            });
            return {
                type: 'Block',
                value: new Uint8Array([]),
                minVintWidth: ebml.minVintWidth
            };
        }
        if (sample.type === 'audio-sample') {
            await callbacks.onAudioSample({
                audioSample: sample.audioSample,
                trackId: sample.trackId
            });
            return {
                type: 'Block',
                value: new Uint8Array([]),
                minVintWidth: ebml.minVintWidth
            };
        }
        if (sample.type === 'no-sample') {
            return {
                type: 'Block',
                value: new Uint8Array([]),
                minVintWidth: ebml.minVintWidth
            };
        }
    }
    if (ebml.type === 'BlockGroup') {
        // Blocks don't have information about keyframes.
        // https://ffmpeg.org/pipermail/ffmpeg-devel/2015-June/173825.html
        // "For Blocks, keyframes is
        // inferred by the absence of ReferenceBlock element (as done by matroskadec).""
        const block = ebml.value.find((c)=>c.type === 'SimpleBlock' || c.type === 'Block');
        if (!block || block.type !== 'SimpleBlock' && block.type !== 'Block') {
            throw new Error('Expected block segment');
        }
        const hasReferenceBlock = ebml.value.find((c)=>c.type === 'ReferenceBlock');
        const sample = block.value.length === 0 ? null : await (0, get_sample_from_block_1.getSampleFromBlock)({
            ebml: block,
            webmState,
            offset,
            structureState,
            callbacks,
            logLevel,
            onVideoTrack,
            avcState
        });
        if (sample && sample.type === 'partial-video-sample') {
            const completeFrame = {
                ...sample.partialVideoSample,
                type: hasReferenceBlock ? 'delta' : 'key'
            };
            await callbacks.onVideoSample({
                videoSample: completeFrame,
                trackId: sample.trackId
            });
        }
        return {
            type: 'BlockGroup',
            value: [],
            minVintWidth: ebml.minVintWidth
        };
    }
    return ebml;
};
exports.postprocessEbml = postprocessEbml;
}),
"[project]/node_modules/@remotion/media-parser/dist/errors.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasBeenAborted = exports.MediaParserAbortError = exports.IsAnUnsupportedFileTypeError = exports.IsAPdfError = exports.IsAnImageError = void 0;
class IsAnImageError extends Error {
    constructor({ dimensions, imageType, message, mimeType, sizeInBytes, fileName }){
        super(message);
        this.name = 'IsAnImageError';
        this.imageType = imageType;
        this.dimensions = dimensions;
        this.mimeType = mimeType;
        this.sizeInBytes = sizeInBytes;
        this.fileName = fileName;
        if (Error.captureStackTrace) {
            Error.captureStackTrace(this, IsAnImageError);
        }
    }
}
exports.IsAnImageError = IsAnImageError;
class IsAPdfError extends Error {
    constructor({ message, mimeType, sizeInBytes, fileName }){
        super(message);
        this.name = 'IsAPdfError';
        this.mimeType = mimeType;
        this.sizeInBytes = sizeInBytes;
        this.fileName = fileName;
        if (Error.captureStackTrace) {
            Error.captureStackTrace(this, IsAPdfError);
        }
    }
}
exports.IsAPdfError = IsAPdfError;
class IsAnUnsupportedFileTypeError extends Error {
    constructor({ message, mimeType, sizeInBytes, fileName }){
        super(message);
        this.name = 'IsAnUnsupportedFileTypeError';
        this.mimeType = mimeType;
        this.sizeInBytes = sizeInBytes;
        this.fileName = fileName;
        if (Error.captureStackTrace) {
            Error.captureStackTrace(this, IsAnUnsupportedFileTypeError);
        }
    }
}
exports.IsAnUnsupportedFileTypeError = IsAnUnsupportedFileTypeError;
class MediaParserAbortError extends Error {
    constructor(message){
        super(message);
        this.name = 'MediaParserAbortError';
        this.cause = undefined;
    }
}
exports.MediaParserAbortError = MediaParserAbortError;
const hasBeenAborted = (error)=>{
    return error instanceof MediaParserAbortError || // On worker it is not the same instance, but same name
    error.name === 'MediaParserAbortError' || // fetch gives BodyStreamBuffer was aborted
    error.name === 'AbortError';
};
exports.hasBeenAborted = hasBeenAborted;
}),
"[project]/node_modules/@remotion/media-parser/dist/with-resolvers.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.withResolvers = void 0;
const withResolvers = function() {
    let resolve;
    let reject;
    const promise = new Promise((res, rej)=>{
        resolve = res;
        reject = rej;
    });
    return {
        promise,
        resolve: resolve,
        reject: reject
    };
};
exports.withResolvers = withResolvers;
}),
"[project]/node_modules/@remotion/media-parser/dist/controller/emitter.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

var __classPrivateFieldSet = /*TURBOPACK member replacement*/ __turbopack_context__.e && /*TURBOPACK member replacement*/ __turbopack_context__.e.__classPrivateFieldSet || function(receiver, state, value, kind, f) {
    if (kind === "m") throw new TypeError("Private method is not writable");
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
    return kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value), value;
};
var __classPrivateFieldGet = /*TURBOPACK member replacement*/ __turbopack_context__.e && /*TURBOPACK member replacement*/ __turbopack_context__.e.__classPrivateFieldGet || function(receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var _MediaParserEmitter_markAsReady;
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.MediaParserEmitter = void 0;
const with_resolvers_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/with-resolvers.js [app-route] (ecmascript)");
class MediaParserEmitter {
    constructor(){
        this.listeners = {
            pause: [],
            resume: [],
            abort: [],
            seek: []
        };
        _MediaParserEmitter_markAsReady.set(this, void 0);
        this.markAsReady = ()=>{
            __classPrivateFieldGet(this, _MediaParserEmitter_markAsReady, "f").call(this);
        };
        this.addEventListener = (name, callback)=>{
            this.listeners[name].push(callback);
        };
        this.removeEventListener = (name, callback)=>{
            this.listeners[name] = this.listeners[name].filter((l)=>l !== callback);
        };
        this.dispatchPause = ()=>{
            this.readyPromise = this.readyPromise.then(()=>{
                this.dispatchEvent('pause', undefined);
            });
        };
        this.dispatchResume = ()=>{
            this.readyPromise = this.readyPromise.then(()=>{
                this.dispatchEvent('resume', undefined);
            });
        };
        this.dispatchAbort = (reason)=>{
            this.readyPromise = this.readyPromise.then(()=>{
                this.dispatchEvent('abort', {
                    reason
                });
            });
        };
        this.dispatchSeek = (seek)=>{
            this.readyPromise = this.readyPromise.then(()=>{
                this.dispatchEvent('seek', {
                    seek
                });
            });
        };
        const { promise, resolve } = (0, with_resolvers_1.withResolvers)();
        this.readyPromise = promise;
        __classPrivateFieldSet(this, _MediaParserEmitter_markAsReady, resolve, "f");
    }
    dispatchEvent(dispatchName, context) {
        this.listeners[dispatchName].forEach((callback)=>{
            callback({
                detail: context
            });
        });
    }
}
exports.MediaParserEmitter = MediaParserEmitter;
_MediaParserEmitter_markAsReady = new WeakMap();
}),
"[project]/node_modules/@remotion/media-parser/dist/controller/pause-signal.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makePauseSignal = void 0;
const makePauseSignal = (emitter)=>{
    const waiterFns = [];
    let paused = false;
    return {
        pause: ()=>{
            if (paused) {
                return;
            }
            emitter.dispatchPause();
            paused = true;
        },
        resume: ()=>{
            if (!paused) {
                return;
            }
            paused = false;
            for (const waiterFn of waiterFns){
                waiterFn();
            }
            waiterFns.length = 0;
            emitter.dispatchResume();
        },
        waitUntilResume: ()=>{
            return new Promise((resolve)=>{
                if (!paused) {
                    resolve();
                } else {
                    waiterFns.push(resolve);
                }
            });
        }
    };
};
exports.makePauseSignal = makePauseSignal;
}),
"[project]/node_modules/@remotion/media-parser/dist/controller/performed-seeks-stats.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.performedSeeksStats = void 0;
const performedSeeksStats = ()=>{
    const performedSeeks = [];
    const markLastSeekAsUserInitiated = ()=>{
        if (performedSeeks.length > 0) {
            performedSeeks[performedSeeks.length - 1].type = 'user-initiated';
        }
    };
    return {
        recordSeek: (seek)=>{
            performedSeeks.push(seek);
        },
        getPerformedSeeks: ()=>{
            return performedSeeks;
        },
        markLastSeekAsUserInitiated
    };
};
exports.performedSeeksStats = performedSeeksStats;
}),
"[project]/node_modules/@remotion/media-parser/dist/controller/seek-signal.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makeSeekSignal = void 0;
const makeSeekSignal = (emitter)=>{
    let seek = null;
    return {
        seek: (seekRequest)=>{
            seek = seekRequest;
            emitter.dispatchSeek(seekRequest);
        },
        getSeek () {
            return seek;
        },
        // In the meanwhile a new seek could have been queued
        clearSeekIfStillSame (previousSeek) {
            if (seek === previousSeek) {
                seek = null;
                return {
                    hasChanged: false
                };
            }
            return {
                hasChanged: true
            };
        }
    };
};
exports.makeSeekSignal = makeSeekSignal;
}),
"[project]/node_modules/@remotion/media-parser/dist/controller/media-parser-controller.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mediaParserController = void 0;
const errors_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/errors.js [app-route] (ecmascript)");
const emitter_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/controller/emitter.js [app-route] (ecmascript)");
const pause_signal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/controller/pause-signal.js [app-route] (ecmascript)");
const performed_seeks_stats_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/controller/performed-seeks-stats.js [app-route] (ecmascript)");
const seek_signal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/controller/seek-signal.js [app-route] (ecmascript)");
const mediaParserController = ()=>{
    const abortController = new AbortController();
    const emitter = new emitter_1.MediaParserEmitter();
    const pauseSignal = (0, pause_signal_1.makePauseSignal)(emitter);
    const seekSignal = (0, seek_signal_1.makeSeekSignal)(emitter);
    const performedSeeksSignal = (0, performed_seeks_stats_1.performedSeeksStats)();
    const checkForAbortAndPause = async ()=>{
        if (abortController.signal.aborted) {
            const err = new errors_1.MediaParserAbortError('Aborted');
            if (abortController.signal.reason) {
                err.cause = abortController.signal.reason;
            }
            throw err;
        }
        await pauseSignal.waitUntilResume();
    };
    let seekingHintResolution = null;
    let simulateSeekResolution = null;
    const getSeekingHints = ()=>{
        if (!seekingHintResolution) {
            throw new Error('The mediaParserController() was not yet used in a parseMedia() call');
        }
        return seekingHintResolution();
    };
    const simulateSeek = (seekInSeconds)=>{
        if (!simulateSeekResolution) {
            throw new Error('The mediaParserController() was not yet used in a parseMedia() call');
        }
        return simulateSeekResolution(seekInSeconds);
    };
    const attachSeekingHintResolution = (callback)=>{
        if (seekingHintResolution) {
            throw new Error('The mediaParserController() was used in multiple parseMedia() calls. Create a separate controller for each call.');
        }
        seekingHintResolution = callback;
    };
    const attachSimulateSeekResolution = (callback)=>{
        if (simulateSeekResolution) {
            throw new Error('The mediaParserController() was used in multiple parseMedia() calls. Create a separate controller for each call.');
        }
        simulateSeekResolution = callback;
    };
    return {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        abort: (reason)=>{
            abortController.abort(reason);
            emitter.dispatchAbort(reason);
        },
        seek: seekSignal.seek,
        simulateSeek,
        pause: pauseSignal.pause,
        resume: pauseSignal.resume,
        addEventListener: emitter.addEventListener,
        removeEventListener: emitter.removeEventListener,
        getSeekingHints,
        _internals: {
            signal: abortController.signal,
            checkForAbortAndPause,
            seekSignal,
            markAsReadyToEmitEvents: emitter.markAsReady,
            performedSeeksSignal,
            attachSeekingHintResolution,
            attachSimulateSeekResolution
        }
    };
};
exports.mediaParserController = mediaParserController;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-streams.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.m3uHasStreams = exports.getM3uStreams = exports.isIndependentSegments = void 0;
const isIndependentSegments = (structure)=>{
    if (structure === null || structure.type !== 'm3u') {
        return false;
    }
    return structure.boxes.some((box)=>box.type === 'm3u-independent-segments' || box.type === 'm3u-stream-info');
};
exports.isIndependentSegments = isIndependentSegments;
const getM3uStreams = ({ structure, originalSrc, readerInterface })=>{
    if (structure === null || structure.type !== 'm3u') {
        return null;
    }
    const boxes = [];
    for(let i = 0; i < structure.boxes.length; i++){
        const str = structure.boxes[i];
        if (str.type === 'm3u-stream-info') {
            const next = structure.boxes[i + 1];
            if (next.type !== 'm3u-text-value') {
                throw new Error('Expected m3u-text-value');
            }
            const associatedPlaylists = [];
            if (str.audio) {
                const match = structure.boxes.filter((box)=>{
                    return box.type === 'm3u-media-info' && box.groupId === str.audio;
                });
                for (const audioTrack of match){
                    associatedPlaylists.push({
                        autoselect: audioTrack.autoselect,
                        channels: audioTrack.channels,
                        default: audioTrack.default,
                        groupId: audioTrack.groupId,
                        language: audioTrack.language,
                        name: audioTrack.name,
                        src: readerInterface.createAdjacentFileSource(audioTrack.uri, originalSrc),
                        id: associatedPlaylists.length,
                        isAudio: true
                    });
                }
            }
            boxes.push({
                src: readerInterface.createAdjacentFileSource(next.value, originalSrc),
                averageBandwidthInBitsPerSec: str.averageBandwidthInBitsPerSec,
                bandwidthInBitsPerSec: str.bandwidthInBitsPerSec,
                codecs: str.codecs,
                dimensions: str.dimensions,
                associatedPlaylists
            });
        }
    }
    // Maybe this is already a playlist
    if (boxes.length === 0) {
        return null;
    }
    const sorted = boxes.slice().sort((a, b)=>{
        var _a, _b, _c, _d;
        const aResolution = a.dimensions ? a.dimensions.width * a.dimensions.height : 0;
        const bResolution = b.dimensions ? b.dimensions.width * b.dimensions.height : 0;
        if (aResolution === bResolution) {
            const bandwidthA = (_b = (_a = a.averageBandwidthInBitsPerSec) !== null && _a !== void 0 ? _a : a.bandwidthInBitsPerSec) !== null && _b !== void 0 ? _b : 0;
            const bandwidthB = (_d = (_c = b.averageBandwidthInBitsPerSec) !== null && _c !== void 0 ? _c : b.bandwidthInBitsPerSec) !== null && _d !== void 0 ? _d : 0;
            return bandwidthB - bandwidthA;
        }
        return bResolution - aResolution;
    });
    return sorted.map((box, index)=>({
            ...box,
            id: index
        }));
};
exports.getM3uStreams = getM3uStreams;
const m3uHasStreams = (state)=>{
    const structure = state.structure.getStructureOrNull();
    if (!structure) {
        return false;
    }
    if (structure.type !== 'm3u') {
        return true;
    }
    return state.m3u.hasFinishedManifest();
};
exports.m3uHasStreams = m3uHasStreams;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-container.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasContainer = exports.getContainer = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/traversal.js [app-route] (ecmascript)");
const getContainer = (segments)=>{
    if (segments.type === 'iso-base-media') {
        return 'mp4';
    }
    if (segments.type === 'matroska') {
        return 'webm';
    }
    if (segments.type === 'transport-stream') {
        return 'transport-stream';
    }
    if (segments.type === 'mp3') {
        return 'mp3';
    }
    if (segments.type === 'wav') {
        return 'wav';
    }
    if (segments.type === 'flac') {
        return 'flac';
    }
    if (segments.type === 'riff') {
        if ((0, traversal_1.isRiffAvi)(segments)) {
            return 'avi';
        }
        throw new Error('Unknown RIFF container ' + segments.type);
    }
    if (segments.type === 'aac') {
        return 'aac';
    }
    if (segments.type === 'm3u') {
        return 'm3u8';
    }
    throw new Error('Unknown container ' + segments);
};
exports.getContainer = getContainer;
const hasContainer = (boxes)=>{
    try {
        return (0, exports.getContainer)(boxes) !== null;
    } catch (_a) {
        return false;
    }
};
exports.hasContainer = hasContainer;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-dimensions.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasDimensions = exports.getDimensions = void 0;
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const is_audio_structure_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/is-audio-structure.js [app-route] (ecmascript)");
const getDimensions = (state)=>{
    const structure = state.structure.getStructureOrNull();
    if (structure && (0, is_audio_structure_1.isAudioStructure)(structure)) {
        return null;
    }
    const tracks = (0, get_tracks_1.getTracks)(state, true);
    if (!tracks.length) {
        return null;
    }
    const firstVideoTrack = tracks.find((t)=>t.type === 'video');
    if (!firstVideoTrack) {
        return null;
    }
    return {
        width: firstVideoTrack.width,
        height: firstVideoTrack.height,
        rotation: firstVideoTrack.rotation,
        unrotatedHeight: firstVideoTrack.displayAspectHeight,
        unrotatedWidth: firstVideoTrack.displayAspectWidth
    };
};
exports.getDimensions = getDimensions;
const hasDimensions = (state)=>{
    const structure = state.structure.getStructureOrNull();
    if (structure && (0, is_audio_structure_1.isAudioStructure)(structure)) {
        return true;
    }
    try {
        return (0, exports.getDimensions)(state) !== null;
    } catch (_a) {
        return false;
    }
};
exports.hasDimensions = hasDimensions;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-duration-from-flac.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getDurationFromFlac = void 0;
const getDurationFromFlac = (parserState)=>{
    const structure = parserState.structure.getFlacStructure();
    const streaminfo = structure.boxes.find((b)=>b.type === 'flac-streaminfo');
    if (!streaminfo) {
        throw new Error('Streaminfo not found');
    }
    return streaminfo.totalSamples / streaminfo.sampleRate;
};
exports.getDurationFromFlac = getDurationFromFlac;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/are-samples-complete.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.areSamplesComplete = void 0;
const areSamplesComplete = ({ moofBoxes, tfraBoxes })=>{
    if (moofBoxes.length === 0) {
        return true;
    }
    return tfraBoxes.length > 0 && tfraBoxes.every((t)=>t.entries.length === moofBoxes.length);
};
exports.areSamplesComplete = areSamplesComplete;
}),
"[project]/node_modules/@remotion/media-parser/dist/samples-from-moof.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSamplesFromMoof = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const getSamplesFromTraf = (trafSegment, moofOffset, trexBoxes)=>{
    var _a, _b, _c, _d, _e, _f;
    if (trafSegment.type !== 'regular-box' || trafSegment.boxType !== 'traf') {
        throw new Error('Expected traf-box');
    }
    const tfhdBox = (0, traversal_1.getTfhdBox)(trafSegment);
    const trexBox = (_a = trexBoxes.find((t)=>t.trackId === (tfhdBox === null || tfhdBox === void 0 ? void 0 : tfhdBox.trackId))) !== null && _a !== void 0 ? _a : null;
    // intentional || instead of ?? to allow for 0, doesn't make sense for duration or size
    const defaultTrackSampleDuration = (tfhdBox === null || tfhdBox === void 0 ? void 0 : tfhdBox.defaultSampleDuration) || (trexBox === null || trexBox === void 0 ? void 0 : trexBox.defaultSampleDuration) || null;
    const defaultTrackSampleSize = (tfhdBox === null || tfhdBox === void 0 ? void 0 : tfhdBox.defaultSampleSize) || (trexBox === null || trexBox === void 0 ? void 0 : trexBox.defaultSampleSize) || null;
    // but flags may just be 0 :)
    const defaultTrackSampleFlags = (_c = (_b = tfhdBox === null || tfhdBox === void 0 ? void 0 : tfhdBox.defaultSampleFlags) !== null && _b !== void 0 ? _b : trexBox === null || trexBox === void 0 ? void 0 : trexBox.defaultSampleFlags) !== null && _c !== void 0 ? _c : null;
    const tfdtBox = (0, traversal_1.getTfdtBox)(trafSegment);
    const trunBoxes = (0, traversal_1.getTrunBoxes)(trafSegment);
    let time = 0;
    let offset = 0;
    let dataOffset = 0;
    const samples = [];
    for (const trunBox of trunBoxes){
        let i = -1;
        if (trunBox.dataOffset) {
            dataOffset = trunBox.dataOffset;
            offset = 0;
        }
        for (const sample of trunBox.samples){
            i++;
            const duration = sample.sampleDuration || defaultTrackSampleDuration;
            if (duration === null) {
                throw new Error('Expected duration');
            }
            const size = (_d = sample.sampleSize) !== null && _d !== void 0 ? _d : defaultTrackSampleSize;
            if (size === null) {
                throw new Error('Expected size');
            }
            const isFirstSample = i === 0;
            const sampleFlags = sample.sampleFlags ? sample.sampleFlags : isFirstSample && trunBox.firstSampleFlags !== null ? trunBox.firstSampleFlags : defaultTrackSampleFlags;
            if (sampleFlags === null) {
                throw new Error('Expected sample flags');
            }
            const keyframe = !(sampleFlags >> 16 & 0x1);
            const dts = time + ((_e = tfdtBox === null || tfdtBox === void 0 ? void 0 : tfdtBox.baseMediaDecodeTime) !== null && _e !== void 0 ? _e : 0);
            const samplePosition = {
                offset: offset + (moofOffset !== null && moofOffset !== void 0 ? moofOffset : 0) + (dataOffset !== null && dataOffset !== void 0 ? dataOffset : 0),
                decodingTimestamp: dts,
                timestamp: dts + ((_f = sample.sampleCompositionTimeOffset) !== null && _f !== void 0 ? _f : 0),
                duration,
                isKeyframe: keyframe,
                size,
                chunk: 0,
                bigEndian: false,
                chunkSize: null
            };
            samples.push(samplePosition);
            offset += size;
            time += duration;
        }
    }
    return samples;
};
const getSamplesFromMoof = ({ moofBox, trackId, trexBoxes })=>{
    const mapped = moofBox.trafBoxes.map((traf)=>{
        const tfhdBox = (0, traversal_1.getTfhdBox)(traf);
        if (!tfhdBox || tfhdBox.trackId !== trackId) {
            return [];
        }
        return getSamplesFromTraf(traf, moofBox.offset, trexBoxes);
    });
    return mapped.flat(1);
};
exports.getSamplesFromMoof = getSamplesFromMoof;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/collect-sample-positions-from-moof-boxes.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.collectSamplePositionsFromMoofBoxes = void 0;
const samples_from_moof_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/samples-from-moof.js [app-route] (ecmascript)");
const collectSamplePositionsFromMoofBoxes = ({ moofBoxes, tkhdBox, isComplete, trexBoxes })=>{
    const samplePositions = moofBoxes.map((m, index)=>{
        const isLastFragment = index === moofBoxes.length - 1 && isComplete;
        return {
            isLastFragment,
            samples: (0, samples_from_moof_1.getSamplesFromMoof)({
                moofBox: m,
                trackId: tkhdBox.trackId,
                trexBoxes
            })
        };
    });
    return {
        samplePositions,
        isComplete
    };
};
exports.collectSamplePositionsFromMoofBoxes = collectSamplePositionsFromMoofBoxes;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-sample-positions.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSamplePositions = void 0;
const getSamplePositions = ({ stcoBox, stszBox, stscBox, stssBox, sttsBox, cttsBox })=>{
    var _a;
    const sttsDeltas = [];
    for (const distribution of sttsBox.sampleDistribution){
        for(let i = 0; i < distribution.sampleCount; i++){
            sttsDeltas.push(distribution.sampleDelta);
        }
    }
    const cttsEntries = [];
    for (const entry of (_a = cttsBox === null || cttsBox === void 0 ? void 0 : cttsBox.entries) !== null && _a !== void 0 ? _a : [
        {
            sampleCount: sttsDeltas.length,
            sampleOffset: 0
        }
    ]){
        for(let i = 0; i < entry.sampleCount; i++){
            cttsEntries.push(entry.sampleOffset);
        }
    }
    let dts = 0;
    const chunks = stcoBox.entries;
    const samples = [];
    let samplesPerChunk = 1;
    for(let i = 0; i < chunks.length; i++){
        const hasEntry = stscBox.entries.get(i + 1);
        if (hasEntry !== undefined) {
            samplesPerChunk = hasEntry;
        }
        let offsetInThisChunk = 0;
        for(let j = 0; j < samplesPerChunk; j++){
            const size = stszBox.countType === 'fixed' ? stszBox.sampleSize : stszBox.entries[samples.length];
            const isKeyframe = stssBox ? stssBox.sampleNumber.has(samples.length + 1) : true;
            const delta = sttsDeltas[samples.length];
            const ctsOffset = cttsEntries[samples.length];
            const cts = dts + ctsOffset;
            samples.push({
                offset: Number(chunks[i]) + offsetInThisChunk,
                size,
                isKeyframe,
                decodingTimestamp: dts,
                timestamp: cts,
                duration: delta,
                chunk: i,
                bigEndian: false,
                chunkSize: null
            });
            dts += delta;
            offsetInThisChunk += size;
        }
    }
    return samples;
};
exports.getSamplePositions = getSamplePositions;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-sample-positions-from-mp4.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

// If an audio is of type, LPCM, the data structure will include 44100-48000 samples per second
// We need to handle this case differently and treat each chunk as a sample instead
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getGroupedSamplesPositionsFromMp4 = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
// example video: mehmet.mov
const getGroupedSamplesPositionsFromMp4 = ({ trakBox, bigEndian })=>{
    const stscBox = (0, traversal_1.getStscBox)(trakBox);
    const stszBox = (0, traversal_1.getStszBox)(trakBox);
    const stcoBox = (0, traversal_1.getStcoBox)(trakBox);
    if (!stscBox) {
        throw new Error('Expected stsc box in trak box');
    }
    if (!stcoBox) {
        throw new Error('Expected stco box in trak box');
    }
    if (!stszBox) {
        throw new Error('Expected stsz box in trak box');
    }
    if (stszBox.countType !== 'fixed') {
        throw new Error('Only supporting fixed count type in stsz box');
    }
    const samples = [];
    let timestamp = 0;
    const stscKeys = Array.from(stscBox.entries.keys());
    for(let i = 0; i < stcoBox.entries.length; i++){
        const entry = stcoBox.entries[i];
        const chunk = i + 1;
        const stscEntry = stscKeys.findLast((e)=>e <= chunk);
        if (stscEntry === undefined) {
            throw new Error('should not be');
        }
        const samplesPerChunk = stscBox.entries.get(stscEntry);
        if (samplesPerChunk === undefined) {
            throw new Error('should not be');
        }
        samples.push({
            chunk,
            timestamp,
            decodingTimestamp: timestamp,
            offset: Number(entry),
            size: stszBox.sampleSize * samplesPerChunk,
            duration: samplesPerChunk,
            isKeyframe: true,
            bigEndian,
            chunkSize: stszBox.sampleSize
        });
        timestamp += samplesPerChunk;
    }
    return samples;
};
exports.getGroupedSamplesPositionsFromMp4 = getGroupedSamplesPositionsFromMp4;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/should-group-audio-samples.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.shouldGroupAudioSamples = void 0;
const get_audio_codec_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-audio-codec.js [app-route] (ecmascript)");
const shouldGroupAudioSamples = (trakBox)=>{
    const isLpcm = (0, get_audio_codec_1.isLpcmAudioCodec)(trakBox);
    const isIn24 = (0, get_audio_codec_1.isIn24AudioCodec)(trakBox);
    const isTwos = (0, get_audio_codec_1.isTwosAudioCodec)(trakBox);
    if (isLpcm || isIn24 || isTwos) {
        return {
            bigEndian: isTwos || isIn24
        };
    }
    return null;
};
exports.shouldGroupAudioSamples = shouldGroupAudioSamples;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/collect-sample-positions-from-trak.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.collectSamplePositionsFromTrak = void 0;
const get_fps_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-fps.js [app-route] (ecmascript)");
const get_sample_positions_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-sample-positions.js [app-route] (ecmascript)");
const get_sample_positions_from_mp4_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-sample-positions-from-mp4.js [app-route] (ecmascript)");
const should_group_audio_samples_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/should-group-audio-samples.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const collectSamplePositionsFromTrak = (trakBox)=>{
    const shouldGroupSamples = (0, should_group_audio_samples_1.shouldGroupAudioSamples)(trakBox);
    const timescaleAndDuration = (0, get_fps_1.getTimescaleAndDuration)(trakBox);
    if (shouldGroupSamples) {
        return (0, get_sample_positions_from_mp4_1.getGroupedSamplesPositionsFromMp4)({
            trakBox,
            bigEndian: shouldGroupSamples.bigEndian
        });
    }
    const stszBox = (0, traversal_1.getStszBox)(trakBox);
    const stcoBox = (0, traversal_1.getStcoBox)(trakBox);
    const stscBox = (0, traversal_1.getStscBox)(trakBox);
    const stssBox = (0, traversal_1.getStssBox)(trakBox);
    const sttsBox = (0, traversal_1.getSttsBox)(trakBox);
    const cttsBox = (0, traversal_1.getCttsBox)(trakBox);
    if (!stszBox) {
        throw new Error('Expected stsz box in trak box');
    }
    if (!stcoBox) {
        throw new Error('Expected stco box in trak box');
    }
    if (!stscBox) {
        throw new Error('Expected stsc box in trak box');
    }
    if (!sttsBox) {
        throw new Error('Expected stts box in trak box');
    }
    if (!timescaleAndDuration) {
        throw new Error('Expected timescale and duration in trak box');
    }
    const samplePositions = (0, get_sample_positions_1.getSamplePositions)({
        stcoBox,
        stscBox,
        stszBox,
        stssBox,
        sttsBox,
        cttsBox
    });
    return samplePositions;
};
exports.collectSamplePositionsFromTrak = collectSamplePositionsFromTrak;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-sample-positions-from-track.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSamplePositionsFromTrack = void 0;
const collect_sample_positions_from_moof_boxes_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/collect-sample-positions-from-moof-boxes.js [app-route] (ecmascript)");
const collect_sample_positions_from_trak_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/collect-sample-positions-from-trak.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const getSamplePositionsFromTrack = ({ trakBox, moofBoxes, moofComplete, trexBoxes })=>{
    const tkhdBox = (0, traversal_1.getTkhdBox)(trakBox);
    if (!tkhdBox) {
        throw new Error('Expected tkhd box in trak box');
    }
    if (moofBoxes.length > 0) {
        const { samplePositions } = (0, collect_sample_positions_from_moof_boxes_1.collectSamplePositionsFromMoofBoxes)({
            moofBoxes,
            tkhdBox,
            isComplete: moofComplete,
            trexBoxes
        });
        return {
            samplePositions: samplePositions.map((s)=>s.samples).flat(1),
            isComplete: moofComplete
        };
    }
    return {
        samplePositions: (0, collect_sample_positions_from_trak_1.collectSamplePositionsFromTrak)(trakBox),
        isComplete: true
    };
};
exports.getSamplePositionsFromTrack = getSamplePositionsFromTrack;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-playlist.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getDurationFromPlaylist = exports.getPlaylist = exports.getAllPlaylists = void 0;
const get_streams_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-streams.js [app-route] (ecmascript)");
const getAllPlaylists = ({ structure, src })=>{
    const isIndependent = (0, get_streams_1.isIndependentSegments)(structure);
    if (!isIndependent) {
        return [
            {
                type: 'm3u-playlist',
                boxes: structure.boxes,
                src
            }
        ];
    }
    const playlists = structure.boxes.filter((box)=>box.type === 'm3u-playlist');
    // If no playlists found, this might be a single media playlist (not a master playlist)
    // Create a synthetic playlist from the structure boxes
    if (playlists.length === 0) {
        return [
            {
                type: 'm3u-playlist',
                boxes: structure.boxes,
                src
            }
        ];
    }
    return playlists;
};
exports.getAllPlaylists = getAllPlaylists;
const getPlaylist = (structure, src)=>{
    const allPlaylists = (0, exports.getAllPlaylists)({
        structure,
        src
    });
    const playlists = allPlaylists.find((box)=>box.src === src);
    if (!playlists) {
        throw new Error(`Expected m3u-playlist with src ${src}`);
    }
    return playlists;
};
exports.getPlaylist = getPlaylist;
const getDurationFromPlaylist = (playlist)=>{
    const duration = playlist.boxes.filter((box)=>box.type === 'm3u-extinf');
    if (duration.length === 0) {
        throw new Error('Expected duration in m3u playlist');
    }
    return duration.reduce((acc, d)=>acc + d.value, 0);
};
exports.getDurationFromPlaylist = getDurationFromPlaylist;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-duration-from-m3u.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getDurationFromM3u = void 0;
const get_playlist_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-playlist.js [app-route] (ecmascript)");
const getDurationFromM3u = (state)=>{
    const playlists = (0, get_playlist_1.getAllPlaylists)({
        structure: state.structure.getM3uStructure(),
        src: state.src
    });
    return Math.max(...playlists.map((p)=>{
        return (0, get_playlist_1.getDurationFromPlaylist)(p);
    }));
};
exports.getDurationFromM3u = getDurationFromM3u;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-frame-length.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMpegFrameLength = exports.getAverageMpegFrameLength = void 0;
const getUnroundedMpegFrameLength = ({ samplesPerFrame, bitrateKbit, samplingFrequency, padding, layer })=>{
    if (layer === 1) {
        throw new Error('MPEG Layer I is not supported');
    }
    return samplesPerFrame / 8 * bitrateKbit / samplingFrequency * 1000 + (padding ? layer === 1 ? 4 : 1 : 0);
};
const getAverageMpegFrameLength = ({ samplesPerFrame, bitrateKbit, samplingFrequency, layer })=>{
    const withoutPadding = getUnroundedMpegFrameLength({
        bitrateKbit,
        layer,
        padding: false,
        samplesPerFrame,
        samplingFrequency
    });
    const rounded = Math.floor(withoutPadding);
    const rest = withoutPadding % 1;
    return rest * (rounded + 1) + (1 - rest) * rounded;
};
exports.getAverageMpegFrameLength = getAverageMpegFrameLength;
const getMpegFrameLength = ({ samplesPerFrame, bitrateKbit, samplingFrequency, padding, layer })=>{
    return Math.floor(getUnroundedMpegFrameLength({
        bitrateKbit,
        layer,
        padding,
        samplesPerFrame,
        samplingFrequency
    }));
};
exports.getMpegFrameLength = getMpegFrameLength;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/samples-per-mpeg-file.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSamplesPerMpegFrame = void 0;
const getSamplesPerMpegFrame = ({ mpegVersion, layer })=>{
    if (mpegVersion === 1) {
        if (layer === 1) {
            return 384;
        }
        if (layer === 2 || layer === 3) {
            return 1152;
        }
    }
    if (mpegVersion === 2) {
        if (layer === 1) {
            return 384;
        }
        if (layer === 2) {
            return 1152;
        }
        if (layer === 3) {
            return 576;
        }
    }
    throw new Error('Invalid MPEG layer');
};
exports.getSamplesPerMpegFrame = getSamplesPerMpegFrame;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-duration.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getDurationFromMp3 = exports.getDurationFromMp3Xing = void 0;
const get_frame_length_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-frame-length.js [app-route] (ecmascript)");
const samples_per_mpeg_file_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/samples-per-mpeg-file.js [app-route] (ecmascript)");
const getDurationFromMp3Xing = ({ xingData, samplesPerFrame })=>{
    const xingFrames = xingData.numberOfFrames;
    if (!xingFrames) {
        throw new Error('Cannot get duration of VBR MP3 file - no frames');
    }
    const { sampleRate } = xingData;
    if (!sampleRate) {
        throw new Error('Cannot get duration of VBR MP3 file - no sample rate');
    }
    const xingSamples = xingFrames * samplesPerFrame;
    return xingSamples / sampleRate;
};
exports.getDurationFromMp3Xing = getDurationFromMp3Xing;
const getDurationFromMp3 = (state)=>{
    const mp3Info = state.mp3.getMp3Info();
    const mp3BitrateInfo = state.mp3.getMp3BitrateInfo();
    if (!mp3Info || !mp3BitrateInfo) {
        return null;
    }
    const samplesPerFrame = (0, samples_per_mpeg_file_1.getSamplesPerMpegFrame)({
        layer: mp3Info.layer,
        mpegVersion: mp3Info.mpegVersion
    });
    if (mp3BitrateInfo.type === 'variable') {
        return (0, exports.getDurationFromMp3Xing)({
            xingData: mp3BitrateInfo.xingData,
            samplesPerFrame
        });
    }
    /**
     * sonnet: The variation between 1044 and 1045 bytes in MP3 frames occurs due to the bit reservoir mechanism in MP3 encoding. Here's the typical distribution:
     * â€¢	1044 bytes (99% of frames)
     * â€¢	1045 bytes (1% of frames)
     */ // we ignore that fact for now
    const frameLengthInBytes = (0, get_frame_length_1.getMpegFrameLength)({
        bitrateKbit: mp3BitrateInfo.bitrateInKbit,
        padding: false,
        samplesPerFrame,
        samplingFrequency: mp3Info.sampleRate,
        layer: mp3Info.layer
    });
    const frames = Math.floor((state.contentLength - state.mediaSection.getMediaSectionAssertOnlyOne().start) / frameLengthInBytes);
    const samples = frames * samplesPerFrame;
    const durationInSeconds = samples / mp3Info.sampleRate;
    return durationInSeconds;
};
exports.getDurationFromMp3 = getDurationFromMp3;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/get-duration.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSampleRateFromAvi = exports.getDurationFromAvi = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/traversal.js [app-route] (ecmascript)");
const getDurationFromAvi = (structure)=>{
    const strl = (0, traversal_1.getStrlBoxes)(structure);
    const lengths = [];
    for (const s of strl){
        const strh = (0, traversal_1.getStrhBox)(s.children);
        if (!strh) {
            throw new Error('No strh box');
        }
        const samplesPerSecond = strh.rate / strh.scale;
        const streamLength = strh.length / samplesPerSecond;
        lengths.push(streamLength);
    }
    return Math.max(...lengths);
};
exports.getDurationFromAvi = getDurationFromAvi;
const getSampleRateFromAvi = (structure)=>{
    const strl = (0, traversal_1.getStrlBoxes)(structure);
    for (const s of strl){
        const strh = (0, traversal_1.getStrhBox)(s.children);
        if (!strh) {
            throw new Error('No strh box');
        }
        if (strh.strf.type === 'strf-box-audio') {
            return strh.strf.sampleRate;
        }
    }
    return null;
};
exports.getSampleRateFromAvi = getSampleRateFromAvi;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/get-duration-from-wav.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getDurationFromWav = void 0;
const getDurationFromWav = (state)=>{
    const structure = state.structure.getWavStructure();
    const fmt = structure.boxes.find((b)=>b.type === 'wav-fmt');
    if (!fmt) {
        throw new Error('Expected fmt box');
    }
    const dataBox = structure.boxes.find((b)=>b.type === 'wav-data');
    if (!dataBox) {
        throw new Error('Expected data box');
    }
    const durationInSeconds = dataBox.dataSize / (fmt.sampleRate * fmt.blockAlign);
    return durationInSeconds;
};
exports.getDurationFromWav = getDurationFromWav;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/precomputed-tfra.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.deduplicateTfraBoxesByOffset = exports.precomputedTfraState = void 0;
const precomputedTfraState = ()=>{
    let tfraBoxes = [];
    return {
        getTfraBoxes: ()=>tfraBoxes,
        setTfraBoxes: (boxes)=>{
            tfraBoxes = boxes;
        }
    };
};
exports.precomputedTfraState = precomputedTfraState;
const deduplicateTfraBoxesByOffset = (tfraBoxes)=>{
    return tfraBoxes.filter((m, i, arr)=>i === arr.findIndex((t)=>t.offset === m.offset));
};
exports.deduplicateTfraBoxesByOffset = deduplicateTfraBoxesByOffset;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-duration.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasSlowDuration = exports.hasDuration = exports.getDuration = exports.isMatroska = void 0;
const get_duration_from_flac_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-duration-from-flac.js [app-route] (ecmascript)");
const are_samples_complete_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/are-samples-complete.js [app-route] (ecmascript)");
const get_sample_positions_from_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-sample-positions-from-track.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const get_duration_from_m3u_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-duration-from-m3u.js [app-route] (ecmascript)");
const get_duration_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-duration.js [app-route] (ecmascript)");
const get_duration_2 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/get-duration.js [app-route] (ecmascript)");
const get_duration_from_wav_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/get-duration-from-wav.js [app-route] (ecmascript)");
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const precomputed_tfra_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/precomputed-tfra.js [app-route] (ecmascript)");
const getDurationFromMatroska = (segments)=>{
    const mainSegment = segments.find((s)=>s.type === 'Segment');
    if (!mainSegment || mainSegment.type !== 'Segment') {
        return null;
    }
    const { value: children } = mainSegment;
    if (!children) {
        return null;
    }
    const infoSegment = children.find((s)=>s.type === 'Info');
    const relevantBoxes = [
        ...mainSegment.value,
        ...infoSegment && infoSegment.type === 'Info' ? infoSegment.value : []
    ];
    const timestampScale = relevantBoxes.find((s)=>s.type === 'TimestampScale');
    if (!timestampScale || timestampScale.type !== 'TimestampScale') {
        return null;
    }
    const duration = relevantBoxes.find((s)=>s.type === 'Duration');
    if (!duration || duration.type !== 'Duration') {
        return null;
    }
    return duration.value.value / timestampScale.value.value * 1000;
};
const isMatroska = (boxes)=>{
    const matroskaBox = boxes.find((b)=>b.type === 'Segment');
    return matroskaBox;
};
exports.isMatroska = isMatroska;
const getDurationFromIsoBaseMedia = (parserState)=>{
    var _a, _b;
    const structure = parserState.structure.getIsoStructure();
    const moovBox = (0, traversal_1.getMoovBoxFromState)({
        structureState: parserState.structure,
        isoState: parserState.iso,
        mp4HeaderSegment: (_b = (_a = parserState.m3uPlaylistContext) === null || _a === void 0 ? void 0 : _a.mp4HeaderSegment) !== null && _b !== void 0 ? _b : null,
        mayUsePrecomputed: true
    });
    if (!moovBox) {
        return null;
    }
    const moofBoxes = (0, traversal_1.getMoofBoxes)(structure.boxes);
    const mfra = parserState.iso.mfra.getIfAlreadyLoaded();
    const tfraBoxes = (0, precomputed_tfra_1.deduplicateTfraBoxesByOffset)([
        ...mfra ? (0, traversal_1.getTfraBoxesFromMfraBoxChildren)(mfra) : [],
        ...(0, traversal_1.getTfraBoxes)(structure.boxes)
    ]);
    if (!(0, are_samples_complete_1.areSamplesComplete)({
        moofBoxes,
        tfraBoxes
    })) {
        return null;
    }
    const mvhdBox = (0, traversal_1.getMvhdBox)(moovBox);
    if (!mvhdBox) {
        return null;
    }
    if (mvhdBox.type !== 'mvhd-box') {
        throw new Error('Expected mvhd-box');
    }
    if (mvhdBox.durationInSeconds > 0) {
        return mvhdBox.durationInSeconds;
    }
    const tracks = (0, get_tracks_1.getTracks)(parserState, true);
    const allSamples = tracks.map((t)=>{
        const { originalTimescale: ts } = t;
        const trakBox = (0, traversal_1.getTrakBoxByTrackId)(moovBox, t.trackId);
        if (!trakBox) {
            return null;
        }
        const { samplePositions, isComplete } = (0, get_sample_positions_from_track_1.getSamplePositionsFromTrack)({
            trakBox,
            moofBoxes,
            moofComplete: (0, are_samples_complete_1.areSamplesComplete)({
                moofBoxes,
                tfraBoxes
            }),
            trexBoxes: (0, traversal_1.getTrexBoxes)(moovBox)
        });
        if (!isComplete) {
            return null;
        }
        if (samplePositions.length === 0) {
            return null;
        }
        const highest = samplePositions === null || samplePositions === void 0 ? void 0 : samplePositions.map((sp)=>(sp.timestamp + sp.duration) / ts).reduce((a, b)=>Math.max(a, b), 0);
        return highest !== null && highest !== void 0 ? highest : 0;
    });
    if (allSamples.every((s)=>s === null)) {
        return null;
    }
    const highestTimestamp = Math.max(...allSamples.filter((s)=>s !== null));
    return highestTimestamp;
};
const getDuration = (parserState)=>{
    const structure = parserState.structure.getStructure();
    if (structure.type === 'matroska') {
        return getDurationFromMatroska(structure.boxes);
    }
    if (structure.type === 'iso-base-media') {
        return getDurationFromIsoBaseMedia(parserState);
    }
    if (structure.type === 'riff') {
        return (0, get_duration_2.getDurationFromAvi)(structure);
    }
    if (structure.type === 'transport-stream') {
        return null;
    }
    if (structure.type === 'mp3') {
        return (0, get_duration_1.getDurationFromMp3)(parserState);
    }
    if (structure.type === 'wav') {
        return (0, get_duration_from_wav_1.getDurationFromWav)(parserState);
    }
    if (structure.type === 'aac') {
        return null;
    }
    if (structure.type === 'flac') {
        return (0, get_duration_from_flac_1.getDurationFromFlac)(parserState);
    }
    if (structure.type === 'm3u') {
        return (0, get_duration_from_m3u_1.getDurationFromM3u)(parserState);
    }
    throw new Error('Has no duration ' + structure);
};
exports.getDuration = getDuration;
// `duration` just grabs from metadata, and otherwise returns null
// Therefore just checking if we have tracks
const hasDuration = (parserState)=>{
    const structure = parserState.structure.getStructureOrNull();
    if (structure === null) {
        return false;
    }
    return (0, get_tracks_1.getHasTracks)(parserState, true);
};
exports.hasDuration = hasDuration;
// `slowDuration` goes through everything, and therefore is false
// Unless it it somewhere in the metadata and is non-null
const hasSlowDuration = (parserState)=>{
    try {
        if (!(0, exports.hasDuration)(parserState)) {
            return false;
        }
        return (0, exports.getDuration)(parserState) !== null;
    } catch (_a) {
        return false;
    }
};
exports.hasSlowDuration = hasSlowDuration;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-is-hdr.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasHdr = exports.getIsHdr = void 0;
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const isVideoTrackHdr = (track)=>{
    return track.advancedColor.matrix === 'bt2020-ncl' && (track.advancedColor.transfer === 'hlg' || track.advancedColor.transfer === 'pq') && track.advancedColor.primaries === 'bt2020';
};
const getIsHdr = (state)=>{
    const tracks = (0, get_tracks_1.getTracks)(state, true);
    return tracks.some((track)=>track.type === 'video' && isVideoTrackHdr(track));
};
exports.getIsHdr = getIsHdr;
const hasHdr = (state)=>{
    return (0, get_tracks_1.getHasTracks)(state, true);
};
exports.hasHdr = hasHdr;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-keyframes.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getKeyframesFromIsoBaseMedia = void 0;
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const are_samples_complete_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/are-samples-complete.js [app-route] (ecmascript)");
const get_sample_positions_from_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-sample-positions-from-track.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const getKeyframesFromIsoBaseMedia = (state)=>{
    const tracks = (0, get_tracks_1.getTracksFromIsoBaseMedia)({
        isoState: state.iso,
        m3uPlaylistContext: state.m3uPlaylistContext,
        structure: state.structure,
        mayUsePrecomputed: true
    });
    const videoTracks = tracks.filter((t)=>t.type === 'video');
    const structure = state.structure.getIsoStructure();
    const moofBoxes = (0, traversal_1.getMoofBoxes)(structure.boxes);
    const tfraBoxes = (0, traversal_1.getTfraBoxes)(structure.boxes);
    const moov = (0, traversal_1.getMoovFromFromIsoStructure)(structure);
    if (!moov) {
        return [];
    }
    const allSamples = videoTracks.map((t)=>{
        const { originalTimescale: ts } = t;
        const trakBox = (0, traversal_1.getTrakBoxByTrackId)(moov, t.trackId);
        if (!trakBox) {
            return [];
        }
        const { samplePositions, isComplete } = (0, get_sample_positions_from_track_1.getSamplePositionsFromTrack)({
            trakBox,
            moofBoxes,
            moofComplete: (0, are_samples_complete_1.areSamplesComplete)({
                moofBoxes,
                tfraBoxes
            }),
            trexBoxes: (0, traversal_1.getTrexBoxes)(moov)
        });
        if (!isComplete) {
            return [];
        }
        const keyframes = samplePositions.filter((k)=>{
            return k.isKeyframe;
        }).map((k)=>{
            return {
                trackId: t.trackId,
                presentationTimeInSeconds: k.timestamp / ts,
                decodingTimeInSeconds: k.decodingTimestamp / ts,
                positionInBytes: k.offset,
                sizeInBytes: k.size
            };
        });
        return keyframes;
    });
    return allSamples.flat();
};
exports.getKeyframesFromIsoBaseMedia = getKeyframesFromIsoBaseMedia;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-keyframes.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasKeyframes = exports.getKeyframes = void 0;
const get_keyframes_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-keyframes.js [app-route] (ecmascript)");
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const getKeyframes = (state)=>{
    const structure = state.structure.getStructure();
    if (structure.type === 'iso-base-media') {
        return (0, get_keyframes_1.getKeyframesFromIsoBaseMedia)(state);
    }
    return null;
};
exports.getKeyframes = getKeyframes;
const hasKeyframes = (parserState)=>{
    const structure = parserState.structure.getStructure();
    if (structure.type === 'iso-base-media') {
        return (0, get_tracks_1.getHasTracks)(parserState, true);
    }
    // Has, but will be null
    return true;
};
exports.hasKeyframes = hasKeyframes;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-metadata-from-flac.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMetadataFromFlac = void 0;
const getMetadataFromFlac = (structure)=>{
    const box = structure.boxes.find((b)=>b.type === 'flac-vorbis-comment');
    if (!box) {
        return null;
    }
    return box.fields;
};
exports.getMetadataFromFlac = getMetadataFromFlac;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-metadata-from-mp3.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMetadataFromMp3 = void 0;
const getMetadataFromMp3 = (mp3Structure)=>{
    const findHeader = mp3Structure.boxes.find((b)=>b.type === 'id3-header');
    return findHeader ? findHeader.metatags : null;
};
exports.getMetadataFromMp3 = getMetadataFromMp3;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/get-metadata-from-wav.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMetadataFromWav = void 0;
const getMetadataFromWav = (structure)=>{
    const list = structure.boxes.find((b)=>b.type === 'wav-list');
    if (!list) {
        return null;
    }
    return list.metadata;
};
exports.getMetadataFromWav = getMetadataFromWav;
}),
"[project]/node_modules/@remotion/media-parser/dist/metadata/metadata-from-iso.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMetadataFromIsoBase = exports.parseIsoMetaBox = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const truthy_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/truthy.js [app-route] (ecmascript)");
/**
 *
 * @param ilstBox 	Â©ART - Artist
    â–ª	Hex: A9 41 52 54
    2.	Â©alb - Album
    â–ª	Hex: A9 61 6C 62
    3.	Â©cmt - Comment
    â–ª	Hex: A9 63 6D 74
    4.	Â©day - Release Date
    â–ª	Hex: A9 64 61 79
    5.	Â©gen - Genre
    â–ª	Hex: A9 67 65 6E
    6.	Â©nam - Title
    â–ª	Hex: A9 6E 61 6D
    7.	Â©too - Encoder
    â–ª	Hex: A9 74 6F 6F
    8.	Â©wrt - Writer
    â–ª	Hex: A9 77 72 74
    9.	Â©cpy - Copyright
    â–ª	Hex: A9 63 70 79
    10.	Â©dir - Director
    â–ª	Hex: A9 64 69 72
    11.	Â©prd - Producer
    â–ª	Hex: A9 70 72 64
    12.	Â©des - Description
    â–ª	Hex: A9 64 65 73
 */ const mapToKey = (index)=>{
    if (index === 'ï¿½ART') {
        return 'artist';
    }
    if (index === 'ï¿½alb') {
        return 'album';
    }
    if (index === 'ï¿½cmt') {
        return 'comment';
    }
    if (index === 'ï¿½day') {
        return 'releaseDate';
    }
    if (index === 'ï¿½gen') {
        return 'genre';
    }
    if (index === 'ï¿½nam') {
        return 'title';
    }
    if (index === 'ï¿½too') {
        return 'encoder';
    }
    if (index === 'ï¿½wrt') {
        return 'writer';
    }
    if (index === 'ï¿½cpy') {
        return 'copyright';
    }
    if (index === 'ï¿½dir') {
        return 'director';
    }
    if (index === 'ï¿½prd') {
        return 'producer';
    }
    if (index === 'ï¿½des') {
        return 'description';
    }
    return null;
};
const parseIlstBoxWithoutKeys = (ilstBox)=>{
    return ilstBox.entries.map((entry)=>{
        const key = mapToKey(entry.index);
        if (!key) {
            return null;
        }
        if (entry.value.type === 'unknown') {
            return null;
        }
        return {
            trackId: null,
            key,
            value: entry.value.value
        };
    }).filter(truthy_1.truthy);
};
const parseIsoMetaBox = (meta, trackId)=>{
    const ilstBox = meta.children.find((b)=>b.type === 'ilst-box');
    const keysBox = meta.children.find((b)=>b.type === 'keys-box');
    if (!ilstBox || !keysBox) {
        if (ilstBox) {
            return parseIlstBoxWithoutKeys(ilstBox);
        }
        return [];
    }
    const entries = [];
    for(let i = 0; i < ilstBox.entries.length; i++){
        const ilstEntry = ilstBox.entries[i];
        const keysEntry = keysBox.entries[i];
        if (ilstEntry.value.type !== 'unknown') {
            const value = typeof ilstEntry.value.value === 'string' && ilstEntry.value.value.endsWith('\u0000') ? ilstEntry.value.value.slice(0, -1) : ilstEntry.value.value;
            entries.push({
                key: keysEntry.value,
                value,
                trackId
            });
        }
    }
    return entries;
};
exports.parseIsoMetaBox = parseIsoMetaBox;
const getMetadataFromIsoBase = (state)=>{
    var _a, _b;
    const moov = (0, traversal_1.getMoovBoxFromState)({
        structureState: state.structure,
        isoState: state.iso,
        mp4HeaderSegment: (_b = (_a = state.m3uPlaylistContext) === null || _a === void 0 ? void 0 : _a.mp4HeaderSegment) !== null && _b !== void 0 ? _b : null,
        mayUsePrecomputed: true
    });
    if (!moov) {
        return [];
    }
    const traks = (0, traversal_1.getTraks)(moov);
    const meta = moov.children.find((b)=>b.type === 'regular-box' && b.boxType === 'meta');
    const udta = moov.children.find((b)=>b.type === 'regular-box' && b.boxType === 'udta');
    const metaInUdta = udta === null || udta === void 0 ? void 0 : udta.children.find((b)=>{
        return b.type === 'regular-box' && b.boxType === 'meta';
    });
    const metaInTracks = traks.map((t)=>{
        const metaBox = t.children.find((child)=>child.type === 'regular-box' && child.boxType === 'meta');
        if (metaBox) {
            const tkhd = (0, traversal_1.getTkhdBox)(t);
            if (!tkhd) {
                throw new Error('No tkhd box found');
            }
            return (0, exports.parseIsoMetaBox)(metaBox, tkhd.trackId);
        }
        return null;
    }).filter(truthy_1.truthy);
    return [
        ...meta ? (0, exports.parseIsoMetaBox)(meta, null) : [],
        ...metaInUdta ? (0, exports.parseIsoMetaBox)(metaInUdta, null) : [],
        ...metaInTracks.flat(1)
    ];
};
exports.getMetadataFromIsoBase = getMetadataFromIsoBase;
}),
"[project]/node_modules/@remotion/media-parser/dist/metadata/metadata-from-matroska.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMetadataFromMatroska = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/traversal.js [app-route] (ecmascript)");
const removeEndZeroes = (value)=>{
    return value.endsWith('\u0000') ? removeEndZeroes(value.slice(0, -1)) : value;
};
const parseSimpleTagIntoEbml = (children, trackId)=>{
    const tagName = children.find((c)=>c.type === 'TagName');
    const tagString = children.find((c)=>c.type === 'TagString');
    if (!tagName || !tagString) {
        return null;
    }
    return {
        trackId,
        key: tagName.value.toLowerCase(),
        value: removeEndZeroes(tagString.value)
    };
};
const getMetadataFromMatroska = (structure)=>{
    var _a;
    const entries = [];
    for (const segment of structure.boxes){
        if (segment.type !== 'Segment') {
            continue;
        }
        const tags = segment.value.filter((s)=>s.type === 'Tags');
        for (const tag of tags){
            for (const child of tag.value){
                if (child.type !== 'Tag') {
                    continue;
                }
                let trackId = null;
                const target = child.value.find((c)=>c.type === 'Targets');
                if (target) {
                    const tagTrackId = (_a = target.value.find((c)=>c.type === 'TagTrackUID')) === null || _a === void 0 ? void 0 : _a.value;
                    if (tagTrackId) {
                        trackId = (0, traversal_1.getTrackWithUid)(segment, tagTrackId);
                    }
                }
                const simpleTags = child.value.filter((s)=>s.type === 'SimpleTag');
                for (const simpleTag of simpleTags){
                    const parsed = parseSimpleTagIntoEbml(simpleTag.value, trackId);
                    if (parsed) {
                        entries.push(parsed);
                    }
                }
            }
        }
    }
    return entries;
};
exports.getMetadataFromMatroska = getMetadataFromMatroska;
}),
"[project]/node_modules/@remotion/media-parser/dist/metadata/metadata-from-riff.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMetadataFromRiff = void 0;
const truthy_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/truthy.js [app-route] (ecmascript)");
const getMetadataFromRiff = (structure)=>{
    const boxes = structure.boxes.find((b)=>b.type === 'list-box' && b.listType === 'INFO');
    if (!boxes) {
        return [];
    }
    const { children } = boxes;
    return children.map((child)=>{
        if (child.type !== 'isft-box') {
            return null;
        }
        return {
            trackId: null,
            key: 'encoder',
            value: child.software
        };
    }).filter(truthy_1.truthy);
};
exports.getMetadataFromRiff = getMetadataFromRiff;
}),
"[project]/node_modules/@remotion/media-parser/dist/metadata/get-metadata.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasMetadata = exports.getMetadata = void 0;
const get_metadata_from_flac_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-metadata-from-flac.js [app-route] (ecmascript)");
const get_metadata_from_mp3_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-metadata-from-mp3.js [app-route] (ecmascript)");
const get_metadata_from_wav_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/get-metadata-from-wav.js [app-route] (ecmascript)");
const metadata_from_iso_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/metadata/metadata-from-iso.js [app-route] (ecmascript)");
const metadata_from_matroska_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/metadata/metadata-from-matroska.js [app-route] (ecmascript)");
const metadata_from_riff_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/metadata/metadata-from-riff.js [app-route] (ecmascript)");
const getMetadata = (state)=>{
    var _a, _b;
    const structure = state.structure.getStructure();
    if (structure.type === 'matroska') {
        return (0, metadata_from_matroska_1.getMetadataFromMatroska)(structure);
    }
    if (structure.type === 'riff') {
        return (0, metadata_from_riff_1.getMetadataFromRiff)(structure);
    }
    if (structure.type === 'transport-stream' || structure.type === 'm3u') {
        return [];
    }
    if (structure.type === 'mp3') {
        const tags = (0, get_metadata_from_mp3_1.getMetadataFromMp3)(structure);
        // Not all MP3s file have this header.
        // Internal link: https://discord.com/channels/809501355504959528/1001500302375125055/1408880907602890752
        return tags !== null && tags !== void 0 ? tags : [];
    }
    if (structure.type === 'wav') {
        return (_a = (0, get_metadata_from_wav_1.getMetadataFromWav)(structure)) !== null && _a !== void 0 ? _a : [];
    }
    if (structure.type === 'aac') {
        return [];
    }
    if (structure.type === 'flac') {
        return (_b = (0, get_metadata_from_flac_1.getMetadataFromFlac)(structure)) !== null && _b !== void 0 ? _b : [];
    }
    if (structure.type === 'iso-base-media') {
        return (0, metadata_from_iso_1.getMetadataFromIsoBase)(state);
    }
    throw new Error('Unknown container ' + structure);
};
exports.getMetadata = getMetadata;
// TODO: This forces some containers to check the whole file
// we can do this better! skip over video data
const hasMetadata = (structure)=>{
    if (structure.type === 'mp3') {
        return (0, get_metadata_from_mp3_1.getMetadataFromMp3)(structure) !== null;
    }
    if (structure.type === 'wav') {
        return (0, get_metadata_from_wav_1.getMetadataFromWav)(structure) !== null;
    }
    // M3U, Transport Stream, AAC cannot store any metadata
    if (structure.type === 'm3u' || structure.type === 'transport-stream' || structure.type === 'aac') {
        return true;
    }
    if (structure.type === 'flac') {
        return (0, get_metadata_from_flac_1.getMetadataFromFlac)(structure) !== null;
    }
    // The following containers (MP4, Matroska, AVI) all have mechanisms
    // to skip over video sections, and tests for it in read-metadata.test.ts
    if (structure.type === 'iso-base-media') {
        return false;
    }
    if (structure.type === 'matroska') {
        return false;
    }
    if (structure.type === 'riff') {
        return false;
    }
    throw new Error('Unknown container ' + structure);
};
exports.hasMetadata = hasMetadata;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-location.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getLocation = void 0;
exports.parseLocation = parseLocation;
const get_metadata_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/metadata/get-metadata.js [app-route] (ecmascript)");
function parseLocation(locationString) {
    const locationPattern = /^([+-]\d{2}\.?\d{0,10})([+-]\d{3}\.?\d{0,10})([+-]\d+(\.\d+)?)?\/$/;
    const match = locationString.match(locationPattern);
    if (!match) {
        return null;
    }
    // Extract latitude, longitude, and altitude
    const latitude = parseFloat(match[1]);
    const longitude = parseFloat(match[2]);
    const altitude = match[3] ? parseFloat(match[3]) : null;
    return {
        latitude,
        longitude,
        altitude
    };
}
const getLocation = (state)=>{
    const metadata = (0, get_metadata_1.getMetadata)(state);
    const locationEntry = metadata.find((entry)=>entry.key === 'com.apple.quicktime.location.ISO6709');
    const horizontalAccuracy = metadata.find((entry)=>entry.key === 'com.apple.quicktime.location.accuracy.horizontal');
    if (locationEntry) {
        const parsed = parseLocation(locationEntry.value);
        if (parsed === null) {
            return null;
        }
        return {
            ...parsed,
            horizontalAccuracy: (horizontalAccuracy === null || horizontalAccuracy === void 0 ? void 0 : horizontalAccuracy.value) ? parseFloat(String(horizontalAccuracy.value)) : null
        };
    }
    return null;
};
exports.getLocation = getLocation;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-number-of-audio-channels.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasNumberOfAudioChannels = exports.getNumberOfAudioChannels = void 0;
const getNumberOfAudioChannels = (state)=>{
    var _a, _b;
    return (_b = (_a = state.callbacks.tracks.getTracks().find((track)=>{
        return track.type === 'audio';
    })) === null || _a === void 0 ? void 0 : _a.numberOfChannels) !== null && _b !== void 0 ? _b : null;
};
exports.getNumberOfAudioChannels = getNumberOfAudioChannels;
const hasNumberOfAudioChannels = (state)=>{
    return state.callbacks.tracks.hasAllTracks();
};
exports.hasNumberOfAudioChannels = hasNumberOfAudioChannels;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-sample-rate.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasSampleRate = exports.getSampleRate = void 0;
const getSampleRate = (state)=>{
    var _a, _b;
    return (_b = (_a = state.callbacks.tracks.getTracks().find((track)=>{
        return track.type === 'audio';
    })) === null || _a === void 0 ? void 0 : _a.sampleRate) !== null && _b !== void 0 ? _b : null;
};
exports.getSampleRate = getSampleRate;
const hasSampleRate = (state)=>{
    return state.callbacks.tracks.hasAllTracks();
};
exports.hasSampleRate = hasSampleRate;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/aac/get-seeking-byte.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingByteForAac = void 0;
const getSeekingByteForAac = ({ time, seekingHints })=>{
    let bestAudioSample;
    for (const hint of seekingHints.audioSampleMap){
        if (hint.timeInSeconds > time) {
            continue;
        }
        // Everything is a keyframe in flac, so if this sample does not cover the time, it's not a good candidate.
        // Let's go to the next one. Exception: If we already saw the last sample, we use it so we find can at least
        // find the closest one.
        if (hint.timeInSeconds + hint.durationInSeconds < time && !seekingHints.lastSampleObserved) {
            continue;
        }
        if (!bestAudioSample) {
            bestAudioSample = hint;
            continue;
        }
        if (bestAudioSample.timeInSeconds < hint.timeInSeconds) {
            bestAudioSample = hint;
        }
    }
    if (bestAudioSample) {
        return {
            type: 'do-seek',
            byte: bestAudioSample.offset,
            timeInSeconds: bestAudioSample.timeInSeconds
        };
    }
    return {
        type: 'valid-but-must-wait'
    };
};
exports.getSeekingByteForAac = getSeekingByteForAac;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-seeking-byte.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingByteForFlac = void 0;
const getSeekingByteForFlac = ({ time, seekingHints })=>{
    let bestAudioSample;
    for (const hint of seekingHints.audioSampleMap){
        if (hint.timeInSeconds > time) {
            continue;
        }
        // Everything is a keyframe in flac, so if this sample does not cover the time, it's not a good candidate.
        // Let's go to the next one. Exception: If we already saw the last sample, we use it so we find can at least
        // find the closest one.
        if (hint.timeInSeconds + hint.durationInSeconds < time && !seekingHints.lastSampleObserved) {
            continue;
        }
        if (!bestAudioSample) {
            bestAudioSample = hint;
            continue;
        }
        if (bestAudioSample.timeInSeconds < hint.timeInSeconds) {
            bestAudioSample = hint;
        }
    }
    if (bestAudioSample) {
        return bestAudioSample;
    }
    return null;
};
exports.getSeekingByteForFlac = getSeekingByteForFlac;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/find-keyframe-before-time.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.findKeyframeBeforeTime = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const findKeyframeBeforeTime = ({ samplePositions, time, timescale, mediaSections, logLevel, startInSeconds })=>{
    let videoByte = 0;
    let videoSample = null;
    for (const sample of samplePositions){
        const ctsInSeconds = sample.timestamp / timescale + startInSeconds;
        const dtsInSeconds = sample.decodingTimestamp / timescale + startInSeconds;
        if (!sample.isKeyframe) {
            continue;
        }
        if (!(ctsInSeconds <= time || dtsInSeconds <= time)) {
            continue;
        }
        if (videoByte <= sample.offset) {
            videoByte = sample.offset;
            videoSample = sample;
        }
    }
    if (!videoSample) {
        throw new Error('No sample found');
    }
    const mediaSection = mediaSections.find((section)=>videoSample.offset >= section.start && videoSample.offset < section.start + section.size);
    if (!mediaSection) {
        log_1.Log.trace(logLevel, 'Found a sample, but the offset has not yet been marked as a video section yet. Not yet able to seek, but probably once we have started reading the next box.', videoSample);
        return null;
    }
    return videoSample;
};
exports.findKeyframeBeforeTime = findKeyframeBeforeTime;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/find-track-to-seek.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.findTrackToSeek = exports.findAnyTrackWithSamplePositions = void 0;
const are_samples_complete_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/are-samples-complete.js [app-route] (ecmascript)");
const get_sample_positions_from_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-sample-positions-from-track.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const findAnyTrackWithSamplePositions = (allTracks, struc)=>{
    const moov = (0, traversal_1.getMoovFromFromIsoStructure)(struc);
    if (!moov) {
        return null;
    }
    for (const track of allTracks){
        if (track.type === 'video' || track.type === 'audio') {
            const trakBox = (0, traversal_1.getTrakBoxByTrackId)(moov, track.trackId);
            if (!trakBox) {
                continue;
            }
            const { samplePositions } = (0, get_sample_positions_from_track_1.getSamplePositionsFromTrack)({
                trakBox,
                moofBoxes: (0, traversal_1.getMoofBoxes)(struc.boxes),
                moofComplete: (0, are_samples_complete_1.areSamplesComplete)({
                    moofBoxes: (0, traversal_1.getMoofBoxes)(struc.boxes),
                    tfraBoxes: (0, traversal_1.getTfraBoxes)(struc.boxes)
                }),
                trexBoxes: (0, traversal_1.getTrexBoxes)(moov)
            });
            if (samplePositions.length === 0) {
                continue;
            }
            return {
                track,
                samplePositions
            };
        }
    }
    return null;
};
exports.findAnyTrackWithSamplePositions = findAnyTrackWithSamplePositions;
const findTrackToSeek = (allTracks, structure)=>{
    const firstVideoTrack = allTracks.find((t)=>t.type === 'video');
    const struc = structure.getIsoStructure();
    if (!firstVideoTrack) {
        return (0, exports.findAnyTrackWithSamplePositions)(allTracks, struc);
    }
    const moov = (0, traversal_1.getMoovFromFromIsoStructure)(struc);
    if (!moov) {
        return null;
    }
    const trakBox = (0, traversal_1.getTrakBoxByTrackId)(moov, firstVideoTrack.trackId);
    if (!trakBox) {
        return null;
    }
    const { samplePositions } = (0, get_sample_positions_from_track_1.getSamplePositionsFromTrack)({
        trakBox,
        moofBoxes: (0, traversal_1.getMoofBoxes)(struc.boxes),
        moofComplete: (0, are_samples_complete_1.areSamplesComplete)({
            moofBoxes: (0, traversal_1.getMoofBoxes)(struc.boxes),
            tfraBoxes: (0, traversal_1.getTfraBoxes)(struc.boxes)
        }),
        trexBoxes: (0, traversal_1.getTrexBoxes)(moov)
    });
    if (samplePositions.length === 0) {
        return (0, exports.findAnyTrackWithSamplePositions)(allTracks, struc);
    }
    return {
        track: firstVideoTrack,
        samplePositions
    };
};
exports.findTrackToSeek = findTrackToSeek;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/video-section.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * Keeps track of in which section of the file the video is playing
 * Usually this section is in a different format and it is the only section
 * that can be read partially
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.mediaSectionState = exports.getCurrentMediaSection = exports.isByteInMediaSection = void 0;
const isByteInMediaSection = ({ position, mediaSections })=>{
    if (mediaSections.length === 0) {
        return 'no-section-defined';
    }
    for (const section of mediaSections){
        if (position >= section.start && position < section.start + section.size) {
            return 'in-section';
        }
    }
    return 'outside-section';
};
exports.isByteInMediaSection = isByteInMediaSection;
const getCurrentMediaSection = ({ offset, mediaSections })=>{
    for (const section of mediaSections){
        if (offset >= section.start && offset < section.start + section.size) {
            return section;
        }
    }
    return null;
};
exports.getCurrentMediaSection = getCurrentMediaSection;
const mediaSectionState = ()=>{
    const mediaSections = [];
    const addMediaSection = (section)=>{
        // Check if section overlaps with any existing sections
        const overlaps = mediaSections.some((existingSection)=>section.start < existingSection.start + existingSection.size && section.start + section.size > existingSection.start);
        if (overlaps) {
            return;
        }
        // Remove any existing sections that are encompassed by the new section
        // Needed by Matroska because we need to define a 1 byte media section
        // when seeking into a Cluster we have not seen yet
        for(let i = mediaSections.length - 1; i >= 0; i--){
            const existingSection = mediaSections[i];
            if (section.start <= existingSection.start && section.start + section.size >= existingSection.start + existingSection.size) {
                mediaSections.splice(i, 1);
            }
        }
        mediaSections.push(section);
    };
    const getMediaSections = ()=>{
        return mediaSections;
    };
    const isCurrentByteInMediaSection = (iterator)=>{
        const offset = iterator.counter.getOffset();
        return (0, exports.isByteInMediaSection)({
            position: offset,
            mediaSections
        });
    };
    const getMediaSectionAssertOnlyOne = ()=>{
        if (mediaSections.length !== 1) {
            throw new Error('Expected only one video section');
        }
        return mediaSections[0];
    };
    return {
        addMediaSection,
        getMediaSections,
        isCurrentByteInMediaSection,
        isByteInMediaSection: exports.isByteInMediaSection,
        getCurrentMediaSection: exports.getCurrentMediaSection,
        getMediaSectionAssertOnlyOne,
        mediaSections
    };
};
exports.mediaSectionState = mediaSectionState;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-sample-position-bounds.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSamplePositionBounds = void 0;
const getSamplePositionBounds = (samplePositions, timescale)=>{
    var _a;
    let min = Infinity;
    let max = -Infinity;
    for (const samplePosition of samplePositions){
        const timestampMin = Math.min(samplePosition.timestamp, samplePosition.decodingTimestamp);
        const timestampMax = Math.max(samplePosition.timestamp, samplePosition.decodingTimestamp) + ((_a = samplePosition.duration) !== null && _a !== void 0 ? _a : 0);
        if (timestampMin < min) {
            min = timestampMin;
        }
        if (timestampMax > max) {
            max = timestampMax;
        }
    }
    return {
        min: min / timescale,
        max: max / timescale
    };
};
exports.getSamplePositionBounds = getSamplePositionBounds;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mfra/find-best-segment-from-tfra.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.findBestSegmentFromTfra = void 0;
const findBestSegmentFromTfra = ({ mfra, time, firstTrack, timescale })=>{
    const tfra = mfra.find((b)=>b.type === 'tfra-box' && b.trackId === firstTrack.trackId);
    if (!tfra) {
        return null;
    }
    let bestSegment = null;
    for (const segment of tfra.entries){
        if (segment.time / timescale <= time) {
            bestSegment = segment;
        }
    }
    if (!bestSegment) {
        return null;
    }
    const currentSegmentIndex = tfra.entries.indexOf(bestSegment);
    const offsetOfNext = currentSegmentIndex === tfra.entries.length - 1 ? Infinity : tfra.entries[currentSegmentIndex + 1].moofOffset;
    return {
        start: bestSegment.moofOffset,
        end: offsetOfNext
    };
};
exports.findBestSegmentFromTfra = findBestSegmentFromTfra;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-seeking-byte-from-fragmented-mp4.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingByteFromFragmentedMp4 = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const video_section_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/video-section.js [app-route] (ecmascript)");
const are_samples_complete_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/are-samples-complete.js [app-route] (ecmascript)");
const collect_sample_positions_from_moof_boxes_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/collect-sample-positions-from-moof-boxes.js [app-route] (ecmascript)");
const find_keyframe_before_time_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/find-keyframe-before-time.js [app-route] (ecmascript)");
const get_sample_position_bounds_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-sample-position-bounds.js [app-route] (ecmascript)");
const find_best_segment_from_tfra_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mfra/find-best-segment-from-tfra.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const getSeekingByteFromFragmentedMp4 = async ({ info, time, logLevel, currentPosition, isoState, tracks, isLastChunkInPlaylist, structure, mp4HeaderSegment })=>{
    const firstVideoTrack = tracks.find((t)=>t.type === 'video');
    // If there is both video and audio, seek based on video, but if not then audio is also okay
    const firstTrack = firstVideoTrack !== null && firstVideoTrack !== void 0 ? firstVideoTrack : tracks.find((t)=>t.type === 'audio');
    if (!firstTrack) {
        throw new Error('no video and no audio tracks');
    }
    const moov = (0, traversal_1.getMoovBoxFromState)({
        structureState: structure,
        isoState,
        mp4HeaderSegment,
        mayUsePrecomputed: true
    });
    if (!moov) {
        throw new Error('No moov atom found');
    }
    const trakBox = (0, traversal_1.getTrakBoxByTrackId)(moov, firstTrack.trackId);
    if (!trakBox) {
        throw new Error('No trak box found');
    }
    const tkhdBox = (0, traversal_1.getTkhdBox)(trakBox);
    if (!tkhdBox) {
        throw new Error('Expected tkhd box in trak box');
    }
    const isComplete = (0, are_samples_complete_1.areSamplesComplete)({
        moofBoxes: info.moofBoxes,
        tfraBoxes: info.tfraBoxes
    });
    const { samplePositions: samplePositionsArray } = (0, collect_sample_positions_from_moof_boxes_1.collectSamplePositionsFromMoofBoxes)({
        moofBoxes: info.moofBoxes,
        tkhdBox,
        isComplete,
        trexBoxes: (0, traversal_1.getTrexBoxes)(moov)
    });
    log_1.Log.trace(logLevel, 'Fragmented MP4 - Checking if we have seeking info for this time range');
    for (const positions of samplePositionsArray){
        const { min, max } = (0, get_sample_position_bounds_1.getSamplePositionBounds)(positions.samples, firstTrack.originalTimescale);
        if (min <= time && (positions.isLastFragment || isLastChunkInPlaylist || time <= max)) {
            log_1.Log.trace(logLevel, `Fragmented MP4 - Found that we have seeking info for this time range: ${min} <= ${time} <= ${max}`);
            const kf = (0, find_keyframe_before_time_1.findKeyframeBeforeTime)({
                samplePositions: positions.samples,
                time,
                timescale: firstTrack.originalTimescale,
                logLevel,
                mediaSections: info.mediaSections,
                startInSeconds: firstTrack.startInSeconds
            });
            if (kf) {
                return {
                    type: 'do-seek',
                    byte: kf.offset,
                    timeInSeconds: Math.min(kf.decodingTimestamp, kf.timestamp) / firstTrack.originalTimescale
                };
            }
        }
    }
    const atom = await (info.mfraAlreadyLoaded ? Promise.resolve(info.mfraAlreadyLoaded) : isoState.mfra.triggerLoad());
    if (atom) {
        const moofOffset = (0, find_best_segment_from_tfra_1.findBestSegmentFromTfra)({
            mfra: atom,
            time,
            firstTrack,
            timescale: firstTrack.originalTimescale
        });
        if (moofOffset !== null && !(moofOffset.start <= currentPosition && currentPosition < moofOffset.end)) {
            log_1.Log.verbose(logLevel, `Fragmented MP4 - Found based on mfra information that we should seek to: ${moofOffset.start} ${moofOffset.end}`);
            return {
                type: 'intermediary-seek',
                byte: moofOffset.start
            };
        }
    }
    log_1.Log.trace(logLevel, 'Fragmented MP4 - No seeking info found for this time range.');
    if ((0, video_section_1.isByteInMediaSection)({
        position: currentPosition,
        mediaSections: info.mediaSections
    }) !== 'in-section') {
        return {
            type: 'valid-but-must-wait'
        };
    }
    log_1.Log.trace(logLevel, 'Fragmented MP4 - Inside the wrong video section, skipping to the end of the section');
    const mediaSection = (0, video_section_1.getCurrentMediaSection)({
        offset: currentPosition,
        mediaSections: info.mediaSections
    });
    if (!mediaSection) {
        throw new Error('No video section defined');
    }
    return {
        type: 'intermediary-seek',
        byte: mediaSection.start + mediaSection.size
    };
};
exports.getSeekingByteFromFragmentedMp4 = getSeekingByteFromFragmentedMp4;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-seeking-byte.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingByteFromIsoBaseMedia = void 0;
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const find_keyframe_before_time_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/find-keyframe-before-time.js [app-route] (ecmascript)");
const find_track_to_seek_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/find-track-to-seek.js [app-route] (ecmascript)");
const get_seeking_byte_from_fragmented_mp4_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-seeking-byte-from-fragmented-mp4.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const getSeekingByteFromIsoBaseMedia = ({ info, time, logLevel, currentPosition, isoState, m3uPlaylistContext, structure })=>{
    var _a, _b, _c;
    const tracks = (0, get_tracks_1.getTracksFromIsoBaseMedia)({
        isoState,
        m3uPlaylistContext,
        structure,
        mayUsePrecomputed: false
    });
    const hasMoov = Boolean((0, traversal_1.getMoovBoxFromState)({
        structureState: structure,
        isoState,
        mayUsePrecomputed: false,
        mp4HeaderSegment: (_a = m3uPlaylistContext === null || m3uPlaylistContext === void 0 ? void 0 : m3uPlaylistContext.mp4HeaderSegment) !== null && _a !== void 0 ? _a : null
    }));
    if (!hasMoov) {
        log_1.Log.trace(logLevel, 'No moov box found, must wait');
        return Promise.resolve({
            type: 'valid-but-must-wait'
        });
    }
    if (info.moofBoxes.length > 0) {
        return (0, get_seeking_byte_from_fragmented_mp4_1.getSeekingByteFromFragmentedMp4)({
            info,
            time,
            logLevel,
            currentPosition,
            isoState,
            tracks,
            isLastChunkInPlaylist: (_b = m3uPlaylistContext === null || m3uPlaylistContext === void 0 ? void 0 : m3uPlaylistContext.isLastChunkInPlaylist) !== null && _b !== void 0 ? _b : false,
            structure,
            mp4HeaderSegment: (_c = m3uPlaylistContext === null || m3uPlaylistContext === void 0 ? void 0 : m3uPlaylistContext.mp4HeaderSegment) !== null && _c !== void 0 ? _c : null
        });
    }
    const trackWithSamplePositions = (0, find_track_to_seek_1.findTrackToSeek)(tracks, structure);
    if (!trackWithSamplePositions) {
        return Promise.resolve({
            type: 'valid-but-must-wait'
        });
    }
    const { track, samplePositions } = trackWithSamplePositions;
    const keyframe = (0, find_keyframe_before_time_1.findKeyframeBeforeTime)({
        samplePositions,
        time,
        timescale: track.originalTimescale,
        logLevel,
        mediaSections: info.mediaSections,
        startInSeconds: track.startInSeconds
    });
    if (keyframe) {
        return Promise.resolve({
            type: 'do-seek',
            byte: keyframe.offset,
            timeInSeconds: Math.min(keyframe.decodingTimestamp, keyframe.timestamp) / track.originalTimescale
        });
    }
    return Promise.resolve({
        type: 'invalid'
    });
};
exports.getSeekingByteFromIsoBaseMedia = getSeekingByteFromIsoBaseMedia;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-seeking-byte.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingByteForM3u8 = exports.clearM3uStateInPrepareForSeek = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const clearM3uStateInPrepareForSeek = ({ m3uState, logLevel })=>{
    const selectedPlaylists = m3uState.getSelectedPlaylists();
    for (const playlistUrl of selectedPlaylists){
        const streamRun = m3uState.getM3uStreamRun(playlistUrl);
        if (streamRun) {
            streamRun.abort();
        }
        log_1.Log.trace(logLevel, 'Clearing M3U stream run for', playlistUrl);
        m3uState.setM3uStreamRun(playlistUrl, null);
    }
    m3uState.clearAllChunksProcessed();
    m3uState.sampleSorter.clearSamples();
};
exports.clearM3uStateInPrepareForSeek = clearM3uStateInPrepareForSeek;
const getSeekingByteForM3u8 = ({ time, currentPosition, m3uState, logLevel })=>{
    (0, exports.clearM3uStateInPrepareForSeek)({
        m3uState,
        logLevel
    });
    const selectedPlaylists = m3uState.getSelectedPlaylists();
    for (const playlistUrl of selectedPlaylists){
        m3uState.setSeekToSecondsToProcess(playlistUrl, {
            targetTime: time
        });
    }
    return {
        type: 'do-seek',
        byte: currentPosition,
        // TODO: This will be imperfect when seeking in playMedia()
        timeInSeconds: time
    };
};
exports.getSeekingByteForM3u8 = getSeekingByteForM3u8;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/get-approximate-byte-from-bitrate.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getApproximateByteFromBitrate = void 0;
const get_frame_length_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-frame-length.js [app-route] (ecmascript)");
const samples_per_mpeg_file_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/samples-per-mpeg-file.js [app-route] (ecmascript)");
const getApproximateByteFromBitrate = ({ mp3BitrateInfo, timeInSeconds, mp3Info, mediaSection, contentLength })=>{
    if (mp3BitrateInfo.type === 'variable') {
        return null;
    }
    const samplesPerFrame = (0, samples_per_mpeg_file_1.getSamplesPerMpegFrame)({
        layer: mp3Info.layer,
        mpegVersion: mp3Info.mpegVersion
    });
    const frameLengthInBytes = (0, get_frame_length_1.getMpegFrameLength)({
        bitrateKbit: mp3BitrateInfo.bitrateInKbit,
        padding: false,
        samplesPerFrame,
        samplingFrequency: mp3Info.sampleRate,
        layer: mp3Info.layer
    });
    const frameIndexUnclamped = Math.floor(timeInSeconds * mp3Info.sampleRate / samplesPerFrame);
    const frames = Math.floor((contentLength - mediaSection.start) / frameLengthInBytes);
    const frameIndex = Math.min(frames - 1, frameIndexUnclamped);
    const byteRelativeToMediaSection = frameIndex * frameLengthInBytes;
    const byteBeforeFrame = byteRelativeToMediaSection + mediaSection.start;
    return byteBeforeFrame;
};
exports.getApproximateByteFromBitrate = getApproximateByteFromBitrate;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/get-byte-from-observed-samples.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getByteFromObservedSamples = void 0;
const getByteFromObservedSamples = ({ info, timeInSeconds })=>{
    let bestAudioSample;
    for (const hint of info.audioSampleMap){
        if (hint.timeInSeconds > timeInSeconds) {
            continue;
        }
        // Everything is a keyframe in mp3, so if this sample does not cover the time, it's not a good candidate.
        // Let's go to the next one. Exception: If we already saw the last sample, we use it so we find can at least
        // find the closest one.
        if (hint.timeInSeconds + hint.durationInSeconds < timeInSeconds && !info.lastSampleObserved) {
            continue;
        }
        if (!bestAudioSample) {
            bestAudioSample = hint;
            continue;
        }
        if (bestAudioSample.timeInSeconds < hint.timeInSeconds) {
            bestAudioSample = hint;
        }
    }
    return bestAudioSample;
};
exports.getByteFromObservedSamples = getByteFromObservedSamples;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/parse-xing.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

// implementation of http://www.mp3-tech.org/programmer/sources/vbrheadersdk.zip
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getTimeFromPosition = exports.getSeekPointInBytes = exports.parseXing = void 0;
const SAMPLE_RATES = [
    44100,
    48000,
    32000,
    99999
];
const FRAMES_FLAG = 0x0001;
const BYTES_FLAG = 0x0002;
const TOC_FLAG = 0x0004;
const VBR_SCALE_FLAG = 0x0008;
const extractI4 = (data, offset)=>{
    let x = 0;
    x = data[offset];
    x <<= 8;
    x |= data[offset + 1];
    x <<= 8;
    x |= data[offset + 2];
    x <<= 8;
    x |= data[offset + 3];
    return x;
};
const parseXing = (data)=>{
    const h_id = data[1] >> 3 & 1;
    const h_sr_index = data[2] >> 2 & 3;
    const h_mode = data[3] >> 6 & 3;
    let xingOffset = 0;
    if (h_id) {
        // mpeg1
        if (h_mode !== 3) {
            xingOffset += 32 + 4;
        } else {
            xingOffset += 17 + 4;
        }
    } else if (h_mode !== 3) {
        xingOffset += 17 + 4;
    } else {
        xingOffset += 9 + 4;
    }
    const expectXing = new TextDecoder('utf8').decode(data.slice(xingOffset, xingOffset + 4));
    if (expectXing !== 'Xing') {
        throw new Error('Invalid Xing header');
    }
    let sampleRate = SAMPLE_RATES[h_sr_index];
    if (h_id === 0) {
        sampleRate >>= 1;
    }
    let offset = xingOffset + 4;
    const flags = extractI4(data, offset);
    offset += 4;
    let numberOfFrames;
    let fileSize;
    let tableOfContents;
    let vbrScale;
    if (flags & FRAMES_FLAG) {
        numberOfFrames = extractI4(data, offset);
        offset += 4;
    }
    if (flags & BYTES_FLAG) {
        fileSize = extractI4(data, offset);
        offset += 4;
    }
    if (flags & TOC_FLAG) {
        tableOfContents = data.slice(offset, offset + 100);
        offset += 100;
    }
    if (flags & VBR_SCALE_FLAG) {
        vbrScale = extractI4(data, offset);
        offset += 4;
    }
    // Allow extra data after the standard Xing fields, as some encoders add additional information
    if (offset > data.length) {
        throw new Error('xing header was parsed wrong: read beyond available data');
    }
    return {
        sampleRate,
        numberOfFrames: numberOfFrames !== null && numberOfFrames !== void 0 ? numberOfFrames : null,
        fileSize: fileSize !== null && fileSize !== void 0 ? fileSize : null,
        tableOfContents: tableOfContents ? Array.from(tableOfContents.slice(0, 100)) : null,
        vbrScale: vbrScale !== null && vbrScale !== void 0 ? vbrScale : null
    };
};
exports.parseXing = parseXing;
const getSeekPointInBytes = ({ fileSize, percentBetween0And100, tableOfContents })=>{
    let index = Math.floor(percentBetween0And100);
    if (index > 99) {
        index = 99;
    }
    const fa = tableOfContents[index];
    let fb;
    if (index < 99) {
        fb = tableOfContents[index + 1];
    } else {
        fb = 256;
    }
    const fx = fa + (fb - fa) * (percentBetween0And100 - index);
    const seekPoint = 1 / 256 * fx * fileSize;
    return Math.floor(seekPoint);
};
exports.getSeekPointInBytes = getSeekPointInBytes;
const getTimeFromPosition = ({ position, fileSize, tableOfContents, durationInSeconds })=>{
    // Convert position to a value between 0-256
    const positionNormalized = position / fileSize * 256;
    // Find the closest indices in the table of contents
    let index = 0;
    while(index < 99 && tableOfContents[index + 1] <= positionNormalized){
        index++;
    }
    const fa = tableOfContents[index];
    const fb = index < 99 ? tableOfContents[index + 1] : 256;
    // Interpolate between the two points
    const percentWithinSegment = (positionNormalized - fa) / (fb - fa);
    const percentBetween0And100 = index + percentWithinSegment;
    // Convert percentage to time
    return percentBetween0And100 / 100 * durationInSeconds;
};
exports.getTimeFromPosition = getTimeFromPosition;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/get-seek-point-from-xing.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekPointFromXing = void 0;
const get_duration_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-duration.js [app-route] (ecmascript)");
const parse_xing_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/parse-xing.js [app-route] (ecmascript)");
const samples_per_mpeg_file_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/samples-per-mpeg-file.js [app-route] (ecmascript)");
const getSeekPointFromXing = ({ timeInSeconds, xingData, mp3Info })=>{
    const samplesPerFrame = (0, samples_per_mpeg_file_1.getSamplesPerMpegFrame)({
        layer: mp3Info.layer,
        mpegVersion: mp3Info.mpegVersion
    });
    const duration = (0, get_duration_1.getDurationFromMp3Xing)({
        xingData,
        samplesPerFrame
    });
    const totalSamples = timeInSeconds * xingData.sampleRate;
    // -1 frame so we are sure to be before the target
    const oneFrameSubtracted = totalSamples - samplesPerFrame;
    const timeToTarget = Math.max(0, oneFrameSubtracted / xingData.sampleRate);
    if (!xingData.fileSize || !xingData.tableOfContents) {
        throw new Error('Cannot seek of VBR MP3 file');
    }
    return (0, parse_xing_1.getSeekPointInBytes)({
        fileSize: xingData.fileSize,
        percentBetween0And100: timeToTarget / duration * 100,
        tableOfContents: xingData.tableOfContents
    });
};
exports.getSeekPointFromXing = getSeekPointFromXing;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-seeking-byte.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingByteForMp3 = void 0;
const get_approximate_byte_from_bitrate_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/get-approximate-byte-from-bitrate.js [app-route] (ecmascript)");
const get_byte_from_observed_samples_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/get-byte-from-observed-samples.js [app-route] (ecmascript)");
const get_seek_point_from_xing_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/get-seek-point-from-xing.js [app-route] (ecmascript)");
const getSeekingByteForMp3 = ({ time, info })=>{
    var _a;
    if (info.mp3BitrateInfo === null || info.mp3Info === null || info.mediaSection === null) {
        return {
            type: 'valid-but-must-wait'
        };
    }
    const approximateByte = (0, get_approximate_byte_from_bitrate_1.getApproximateByteFromBitrate)({
        mp3BitrateInfo: info.mp3BitrateInfo,
        timeInSeconds: time,
        mp3Info: info.mp3Info,
        mediaSection: info.mediaSection,
        contentLength: info.contentLength
    });
    const bestAudioSample = (0, get_byte_from_observed_samples_1.getByteFromObservedSamples)({
        info,
        timeInSeconds: time
    });
    const xingSeekPoint = info.mp3BitrateInfo.type === 'variable' ? (0, get_seek_point_from_xing_1.getSeekPointFromXing)({
        mp3Info: info.mp3Info,
        timeInSeconds: time,
        xingData: info.mp3BitrateInfo.xingData
    }) : null;
    const candidates = [
        approximateByte,
        (_a = bestAudioSample === null || bestAudioSample === void 0 ? void 0 : bestAudioSample.offset) !== null && _a !== void 0 ? _a : null,
        xingSeekPoint
    ].filter((b)=>b !== null);
    if (candidates.length === 0) {
        return {
            type: 'valid-but-must-wait'
        };
    }
    const byte = Math.max(...candidates);
    const timeInSeconds = byte === (bestAudioSample === null || bestAudioSample === void 0 ? void 0 : bestAudioSample.offset) ? bestAudioSample.timeInSeconds : time;
    return {
        type: 'do-seek',
        byte,
        timeInSeconds
    };
};
exports.getSeekingByteForMp3 = getSeekingByteForMp3;
}),
"[project]/node_modules/@remotion/media-parser/dist/find-last-keyframe.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.findLastKeyframe = findLastKeyframe;
function findLastKeyframe({ keyframes, timeInSeconds }) {
    let bestKeyframe = null;
    for (const keyframe of keyframes){
        if (keyframe.presentationTimeInSeconds > timeInSeconds && keyframe.decodingTimeInSeconds > timeInSeconds) {
            break;
        }
        if (bestKeyframe === null || keyframe.presentationTimeInSeconds > bestKeyframe.presentationTimeInSeconds) {
            bestKeyframe = keyframe;
        }
    }
    return bestKeyframe;
}
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/get-seeking-byte.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingByteForRiff = void 0;
const find_last_keyframe_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/find-last-keyframe.js [app-route] (ecmascript)");
const getSeekingByteForRiff = async ({ info, time, riffState, avcState })=>{
    const idx1Entries = await (info.hasIndex ? riffState.lazyIdx1.waitForLoaded() : Promise.resolve(null));
    if (idx1Entries === null) {
        const lastKeyframe = (0, find_last_keyframe_1.findLastKeyframe)({
            keyframes: info.observedKeyframes,
            timeInSeconds: time
        });
        if (lastKeyframe === null) {
            return {
                type: 'valid-but-must-wait'
            };
        }
        riffState.sampleCounter.setSamplesFromSeek(lastKeyframe.sampleCounts);
        riffState.queuedBFrames.clear();
        avcState.clear();
        return {
            type: 'do-seek',
            byte: lastKeyframe.positionInBytes,
            timeInSeconds: Math.min(lastKeyframe.decodingTimeInSeconds, lastKeyframe.presentationTimeInSeconds)
        };
    }
    if (idx1Entries.videoTrackIndex === null) {
        throw new Error('videoTrackIndex is null');
    }
    if (info.samplesPerSecond === null) {
        throw new Error('samplesPerSecond is null');
    }
    const index = Math.floor(time * info.samplesPerSecond);
    let bestEntry = null;
    for (const entry of idx1Entries.entries){
        if (entry.sampleCounts[idx1Entries.videoTrackIndex] > index) {
            continue;
        }
        if (bestEntry && entry.sampleCounts[idx1Entries.videoTrackIndex] < bestEntry.sampleCounts[idx1Entries.videoTrackIndex]) {
            continue;
        }
        bestEntry = entry;
    }
    if (!bestEntry) {
        throw new Error('No best entry');
    }
    if (info.moviOffset === null) {
        throw new Error('moviOffset is null');
    }
    riffState.sampleCounter.setSamplesFromSeek(bestEntry.sampleCounts);
    riffState.queuedBFrames.clear();
    avcState.clear();
    return {
        type: 'do-seek',
        byte: bestEntry.offset + info.moviOffset - 4,
        timeInSeconds: bestEntry.sampleCounts[idx1Entries.videoTrackIndex] / info.samplesPerSecond
    };
};
exports.getSeekingByteForRiff = getSeekingByteForRiff;
}),
"[project]/node_modules/@remotion/media-parser/dist/convert-audio-or-video-sample.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.convertAudioOrVideoSampleToWebCodecsTimestamps = void 0;
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const fixFloat = (value)=>{
    if (value % 1 < 0.0000001) {
        return Math.floor(value);
    }
    if (value % 1 > 0.9999999) {
        return Math.ceil(value);
    }
    return value;
};
const convertAudioOrVideoSampleToWebCodecsTimestamps = ({ sample, timescale })=>{
    if (timescale === webcodecs_timescale_1.WEBCODECS_TIMESCALE) {
        return sample;
    }
    const { decodingTimestamp: dts, timestamp } = sample;
    return {
        decodingTimestamp: fixFloat(dts * (webcodecs_timescale_1.WEBCODECS_TIMESCALE / timescale)),
        timestamp: fixFloat(timestamp * (webcodecs_timescale_1.WEBCODECS_TIMESCALE / timescale)),
        duration: sample.duration === undefined ? undefined : fixFloat(sample.duration * (webcodecs_timescale_1.WEBCODECS_TIMESCALE / timescale)),
        data: sample.data,
        type: sample.type,
        offset: sample.offset,
        ...'avc' in sample ? {
            avc: sample.avc
        } : {}
    };
};
exports.convertAudioOrVideoSampleToWebCodecsTimestamps = convertAudioOrVideoSampleToWebCodecsTimestamps;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/avc/interpret-sps.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getVideoColorFromSps = exports.getSampleAspectRatioFromSps = exports.getDimensionsFromSps = void 0;
const color_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/color.js [app-route] (ecmascript)");
const getDimensionsFromSps = (sps)=>{
    var _a, _b, _c, _d;
    const height = sps.pic_height_in_map_units_minus1;
    const width = sps.pic_width_in_mbs_minus1;
    // https://stackoverflow.com/questions/12018535/get-the-width-height-of-the-video-from-h-264-nalu
    return {
        height: (height + 1) * 16 - ((_a = sps.frame_crop_bottom_offset) !== null && _a !== void 0 ? _a : 0) * 2 - ((_b = sps.frame_crop_top_offset) !== null && _b !== void 0 ? _b : 0) * 2,
        width: (width + 1) * 16 - ((_c = sps.frame_crop_right_offset) !== null && _c !== void 0 ? _c : 0) * 2 - ((_d = sps.frame_crop_left_offset) !== null && _d !== void 0 ? _d : 0) * 2
    };
};
exports.getDimensionsFromSps = getDimensionsFromSps;
const getSampleAspectRatioFromSps = (sps)=>{
    var _a;
    if (((_a = sps.vui_parameters) === null || _a === void 0 ? void 0 : _a.sar_height) && sps.vui_parameters.sar_width) {
        return {
            width: sps.vui_parameters.sar_width,
            height: sps.vui_parameters.sar_height
        };
    }
    return {
        width: 1,
        height: 1
    };
};
exports.getSampleAspectRatioFromSps = getSampleAspectRatioFromSps;
const getVideoColorFromSps = (sps)=>{
    var _a, _b, _c, _d, _e;
    const matrixCoefficients = (_a = sps.vui_parameters) === null || _a === void 0 ? void 0 : _a.matrix_coefficients;
    const transferCharacteristics = (_b = sps.vui_parameters) === null || _b === void 0 ? void 0 : _b.transfer_characteristics;
    const colorPrimaries = (_c = sps.vui_parameters) === null || _c === void 0 ? void 0 : _c.colour_primaries;
    return {
        matrix: matrixCoefficients ? (0, color_1.getMatrixCoefficientsFromIndex)(matrixCoefficients) : null,
        transfer: transferCharacteristics ? (0, color_1.getTransferCharacteristicsFromIndex)(transferCharacteristics) : null,
        primaries: colorPrimaries ? (0, color_1.getPrimariesFromIndex)(colorPrimaries) : null,
        fullRange: (_e = (_d = sps.vui_parameters) === null || _d === void 0 ? void 0 : _d.video_full_range_flag) !== null && _e !== void 0 ? _e : null
    };
};
exports.getVideoColorFromSps = getVideoColorFromSps;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/avc/key.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getKeyFrameOrDeltaFromAvcInfo = void 0;
const getKeyFrameOrDeltaFromAvcInfo = (infos)=>{
    const keyOrDelta = infos.find((i)=>i.type === 'keyframe' || i.type === 'delta-frame');
    if (!keyOrDelta) {
        throw new Error('expected avc to contain info about key or delta');
    }
    return keyOrDelta.type === 'keyframe' ? 'key' : keyOrDelta.isBidirectionalFrame ? 'bidirectional' : 'delta';
};
exports.getKeyFrameOrDeltaFromAvcInfo = getKeyFrameOrDeltaFromAvcInfo;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/avc/sps-and-pps.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSpsAndPps = void 0;
const getSpsAndPps = (infos)=>{
    const avcProfile = infos.find((i)=>i.type === 'avc-profile');
    const ppsProfile = infos.find((i)=>i.type === 'avc-pps');
    if (!avcProfile || !ppsProfile) {
        throw new Error('Expected avcProfile and ppsProfile');
    }
    return {
        pps: ppsProfile,
        sps: avcProfile
    };
};
exports.getSpsAndPps = getSpsAndPps;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/handle-avc-packet.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.handleAvcPacket = exports.MPEG_TIMESCALE = void 0;
const convert_audio_or_video_sample_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/convert-audio-or-video-sample.js [app-route] (ecmascript)");
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const codec_string_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/codec-string.js [app-route] (ecmascript)");
const create_sps_pps_data_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/create-sps-pps-data.js [app-route] (ecmascript)");
const interpret_sps_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/interpret-sps.js [app-route] (ecmascript)");
const key_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/key.js [app-route] (ecmascript)");
const parse_avc_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/parse-avc.js [app-route] (ecmascript)");
const sps_and_pps_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/sps-and-pps.js [app-route] (ecmascript)");
const color_to_webcodecs_colors_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/color-to-webcodecs-colors.js [app-route] (ecmascript)");
exports.MPEG_TIMESCALE = 90000;
const handleAvcPacket = async ({ streamBuffer, programId, offset, sampleCallbacks, logLevel, onVideoTrack, transportStream, makeSamplesStartAtZero, avcState })=>{
    var _a, _b;
    const avc = (0, parse_avc_1.parseAvc)(streamBuffer.getBuffer(), avcState);
    const isTrackRegistered = sampleCallbacks.tracks.getTracks().find((t)=>{
        return t.trackId === programId;
    });
    if (!isTrackRegistered) {
        const spsAndPps = (0, sps_and_pps_1.getSpsAndPps)(avc);
        const dimensions = (0, interpret_sps_1.getDimensionsFromSps)(spsAndPps.sps.spsData);
        const sampleAspectRatio = (0, interpret_sps_1.getSampleAspectRatioFromSps)(spsAndPps.sps.spsData);
        const startOffset = makeSamplesStartAtZero ? Math.min(streamBuffer.pesHeader.pts, (_a = streamBuffer.pesHeader.dts) !== null && _a !== void 0 ? _a : Infinity) : 0;
        transportStream.startOffset.setOffset({
            trackId: programId,
            newOffset: startOffset
        });
        const codecPrivate = (0, create_sps_pps_data_1.createSpsPpsData)(spsAndPps);
        const advancedColor = (0, interpret_sps_1.getVideoColorFromSps)(spsAndPps.sps.spsData);
        const track = {
            m3uStreamFormat: null,
            rotation: 0,
            trackId: programId,
            type: 'video',
            originalTimescale: exports.MPEG_TIMESCALE,
            codec: (0, codec_string_1.getCodecStringFromSpsAndPps)(spsAndPps.sps),
            codecData: {
                type: 'avc-sps-pps',
                data: codecPrivate
            },
            fps: null,
            codedWidth: dimensions.width,
            codedHeight: dimensions.height,
            height: dimensions.height,
            width: dimensions.width,
            displayAspectWidth: dimensions.width,
            displayAspectHeight: dimensions.height,
            codecEnum: 'h264',
            // ChatGPT: In a transport stream (â .ts), H.264 video is always stored in Annex B format
            // WebCodecs spec says that description must be undefined for Annex B format
            // https://www.w3.org/TR/webcodecs-avc-codec-registration/#videodecoderconfig-description
            description: undefined,
            sampleAspectRatio: {
                denominator: sampleAspectRatio.height,
                numerator: sampleAspectRatio.width
            },
            colorSpace: (0, color_to_webcodecs_colors_1.mediaParserAdvancedColorToWebCodecsColor)(advancedColor),
            advancedColor,
            startInSeconds: 0,
            timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
            trackMediaTimeOffsetInTrackTimescale: 0
        };
        await (0, register_track_1.registerVideoTrack)({
            track,
            container: 'transport-stream',
            logLevel,
            onVideoTrack,
            registerVideoSampleCallback: sampleCallbacks.registerVideoSampleCallback,
            tracks: sampleCallbacks.tracks
        });
    }
    const type = (0, key_1.getKeyFrameOrDeltaFromAvcInfo)(avc);
    // sample for webcodecs needs to be in nano seconds
    const sample = {
        decodingTimestamp: ((_b = streamBuffer.pesHeader.dts) !== null && _b !== void 0 ? _b : streamBuffer.pesHeader.pts) - transportStream.startOffset.getOffset(programId),
        timestamp: streamBuffer.pesHeader.pts - transportStream.startOffset.getOffset(programId),
        duration: undefined,
        data: streamBuffer.getBuffer(),
        type: type === 'bidirectional' ? 'delta' : type,
        offset
    };
    if (type === 'key') {
        transportStream.observedPesHeaders.markPtsAsKeyframe(streamBuffer.pesHeader.pts);
    }
    const videoSample = (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
        sample,
        timescale: exports.MPEG_TIMESCALE
    });
    await sampleCallbacks.onVideoSample({
        videoSample,
        trackId: programId
    });
    transportStream.lastEmittedSample.setLastEmittedSample(sample);
};
exports.handleAvcPacket = handleAvcPacket;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/get-seeking-byte.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingByteFromWav = exports.WAVE_SAMPLES_PER_SECOND = void 0;
exports.WAVE_SAMPLES_PER_SECOND = 25;
const getSeekingByteFromWav = ({ info, time })=>{
    const bytesPerSecond = info.sampleRate * info.blockAlign;
    const durationInSeconds = info.mediaSection.size / bytesPerSecond;
    const timeRoundedDown = Math.floor(Math.min(time, durationInSeconds - 0.0000001) * exports.WAVE_SAMPLES_PER_SECOND) / exports.WAVE_SAMPLES_PER_SECOND;
    const byteOffset = bytesPerSecond * timeRoundedDown;
    return Promise.resolve({
        type: 'do-seek',
        byte: byteOffset + info.mediaSection.start,
        timeInSeconds: timeRoundedDown
    });
};
exports.getSeekingByteFromWav = getSeekingByteFromWav;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/seek/get-seeking-byte.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingByteFromMatroska = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const toSeconds = (timeInTimescale, track)=>{
    return timeInTimescale / track.timescale * 1000;
};
const findBiggestCueBeforeTime = ({ cues, time, track })=>{
    let biggestCueBeforeTime;
    for (const cue of cues){
        const cueTimeInSeconds = toSeconds(cue.timeInTimescale, track);
        if (cueTimeInSeconds < time && (!biggestCueBeforeTime || cueTimeInSeconds > toSeconds(biggestCueBeforeTime.timeInTimescale, track))) {
            biggestCueBeforeTime = cue;
        }
    }
    return biggestCueBeforeTime;
};
const findKeyframeBeforeTime = ({ keyframes, time })=>{
    let keyframeBeforeTime;
    for (const keyframe of keyframes){
        if (keyframe.decodingTimeInSeconds < time && (!keyframeBeforeTime || keyframe.decodingTimeInSeconds > keyframeBeforeTime.decodingTimeInSeconds)) {
            keyframeBeforeTime = keyframe;
        }
    }
    return keyframeBeforeTime !== null && keyframeBeforeTime !== void 0 ? keyframeBeforeTime : null;
};
const getByteFromCues = ({ cuesResponse, time, info, logLevel })=>{
    if (!cuesResponse) {
        log_1.Log.trace(logLevel, 'Has no Matroska cues at the moment, cannot use them');
        return null;
    }
    const { cues, segmentOffset } = cuesResponse;
    log_1.Log.trace(logLevel, 'Has Matroska cues. Will use them to perform a seek.');
    const biggestCueBeforeTime = findBiggestCueBeforeTime({
        cues,
        time,
        track: info.track
    });
    if (!biggestCueBeforeTime) {
        return null;
    }
    return {
        byte: biggestCueBeforeTime.clusterPositionInSegment + segmentOffset,
        timeInSeconds: toSeconds(biggestCueBeforeTime.timeInTimescale, info.track)
    };
};
const getSeekingByteFromMatroska = async ({ time, webmState, info, logLevel, mediaSection })=>{
    var _a, _b, _c, _d, _e;
    if (!info.track) {
        log_1.Log.trace(logLevel, 'No video track found, cannot seek yet');
        return {
            type: 'valid-but-must-wait'
        };
    }
    const cuesResponse = (_a = info.loadedCues) !== null && _a !== void 0 ? _a : await webmState.cues.getLoadedCues();
    // Check if we have already read keyframes
    const byteFromObservedKeyframe = findKeyframeBeforeTime({
        keyframes: info.keyframes,
        time
    });
    // Check if we have `Cues`
    const byteFromCues = getByteFromCues({
        cuesResponse,
        time,
        info,
        logLevel
    });
    // Fallback: back to the beginning
    const byteFromFirstMediaSection = (_c = (_b = webmState.getFirstCluster()) === null || _b === void 0 ? void 0 : _b.start) !== null && _c !== void 0 ? _c : null;
    // Optimization possibility for later:
    // Don't seek back, if the last seen time is smaller than the time we want to seek to
    const seekPossibilities = [
        (_d = byteFromCues === null || byteFromCues === void 0 ? void 0 : byteFromCues.byte) !== null && _d !== void 0 ? _d : null,
        (_e = byteFromObservedKeyframe === null || byteFromObservedKeyframe === void 0 ? void 0 : byteFromObservedKeyframe.positionInBytes) !== null && _e !== void 0 ? _e : null,
        byteFromFirstMediaSection
    ].filter((n)=>n !== null);
    const byteToSeekTo = seekPossibilities.length === 0 ? null : Math.max(...seekPossibilities);
    if (byteToSeekTo === null) {
        // dont know what to do
        return {
            type: 'invalid'
        };
    }
    // we have assured this is in a media section, but it might not be marked yet
    // setting size because there is deduplication and media sections which are encompassed
    // by others will get deleted
    mediaSection.addMediaSection({
        start: byteToSeekTo,
        size: 1
    });
    const timeInSeconds = (()=>{
        if (byteToSeekTo === (byteFromObservedKeyframe === null || byteFromObservedKeyframe === void 0 ? void 0 : byteFromObservedKeyframe.positionInBytes)) {
            return Math.min(byteFromObservedKeyframe.decodingTimeInSeconds, byteFromObservedKeyframe.presentationTimeInSeconds);
        }
        if (byteToSeekTo === (byteFromCues === null || byteFromCues === void 0 ? void 0 : byteFromCues.byte)) {
            return byteFromCues.timeInSeconds;
        }
        if (byteToSeekTo === byteFromFirstMediaSection) {
            return 0;
        }
        throw new Error('Should not happen');
    })();
    return {
        type: 'do-seek',
        byte: byteToSeekTo,
        timeInSeconds
    };
};
exports.getSeekingByteFromMatroska = getSeekingByteFromMatroska;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/transport-stream/observed-pes-header.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getLastKeyFrameBeforeTimeInSeconds = exports.makeObservedPesHeader = void 0;
const handle_avc_packet_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/handle-avc-packet.js [app-route] (ecmascript)");
const makeObservedPesHeader = ()=>{
    const pesHeaders = [];
    const confirmedAsKeyframe = [];
    const addPesHeader = (pesHeader)=>{
        if (pesHeaders.find((p)=>p.offset === pesHeader.offset)) {
            return;
        }
        pesHeaders.push(pesHeader);
    };
    const markPtsAsKeyframe = (pts)=>{
        confirmedAsKeyframe.push(pts);
    };
    const getPesKeyframeHeaders = ()=>{
        return pesHeaders.filter((p)=>confirmedAsKeyframe.includes(p.pts));
    };
    const setPesKeyframesFromSeekingHints = (hints)=>{
        for (const pesHeader of hints.observedPesHeaders){
            addPesHeader(pesHeader);
            markPtsAsKeyframe(pesHeader.pts);
        }
    };
    const state = {
        pesHeaders,
        addPesHeader,
        markPtsAsKeyframe,
        getPesKeyframeHeaders,
        setPesKeyframesFromSeekingHints
    };
    return state;
};
exports.makeObservedPesHeader = makeObservedPesHeader;
const getLastKeyFrameBeforeTimeInSeconds = ({ observedPesHeaders, timeInSeconds, ptsStartOffset })=>{
    return observedPesHeaders.findLast((k)=>(k.pts - ptsStartOffset) / handle_avc_packet_1.MPEG_TIMESCALE <= timeInSeconds);
};
exports.getLastKeyFrameBeforeTimeInSeconds = getLastKeyFrameBeforeTimeInSeconds;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-seeking-byte.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingByte = void 0;
const get_seeking_byte_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/aac/get-seeking-byte.js [app-route] (ecmascript)");
const get_seeking_byte_2 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-seeking-byte.js [app-route] (ecmascript)");
const get_seeking_byte_3 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-seeking-byte.js [app-route] (ecmascript)");
const get_seeking_byte_4 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-seeking-byte.js [app-route] (ecmascript)");
const get_seeking_byte_5 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-seeking-byte.js [app-route] (ecmascript)");
const get_seeking_byte_6 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/get-seeking-byte.js [app-route] (ecmascript)");
const handle_avc_packet_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/handle-avc-packet.js [app-route] (ecmascript)");
const get_seeking_byte_7 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/get-seeking-byte.js [app-route] (ecmascript)");
const get_seeking_byte_8 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/seek/get-seeking-byte.js [app-route] (ecmascript)");
const observed_pes_header_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/transport-stream/observed-pes-header.js [app-route] (ecmascript)");
const getSeekingByte = ({ info, time, logLevel, currentPosition, isoState, transportStream, webmState, mediaSection, m3uPlaylistContext, structure, riffState, m3uState, avcState })=>{
    var _a;
    if (info.type === 'iso-base-media-seeking-hints') {
        return (0, get_seeking_byte_3.getSeekingByteFromIsoBaseMedia)({
            info,
            time,
            logLevel,
            currentPosition,
            isoState,
            structure,
            m3uPlaylistContext
        });
    }
    if (info.type === 'wav-seeking-hints') {
        return (0, get_seeking_byte_7.getSeekingByteFromWav)({
            info,
            time
        });
    }
    if (info.type === 'webm-seeking-hints') {
        return (0, get_seeking_byte_8.getSeekingByteFromMatroska)({
            info,
            time,
            webmState,
            logLevel,
            mediaSection
        });
    }
    if (info.type === 'flac-seeking-hints') {
        const byte = (0, get_seeking_byte_2.getSeekingByteForFlac)({
            seekingHints: info,
            time
        });
        if (byte) {
            return Promise.resolve({
                type: 'do-seek',
                byte: byte.offset,
                timeInSeconds: byte.timeInSeconds
            });
        }
        return Promise.resolve({
            type: 'valid-but-must-wait'
        });
    }
    if (info.type === 'transport-stream-seeking-hints') {
        const lastKeyframeBeforeTimeInSeconds = (0, observed_pes_header_1.getLastKeyFrameBeforeTimeInSeconds)({
            observedPesHeaders: info.observedPesHeaders,
            timeInSeconds: time,
            ptsStartOffset: info.ptsStartOffset
        });
        if (!lastKeyframeBeforeTimeInSeconds) {
            transportStream.resetBeforeSeek();
            return Promise.resolve({
                type: 'do-seek',
                byte: 0,
                timeInSeconds: 0
            });
        }
        const byte = lastKeyframeBeforeTimeInSeconds.offset;
        transportStream.resetBeforeSeek();
        return Promise.resolve({
            type: 'do-seek',
            byte,
            timeInSeconds: Math.min(lastKeyframeBeforeTimeInSeconds.pts, (_a = lastKeyframeBeforeTimeInSeconds.dts) !== null && _a !== void 0 ? _a : Infinity) / handle_avc_packet_1.MPEG_TIMESCALE
        });
    }
    if (info.type === 'riff-seeking-hints') {
        return (0, get_seeking_byte_6.getSeekingByteForRiff)({
            info,
            time,
            riffState,
            avcState
        });
    }
    if (info.type === 'mp3-seeking-hints') {
        return Promise.resolve((0, get_seeking_byte_5.getSeekingByteForMp3)({
            info,
            time
        }));
    }
    if (info.type === 'aac-seeking-hints') {
        return Promise.resolve((0, get_seeking_byte_1.getSeekingByteForAac)({
            time,
            seekingHints: info
        }));
    }
    if (info.type === 'm3u8-seeking-hints') {
        return Promise.resolve((0, get_seeking_byte_4.getSeekingByteForM3u8)({
            time,
            currentPosition,
            m3uState,
            logLevel
        }));
    }
    throw new Error(`Unknown seeking info type: ${info}`);
};
exports.getSeekingByte = getSeekingByte;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/aac/seeking-hints.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.setSeekingHintsForAac = exports.getSeekingHintsForAac = void 0;
const getSeekingHintsForAac = ({ aacState, samplesObserved })=>{
    return {
        type: 'aac-seeking-hints',
        audioSampleMap: aacState.audioSamples.getSamples(),
        lastSampleObserved: samplesObserved.getLastSampleObserved()
    };
};
exports.getSeekingHintsForAac = getSeekingHintsForAac;
// TODO: Implement this and maintain index
const setSeekingHintsForAac = ()=>{};
exports.setSeekingHintsForAac = setSeekingHintsForAac;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/seeking-hints.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.setSeekingHintsForFlac = exports.getSeekingHintsForFlac = void 0;
const getSeekingHintsForFlac = ({ flacState, samplesObserved })=>{
    var _a;
    return {
        type: 'flac-seeking-hints',
        audioSampleMap: flacState.audioSamples.getSamples(),
        blockingBitStrategy: (_a = flacState.getBlockingBitStrategy()) !== null && _a !== void 0 ? _a : null,
        lastSampleObserved: samplesObserved.getLastSampleObserved()
    };
};
exports.getSeekingHintsForFlac = getSeekingHintsForFlac;
const setSeekingHintsForFlac = ({ hints, state })=>{
    if (hints.blockingBitStrategy !== null) {
        state.flac.setBlockingBitStrategy(hints.blockingBitStrategy);
    }
    state.flac.audioSamples.setFromSeekingHints(hints.audioSampleMap);
};
exports.setSeekingHintsForFlac = setSeekingHintsForFlac;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/seeking-hints.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.setSeekingHintsForMp4 = exports.getSeekingHintsFromMp4 = void 0;
const precomputed_moof_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/precomputed-moof.js [app-route] (ecmascript)");
const precomputed_tfra_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/precomputed-tfra.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const getSeekingHintsFromMp4 = ({ structureState, isoState, mp4HeaderSegment, mediaSectionState })=>{
    const structure = structureState.getIsoStructure();
    const moovAtom = (0, traversal_1.getMoovBoxFromState)({
        isoState,
        mp4HeaderSegment,
        structureState,
        mayUsePrecomputed: true
    });
    const moofBoxes = (0, precomputed_moof_1.deduplicateMoofBoxesByOffset)([
        ...isoState.moof.getMoofBoxes(),
        ...(0, traversal_1.getMoofBoxes)(structure.boxes)
    ]);
    const tfraBoxes = (0, precomputed_tfra_1.deduplicateTfraBoxesByOffset)([
        ...isoState.tfra.getTfraBoxes(),
        ...(0, traversal_1.getTfraBoxes)(structure.boxes)
    ]);
    if (!moovAtom) {
        return null;
    }
    return {
        type: 'iso-base-media-seeking-hints',
        moovBox: moovAtom,
        moofBoxes,
        tfraBoxes,
        mediaSections: mediaSectionState.getMediaSections(),
        mfraAlreadyLoaded: isoState.mfra.getIfAlreadyLoaded()
    };
};
exports.getSeekingHintsFromMp4 = getSeekingHintsFromMp4;
// eslint-disable-next-line no-empty-pattern
const setSeekingHintsForMp4 = ({})=>{
// state.iso.moov.setMoovBox({
//	moovBox: hints.moovBox,
//	precomputed: true,
// });
// 	state.iso.mfra.setFromSeekingHints(hints);
// state.iso.moof.setMoofBoxes(hints.moofBoxes);
// TODO: Make use of these seeking hints and make tests pass
/*
    //	state.iso.tfra.setTfraBoxes(hints.tfraBoxes);

    for (const mediaSection of hints.mediaSections) {
        // state.mediaSection.addMediaSection(mediaSection);
    }
    */ };
exports.setSeekingHintsForMp4 = setSeekingHintsForMp4;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/seeking-hints.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingHintsForM3u = void 0;
const getSeekingHintsForM3u = ()=>{
    return {
        type: 'm3u8-seeking-hints'
    };
};
exports.getSeekingHintsForM3u = getSeekingHintsForM3u;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seeking-hints.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.setSeekingHintsForMp3 = exports.getSeekingHintsForMp3 = void 0;
const getSeekingHintsForMp3 = ({ mp3State, samplesObserved, mediaSectionState, contentLength })=>{
    var _a;
    return {
        type: 'mp3-seeking-hints',
        audioSampleMap: mp3State.audioSamples.getSamples(),
        lastSampleObserved: samplesObserved.getLastSampleObserved(),
        mp3BitrateInfo: mp3State.getMp3BitrateInfo(),
        mp3Info: mp3State.getMp3Info(),
        mediaSection: (_a = mediaSectionState.getMediaSections()[0]) !== null && _a !== void 0 ? _a : null,
        contentLength
    };
};
exports.getSeekingHintsForMp3 = getSeekingHintsForMp3;
// TODO: could set xing data in the hints
const setSeekingHintsForMp3 = ({ hints, state })=>{
    state.mp3.audioSamples.setFromSeekingHints(hints.audioSampleMap);
};
exports.setSeekingHintsForMp3 = setSeekingHintsForMp3;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/has-index.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.riffHasIndex = void 0;
const riffHasIndex = (structure)=>{
    var _a, _b, _c;
    return (_c = (_b = (_a = structure.boxes.find((b)=>b.type === 'list-box' && b.listType === 'hdrl')) === null || _a === void 0 ? void 0 : _a.children.find((box)=>box.type === 'avih-box')) === null || _b === void 0 ? void 0 : _b.hasIndex) !== null && _c !== void 0 ? _c : false;
};
exports.riffHasIndex = riffHasIndex;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/seeking-hints.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.setSeekingHintsForRiff = exports.getSeekingHintsForRiff = void 0;
const has_index_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/has-index.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/traversal.js [app-route] (ecmascript)");
const getSeekingHintsForRiff = ({ structureState, riffState, mediaSectionState })=>{
    var _a, _b;
    const structure = structureState.getRiffStructure();
    const strl = (0, traversal_1.getStrlBoxes)(structure);
    let samplesPerSecond = null;
    for (const s of strl){
        const strh = (0, traversal_1.getStrhBox)(s.children);
        if (!strh) {
            throw new Error('No strh box');
        }
        if (strh.strf.type !== 'strf-box-video') {
            continue;
        }
        samplesPerSecond = strh.rate / strh.scale;
        break;
    }
    return {
        type: 'riff-seeking-hints',
        hasIndex: (0, has_index_1.riffHasIndex)(structure),
        idx1Entries: riffState.lazyIdx1.getIfAlreadyLoaded(),
        samplesPerSecond,
        moviOffset: (_b = (_a = mediaSectionState.getMediaSections()[0]) === null || _a === void 0 ? void 0 : _a.start) !== null && _b !== void 0 ? _b : null,
        observedKeyframes: riffState.sampleCounter.riffKeys.getKeyframes()
    };
};
exports.getSeekingHintsForRiff = getSeekingHintsForRiff;
const setSeekingHintsForRiff = ({ hints, state })=>{
    state.riff.lazyIdx1.setFromSeekingHints(hints);
    state.riff.sampleCounter.riffKeys.setFromSeekingHints(hints.observedKeyframes);
};
exports.setSeekingHintsForRiff = setSeekingHintsForRiff;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/seeking-hints.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.setSeekingHintsForTransportStream = exports.getSeekingHintsFromTransportStream = void 0;
const getSeekingHintsFromTransportStream = (transportStream, tracksState)=>{
    const firstVideoTrack = tracksState.getTracks().find((t)=>t.type === 'video');
    if (!firstVideoTrack) {
        return null;
    }
    return {
        type: 'transport-stream-seeking-hints',
        observedPesHeaders: transportStream.observedPesHeaders.getPesKeyframeHeaders(),
        ptsStartOffset: transportStream.startOffset.getOffset(firstVideoTrack.trackId),
        firstVideoTrackId: firstVideoTrack.trackId
    };
};
exports.getSeekingHintsFromTransportStream = getSeekingHintsFromTransportStream;
const setSeekingHintsForTransportStream = ({ hints, state })=>{
    state.transportStream.observedPesHeaders.setPesKeyframesFromSeekingHints(hints);
    state.transportStream.startOffset.setOffset({
        trackId: hints.firstVideoTrackId,
        newOffset: hints.ptsStartOffset
    });
};
exports.setSeekingHintsForTransportStream = setSeekingHintsForTransportStream;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/seeking-hints.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.setSeekingHintsForWav = exports.getSeekingHintsFromWav = void 0;
const getSeekingHintsFromWav = ({ structure, mediaSectionState })=>{
    const fmtBox = structure.boxes.find((box)=>box.type === 'wav-fmt');
    if (!fmtBox) {
        return null;
    }
    const mediaSection = mediaSectionState.getMediaSections();
    if (mediaSection.length !== 1) {
        return null;
    }
    return {
        type: 'wav-seeking-hints',
        sampleRate: fmtBox.sampleRate,
        blockAlign: fmtBox.blockAlign,
        mediaSection: mediaSection[0]
    };
};
exports.getSeekingHintsFromWav = getSeekingHintsFromWav;
const setSeekingHintsForWav = ({ hints, state })=>{
    // abstaining from setting fmt box, usually it is at the very beginning
    state.mediaSection.addMediaSection(hints.mediaSection);
};
exports.setSeekingHintsForWav = setSeekingHintsForWav;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/seek/seeking-hints.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.setSeekingHintsForWebm = exports.getSeekingHintsFromMatroska = void 0;
const getSeekingHintsFromMatroska = (tracksState, keyframesState, webmState)=>{
    const tracks = tracksState.getTracks();
    const firstVideoTrack = tracks.find((track)=>track.type === 'video');
    const keyframes = keyframesState.getKeyframes();
    const loadedCues = webmState.cues.getIfAlreadyLoaded();
    return {
        type: 'webm-seeking-hints',
        track: firstVideoTrack ? {
            timescale: firstVideoTrack.originalTimescale,
            trackId: firstVideoTrack.trackId
        } : null,
        keyframes,
        loadedCues,
        timestampMap: webmState.getTimeStampMapForSeekingHints()
    };
};
exports.getSeekingHintsFromMatroska = getSeekingHintsFromMatroska;
const setSeekingHintsForWebm = ({ hints, state })=>{
    state.webm.cues.setFromSeekingHints(hints);
    state.keyframes.setFromSeekingHints(hints.keyframes);
    state.webm.setTimeStampMapForSeekingHints(hints.timestampMap);
};
exports.setSeekingHintsForWebm = setSeekingHintsForWebm;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-seeking-hints.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSeekingHints = void 0;
const seeking_hints_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/aac/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_2 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_3 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_4 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_5 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_6 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_7 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_8 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_9 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/seek/seeking-hints.js [app-route] (ecmascript)");
const getSeekingHints = ({ structureState, m3uPlaylistContext, mediaSectionState, isoState, transportStream, tracksState, keyframesState, webmState, flacState, samplesObserved, riffState, mp3State, contentLength, aacState })=>{
    var _a;
    const structure = structureState.getStructureOrNull();
    if (!structure) {
        return null;
    }
    if (structure.type === 'iso-base-media') {
        return (0, seeking_hints_3.getSeekingHintsFromMp4)({
            structureState,
            isoState,
            mp4HeaderSegment: (_a = m3uPlaylistContext === null || m3uPlaylistContext === void 0 ? void 0 : m3uPlaylistContext.mp4HeaderSegment) !== null && _a !== void 0 ? _a : null,
            mediaSectionState
        });
    }
    if (structure.type === 'wav') {
        return (0, seeking_hints_8.getSeekingHintsFromWav)({
            structure,
            mediaSectionState
        });
    }
    if (structure.type === 'matroska') {
        return (0, seeking_hints_9.getSeekingHintsFromMatroska)(tracksState, keyframesState, webmState);
    }
    if (structure.type === 'transport-stream') {
        return (0, seeking_hints_7.getSeekingHintsFromTransportStream)(transportStream, tracksState);
    }
    if (structure.type === 'flac') {
        return (0, seeking_hints_2.getSeekingHintsForFlac)({
            flacState,
            samplesObserved
        });
    }
    if (structure.type === 'riff') {
        return (0, seeking_hints_6.getSeekingHintsForRiff)({
            structureState,
            riffState,
            mediaSectionState
        });
    }
    if (structure.type === 'mp3') {
        return (0, seeking_hints_5.getSeekingHintsForMp3)({
            mp3State,
            samplesObserved,
            mediaSectionState,
            contentLength
        });
    }
    if (structure.type === 'aac') {
        return (0, seeking_hints_1.getSeekingHintsForAac)({
            aacState,
            samplesObserved
        });
    }
    if (structure.type === 'm3u') {
        return (0, seeking_hints_4.getSeekingHintsForM3u)();
    }
    throw new Error(`Seeking is not supported for this format: ${structure}`);
};
exports.getSeekingHints = getSeekingHints;
}),
"[project]/node_modules/@remotion/media-parser/dist/seek-backwards.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.seekBackwards = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const seekBackwards = async ({ iterator, seekTo, readerInterface, src, controller, logLevel, currentReader, prefetchCache })=>{
    // (a) data has not been discarded yet
    const howManyBytesWeCanGoBack = iterator.counter.getDiscardedOffset();
    if (iterator.counter.getOffset() - howManyBytesWeCanGoBack <= seekTo) {
        log_1.Log.verbose(logLevel, `Seeking back to ${seekTo}`);
        iterator.skipTo(seekTo);
        return;
    }
    // (b) data has been discarded, making new reader
    const time = Date.now();
    log_1.Log.verbose(logLevel, `Seeking in video from position ${iterator.counter.getOffset()} -> ${seekTo}. Re-reading because this portion is not available.`);
    await currentReader.getCurrent().abort();
    const { reader: newReader } = await readerInterface.read({
        src,
        range: seekTo,
        controller,
        logLevel,
        prefetchCache
    });
    iterator.replaceData(new Uint8Array([]), seekTo);
    log_1.Log.verbose(logLevel, `Re-reading took ${Date.now() - time}ms. New position: ${iterator.counter.getOffset()}`);
    currentReader.setCurrent(newReader);
};
exports.seekBackwards = seekBackwards;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/need-samples-for-fields.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.needsToIterateOverEverySample = exports.needsToIterateOverSamples = exports.fieldsNeedSamplesMap = void 0;
exports.fieldsNeedSamplesMap = {
    slowDurationInSeconds: true,
    slowFps: true,
    slowKeyframes: true,
    slowNumberOfFrames: true,
    audioCodec: false,
    container: false,
    dimensions: false,
    durationInSeconds: false,
    fps: false,
    internalStats: false,
    isHdr: false,
    name: false,
    rotation: false,
    size: false,
    slowStructure: false,
    tracks: false,
    unrotatedDimensions: false,
    videoCodec: false,
    metadata: false,
    location: false,
    mimeType: false,
    keyframes: false,
    images: false,
    numberOfAudioChannels: false,
    sampleRate: false,
    slowAudioBitrate: true,
    slowVideoBitrate: true,
    m3uStreams: false
};
const needsToIterateOverSamples = ({ fields, emittedFields })=>{
    const keys = Object.keys(fields !== null && fields !== void 0 ? fields : {});
    const selectedKeys = keys.filter((k)=>fields[k]);
    return selectedKeys.some((k)=>exports.fieldsNeedSamplesMap[k] && !emittedFields[k]);
};
exports.needsToIterateOverSamples = needsToIterateOverSamples;
// For duration, we only need the first and last sample
const fieldsNeedEverySampleMap = {
    ...exports.fieldsNeedSamplesMap,
    slowDurationInSeconds: false
};
const needsToIterateOverEverySample = ({ fields, emittedFields })=>{
    const keys = Object.keys(fields !== null && fields !== void 0 ? fields : {});
    const selectedKeys = keys.filter((k)=>fields[k]);
    return selectedKeys.some((k)=>fieldsNeedEverySampleMap[k] && !emittedFields[k]);
};
exports.needsToIterateOverEverySample = needsToIterateOverEverySample;
}),
"[project]/node_modules/@remotion/media-parser/dist/disallow-forward-seek-if-samples-are-needed.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.disallowForwardSeekIfSamplesAreNeeded = void 0;
const need_samples_for_fields_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/need-samples-for-fields.js [app-route] (ecmascript)");
const disallowForwardSeekIfSamplesAreNeeded = ({ seekTo, previousPosition, fields })=>{
    const fieldsNeedingSamples = Object.entries(fields).filter(([, value])=>value).map(([key])=>key).filter((key)=>need_samples_for_fields_1.fieldsNeedSamplesMap[key]);
    if (fieldsNeedingSamples.length > 0) {
        throw new Error(`Forward seeking is not allowed when the following fields are requested from parseMedia(): ${fieldsNeedingSamples.join(', ')}. Seek was from 0x${previousPosition.toString(16)} to 0x${seekTo.toString(16)}. Either don't seek forward, or don't request these fields.`);
    }
};
exports.disallowForwardSeekIfSamplesAreNeeded = disallowForwardSeekIfSamplesAreNeeded;
}),
"[project]/node_modules/@remotion/media-parser/dist/seek-forwards.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.seekForward = void 0;
const disallow_forward_seek_if_samples_are_needed_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/disallow-forward-seek-if-samples-are-needed.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const seekForward = async ({ seekTo, userInitiated, iterator, fields, logLevel, currentReader, readerInterface, src, controller, discardReadBytes, prefetchCache })=>{
    if (userInitiated) {
        (0, disallow_forward_seek_if_samples_are_needed_1.disallowForwardSeekIfSamplesAreNeeded)({
            fields,
            seekTo,
            previousPosition: iterator.counter.getOffset()
        });
    }
    const alreadyHasBuffer = iterator.bytesRemaining() >= seekTo - iterator.counter.getOffset();
    log_1.Log.verbose(logLevel, `Performing seek from ${iterator.counter.getOffset()} to ${seekTo}`);
    // (a) starting byte has already been fetched
    if (alreadyHasBuffer) {
        iterator.skipTo(seekTo);
        log_1.Log.verbose(logLevel, `Already read ahead enough, skipping forward`);
        return;
    }
    // (b) starting byte has not been fetched yet, making new reader
    const time = Date.now();
    log_1.Log.verbose(logLevel, `Skipping over video data from position ${iterator.counter.getOffset()} -> ${seekTo}. Re-reading because this portion is not available`);
    await currentReader.getCurrent().abort();
    const { reader: newReader } = await readerInterface.read({
        src,
        range: seekTo,
        controller,
        logLevel,
        prefetchCache
    });
    iterator.skipTo(seekTo);
    await discardReadBytes(true);
    log_1.Log.verbose(logLevel, `Re-reading took ${Date.now() - time}ms. New position: ${iterator.counter.getOffset()}`);
    currentReader.setCurrent(newReader);
};
exports.seekForward = seekForward;
}),
"[project]/node_modules/@remotion/media-parser/dist/perform-seek.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.performSeek = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const seek_backwards_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/seek-backwards.js [app-route] (ecmascript)");
const seek_forwards_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/seek-forwards.js [app-route] (ecmascript)");
const video_section_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/video-section.js [app-route] (ecmascript)");
const performSeek = async ({ seekTo, userInitiated, controller, mediaSection, iterator, seekInfiniteLoop, logLevel, mode, contentLength, currentReader, readerInterface, src, discardReadBytes, fields, prefetchCache, isoState })=>{
    const byteInMediaSection = (0, video_section_1.isByteInMediaSection)({
        position: seekTo,
        mediaSections: mediaSection.getMediaSections()
    });
    if (byteInMediaSection !== 'in-section' && userInitiated) {
        const sections = mediaSection.getMediaSections();
        const sectionStrings = sections.map((section)=>{
            return `start: ${section.start}, end: ${section.size + section.start}`;
        });
        throw new Error(`Cannot seek to a byte that is not in the video section. Seeking to: ${seekTo}, sections: ${sectionStrings.join(' | ')}`);
    }
    seekInfiniteLoop.registerSeek(seekTo);
    if (seekTo <= iterator.counter.getOffset() && mode === 'download') {
        throw new Error(`Seeking backwards is not supported in parseAndDownloadMedia() mode. Current position: ${iterator.counter.getOffset()}, seekTo: ${seekTo}`);
    }
    if (seekTo > contentLength) {
        throw new Error(`Cannot seek beyond the end of the file: ${seekTo} > ${contentLength}`);
    }
    if (mode === 'download') {
        log_1.Log.verbose(logLevel, `Skipping over video data from position ${iterator.counter.getOffset()} -> ${seekTo}. Fetching but not reading all the data inbetween because in download mode`);
        iterator.discard(seekTo - iterator.counter.getOffset());
        return;
    }
    await controller._internals.checkForAbortAndPause();
    const alreadyAtByte = iterator.counter.getOffset() === seekTo;
    if (alreadyAtByte) {
        log_1.Log.verbose(logLevel, `Already at the desired position, seeking done`);
        controller._internals.performedSeeksSignal.markLastSeekAsUserInitiated();
        return;
    }
    const skippingForward = seekTo > iterator.counter.getOffset();
    controller._internals.performedSeeksSignal.recordSeek({
        from: iterator.counter.getOffset(),
        to: seekTo,
        type: userInitiated ? 'user-initiated' : 'internal'
    });
    if (skippingForward) {
        await (0, seek_forwards_1.seekForward)({
            seekTo,
            userInitiated,
            iterator,
            fields,
            logLevel,
            currentReader,
            readerInterface,
            src,
            controller,
            discardReadBytes,
            prefetchCache
        });
    } else {
        await (0, seek_backwards_1.seekBackwards)({
            controller,
            seekTo,
            iterator,
            logLevel,
            currentReader,
            readerInterface,
            src,
            prefetchCache
        });
    }
    if (userInitiated) {
        isoState.flatSamples.updateAfterSeek(seekTo);
    }
    await controller._internals.checkForAbortAndPause();
};
exports.performSeek = performSeek;
}),
"[project]/node_modules/@remotion/media-parser/dist/work-on-seek-request.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.workOnSeekRequest = exports.getWorkOnSeekRequestOptions = exports.turnSeekIntoByte = void 0;
const get_seeking_byte_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-seeking-byte.js [app-route] (ecmascript)");
const get_seeking_hints_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-seeking-hints.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const perform_seek_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/perform-seek.js [app-route] (ecmascript)");
const turnSeekIntoByte = async ({ seek, mediaSectionState, logLevel, iterator, structureState, m3uPlaylistContext, isoState, transportStream, tracksState, webmState, keyframes, flacState, samplesObserved, riffState, mp3State, contentLength, aacState, m3uState, avcState })=>{
    const mediaSections = mediaSectionState.getMediaSections();
    if (mediaSections.length === 0) {
        log_1.Log.trace(logLevel, 'No media sections defined, cannot seek yet');
        return {
            type: 'valid-but-must-wait'
        };
    }
    if (seek < 0) {
        throw new Error(`Cannot seek to a negative time: ${JSON.stringify(seek)}`);
    }
    const seekingHints = (0, get_seeking_hints_1.getSeekingHints)({
        riffState,
        samplesObserved,
        structureState,
        mediaSectionState,
        isoState,
        transportStream,
        tracksState,
        keyframesState: keyframes,
        webmState,
        flacState,
        mp3State,
        contentLength,
        aacState,
        m3uPlaylistContext
    });
    if (!seekingHints) {
        log_1.Log.trace(logLevel, 'No seeking info, cannot seek yet');
        return {
            type: 'valid-but-must-wait'
        };
    }
    const seekingByte = await (0, get_seeking_byte_1.getSeekingByte)({
        info: seekingHints,
        time: seek,
        logLevel,
        currentPosition: iterator.counter.getOffset(),
        isoState,
        transportStream,
        webmState,
        mediaSection: mediaSectionState,
        m3uPlaylistContext,
        structure: structureState,
        riffState,
        m3uState,
        avcState
    });
    return seekingByte;
};
exports.turnSeekIntoByte = turnSeekIntoByte;
const getWorkOnSeekRequestOptions = (state)=>{
    return {
        logLevel: state.logLevel,
        controller: state.controller,
        isoState: state.iso,
        iterator: state.iterator,
        structureState: state.structure,
        src: state.src,
        contentLength: state.contentLength,
        readerInterface: state.readerInterface,
        mediaSection: state.mediaSection,
        m3uPlaylistContext: state.m3uPlaylistContext,
        mode: state.mode,
        seekInfiniteLoop: state.seekInfiniteLoop,
        currentReader: state.currentReader,
        discardReadBytes: state.discardReadBytes,
        fields: state.fields,
        transportStream: state.transportStream,
        tracksState: state.callbacks.tracks,
        webmState: state.webm,
        keyframes: state.keyframes,
        flacState: state.flac,
        samplesObserved: state.samplesObserved,
        riffState: state.riff,
        mp3State: state.mp3,
        aacState: state.aac,
        m3uState: state.m3u,
        prefetchCache: state.prefetchCache,
        avcState: state.avc
    };
};
exports.getWorkOnSeekRequestOptions = getWorkOnSeekRequestOptions;
const workOnSeekRequest = async (options)=>{
    const { logLevel, controller, mediaSection, m3uPlaylistContext, isoState, iterator, structureState, src, contentLength, readerInterface, mode, seekInfiniteLoop, currentReader, discardReadBytes, fields, transportStream, tracksState, webmState, keyframes, flacState, samplesObserved, riffState, mp3State, aacState, prefetchCache, m3uState, avcState } = options;
    const seek = controller._internals.seekSignal.getSeek();
    if (seek === null) {
        return;
    }
    log_1.Log.trace(logLevel, `Has seek request for ${src}: ${JSON.stringify(seek)}`);
    const resolution = await (0, exports.turnSeekIntoByte)({
        seek,
        mediaSectionState: mediaSection,
        logLevel,
        iterator,
        structureState,
        m3uPlaylistContext,
        isoState,
        transportStream,
        tracksState,
        webmState,
        keyframes,
        flacState,
        samplesObserved,
        riffState,
        mp3State,
        contentLength,
        aacState,
        m3uState,
        avcState
    });
    log_1.Log.trace(logLevel, `Seek action: ${JSON.stringify(resolution)}`);
    if (resolution.type === 'intermediary-seek') {
        await (0, perform_seek_1.performSeek)({
            seekTo: resolution.byte,
            userInitiated: false,
            controller,
            mediaSection,
            iterator,
            logLevel,
            mode,
            contentLength,
            seekInfiniteLoop,
            currentReader,
            readerInterface,
            src,
            discardReadBytes,
            fields,
            prefetchCache,
            isoState
        });
        return;
    }
    if (resolution.type === 'do-seek') {
        await (0, perform_seek_1.performSeek)({
            seekTo: resolution.byte,
            userInitiated: true,
            controller,
            mediaSection,
            iterator,
            logLevel,
            mode,
            contentLength,
            seekInfiniteLoop,
            currentReader,
            readerInterface,
            src,
            discardReadBytes,
            fields,
            prefetchCache,
            isoState
        });
        const { hasChanged } = controller._internals.seekSignal.clearSeekIfStillSame(seek);
        if (hasChanged) {
            log_1.Log.trace(logLevel, `Seek request has changed while seeking, seeking again`);
            await (0, exports.workOnSeekRequest)(options);
        }
        return;
    }
    if (resolution.type === 'invalid') {
        throw new Error(`The seek request ${JSON.stringify(seek)} cannot be processed`);
    }
    if (resolution.type === 'valid-but-must-wait') {
        log_1.Log.trace(logLevel, 'Seek request is valid but cannot be processed yet');
    }
};
exports.workOnSeekRequest = workOnSeekRequest;
}),
"[project]/node_modules/@remotion/media-parser/dist/emit-available-info.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.emitAvailableInfo = void 0;
const get_streams_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-streams.js [app-route] (ecmascript)");
const get_audio_codec_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-audio-codec.js [app-route] (ecmascript)");
const get_container_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-container.js [app-route] (ecmascript)");
const get_dimensions_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-dimensions.js [app-route] (ecmascript)");
const get_duration_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-duration.js [app-route] (ecmascript)");
const get_fps_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-fps.js [app-route] (ecmascript)");
const get_is_hdr_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-is-hdr.js [app-route] (ecmascript)");
const get_keyframes_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-keyframes.js [app-route] (ecmascript)");
const get_location_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-location.js [app-route] (ecmascript)");
const get_number_of_audio_channels_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-number-of-audio-channels.js [app-route] (ecmascript)");
const get_sample_rate_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-sample-rate.js [app-route] (ecmascript)");
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const get_video_codec_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-video-codec.js [app-route] (ecmascript)");
const get_metadata_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/metadata/get-metadata.js [app-route] (ecmascript)");
const work_on_seek_request_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/work-on-seek-request.js [app-route] (ecmascript)");
const emitAvailableInfo = async ({ hasInfo, state })=>{
    var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v, _w, _x, _y, _z, _0, _1, _2, _3, _4, _5, _6;
    const keys = Object.keys(hasInfo);
    const { emittedFields, fieldsInReturnValue, returnValue, name, callbackFunctions } = state;
    for (const key of keys){
        await (0, work_on_seek_request_1.workOnSeekRequest)((0, work_on_seek_request_1.getWorkOnSeekRequestOptions)(state));
        if (key === 'slowStructure') {
            if (hasInfo.slowStructure && !emittedFields.slowStructure) {
                await ((_a = callbackFunctions.onSlowStructure) === null || _a === void 0 ? void 0 : _a.call(callbackFunctions, state.structure.getStructure()));
                if (fieldsInReturnValue.slowStructure) {
                    returnValue.slowStructure = state.structure.getStructure();
                }
                emittedFields.slowStructure = true;
            }
            continue;
        }
        if (key === 'durationInSeconds') {
            if (hasInfo.durationInSeconds) {
                if (!emittedFields.durationInSeconds) {
                    const durationInSeconds = (0, get_duration_1.getDuration)(state);
                    await ((_b = callbackFunctions.onDurationInSeconds) === null || _b === void 0 ? void 0 : _b.call(callbackFunctions, durationInSeconds));
                    if (fieldsInReturnValue.durationInSeconds) {
                        returnValue.durationInSeconds = durationInSeconds;
                    }
                    emittedFields.durationInSeconds = true;
                }
            }
            continue;
        }
        if (key === 'slowDurationInSeconds') {
            if (hasInfo.slowDurationInSeconds && !emittedFields.slowDurationInSeconds) {
                const slowDurationInSeconds = (_c = (0, get_duration_1.getDuration)(state)) !== null && _c !== void 0 ? _c : state.samplesObserved.getSlowDurationInSeconds();
                await ((_d = callbackFunctions.onSlowDurationInSeconds) === null || _d === void 0 ? void 0 : _d.call(callbackFunctions, slowDurationInSeconds));
                if (fieldsInReturnValue.slowDurationInSeconds) {
                    returnValue.slowDurationInSeconds = slowDurationInSeconds;
                }
                emittedFields.slowDurationInSeconds = true;
            }
            continue;
        }
        if (key === 'fps') {
            if (hasInfo.fps) {
                if (!emittedFields.fps) {
                    const fps = (0, get_fps_1.getFps)(state);
                    await ((_e = callbackFunctions.onFps) === null || _e === void 0 ? void 0 : _e.call(callbackFunctions, fps));
                    if (fieldsInReturnValue.fps) {
                        returnValue.fps = fps;
                    }
                    emittedFields.fps = true;
                }
                if (!emittedFields.slowFps) {
                    const fps = (0, get_fps_1.getFps)(state);
                    if (fps) {
                        await ((_f = callbackFunctions.onSlowFps) === null || _f === void 0 ? void 0 : _f.call(callbackFunctions, fps));
                        if (fieldsInReturnValue.slowFps) {
                            returnValue.slowFps = fps;
                        }
                        emittedFields.slowFps = true;
                    }
                }
            }
            continue;
        }
        // must be handled after fps
        if (key === 'slowFps') {
            if (hasInfo.slowFps && !emittedFields.slowFps) {
                const slowFps = (_g = (0, get_fps_1.getFps)(state)) !== null && _g !== void 0 ? _g : state.samplesObserved.getFps();
                await ((_h = callbackFunctions.onSlowFps) === null || _h === void 0 ? void 0 : _h.call(callbackFunctions, slowFps));
                if (fieldsInReturnValue.slowFps) {
                    returnValue.slowFps = slowFps;
                }
                emittedFields.slowFps = true;
            }
            continue;
        }
        if (key === 'dimensions') {
            if (hasInfo.dimensions && !emittedFields.dimensions) {
                const dimensionsQueried = (0, get_dimensions_1.getDimensions)(state);
                const dimensions = dimensionsQueried === null ? null : {
                    height: dimensionsQueried.height,
                    width: dimensionsQueried.width
                };
                await ((_j = callbackFunctions.onDimensions) === null || _j === void 0 ? void 0 : _j.call(callbackFunctions, dimensions));
                if (fieldsInReturnValue.dimensions) {
                    returnValue.dimensions = dimensions;
                }
                emittedFields.dimensions = true;
            }
            continue;
        }
        if (key === 'unrotatedDimensions') {
            if (hasInfo.unrotatedDimensions && !emittedFields.unrotatedDimensions) {
                const dimensionsQueried = (0, get_dimensions_1.getDimensions)(state);
                const unrotatedDimensions = dimensionsQueried === null ? null : {
                    height: dimensionsQueried.unrotatedHeight,
                    width: dimensionsQueried.unrotatedWidth
                };
                await ((_k = callbackFunctions.onUnrotatedDimensions) === null || _k === void 0 ? void 0 : _k.call(callbackFunctions, unrotatedDimensions));
                if (fieldsInReturnValue.unrotatedDimensions) {
                    returnValue.unrotatedDimensions = unrotatedDimensions;
                }
                emittedFields.unrotatedDimensions = true;
            }
            continue;
        }
        if (key === 'rotation') {
            if (hasInfo.rotation && !emittedFields.rotation) {
                const dimensionsQueried = (0, get_dimensions_1.getDimensions)(state);
                const rotation = (_l = dimensionsQueried === null || dimensionsQueried === void 0 ? void 0 : dimensionsQueried.rotation) !== null && _l !== void 0 ? _l : 0;
                await ((_m = callbackFunctions.onRotation) === null || _m === void 0 ? void 0 : _m.call(callbackFunctions, rotation));
                if (fieldsInReturnValue.rotation) {
                    returnValue.rotation = rotation;
                }
                emittedFields.rotation = true;
            }
            continue;
        }
        if (key === 'videoCodec') {
            if (!emittedFields.videoCodec && hasInfo.videoCodec) {
                const videoCodec = (0, get_video_codec_1.getVideoCodec)(state);
                await ((_o = callbackFunctions.onVideoCodec) === null || _o === void 0 ? void 0 : _o.call(callbackFunctions, videoCodec));
                if (fieldsInReturnValue.videoCodec) {
                    returnValue.videoCodec = videoCodec;
                }
                emittedFields.videoCodec = true;
            }
            continue;
        }
        if (key === 'audioCodec') {
            if (!emittedFields.audioCodec && hasInfo.audioCodec) {
                const audioCodec = (0, get_audio_codec_1.getAudioCodec)(state);
                await ((_p = callbackFunctions.onAudioCodec) === null || _p === void 0 ? void 0 : _p.call(callbackFunctions, audioCodec));
                if (fieldsInReturnValue.audioCodec) {
                    returnValue.audioCodec = audioCodec;
                }
                emittedFields.audioCodec = true;
            }
            continue;
        }
        if (key === 'tracks') {
            if (!emittedFields.tracks && hasInfo.tracks) {
                const tracks = (0, get_tracks_1.getTracks)(state, true);
                await ((_q = callbackFunctions.onTracks) === null || _q === void 0 ? void 0 : _q.call(callbackFunctions, tracks));
                if (fieldsInReturnValue.tracks) {
                    returnValue.tracks = tracks;
                }
                emittedFields.tracks = true;
            }
            continue;
        }
        if (key === 'internalStats') {
            // Special case: Always emitting internal stats at the end
            if (hasInfo.internalStats) {
                const internalStats = state.getInternalStats();
                if (fieldsInReturnValue.internalStats) {
                    returnValue.internalStats = internalStats;
                }
                emittedFields.internalStats = true;
            }
            continue;
        }
        if (key === 'size') {
            if (!emittedFields.size && hasInfo.size) {
                await ((_r = callbackFunctions.onSize) === null || _r === void 0 ? void 0 : _r.call(callbackFunctions, state.contentLength));
                if (fieldsInReturnValue.size) {
                    returnValue.size = state.contentLength;
                }
                emittedFields.size = true;
            }
            continue;
        }
        if (key === 'mimeType') {
            if (!emittedFields.mimeType && hasInfo.mimeType) {
                await ((_s = callbackFunctions.onMimeType) === null || _s === void 0 ? void 0 : _s.call(callbackFunctions, state.mimeType));
                if (fieldsInReturnValue.mimeType) {
                    returnValue.mimeType = state.mimeType;
                }
                emittedFields.mimeType = true;
            }
            continue;
        }
        if (key === 'name') {
            if (!emittedFields.name && hasInfo.name) {
                await ((_t = callbackFunctions.onName) === null || _t === void 0 ? void 0 : _t.call(callbackFunctions, name));
                if (fieldsInReturnValue.name) {
                    returnValue.name = name;
                }
                emittedFields.name = true;
            }
            continue;
        }
        if (key === 'isHdr') {
            if (!returnValue.isHdr && hasInfo.isHdr) {
                const isHdr = (0, get_is_hdr_1.getIsHdr)(state);
                await ((_u = callbackFunctions.onIsHdr) === null || _u === void 0 ? void 0 : _u.call(callbackFunctions, isHdr));
                if (fieldsInReturnValue.isHdr) {
                    returnValue.isHdr = isHdr;
                }
                emittedFields.isHdr = true;
            }
            continue;
        }
        if (key === 'container') {
            if (!returnValue.container && hasInfo.container) {
                const container = (0, get_container_1.getContainer)(state.structure.getStructure());
                await ((_v = callbackFunctions.onContainer) === null || _v === void 0 ? void 0 : _v.call(callbackFunctions, container));
                if (fieldsInReturnValue.container) {
                    returnValue.container = container;
                }
                emittedFields.container = true;
            }
            continue;
        }
        if (key === 'metadata') {
            if (!emittedFields.metadata && hasInfo.metadata) {
                const metadata = (0, get_metadata_1.getMetadata)(state);
                await ((_w = callbackFunctions.onMetadata) === null || _w === void 0 ? void 0 : _w.call(callbackFunctions, metadata));
                if (fieldsInReturnValue.metadata) {
                    returnValue.metadata = metadata;
                }
                emittedFields.metadata = true;
            }
            continue;
        }
        if (key === 'location') {
            if (!emittedFields.location && hasInfo.location) {
                const location = (0, get_location_1.getLocation)(state);
                await ((_x = callbackFunctions.onLocation) === null || _x === void 0 ? void 0 : _x.call(callbackFunctions, location));
                if (fieldsInReturnValue.location) {
                    returnValue.location = location;
                }
                emittedFields.location = true;
            }
            continue;
        }
        if (key === 'slowKeyframes') {
            if (!emittedFields.slowKeyframes && hasInfo.slowKeyframes) {
                await ((_y = callbackFunctions.onSlowKeyframes) === null || _y === void 0 ? void 0 : _y.call(callbackFunctions, state.keyframes.getKeyframes()));
                if (fieldsInReturnValue.slowKeyframes) {
                    returnValue.slowKeyframes = state.keyframes.getKeyframes();
                }
                emittedFields.slowKeyframes = true;
            }
            continue;
        }
        if (key === 'slowNumberOfFrames') {
            if (!emittedFields.slowNumberOfFrames && hasInfo.slowNumberOfFrames) {
                await ((_z = callbackFunctions.onSlowNumberOfFrames) === null || _z === void 0 ? void 0 : _z.call(callbackFunctions, state.samplesObserved.getSlowNumberOfFrames()));
                if (fieldsInReturnValue.slowNumberOfFrames) {
                    returnValue.slowNumberOfFrames = state.samplesObserved.getSlowNumberOfFrames();
                }
                emittedFields.slowNumberOfFrames = true;
            }
            continue;
        }
        if (key === 'slowAudioBitrate') {
            if (!emittedFields.slowAudioBitrate && hasInfo.slowAudioBitrate) {
                await ((_0 = callbackFunctions.onSlowAudioBitrate) === null || _0 === void 0 ? void 0 : _0.call(callbackFunctions, state.samplesObserved.getAudioBitrate()));
                if (fieldsInReturnValue.slowAudioBitrate) {
                    returnValue.slowAudioBitrate = state.samplesObserved.getAudioBitrate();
                }
                emittedFields.slowAudioBitrate = true;
            }
            continue;
        }
        if (key === 'slowVideoBitrate') {
            if (!emittedFields.slowVideoBitrate && hasInfo.slowVideoBitrate) {
                await ((_1 = callbackFunctions.onSlowVideoBitrate) === null || _1 === void 0 ? void 0 : _1.call(callbackFunctions, state.samplesObserved.getVideoBitrate()));
                if (fieldsInReturnValue.slowVideoBitrate) {
                    returnValue.slowVideoBitrate = state.samplesObserved.getVideoBitrate();
                }
                emittedFields.slowVideoBitrate = true;
            }
            continue;
        }
        if (key === 'keyframes') {
            if (!emittedFields.keyframes && hasInfo.keyframes) {
                await ((_2 = callbackFunctions.onKeyframes) === null || _2 === void 0 ? void 0 : _2.call(callbackFunctions, (0, get_keyframes_1.getKeyframes)(state)));
                if (fieldsInReturnValue.keyframes) {
                    returnValue.keyframes = (0, get_keyframes_1.getKeyframes)(state);
                }
                emittedFields.keyframes = true;
            }
            continue;
        }
        if (key === 'images') {
            if (!emittedFields.images && hasInfo.images) {
                await ((_3 = callbackFunctions.onImages) === null || _3 === void 0 ? void 0 : _3.call(callbackFunctions, state.images.images));
                if (fieldsInReturnValue.images) {
                    returnValue.images = state.images.images;
                }
                emittedFields.images = true;
            }
            continue;
        }
        if (key === 'sampleRate') {
            if (!emittedFields.sampleRate && hasInfo.sampleRate) {
                const sampleRate = (0, get_sample_rate_1.getSampleRate)(state);
                await ((_4 = callbackFunctions.onSampleRate) === null || _4 === void 0 ? void 0 : _4.call(callbackFunctions, sampleRate));
                if (fieldsInReturnValue.sampleRate) {
                    returnValue.sampleRate = sampleRate;
                }
                emittedFields.sampleRate = true;
            }
            continue;
        }
        if (key === 'numberOfAudioChannels') {
            if (!emittedFields.numberOfAudioChannels && hasInfo.numberOfAudioChannels) {
                const numberOfAudioChannels = (0, get_number_of_audio_channels_1.getNumberOfAudioChannels)(state);
                await ((_5 = callbackFunctions.onNumberOfAudioChannels) === null || _5 === void 0 ? void 0 : _5.call(callbackFunctions, numberOfAudioChannels));
                if (fieldsInReturnValue.numberOfAudioChannels) {
                    returnValue.numberOfAudioChannels = numberOfAudioChannels;
                }
                emittedFields.numberOfAudioChannels = true;
            }
            continue;
        }
        if (key === 'm3uStreams') {
            if (!emittedFields.m3uStreams && hasInfo.m3uStreams) {
                const streams = (0, get_streams_1.getM3uStreams)({
                    structure: state.structure.getStructureOrNull(),
                    originalSrc: state.src,
                    readerInterface: state.readerInterface
                });
                await ((_6 = callbackFunctions.onM3uStreams) === null || _6 === void 0 ? void 0 : _6.call(callbackFunctions, streams));
                if (fieldsInReturnValue.m3uStreams) {
                    returnValue.m3uStreams = streams;
                }
                emittedFields.m3uStreams = true;
            }
            continue;
        }
        throw new Error(`Unhandled key: ${key}`);
    }
    await (0, work_on_seek_request_1.workOnSeekRequest)((0, work_on_seek_request_1.getWorkOnSeekRequestOptions)(state));
};
exports.emitAvailableInfo = emitAvailableInfo;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/may-skip-video-data.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.maySkipOverSamplesInTheMiddle = exports.maySkipVideoData = exports.missesMatroskaTracks = void 0;
const get_ready_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/get-ready-tracks.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/traversal.js [app-route] (ecmascript)");
const need_samples_for_fields_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/need-samples-for-fields.js [app-route] (ecmascript)");
const getHasCallbacks = (state)=>{
    const hasNoTrackHandlers = !state.callbacks.hasAudioTrackHandlers && !state.callbacks.hasVideoTrackHandlers;
    if (hasNoTrackHandlers) {
        return false;
    }
    const hasAllTracksAndNoCallbacks = !state.callbacks.tracks.hasAllTracks() || Object.values(state.callbacks.videoSampleCallbacks).length > 0 || Object.values(state.callbacks.audioSampleCallbacks).length > 0;
    return hasAllTracksAndNoCallbacks;
};
const missesMatroskaTracks = (state)=>{
    const struct = state.structure.getStructureOrNull();
    if (struct === null) {
        return false;
    }
    if (struct.type !== 'matroska') {
        return false;
    }
    const mainSegment = (0, traversal_1.getMainSegment)(struct.boxes);
    if (mainSegment === null) {
        return false;
    }
    return (0, get_ready_tracks_1.getTracksFromMatroska)({
        structureState: state.structure,
        webmState: state.webm
    }).missingInfo.length > 0;
};
exports.missesMatroskaTracks = missesMatroskaTracks;
const maySkipVideoData = ({ state })=>{
    const hasCallbacks = getHasCallbacks(state);
    return !hasCallbacks && !(0, need_samples_for_fields_1.needsToIterateOverSamples)({
        emittedFields: state.emittedFields,
        fields: state.fields
    }) && !(0, exports.missesMatroskaTracks)(state);
};
exports.maySkipVideoData = maySkipVideoData;
const maySkipOverSamplesInTheMiddle = ({ state })=>{
    const hasCallbacks = getHasCallbacks(state);
    return !hasCallbacks && !(0, need_samples_for_fields_1.needsToIterateOverEverySample)({
        emittedFields: state.emittedFields,
        fields: state.fields
    });
};
exports.maySkipOverSamplesInTheMiddle = maySkipOverSamplesInTheMiddle;
}),
"[project]/node_modules/@remotion/media-parser/dist/has-all-info.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasAllInfo = exports.getAvailableInfo = void 0;
const get_streams_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-streams.js [app-route] (ecmascript)");
const get_audio_codec_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-audio-codec.js [app-route] (ecmascript)");
const get_container_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-container.js [app-route] (ecmascript)");
const get_dimensions_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-dimensions.js [app-route] (ecmascript)");
const get_duration_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-duration.js [app-route] (ecmascript)");
const get_fps_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-fps.js [app-route] (ecmascript)");
const get_is_hdr_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-is-hdr.js [app-route] (ecmascript)");
const get_keyframes_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-keyframes.js [app-route] (ecmascript)");
const get_number_of_audio_channels_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-number-of-audio-channels.js [app-route] (ecmascript)");
const get_sample_rate_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-sample-rate.js [app-route] (ecmascript)");
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const get_video_codec_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-video-codec.js [app-route] (ecmascript)");
const get_metadata_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/metadata/get-metadata.js [app-route] (ecmascript)");
const may_skip_video_data_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/may-skip-video-data.js [app-route] (ecmascript)");
const getAvailableInfo = ({ state })=>{
    const keys = Object.entries(state.fields).filter(([, value])=>value);
    const structure = state.structure.getStructureOrNull();
    const infos = keys.map(([_key])=>{
        const key = _key;
        if (key === 'slowStructure') {
            return false;
        }
        if (key === 'durationInSeconds') {
            return Boolean(structure && (0, get_duration_1.hasDuration)(state));
        }
        if (key === 'slowDurationInSeconds') {
            const res = Boolean(structure && (0, get_duration_1.hasSlowDuration)(state));
            return res;
        }
        if (key === 'dimensions' || key === 'rotation' || key === 'unrotatedDimensions') {
            return Boolean(structure && (0, get_dimensions_1.hasDimensions)(state));
        }
        if (key === 'fps') {
            return Boolean(structure && (0, get_fps_1.hasFps)(state));
        }
        if (key === 'slowFps') {
            // In case FPS is available an non-null, it also works for `slowFps`
            return Boolean(structure && (0, get_fps_1.hasFpsSuitedForSlowFps)(state));
        }
        if (key === 'isHdr') {
            return Boolean(structure && (0, get_is_hdr_1.hasHdr)(state));
        }
        if (key === 'videoCodec') {
            return Boolean(structure && (0, get_video_codec_1.hasVideoCodec)(state));
        }
        if (key === 'audioCodec') {
            return Boolean(structure && (0, get_audio_codec_1.hasAudioCodec)(state));
        }
        if (key === 'tracks') {
            return Boolean(structure && (0, get_tracks_1.getHasTracks)(state, true));
        }
        if (key === 'keyframes') {
            return Boolean(structure && (0, get_keyframes_1.hasKeyframes)(state));
        }
        if (key === 'internalStats') {
            return true;
        }
        if (key === 'size') {
            return true;
        }
        if (key === 'mimeType') {
            return true;
        }
        if (key === 'name') {
            return true;
        }
        if (key === 'container') {
            return Boolean(structure && (0, get_container_1.hasContainer)(structure));
        }
        if (key === 'metadata' || key === 'location' || key === 'images') {
            return Boolean(structure && (0, get_metadata_1.hasMetadata)(structure));
        }
        if (key === 'slowKeyframes' || key === 'slowVideoBitrate' || key === 'slowAudioBitrate' || key === 'slowNumberOfFrames') {
            return false;
        }
        if (key === 'numberOfAudioChannels') {
            return (0, get_number_of_audio_channels_1.hasNumberOfAudioChannels)(state);
        }
        if (key === 'sampleRate') {
            return (0, get_sample_rate_1.hasSampleRate)(state);
        }
        if (key === 'm3uStreams') {
            return (0, get_streams_1.m3uHasStreams)(state);
        }
        throw new Error(`Unknown field passed: ${key}. Available fields: ${Object.keys(state.fields).join(', ')}`);
    });
    const entries = [];
    let i = 0;
    for (const [key] of keys){
        entries.push([
            key,
            infos[i++]
        ]);
    }
    return Object.fromEntries(entries);
};
exports.getAvailableInfo = getAvailableInfo;
const hasAllInfo = ({ state })=>{
    const availableInfo = (0, exports.getAvailableInfo)({
        state
    });
    if (!Object.values(availableInfo).every(Boolean)) {
        return false;
    }
    if ((0, may_skip_video_data_1.maySkipVideoData)({
        state
    })) {
        return true;
    }
    if (state.callbacks.canSkipTracksState.canSkipTracks()) {
        return true;
    }
    return false;
};
exports.hasAllInfo = hasAllInfo;
}),
"[project]/node_modules/@remotion/media-parser/dist/emit-all-info.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.triggerInfoEmit = exports.emitAllInfo = void 0;
const emit_available_info_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/emit-available-info.js [app-route] (ecmascript)");
const has_all_info_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/has-all-info.js [app-route] (ecmascript)");
const emitAllInfo = async (state)=>{
    // Force assign
    const allFields = Object.keys(state.fields).reduce((acc, key)=>{
        var _a;
        if ((_a = state.fields) === null || _a === void 0 ? void 0 : _a[key]) {
            acc[key] = true;
        }
        return acc;
    }, {});
    await (0, emit_available_info_1.emitAvailableInfo)({
        hasInfo: allFields,
        state
    });
};
exports.emitAllInfo = emitAllInfo;
const triggerInfoEmit = async (state)=>{
    const availableInfo = (0, has_all_info_1.getAvailableInfo)({
        state
    });
    await (0, emit_available_info_1.emitAvailableInfo)({
        hasInfo: availableInfo,
        state
    });
};
exports.triggerInfoEmit = triggerInfoEmit;
}),
"[project]/node_modules/@remotion/media-parser/dist/check-if-done.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.checkIfDone = void 0;
const has_all_info_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/has-all-info.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const checkIfDone = async (state)=>{
    const startCheck = Date.now();
    const hasAll = (0, has_all_info_1.hasAllInfo)({
        state
    });
    state.timings.timeCheckingIfDone += Date.now() - startCheck;
    if (hasAll && state.mode === 'query') {
        log_1.Log.verbose(state.logLevel, 'Got all info, skipping to the end.');
        state.increaseSkippedBytes(state.contentLength - state.iterator.counter.getOffset());
        return true;
    }
    if (state.iterator.counter.getOffset() === state.contentLength) {
        if (state.structure.getStructure().type === 'm3u' && !state.m3u.getAllChunksProcessedOverall()) {
            return false;
        }
        state.riff.queuedBFrames.flush();
        if (state.riff.queuedBFrames.hasReleasedFrames()) {
            return false;
        }
        log_1.Log.verbose(state.logLevel, 'Reached end of file');
        await state.discardReadBytes(true);
        return true;
    }
    if (state.iterator.counter.getOffset() + state.iterator.bytesRemaining() === state.contentLength && state.errored) {
        log_1.Log.verbose(state.logLevel, 'Reached end of file and errorred');
        return true;
    }
    return false;
};
exports.checkIfDone = checkIfDone;
}),
"[project]/node_modules/@remotion/media-parser/dist/make-progress-object.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makeProgressObject = void 0;
const makeProgressObject = (state)=>{
    return {
        bytes: state.iterator.counter.getOffset(),
        percentage: state.contentLength ? state.iterator.counter.getOffset() / state.contentLength : null,
        totalBytes: state.contentLength
    };
};
exports.makeProgressObject = makeProgressObject;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/aac/parse-aac.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseAac = void 0;
const aac_codecprivate_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/aac-codecprivate.js [app-route] (ecmascript)");
const convert_audio_or_video_sample_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/convert-audio-or-video-sample.js [app-route] (ecmascript)");
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const parseAac = async (state)=>{
    const { iterator } = state;
    const startOffset = iterator.counter.getOffset();
    iterator.startReadingBits();
    const syncWord = iterator.getBits(12);
    if (syncWord !== 0xfff) {
        throw new Error('Invalid syncword: ' + syncWord);
    }
    const id = iterator.getBits(1);
    if (id !== 0) {
        throw new Error('Only supporting MPEG-4 for .aac');
    }
    const layer = iterator.getBits(2);
    if (layer !== 0) {
        throw new Error('Only supporting layer 0 for .aac');
    }
    const protectionAbsent = iterator.getBits(1); // protection absent
    const audioObjectType = iterator.getBits(2); // 1 = 'AAC-LC'
    const samplingFrequencyIndex = iterator.getBits(4);
    const sampleRate = (0, aac_codecprivate_1.getSampleRateFromSampleFrequencyIndex)(samplingFrequencyIndex);
    iterator.getBits(1); // private bit
    const channelConfiguration = iterator.getBits(3);
    const codecPrivate = (0, aac_codecprivate_1.createAacCodecPrivate)({
        audioObjectType,
        sampleRate,
        channelConfiguration,
        codecPrivate: null
    });
    iterator.getBits(1); // originality
    iterator.getBits(1); // home
    iterator.getBits(1); // copyright bit
    iterator.getBits(1); // copy start
    const frameLength = iterator.getBits(13); // frame length
    iterator.getBits(11); // buffer fullness
    iterator.getBits(2); // number of AAC frames minus 1
    if (!protectionAbsent) {
        iterator.getBits(16); // crc
    }
    iterator.stopReadingBits();
    iterator.counter.decrement(iterator.counter.getOffset() - startOffset);
    const data = iterator.getSlice(frameLength);
    if (state.callbacks.tracks.getTracks().length === 0) {
        state.mediaSection.addMediaSection({
            start: startOffset,
            size: state.contentLength - startOffset
        });
        await (0, register_track_1.registerAudioTrack)({
            container: 'aac',
            track: {
                codec: (0, aac_codecprivate_1.mapAudioObjectTypeToCodecString)(audioObjectType),
                codecEnum: 'aac',
                codecData: {
                    type: 'aac-config',
                    data: codecPrivate
                },
                description: codecPrivate,
                numberOfChannels: channelConfiguration,
                sampleRate,
                originalTimescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
                trackId: 0,
                type: 'audio',
                startInSeconds: 0,
                timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
                trackMediaTimeOffsetInTrackTimescale: 0
            },
            registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,
            tracks: state.callbacks.tracks,
            logLevel: state.logLevel,
            onAudioTrack: state.onAudioTrack
        });
        state.callbacks.tracks.setIsDone(state.logLevel);
    }
    const duration = 1024 / sampleRate;
    const { index } = state.aac.addSample({
        offset: startOffset,
        size: frameLength
    });
    const timestamp = 1024 / sampleRate * index;
    state.aac.audioSamples.addSample({
        timeInSeconds: timestamp,
        offset: startOffset,
        durationInSeconds: duration
    });
    // One ADTS frame contains 1024 samples
    const audioSample = (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
        sample: {
            duration,
            type: 'key',
            data,
            offset: startOffset,
            decodingTimestamp: timestamp,
            timestamp
        },
        timescale: 1
    });
    await state.callbacks.onAudioSample({
        audioSample,
        trackId: 0
    });
    return Promise.resolve(null);
};
exports.parseAac = parseAac;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-block-size.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getBlockSize = void 0;
const getBlockSize = (iterator)=>{
    const bits = iterator.getBits(4);
    if (bits === 0b0000) {
        // Probably we are in the wrong spot overall, and just landed on a spot that incidentially hit the syncword.
        // Don't throw an error, in the parent function just keep reading.
        // Internal message with repro: https://discord.com/channels/@me/1314232261008162876/1410312296709881988
        return null;
    }
    if (bits === 0b0001) {
        return 192;
    }
    if (bits >= 0b0010 && bits <= 0b0101) {
        return 144 * 2 ** bits;
    }
    if (bits === 0b0110) {
        return 'uncommon-u8';
    }
    if (bits === 0b0111) {
        return 'uncommon-u16';
    }
    if (bits >= 0b1000 && bits <= 0b1111) {
        return 2 ** bits;
    }
    throw new Error('Invalid block size');
};
exports.getBlockSize = getBlockSize;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-channel-count.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getChannelCount = void 0;
// https://www.rfc-editor.org/rfc/rfc9639.html#name-channels-bits
const getChannelCount = (iterator)=>{
    const bits = iterator.getBits(4);
    if (bits === 0b0000) {
        return 1;
    }
    if (bits === 0b0001) {
        return 2;
    }
    if (bits === 0b0010) {
        return 3;
    }
    if (bits === 0b0011) {
        return 4;
    }
    if (bits === 0b0100) {
        return 5;
    }
    if (bits === 0b0101) {
        return 6;
    }
    if (bits === 0b0110) {
        return 7;
    }
    if (bits === 0b0111) {
        return 8;
    }
    if (bits === 0b1000 || bits === 0b1001 || bits === 0b1010) {
        return 2;
    }
    // 0b1011..0b1111 are reserved per RFC 9639 Â§9.1.3 (Channels Bits).
    // Some encoders/files in the wild may nonetheless use these values.
    // Be lenient and treat them as stereo (2 channels) to keep parsing robust.
    if (bits >= 0b1011 && bits <= 0b1111) {
        return 2;
    }
    throw new Error(`Invalid channel count: ${bits.toString(2)}`);
};
exports.getChannelCount = getChannelCount;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-sample-rate.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSampleRate = void 0;
// https://www.rfc-editor.org/rfc/rfc9639.html#name-sample-rate-bits
const getSampleRate = (iterator, state)=>{
    var _a, _b;
    const mode = iterator.getBits(4);
    if (mode === 0b0000 || mode === 0b1111) {
        const structure = state.structure.getFlacStructure();
        const sampleRate = (_b = (_a = structure.boxes.find((box)=>box.type === 'flac-streaminfo')) === null || _a === void 0 ? void 0 : _a.sampleRate) !== null && _b !== void 0 ? _b : null;
        if (sampleRate === null) {
            throw new Error('Sample rate not found');
        }
        return sampleRate;
    }
    if (mode === 0b0001) {
        return 88200;
    }
    if (mode === 0b0010) {
        return 176400;
    }
    if (mode === 0b0011) {
        return 192000;
    }
    if (mode === 0b0100) {
        return 8000;
    }
    if (mode === 0b0101) {
        return 16000;
    }
    if (mode === 0b0110) {
        return 22050;
    }
    if (mode === 0b0111) {
        return 24000;
    }
    if (mode === 0b1000) {
        return 32000;
    }
    if (mode === 0b1001) {
        return 44100;
    }
    if (mode === 0b1010) {
        return 48000;
    }
    if (mode === 0b1011) {
        return 96000;
    }
    if (mode === 0b1100) {
        return 'uncommon-u8';
    }
    if (mode === 0b1101) {
        return 'uncommon-u16';
    }
    if (mode === 0b1110) {
        return 'uncommon-u16-10';
    }
    throw new Error(`Invalid sample rate mode: ${mode.toString(2)}`);
};
exports.getSampleRate = getSampleRate;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-flac-frame.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseFlacFrame = exports.parseFrameHeader = void 0;
const convert_audio_or_video_sample_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/convert-audio-or-video-sample.js [app-route] (ecmascript)");
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const get_block_size_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-block-size.js [app-route] (ecmascript)");
const get_channel_count_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-channel-count.js [app-route] (ecmascript)");
const get_sample_rate_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/get-sample-rate.js [app-route] (ecmascript)");
// https://www.rfc-editor.org/rfc/rfc9639.html#section-9.1.1
function calculateCRC8(data) {
    const polynomial = 0x07; // x^8 + x^2 + x^1 + x^0
    let crc = 0x00; // Initialize CRC to 0
    for (const byte of data){
        crc ^= byte; // XOR byte into least significant byte of crc
        for(let i = 0; i < 8; i++){
            // For each bit in the byte
            if ((crc & 0x80) !== 0) {
                // If the leftmost bit (MSB) is set
                crc = crc << 1 ^ polynomial; // Shift left and XOR with polynomial
            } else {
                crc <<= 1; // Just shift left
            }
            crc &= 0xff; // Ensure CRC remains 8-bit
        }
    }
    return crc;
}
const parseFrameHeader = ({ iterator, state })=>{
    if (iterator.bytesRemaining() < 10) {
        return null;
    }
    const startOffset = iterator.counter.getOffset();
    iterator.discard(2); // sync code
    iterator.startReadingBits();
    const blockSizeBits = (0, get_block_size_1.getBlockSize)(iterator);
    if (blockSizeBits === null) {
        return null;
    }
    const sampleRateBits = (0, get_sample_rate_1.getSampleRate)(iterator, state);
    (0, get_channel_count_1.getChannelCount)(iterator); // channel count
    iterator.getBits(3); // bit depth
    iterator.getBits(1);
    const num = iterator.getFlacCodecNumber();
    const blockSize = blockSizeBits === 'uncommon-u16' ? iterator.getBits(16) + 1 : blockSizeBits === 'uncommon-u8' ? iterator.getBits(8) + 1 : blockSizeBits;
    const sampleRate = sampleRateBits === 'uncommon-u16' ? iterator.getBits(16) : sampleRateBits === 'uncommon-u16-10' ? iterator.getBits(16) * 10 : sampleRateBits === 'uncommon-u8' ? iterator.getBits(8) : sampleRateBits;
    iterator.stopReadingBits();
    const size = iterator.counter.getOffset() - startOffset;
    const crc = iterator.getUint8();
    iterator.counter.decrement(size + 1);
    const crcCalculated = calculateCRC8(iterator.getSlice(size));
    iterator.counter.decrement(size);
    if (crcCalculated !== crc) {
        return null;
    }
    return {
        num,
        blockSize,
        sampleRate
    };
};
exports.parseFrameHeader = parseFrameHeader;
const emitSample = async ({ state, data, offset })=>{
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: data,
        maxBytes: data.length,
        logLevel: 'error'
    });
    const parsed = (0, exports.parseFrameHeader)({
        iterator,
        state
    });
    if (!parsed) {
        throw new Error('Invalid CRC');
    }
    const { blockSize, num, sampleRate } = parsed;
    const duration = blockSize / sampleRate;
    const structure = state.structure.getFlacStructure();
    const streamInfo = structure.boxes.find((box)=>box.type === 'flac-streaminfo');
    if (!streamInfo) {
        throw new Error('Stream info not found');
    }
    if (streamInfo.minimumBlockSize !== streamInfo.maximumBlockSize) {
        throw new Error('Cannot determine timestamp');
    }
    const timestamp = num * streamInfo.maximumBlockSize / streamInfo.sampleRate;
    state.flac.audioSamples.addSample({
        timeInSeconds: timestamp,
        offset,
        durationInSeconds: duration
    });
    const audioSample = (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
        sample: {
            data,
            duration,
            decodingTimestamp: timestamp,
            timestamp,
            type: 'key',
            offset
        },
        timescale: 1
    });
    await state.callbacks.onAudioSample({
        audioSample,
        trackId: 0
    });
    iterator.destroy();
};
const parseFlacFrame = async ({ state, iterator })=>{
    var _a, _b;
    const blockingBit = state.flac.getBlockingBitStrategy();
    const offset = iterator.counter.getOffset();
    const { returnToCheckpoint } = iterator.startCheckpoint();
    iterator.startReadingBits();
    if (blockingBit === undefined) {
        const bits = iterator.getBits(15);
        if (bits !== 0b111111111111100) {
            throw new Error('Invalid sync code');
        }
        state.flac.setBlockingBitStrategy(iterator.getBits(1));
    } else if (blockingBit === 1) {
        const bits = iterator.getBits(16);
        if (bits !== 0b1111111111111001) {
            throw new Error('Blocking bit changed, it should not');
        }
    } else if (blockingBit === 0) {
        const bits = iterator.getBits(16);
        if (bits !== 0b1111111111111000) {
            throw new Error('Blocking bit changed, it should not');
        }
    }
    const setBlockingBit = state.flac.getBlockingBitStrategy();
    if (setBlockingBit === undefined) {
        throw new Error('Blocking bit should be set');
    }
    iterator.stopReadingBits();
    const structure = state.structure.getFlacStructure();
    const minimumFrameSize = (_b = (_a = structure.boxes.find((b)=>b.type === 'flac-streaminfo')) === null || _a === void 0 ? void 0 : _a.minimumFrameSize) !== null && _b !== void 0 ? _b : null;
    if (minimumFrameSize === null) {
        throw new Error('Expected flac-streaminfo');
    }
    if (minimumFrameSize !== 0) {
        iterator.getSlice(minimumFrameSize - 2);
    }
    while(true){
        if (iterator.counter.getOffset() === state.contentLength) {
            const size = iterator.counter.getOffset() - offset;
            returnToCheckpoint();
            const slice = iterator.getSlice(size);
            await emitSample({
                state,
                data: slice,
                offset
            });
            break;
        }
        if (iterator.bytesRemaining() === 0) {
            returnToCheckpoint();
            break;
        }
        const nextByte = iterator.getUint8();
        if (nextByte === 0xff) {
            const nextBits = iterator.getUint8();
            const expected = setBlockingBit === 1 ? 249 : 248;
            if (nextBits !== expected) {
                iterator.counter.decrement(1);
                continue;
            }
            iterator.counter.decrement(2);
            const nextIsLegit = (0, exports.parseFrameHeader)({
                iterator,
                state
            });
            if (!nextIsLegit) {
                iterator.discard(1);
                continue;
            }
            const size = iterator.counter.getOffset() - offset;
            returnToCheckpoint();
            const data = iterator.getSlice(size);
            await emitSample({
                state,
                data,
                offset
            });
            break;
        }
    }
    return null;
};
exports.parseFlacFrame = parseFlacFrame;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-header.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseFlacHeader = void 0;
const parseFlacHeader = ({ state })=>{
    state.structure.getFlacStructure().boxes.push({
        type: 'flac-header'
    });
    return Promise.resolve(null);
};
exports.parseFlacHeader = parseFlacHeader;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-metadata.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseVorbisComment = void 0;
const parseVorbisComment = ({ state, iterator, size })=>{
    const { expectNoMoreBytes } = iterator.startBox(size);
    const box = {
        type: 'flac-vorbis-comment',
        fields: []
    };
    const vendorLength = iterator.getUint32Le();
    const vendorString = iterator.getByteString(vendorLength, true);
    const numberOfFields = iterator.getUint32Le();
    box.fields.push({
        key: 'vendor',
        value: vendorString,
        trackId: null
    });
    for(let i = 0; i < numberOfFields; i++){
        const fieldLength = iterator.getUint32Le();
        const field = iterator.getByteString(fieldLength, true);
        const [key, value] = field.split('=');
        box.fields.push({
            key: key.toLowerCase(),
            value,
            trackId: null
        });
    }
    state.structure.getFlacStructure().boxes.push(box);
    expectNoMoreBytes();
    return Promise.resolve(null);
};
exports.parseVorbisComment = parseVorbisComment;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-streaminfo.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseStreamInfo = void 0;
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const parseStreamInfo = async ({ iterator, state })=>{
    const counter = iterator.counter.getOffset();
    const minimumBlockSize = iterator.getUint16();
    const maximumBlockSize = iterator.getUint16();
    const minimumFrameSize = iterator.getUint24();
    const maximumFrameSize = iterator.getUint24();
    iterator.startReadingBits();
    const sampleRate = iterator.getBits(20);
    const channels = iterator.getBits(3) + 1;
    const bitsPerSample = iterator.getBits(5);
    const totalSamples = iterator.getBits(36);
    iterator.getBits(128); // md5
    iterator.stopReadingBits();
    const counterNow = iterator.counter.getOffset();
    const size = counterNow - counter;
    iterator.counter.decrement(size);
    const asUint8Array = iterator.getSlice(size);
    const flacStreamInfo = {
        type: 'flac-streaminfo',
        bitsPerSample,
        channels,
        maximumBlockSize,
        maximumFrameSize,
        minimumBlockSize,
        minimumFrameSize,
        sampleRate,
        totalSamples
    };
    state.structure.getFlacStructure().boxes.push(flacStreamInfo);
    await (0, register_track_1.registerAudioTrack)({
        container: 'flac',
        track: {
            codec: 'flac',
            type: 'audio',
            description: asUint8Array,
            codecData: {
                type: 'flac-description',
                data: asUint8Array
            },
            codecEnum: 'flac',
            numberOfChannels: channels,
            sampleRate,
            originalTimescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
            trackId: 0,
            startInSeconds: 0,
            timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
            trackMediaTimeOffsetInTrackTimescale: 0
        },
        registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,
        tracks: state.callbacks.tracks,
        logLevel: state.logLevel,
        onAudioTrack: state.onAudioTrack
    });
    state.callbacks.tracks.setIsDone(state.logLevel);
    return Promise.resolve(null);
};
exports.parseStreamInfo = parseStreamInfo;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-unknown-block.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseFlacUnkownBlock = void 0;
const parseFlacUnkownBlock = ({ iterator, state, size })=>{
    iterator.discard(size);
    state.structure.getFlacStructure().boxes.push({
        type: 'flac-header'
    });
    return Promise.resolve(null);
};
exports.parseFlacUnkownBlock = parseFlacUnkownBlock;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-meta.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMetaBlock = void 0;
const parse_metadata_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-metadata.js [app-route] (ecmascript)");
const parse_streaminfo_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-streaminfo.js [app-route] (ecmascript)");
const parse_unknown_block_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-unknown-block.js [app-route] (ecmascript)");
const flacTypes = {
    streaminfo: 0,
    vorbisComment: 4
};
const parseMetaBlock = ({ iterator, state })=>{
    iterator.startReadingBits();
    const isLastMetadata = iterator.getBits(1);
    const metaBlockType = iterator.getBits(7);
    iterator.stopReadingBits();
    const size = iterator.getUint24();
    if (isLastMetadata) {
        state.mediaSection.addMediaSection({
            start: iterator.counter.getOffset() + size,
            size: state.contentLength - iterator.counter.getOffset() - size
        });
    }
    if (metaBlockType === flacTypes.streaminfo) {
        return (0, parse_streaminfo_1.parseStreamInfo)({
            iterator,
            state
        });
    }
    if (metaBlockType === flacTypes.vorbisComment) {
        return (0, parse_metadata_1.parseVorbisComment)({
            iterator,
            state,
            size
        });
    }
    return (0, parse_unknown_block_1.parseFlacUnkownBlock)({
        iterator,
        state,
        size
    });
};
exports.parseMetaBlock = parseMetaBlock;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-flac.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseFlac = void 0;
const skip_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/skip.js [app-route] (ecmascript)");
const may_skip_video_data_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/may-skip-video-data.js [app-route] (ecmascript)");
const parse_flac_frame_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-flac-frame.js [app-route] (ecmascript)");
const parse_header_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-header.js [app-route] (ecmascript)");
const parse_meta_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-meta.js [app-route] (ecmascript)");
const parseFlac = ({ iterator, state })=>{
    const mediaSectionState = state.mediaSection.isCurrentByteInMediaSection(iterator);
    if (mediaSectionState === 'in-section') {
        if ((0, may_skip_video_data_1.maySkipVideoData)({
            state
        })) {
            return Promise.resolve((0, skip_1.makeSkip)(state.contentLength));
        }
        return (0, parse_flac_frame_1.parseFlacFrame)({
            state,
            iterator
        });
    }
    const bytes = iterator.getByteString(4, true);
    if (bytes === 'fLaC') {
        return (0, parse_header_1.parseFlacHeader)({
            state,
            iterator
        });
    }
    iterator.counter.decrement(4);
    // https://www.rfc-editor.org/rfc/rfc9639.html#name-streaminfo
    // section 8.1
    return (0, parse_meta_1.parseMetaBlock)({
        iterator,
        state
    });
};
exports.parseFlac = parseFlac;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/cached-sample-positions.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSampleWithLowestDts = exports.cachedSamplePositionsState = exports.calculateSamplePositions = void 0;
const are_samples_complete_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/are-samples-complete.js [app-route] (ecmascript)");
const get_sample_positions_from_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-sample-positions-from-track.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const precomputed_tfra_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/precomputed-tfra.js [app-route] (ecmascript)");
const calculateSamplePositions = ({ state, mediaSectionStart, trackIds })=>{
    var _a, _b;
    const tracks = (0, get_tracks_1.getTracks)(state, true);
    const moofBoxes = (0, traversal_1.getMoofBoxes)(state.structure.getIsoStructure().boxes);
    const tfraBoxes = (0, precomputed_tfra_1.deduplicateTfraBoxesByOffset)([
        ...state.iso.tfra.getTfraBoxes(),
        ...(0, traversal_1.getTfraBoxes)(state.structure.getIsoStructure().boxes)
    ]);
    const moofComplete = (0, are_samples_complete_1.areSamplesComplete)({
        moofBoxes,
        tfraBoxes
    });
    const relevantMoofBox = moofBoxes.find((moofBox)=>moofBox.offset + moofBox.size + 8 === mediaSectionStart);
    if (moofBoxes.length > 0 && !relevantMoofBox) {
        throw new Error('No relevant moof box found');
    }
    const moov = (0, traversal_1.getMoovBoxFromState)({
        structureState: state.structure,
        isoState: state.iso,
        mp4HeaderSegment: (_b = (_a = state.m3uPlaylistContext) === null || _a === void 0 ? void 0 : _a.mp4HeaderSegment) !== null && _b !== void 0 ? _b : null,
        mayUsePrecomputed: true
    });
    if (!moov) {
        throw new Error('No moov box found');
    }
    const trackIdAndSamplePositions = [];
    for (const track of tracks){
        const trakBox = (0, traversal_1.getTrakBoxByTrackId)(moov, track.trackId);
        if (!trackIds.includes(track.trackId)) {
            log_1.Log.verbose(state.logLevel, 'Skipping calculating sample positions for track', track.trackId);
            continue;
        }
        if (!trakBox) {
            throw new Error('No trak box found');
        }
        const { samplePositions } = (0, get_sample_positions_from_track_1.getSamplePositionsFromTrack)({
            trakBox,
            moofBoxes: relevantMoofBox ? [
                relevantMoofBox
            ] : [],
            moofComplete,
            trexBoxes: (0, traversal_1.getTrexBoxes)(moov)
        });
        trackIdAndSamplePositions.push({
            trackId: track.trackId,
            samplePositions
        });
    }
    return trackIdAndSamplePositions;
};
exports.calculateSamplePositions = calculateSamplePositions;
const updateSampleIndicesAfterSeek = ({ samplePositionsForMdatStart, seekedByte })=>{
    const currentSampleIndices = {};
    const keys = Object.keys(samplePositionsForMdatStart).map(Number).sort();
    const mdat = keys.find((key)=>seekedByte >= key);
    if (!mdat) {
        return currentSampleIndices;
    }
    const samplePositions = samplePositionsForMdatStart[mdat];
    if (!samplePositions) {
        return currentSampleIndices;
    }
    for (const track of samplePositions){
        const currentSampleIndex = track.samplePositions.findIndex((sample)=>sample.offset >= seekedByte);
        if (!currentSampleIndices[mdat]) {
            currentSampleIndices[mdat] = {};
        }
        if (!currentSampleIndices[mdat][track.trackId]) {
            currentSampleIndices[mdat][track.trackId] = 0;
        }
        if (currentSampleIndex === -1) {
            currentSampleIndices[mdat][track.trackId] = track.samplePositions.length;
        } else {
            currentSampleIndices[mdat][track.trackId] = currentSampleIndex;
        }
    }
    return currentSampleIndices;
};
const cachedSamplePositionsState = ()=>{
    // offset -> sample positions
    const samplePositionsForMdatStart = {};
    let currentSampleIndex = {};
    return {
        getSamples: (mdatStart)=>{
            var _a;
            return (_a = samplePositionsForMdatStart[mdatStart]) !== null && _a !== void 0 ? _a : null;
        },
        setSamples: (mdatStart, samples)=>{
            samplePositionsForMdatStart[mdatStart] = samples;
        },
        setCurrentSampleIndex: (mdatStart, trackId, index)=>{
            if (!currentSampleIndex[mdatStart]) {
                currentSampleIndex[mdatStart] = {};
            }
            if (!currentSampleIndex[mdatStart][trackId]) {
                currentSampleIndex[mdatStart][trackId] = 0;
            }
            currentSampleIndex[mdatStart][trackId] = index;
        },
        getCurrentSampleIndices: (mdatStart)=>{
            var _a;
            return (_a = currentSampleIndex[mdatStart]) !== null && _a !== void 0 ? _a : {};
        },
        updateAfterSeek: (seekedByte)=>{
            currentSampleIndex = updateSampleIndicesAfterSeek({
                samplePositionsForMdatStart,
                seekedByte
            });
        }
    };
};
exports.cachedSamplePositionsState = cachedSamplePositionsState;
const getSampleWithLowestDts = (samplePositions, currentSampleIndexMap)=>{
    var _a;
    const lowestDts = [];
    for (const track of samplePositions){
        const currentSampleIndex = (_a = currentSampleIndexMap[track.trackId]) !== null && _a !== void 0 ? _a : 0;
        const currentSample = track.samplePositions[currentSampleIndex];
        if (currentSample && (lowestDts.length === 0 || currentSample.decodingTimestamp <= lowestDts[0].samplePosition.decodingTimestamp)) {
            lowestDts.push({
                samplePosition: currentSample,
                trackId: track.trackId,
                index: currentSampleIndex
            });
        }
    }
    return lowestDts;
};
exports.getSampleWithLowestDts = getSampleWithLowestDts;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/last-moof-box.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMaxFirstMoofOffset = exports.getLastMoofBox = void 0;
const truthy_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/truthy.js [app-route] (ecmascript)");
const getLastMoofBox = (boxes)=>{
    if (boxes) {
        const tfras = boxes.filter((b)=>b.type === 'tfra-box');
        const lastMoofOffsets = tfras.map((f)=>{
            if (f.entries.length <= 1) {
                return null;
            }
            return f.entries[f.entries.length - 1].moofOffset;
        });
        if (lastMoofOffsets.length > 0) {
            const maxOffset = Math.max(...lastMoofOffsets.filter(truthy_1.truthy));
            return maxOffset;
        }
        return null;
    }
};
exports.getLastMoofBox = getLastMoofBox;
const getMaxFirstMoofOffset = (boxes)=>{
    const tfras = boxes.filter((b)=>b.type === 'tfra-box');
    const firstMoofOffsets = tfras.map((f)=>{
        return f.entries[0].moofOffset;
    });
    return Math.max(...firstMoofOffsets.filter(truthy_1.truthy));
};
exports.getMaxFirstMoofOffset = getMaxFirstMoofOffset;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/can-skip-tracks.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makeCanSkipTracksState = exports.needsTracksForField = void 0;
const needsTracksForField = ({ field, structure })=>{
    if (field === 'dimensions') {
        if ((structure === null || structure === void 0 ? void 0 : structure.type) === 'riff') {
            return false;
        }
        return true;
    }
    if (field === 'audioCodec' || field === 'durationInSeconds' || field === 'slowDurationInSeconds' || field === 'slowFps' || field === 'fps' || field === 'isHdr' || field === 'rotation' || field === 'slowStructure' || field === 'tracks' || field === 'unrotatedDimensions' || field === 'videoCodec' || field === 'metadata' || field === 'location' || field === 'slowKeyframes' || field === 'slowNumberOfFrames' || field === 'keyframes' || field === 'images' || field === 'sampleRate' || field === 'numberOfAudioChannels' || field === 'slowAudioBitrate' || field === 'slowVideoBitrate' || field === 'm3uStreams') {
        return true;
    }
    if (field === 'container' || field === 'internalStats' || field === 'mimeType' || field === 'name' || field === 'size') {
        return false;
    }
    throw new Error(`field not implemeted ${field}`);
};
exports.needsTracksForField = needsTracksForField;
const makeCanSkipTracksState = ({ hasAudioTrackHandlers, fields, hasVideoTrackHandlers, structure })=>{
    const doFieldsNeedTracks = ()=>{
        const keys = Object.keys(fields !== null && fields !== void 0 ? fields : {});
        const selectedKeys = keys.filter((k)=>fields[k]);
        return selectedKeys.some((k)=>(0, exports.needsTracksForField)({
                field: k,
                structure: structure.getStructureOrNull()
            }));
    };
    return {
        doFieldsNeedTracks,
        canSkipTracks: ()=>{
            if (hasAudioTrackHandlers || hasVideoTrackHandlers) {
                return false;
            }
            return !doFieldsNeedTracks();
        }
    };
};
exports.makeCanSkipTracksState = makeCanSkipTracksState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/has-tracks-section.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makeTracksSectionState = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const makeTracksSectionState = (canSkipTracksState, src)=>{
    const tracks = [];
    let doneWithTracks = false;
    return {
        hasAllTracks: ()=>doneWithTracks,
        getIsDone: ()=>doneWithTracks,
        setIsDone: (logLevel)=>{
            if (doneWithTracks) {
                throw new Error('Error in Media Parser: Tracks have already been parsed');
            }
            log_1.Log.verbose(logLevel, 'All tracks have been parsed');
            doneWithTracks = true;
        },
        addTrack: (track)=>{
            tracks.push(track);
        },
        getTracks: ()=>{
            return tracks;
        },
        ensureHasTracksAtEnd: (fields)=>{
            if (canSkipTracksState.canSkipTracks()) {
                return;
            }
            if (!fields.tracks) {
                return;
            }
            if (!doneWithTracks) {
                throw new Error('Error in Media Parser: End of parsing of ' + src + ' has been reached, but no tracks have been found ');
            }
        }
    };
};
exports.makeTracksSectionState = makeTracksSectionState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/structure.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.structureState = void 0;
const structureState = ()=>{
    let structure = null;
    const getStructure = ()=>{
        if (structure === null) {
            throw new Error('Expected structure');
        }
        return structure;
    };
    return {
        getStructureOrNull: ()=>{
            return structure;
        },
        getStructure,
        setStructure: (value)=>{
            structure = value;
        },
        getFlacStructure: ()=>{
            const struc = getStructure();
            if (struc.type !== 'flac') {
                throw new Error('Invalid structure type');
            }
            return struc;
        },
        getIsoStructure: ()=>{
            const struc = getStructure();
            if (struc.type !== 'iso-base-media') {
                throw new Error('Invalid structure type');
            }
            return struc;
        },
        getMp3Structure: ()=>{
            const struc = getStructure();
            if (struc.type !== 'mp3') {
                throw new Error('Invalid structure type');
            }
            return struc;
        },
        getM3uStructure: ()=>{
            const struc = getStructure();
            if (struc.type !== 'm3u') {
                throw new Error('Invalid structure type');
            }
            return struc;
        },
        getRiffStructure: ()=>{
            const struc = getStructure();
            if (struc.type !== 'riff') {
                throw new Error('Invalid structure type');
            }
            return struc;
        },
        getTsStructure: ()=>{
            const struc = getStructure();
            if (struc.type !== 'transport-stream') {
                throw new Error('Invalid structure type');
            }
            return struc;
        },
        getWavStructure: ()=>{
            const struc = getStructure();
            if (struc.type !== 'wav') {
                throw new Error('Invalid structure type');
            }
            return struc;
        },
        getMatroskaStructure: ()=>{
            const struc = getStructure();
            if (struc.type !== 'matroska') {
                throw new Error('Invalid structure type');
            }
            return struc;
        }
    };
};
exports.structureState = structureState;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-moov-atom.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMoovAtom = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const can_skip_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/can-skip-tracks.js [app-route] (ecmascript)");
const has_tracks_section_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/has-tracks-section.js [app-route] (ecmascript)");
const structure_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/structure.js [app-route] (ecmascript)");
const process_box_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/process-box.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const getMoovAtom = async ({ endOfMdat, state })=>{
    var _a;
    const headerSegment = (_a = state.m3uPlaylistContext) === null || _a === void 0 ? void 0 : _a.mp4HeaderSegment;
    if (headerSegment) {
        const segment = (0, traversal_1.getMoovFromFromIsoStructure)(headerSegment);
        if (!segment) {
            throw new Error('No moov box found in header segment');
        }
        return segment;
    }
    const start = Date.now();
    log_1.Log.verbose(state.logLevel, 'Starting second fetch to get moov atom');
    const { reader } = await state.readerInterface.read({
        src: state.src,
        range: endOfMdat,
        controller: state.controller,
        logLevel: state.logLevel,
        prefetchCache: state.prefetchCache
    });
    const onAudioTrack = state.onAudioTrack ? async ({ track, container })=>{
        await (0, register_track_1.registerAudioTrack)({
            track,
            container,
            logLevel: state.logLevel,
            onAudioTrack: state.onAudioTrack,
            registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,
            tracks: state.callbacks.tracks
        });
        return null;
    } : null;
    const onVideoTrack = state.onVideoTrack ? async ({ track, container })=>{
        await (0, register_track_1.registerVideoTrack)({
            track,
            container,
            logLevel: state.logLevel,
            onVideoTrack: state.onVideoTrack,
            registerVideoSampleCallback: state.callbacks.registerVideoSampleCallback,
            tracks: state.callbacks.tracks
        });
        return null;
    } : null;
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: new Uint8Array([]),
        maxBytes: state.contentLength - endOfMdat,
        logLevel: 'error'
    });
    while(true){
        const result = await reader.reader.read();
        if (result.value) {
            iterator.addData(result.value);
        }
        if (result.done) {
            break;
        }
    }
    const boxes = [];
    const canSkipTracksState = (0, can_skip_tracks_1.makeCanSkipTracksState)({
        hasAudioTrackHandlers: false,
        fields: {
            slowStructure: true
        },
        hasVideoTrackHandlers: false,
        structure: (0, structure_1.structureState)()
    });
    const tracksState = (0, has_tracks_section_1.makeTracksSectionState)(canSkipTracksState, state.src);
    while(true){
        const box = await (0, process_box_1.processBox)({
            iterator,
            logLevel: state.logLevel,
            onlyIfMoovAtomExpected: {
                tracks: tracksState,
                isoState: null,
                movieTimeScaleState: state.iso.movieTimeScale,
                onAudioTrack,
                onVideoTrack,
                registerVideoSampleCallback: ()=>Promise.resolve(),
                registerAudioSampleCallback: ()=>Promise.resolve()
            },
            onlyIfMdatAtomExpected: null,
            contentLength: state.contentLength - endOfMdat
        });
        if (box.type === 'box') {
            boxes.push(box.box);
        }
        if (iterator.counter.getOffset() + endOfMdat > state.contentLength) {
            throw new Error('Read past end of file');
        }
        if (iterator.counter.getOffset() + endOfMdat === state.contentLength) {
            break;
        }
    }
    const moov = boxes.find((b)=>b.type === 'moov-box');
    if (!moov) {
        throw new Error('No moov box found');
    }
    log_1.Log.verbose(state.logLevel, `Finished fetching moov atom in ${Date.now() - start}ms`);
    return moov;
};
exports.getMoovAtom = getMoovAtom;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mdat/postprocess-bytes.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

// Addressing the issue of audio that is stored in big-endian format!
// If a "twos" atom is present, that is the case.
// The samples are stored internally in small chunks, like 4 bytes
// but WebCodecs does not accept such small chunks.
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.postprocessBytes = void 0;
// When entering this function, they are already concatenated, but in litte endian order.
// This function reverses the bytes in each chunk, so that they are in big-endian order.
const postprocessBytes = ({ bytes, bigEndian, chunkSize })=>{
    if (!bigEndian) {
        return bytes;
    }
    if (chunkSize === null) {
        return bytes;
    }
    const newBuffer = new Uint8Array(bytes);
    for(let i = 0; i < newBuffer.length; i += chunkSize){
        const slice = newBuffer.slice(i, i + chunkSize);
        slice.reverse();
        newBuffer.set(slice, i);
    }
    return newBuffer;
};
exports.postprocessBytes = postprocessBytes;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mdat/mdat.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMdatSection = void 0;
const convert_audio_or_video_sample_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/convert-audio-or-video-sample.js [app-route] (ecmascript)");
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const skip_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/skip.js [app-route] (ecmascript)");
const cached_sample_positions_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/cached-sample-positions.js [app-route] (ecmascript)");
const last_moof_box_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/last-moof-box.js [app-route] (ecmascript)");
const may_skip_video_data_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/may-skip-video-data.js [app-route] (ecmascript)");
const video_section_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/video-section.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const get_moov_atom_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-moov-atom.js [app-route] (ecmascript)");
const postprocess_bytes_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mdat/postprocess-bytes.js [app-route] (ecmascript)");
const parseMdatSection = async (state)=>{
    const mediaSection = (0, video_section_1.getCurrentMediaSection)({
        offset: state.iterator.counter.getOffset(),
        mediaSections: state.mediaSection.getMediaSections()
    });
    if (!mediaSection) {
        throw new Error('No video section defined');
    }
    const endOfMdat = mediaSection.size + mediaSection.start;
    // don't need mdat at all, can skip
    if ((0, may_skip_video_data_1.maySkipVideoData)({
        state
    })) {
        const mfra = state.iso.mfra.getIfAlreadyLoaded();
        if (mfra) {
            const lastMoof = (0, last_moof_box_1.getLastMoofBox)(mfra);
            if (lastMoof && lastMoof > endOfMdat) {
                log_1.Log.verbose(state.logLevel, 'Skipping to last moof', lastMoof);
                return (0, skip_1.makeSkip)(lastMoof);
            }
        }
        return (0, skip_1.makeSkip)(endOfMdat);
    }
    // if we only need the first and last sample, we may skip over the samples in the middle
    // this logic skips the samples in the middle for a fragmented mp4
    if ((0, may_skip_video_data_1.maySkipOverSamplesInTheMiddle)({
        state
    })) {
        const mfra = state.iso.mfra.getIfAlreadyLoaded();
        if (mfra) {
            const lastMoof = (0, last_moof_box_1.getLastMoofBox)(mfra);
            // we require that all moof boxes of both tracks have been processed, for correct duration calculation
            const firstMax = (0, last_moof_box_1.getMaxFirstMoofOffset)(mfra);
            const mediaSectionsBiggerThanMoof = state.mediaSection.getMediaSections().filter((m)=>m.start > firstMax).length;
            if (mediaSectionsBiggerThanMoof > 1 && lastMoof && lastMoof > endOfMdat) {
                log_1.Log.verbose(state.logLevel, 'Skipping to last moof because only first and last samples are needed');
                return (0, skip_1.makeSkip)(lastMoof);
            }
        }
    }
    const alreadyHasMoov = (0, get_tracks_1.getHasTracks)(state, true);
    if (!alreadyHasMoov) {
        const moov = await (0, get_moov_atom_1.getMoovAtom)({
            endOfMdat,
            state
        });
        const tracksFromMoov = (0, get_tracks_1.getTracksFromMoovBox)(moov);
        state.iso.moov.setMoovBox({
            moovBox: moov,
            precomputed: false
        });
        const existingTracks = state.callbacks.tracks.getTracks();
        for (const trackFromMoov of tracksFromMoov){
            if (existingTracks.find((t)=>t.trackId === trackFromMoov.trackId)) {
                continue;
            }
            if (trackFromMoov.type === 'other') {
                continue;
            }
            state.callbacks.tracks.addTrack(trackFromMoov);
        }
        state.callbacks.tracks.setIsDone(state.logLevel);
        state.structure.getIsoStructure().boxes.push(moov);
        return (0, exports.parseMdatSection)(state);
    }
    const tracks = state.callbacks.tracks.getTracks();
    if (!state.iso.flatSamples.getSamples(mediaSection.start)) {
        const samplePosition = (0, cached_sample_positions_1.calculateSamplePositions)({
            state,
            mediaSectionStart: mediaSection.start,
            trackIds: tracks.map((t)=>t.trackId)
        });
        state.iso.flatSamples.setSamples(mediaSection.start, samplePosition);
    }
    const samplePositions = state.iso.flatSamples.getSamples(mediaSection.start);
    const sampleIndices = state.iso.flatSamples.getCurrentSampleIndices(mediaSection.start);
    const nextSampleArray = (0, cached_sample_positions_1.getSampleWithLowestDts)(samplePositions, sampleIndices);
    if (nextSampleArray.length === 0) {
        log_1.Log.verbose(state.logLevel, 'Iterated over all samples.', endOfMdat);
        return (0, skip_1.makeSkip)(endOfMdat);
    }
    const exactMatch = nextSampleArray.find((s)=>s.samplePosition.offset === state.iterator.counter.getOffset());
    const nextSample = exactMatch !== null && exactMatch !== void 0 ? exactMatch : nextSampleArray.sort((a, b)=>a.samplePosition.offset - b.samplePosition.offset)[0];
    if (nextSample.samplePosition.offset !== state.iterator.counter.getOffset()) {
        return (0, skip_1.makeSkip)(nextSample.samplePosition.offset);
    }
    // Corrupt file: Sample is beyond the end of the file. Don't process it.
    if (nextSample.samplePosition.offset + nextSample.samplePosition.size > state.contentLength) {
        log_1.Log.verbose(state.logLevel, "Sample is beyond the end of the file. Don't process it.", nextSample.samplePosition.offset + nextSample.samplePosition.size, endOfMdat);
        return (0, skip_1.makeSkip)(endOfMdat);
    }
    const { iterator } = state;
    // Need to fetch more data
    if (iterator.bytesRemaining() < nextSample.samplePosition.size) {
        return (0, skip_1.makeFetchMoreData)(nextSample.samplePosition.size - iterator.bytesRemaining());
    }
    const { timestamp: rawCts, decodingTimestamp: rawDts, duration, isKeyframe, offset, bigEndian, chunkSize } = nextSample.samplePosition;
    const track = tracks.find((t)=>t.trackId === nextSample.trackId);
    const { originalTimescale, startInSeconds, trackMediaTimeOffsetInTrackTimescale, timescale: trackTimescale } = track;
    const cts = rawCts + startInSeconds * originalTimescale - trackMediaTimeOffsetInTrackTimescale / trackTimescale * webcodecs_timescale_1.WEBCODECS_TIMESCALE;
    const dts = rawDts + startInSeconds * originalTimescale - trackMediaTimeOffsetInTrackTimescale / trackTimescale * webcodecs_timescale_1.WEBCODECS_TIMESCALE;
    const bytes = (0, postprocess_bytes_1.postprocessBytes)({
        bytes: iterator.getSlice(nextSample.samplePosition.size),
        bigEndian,
        chunkSize
    });
    if (track.type === 'audio') {
        const audioSample = (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
            sample: {
                data: bytes,
                timestamp: cts,
                duration,
                decodingTimestamp: dts,
                type: isKeyframe ? 'key' : 'delta',
                offset
            },
            timescale: originalTimescale
        });
        await state.callbacks.onAudioSample({
            audioSample,
            trackId: track.trackId
        });
    }
    if (track.type === 'video') {
        // https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/sei_checkpoint.mp4
        // Position in file 0x0001aba615
        // https://github.com/remotion-dev/remotion/issues/4680
        // In Chrome, we may not treat recovery points as keyframes
        // otherwise "a keyframe is required after flushing"
        const nalUnitType = bytes[4] & 0b00011111;
        let isRecoveryPoint = false;
        // SEI (Supplemental enhancement information)
        if (nalUnitType === 6) {
            const seiType = bytes[5];
            isRecoveryPoint = seiType === 6;
        }
        const videoSample = (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
            sample: {
                data: bytes,
                timestamp: cts,
                duration,
                decodingTimestamp: dts,
                type: isKeyframe && !isRecoveryPoint ? 'key' : 'delta',
                offset
            },
            timescale: originalTimescale
        });
        await state.callbacks.onVideoSample({
            videoSample,
            trackId: track.trackId
        });
    }
    state.iso.flatSamples.setCurrentSampleIndex(mediaSection.start, nextSample.trackId, nextSample.index + 1);
    return null;
};
exports.parseMdatSection = parseMdatSection;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/parse-boxes.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseIsoBaseMedia = void 0;
const mdat_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mdat/mdat.js [app-route] (ecmascript)");
const process_box_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/process-box.js [app-route] (ecmascript)");
const parseIsoBaseMedia = async (state)=>{
    const mediaSectionState = state.mediaSection.isCurrentByteInMediaSection(state.iterator);
    if (mediaSectionState === 'in-section') {
        const skipTo = await (0, mdat_1.parseMdatSection)(state);
        return skipTo;
    }
    const result = await (0, process_box_1.processBox)({
        iterator: state.iterator,
        logLevel: state.logLevel,
        onlyIfMoovAtomExpected: {
            tracks: state.callbacks.tracks,
            isoState: state.iso,
            movieTimeScaleState: state.iso.movieTimeScale,
            onAudioTrack: state.onAudioTrack,
            onVideoTrack: state.onVideoTrack,
            registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,
            registerVideoSampleCallback: state.callbacks.registerVideoSampleCallback
        },
        onlyIfMdatAtomExpected: {
            mediaSectionState: state.mediaSection
        },
        contentLength: state.contentLength
    });
    if (result.type === 'fetch-more-data') {
        return result.bytesNeeded;
    }
    if (result.type === 'box') {
        state.structure.getIsoStructure().boxes.push(result.box);
    }
    return null;
};
exports.parseIsoBaseMedia = parseIsoBaseMedia;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-stream-inf.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseStreamInf = void 0;
exports.splitRespectingQuotes = splitRespectingQuotes;
function splitRespectingQuotes(input) {
    const result = [];
    let currentPart = '';
    let insideQuote = false;
    for(let i = 0; i < input.length; i++){
        const char = input[i];
        // Toggle flag when encountering a quote character.
        if (char === '"') {
            insideQuote = !insideQuote;
            currentPart += char;
        } else if (char === ',' && !insideQuote) {
            result.push(currentPart);
            currentPart = '';
        } else {
            currentPart += char;
        }
    }
    // Push the last token, if any.
    if (currentPart) {
        result.push(currentPart);
    }
    return result;
}
const parseStreamInf = (str)=>{
    const quotes = splitRespectingQuotes(str);
    const map = {};
    for (const quote of quotes){
        const firstColon = quote.indexOf('=');
        const key = firstColon === -1 ? quote : quote.slice(0, firstColon);
        const value = firstColon === -1 ? null : quote.slice(firstColon + 1);
        if (value === null) {
            throw new Error('Value is null');
        }
        const actualValue = (value === null || value === void 0 ? void 0 : value.startsWith('"')) && (value === null || value === void 0 ? void 0 : value.endsWith('"')) ? value.slice(1, -1) : value;
        map[key] = actualValue;
    }
    return {
        type: 'm3u-stream-info',
        averageBandwidthInBitsPerSec: map['AVERAGE-BANDWIDTH'] ? parseInt(map['AVERAGE-BANDWIDTH'], 10) : null,
        bandwidthInBitsPerSec: map.BANDWIDTH ? parseInt(map.BANDWIDTH, 10) : null,
        codecs: map.CODECS ? map.CODECS.split(',') : null,
        dimensions: map.RESOLUTION ? {
            width: parseInt(map.RESOLUTION.split('x')[0], 10),
            height: parseInt(map.RESOLUTION.split('x')[1], 10)
        } : null,
        audio: map.AUDIO || null
    };
};
exports.parseStreamInf = parseStreamInf;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-m3u-media-directive.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseM3uMediaDirective = exports.parseM3uKeyValue = void 0;
const parse_stream_inf_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-stream-inf.js [app-route] (ecmascript)");
const parseM3uKeyValue = (str)=>{
    const quotes = (0, parse_stream_inf_1.splitRespectingQuotes)(str);
    const map = {};
    for (const quote of quotes){
        const firstColon = quote.indexOf('=');
        const key = firstColon === -1 ? quote : quote.slice(0, firstColon);
        const value = firstColon === -1 ? null : quote.slice(firstColon + 1);
        if (value === null) {
            throw new Error('Value is null');
        }
        const actualValue = (value === null || value === void 0 ? void 0 : value.startsWith('"')) && (value === null || value === void 0 ? void 0 : value.endsWith('"')) ? value.slice(1, -1) : value;
        map[key] = actualValue;
    }
    return map;
};
exports.parseM3uKeyValue = parseM3uKeyValue;
const parseM3uMediaDirective = (str)=>{
    const map = (0, exports.parseM3uKeyValue)(str);
    return {
        type: 'm3u-media-info',
        autoselect: map.AUTOSELECT === 'YES',
        channels: map.CHANNELS ? parseInt(map.CHANNELS, 10) : null,
        default: map.DEFAULT === 'YES',
        groupId: map['GROUP-ID'],
        language: map.LANGUAGE || null,
        name: map.NAME || null,
        uri: map.URI,
        mediaType: map.TYPE || null
    };
};
exports.parseM3uMediaDirective = parseM3uMediaDirective;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-directive.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseM3uDirective = void 0;
const parse_m3u_media_directive_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-m3u-media-directive.js [app-route] (ecmascript)");
const parse_stream_inf_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-stream-inf.js [app-route] (ecmascript)");
const parseM3uDirective = (str)=>{
    const firstColon = str.indexOf(':');
    const directive = (firstColon === -1 ? str : str.slice(0, firstColon)).trim();
    const value = firstColon === -1 ? null : str.slice(firstColon + 1);
    if (directive === '#EXT-X-VERSION') {
        if (!value) {
            throw new Error('EXT-X-VERSION directive must have a value');
        }
        return {
            type: 'm3u-version',
            version: value
        };
    }
    if (directive === '#EXT-X-INDEPENDENT-SEGMENTS') {
        return {
            type: 'm3u-independent-segments'
        };
    }
    if (directive === '#EXT-X-MEDIA') {
        if (!value) {
            throw new Error('EXT-X-MEDIA directive must have a value');
        }
        const parsed = (0, parse_m3u_media_directive_1.parseM3uMediaDirective)(value);
        return parsed;
    }
    if (directive === '#EXT-X-TARGETDURATION') {
        if (!value) {
            throw new Error('EXT-X-TARGETDURATION directive must have a value');
        }
        return {
            type: 'm3u-target-duration',
            duration: parseFloat(value)
        };
    }
    if (directive === '#EXTINF') {
        if (!value) {
            throw new Error('EXTINF has no value');
        }
        return {
            type: 'm3u-extinf',
            value: parseFloat(value)
        };
    }
    if (directive === '#EXT-X-ENDLIST') {
        return {
            type: 'm3u-endlist'
        };
    }
    if (directive === '#EXT-X-PLAYLIST-TYPE') {
        if (!value) {
            throw new Error('#EXT-X-PLAYLIST-TYPE. directive must have a value');
        }
        return {
            type: 'm3u-playlist-type',
            playlistType: value
        };
    }
    if (directive === '#EXT-X-MEDIA-SEQUENCE') {
        if (!value) {
            throw new Error('#EXT-X-MEDIA-SEQUENCE directive must have a value');
        }
        return {
            type: 'm3u-media-sequence',
            value: Number(value)
        };
    }
    if (directive === '#EXT-X-DISCONTINUITY-SEQUENCE') {
        if (!value) {
            throw new Error('#EXT-X-DISCONTINUITY-SEQUENCE directive must have a value');
        }
        return {
            type: 'm3u-discontinuity-sequence',
            value: Number(value)
        };
    }
    if (directive === '#EXT-X-STREAM-INF') {
        if (!value) {
            throw new Error('EXT-X-STREAM-INF directive must have a value');
        }
        const res = (0, parse_stream_inf_1.parseStreamInf)(value);
        return res;
    }
    if (directive === '#EXT-X-I-FRAME-STREAM-INF') {
        return {
            type: 'm3u-i-frame-stream-info'
        };
    }
    if (directive === '#EXT-X-ALLOW-CACHE') {
        if (!value) {
            throw new Error('#EXT-X-ALLOW-CACHE directive must have a value');
        }
        return {
            type: 'm3u-allow-cache',
            allowsCache: value === 'YES'
        };
    }
    if (directive === '#EXT-X-MAP') {
        if (!value) {
            throw new Error('#EXT-X-MAP directive must have a value');
        }
        const p = (0, parse_m3u_media_directive_1.parseM3uKeyValue)(value);
        if (!p.URI) {
            throw new Error('EXT-X-MAP directive must have a URI');
        }
        return {
            type: 'm3u-map',
            value: p.URI
        };
    }
    if (directive === '#EXT-X-PROGRAM-DATE-TIME') {
        if (!value) {
            throw new Error('#EXT-X-PROGRAM-DATE-TIME directive must have a value');
        }
        // Store the raw ISO 8601 date-time string without validation.
        // This directive associates media segments with absolute dates but
        // doesn't affect parsing of tracks, dimensions, or other metadata.
        return {
            type: 'm3u-program-date-time',
            dateTime: value
        };
    }
    throw new Error(`Unknown directive ${directive}. Value: ${value}`);
};
exports.parseM3uDirective = parseM3uDirective;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-m3u8-text.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseM3u8Text = void 0;
const parse_directive_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-directive.js [app-route] (ecmascript)");
const parseM3u8Text = (line, boxes)=>{
    if (line === '#EXTM3U') {
        boxes.push({
            type: 'm3u-header'
        });
        return;
    }
    if (line.startsWith('#')) {
        boxes.push((0, parse_directive_1.parseM3uDirective)(line));
        return;
    }
    if (line.trim()) {
        boxes.push({
            type: 'm3u-text-value',
            value: line
        });
    }
};
exports.parseM3u8Text = parseM3u8Text;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/fetch-m3u8-stream.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.fetchM3u8Stream = void 0;
const parse_m3u8_text_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-m3u8-text.js [app-route] (ecmascript)");
const fetchM3u8Stream = async ({ url, readerInterface })=>{
    const text = await readerInterface.readWholeAsText(url);
    const lines = text.split('\n');
    const boxes = [];
    for (const line of lines){
        (0, parse_m3u8_text_1.parseM3u8Text)(line.trim(), boxes);
    }
    return boxes;
};
exports.fetchM3u8Stream = fetchM3u8Stream;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/select-stream.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.defaultSelectM3uStreamFn = exports.selectStream = exports.defaultSelectM3uAssociatedPlaylists = exports.selectAssociatedPlaylists = void 0;
const selectAssociatedPlaylists = async ({ playlists, fn, skipAudioTracks })=>{
    if (playlists.length < 1) {
        return Promise.resolve([]);
    }
    const streams = await fn({
        associatedPlaylists: playlists
    });
    if (!Array.isArray(streams)) {
        throw new Error('Expected an array of associated playlists');
    }
    const selectedStreams = [];
    for (const stream of streams){
        if (stream.isAudio && skipAudioTracks) {
            continue;
        }
        if (!playlists.find((playlist)=>playlist.src === stream.src)) {
            throw new Error(`The associated playlist ${JSON.stringify(streams)} cannot be selected because it was not in the list of selectable playlists`);
        }
        selectedStreams.push(stream);
    }
    return selectedStreams;
};
exports.selectAssociatedPlaylists = selectAssociatedPlaylists;
const defaultSelectM3uAssociatedPlaylists = ({ associatedPlaylists })=>{
    if (associatedPlaylists.length === 1) {
        return associatedPlaylists;
    }
    return associatedPlaylists.filter((playlist)=>playlist.default);
};
exports.defaultSelectM3uAssociatedPlaylists = defaultSelectM3uAssociatedPlaylists;
const selectStream = async ({ streams, fn })=>{
    if (streams.length < 1) {
        throw new Error('No streams found');
    }
    const selectedStreamId = await fn({
        streams
    });
    const selectedStream = streams.find((stream)=>stream.id === selectedStreamId);
    if (!selectedStream) {
        throw new Error(`No stream with the id ${selectedStreamId} found`);
    }
    return Promise.resolve(selectedStream);
};
exports.selectStream = selectStream;
const defaultSelectM3uStreamFn = ({ streams })=>{
    return Promise.resolve(streams[0].id);
};
exports.defaultSelectM3uStreamFn = defaultSelectM3uStreamFn;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/after-manifest-fetch.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.afterManifestFetch = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const fetch_m3u8_stream_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/fetch-m3u8-stream.js [app-route] (ecmascript)");
const get_streams_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-streams.js [app-route] (ecmascript)");
const select_stream_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/select-stream.js [app-route] (ecmascript)");
const afterManifestFetch = async ({ structure, m3uState, src, selectM3uStreamFn, logLevel, selectAssociatedPlaylistsFn, readerInterface, onAudioTrack, canSkipTracks })=>{
    const independentSegments = (0, get_streams_1.isIndependentSegments)(structure);
    const streams = (0, get_streams_1.getM3uStreams)({
        structure,
        originalSrc: src,
        readerInterface
    });
    // Handle single media playlists (not master playlists):
    // 1. If !independentSegments: Old-style single playlist without segment independence
    // 2. If streams === null: Single media playlist (has EXT-X-INDEPENDENT-SEGMENTS but no EXT-X-STREAM-INF)
    // Both cases should iterate over the current URL as the media playlist
    if (!independentSegments || streams === null) {
        if (!src) {
            throw new Error('No src');
        }
        m3uState.setSelectedMainPlaylist({
            type: 'initial-url',
            url: src
        });
        return m3uState.setReadyToIterateOverM3u();
    }
    const selectedPlaylist = await (0, select_stream_1.selectStream)({
        streams,
        fn: selectM3uStreamFn
    });
    if (!selectedPlaylist.dimensions) {
        throw new Error('Stream does not have a resolution');
    }
    m3uState.setSelectedMainPlaylist({
        type: 'selected-stream',
        stream: selectedPlaylist
    });
    const skipAudioTracks = onAudioTrack === null && canSkipTracks.doFieldsNeedTracks() === false;
    const associatedPlaylists = await (0, select_stream_1.selectAssociatedPlaylists)({
        playlists: selectedPlaylist.associatedPlaylists,
        fn: selectAssociatedPlaylistsFn,
        skipAudioTracks
    });
    m3uState.setAssociatedPlaylists(associatedPlaylists);
    const playlistUrls = [
        selectedPlaylist.src,
        ...associatedPlaylists.map((p)=>p.src)
    ];
    const struc = await Promise.all(playlistUrls.map(async (url)=>{
        log_1.Log.verbose(logLevel, `Fetching playlist ${url}`);
        const boxes = await (0, fetch_m3u8_stream_1.fetchM3u8Stream)({
            url,
            readerInterface
        });
        return {
            type: 'm3u-playlist',
            boxes,
            src: url
        };
    }));
    structure.boxes.push(...struc);
    m3uState.setReadyToIterateOverM3u();
};
exports.afterManifestFetch = afterManifestFetch;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-m3u-manifest.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseM3uManifest = void 0;
const parse_m3u8_text_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-m3u8-text.js [app-route] (ecmascript)");
const parseM3uManifest = ({ iterator, structure, contentLength })=>{
    const start = iterator.startCheckpoint();
    const line = iterator.readUntilLineEnd();
    if (iterator.counter.getOffset() > contentLength) {
        throw new Error('Unexpected end of file');
    }
    if (line === null) {
        start.returnToCheckpoint();
        return Promise.resolve(null);
    }
    (0, parse_m3u8_text_1.parseM3u8Text)(line.trim(), structure.boxes);
    return Promise.resolve(null);
};
exports.parseM3uManifest = parseM3uManifest;
}),
"[project]/node_modules/@remotion/media-parser/dist/forward-controller-pause-resume-abort.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.forwardMediaParserControllerPauseResume = void 0;
const forwardMediaParserControllerPauseResume = ({ parentController, childController })=>{
    const onAbort = ({ detail })=>{
        childController.abort(detail.reason);
    };
    const onResume = ()=>{
        childController.resume();
    };
    const onPause = ()=>{
        childController.pause();
    };
    parentController.addEventListener('abort', onAbort);
    parentController.addEventListener('resume', onResume);
    parentController.addEventListener('pause', onPause);
    return {
        cleanup: ()=>{
            parentController.removeEventListener('abort', onAbort);
            parentController.removeEventListener('resume', onResume);
            parentController.removeEventListener('pause', onPause);
        }
    };
};
exports.forwardMediaParserControllerPauseResume = forwardMediaParserControllerPauseResume;
}),
"[project]/node_modules/@remotion/media-parser/dist/readers/fetch/get-body-and-reader.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getLengthAndReader = void 0;
const getLengthAndReader = async ({ canLiveWithoutContentLength, res, ownController, requestedWithoutRange })=>{
    const length = res.headers.get('content-length');
    const contentLength = length === null ? null : parseInt(length, 10);
    if (requestedWithoutRange || canLiveWithoutContentLength && contentLength === null) {
        const buffer = await res.arrayBuffer();
        const encoded = new Uint8Array(buffer);
        let streamCancelled = false;
        const stream = new ReadableStream({
            start (controller) {
                if (ownController.signal.aborted) {
                    return;
                }
                if (streamCancelled) {
                    return;
                }
                try {
                    controller.enqueue(encoded);
                    controller.close();
                } catch (_a) {
                // sometimes on windows after aborting on node 16		: Invalid state: ReadableStreamDefaultController is not in a state where chunk can be enqueued
                }
            },
            cancel () {
                streamCancelled = true;
            }
        });
        return {
            contentLength: encoded.byteLength,
            reader: {
                reader: stream.getReader(),
                abort: ()=>{
                    ownController.abort();
                    return Promise.resolve();
                }
            },
            needsContentRange: false
        };
    }
    if (!res.body) {
        throw new Error('No body');
    }
    const reader = res.body.getReader();
    return {
        reader: {
            reader,
            abort: ()=>{
                ownController.abort();
                return Promise.resolve();
            }
        },
        contentLength,
        needsContentRange: true
    };
};
exports.getLengthAndReader = getLengthAndReader;
}),
"[project]/node_modules/@remotion/media-parser/dist/readers/fetch/resolve-url.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.resolveUrl = void 0;
const resolveUrl = (src)=>{
    try {
        const resolvedUrl = ("TURBOPACK compile-time falsy", 0) ? "TURBOPACK unreachable" : new URL(src);
        return resolvedUrl;
    } catch (_a) {
        return src;
    }
};
exports.resolveUrl = resolveUrl;
}),
"[project]/node_modules/@remotion/media-parser/dist/readers/from-fetch.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.fetchReader = exports.fetchCreateAdjacentFileSource = exports.fetchReadWholeAsText = exports.fetchPreload = exports.fetchReadContent = exports.makeFetchRequest = void 0;
exports.parseContentRange = parseContentRange;
const errors_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/errors.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const get_body_and_reader_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/readers/fetch/get-body-and-reader.js [app-route] (ecmascript)");
const resolve_url_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/readers/fetch/resolve-url.js [app-route] (ecmascript)");
/**
 * Parse Content-Range header.
 * From: https://github.com/gregberge/content-range/blob/main/src/index.ts
 */ function parseContentRange(input) {
    const matches = input.match(/^(\w+) ((\d+)-(\d+)|\*)\/(\d+|\*)$/);
    if (!matches) return null;
    const [, unit, , start, end, size] = matches;
    const range = {
        unit,
        start: start != null ? Number(start) : null,
        end: end != null ? Number(end) : null,
        size: size === '*' ? null : Number(size)
    };
    if (range.start === null && range.end === null && range.size === null) {
        return null;
    }
    return range;
}
const validateContentRangeAndDetectIfSupported = ({ requestedRange, parsedContentRange, statusCode })=>{
    if (statusCode === 206) {
        return {
            supportsContentRange: true
        };
    }
    if (typeof requestedRange === 'number' && (parsedContentRange === null || parsedContentRange === void 0 ? void 0 : parsedContentRange.start) !== requestedRange) {
        if (requestedRange === 0) {
            return {
                supportsContentRange: false
            };
        }
        throw new Error(`Range header (${requestedRange}) does not match content-range header (${parsedContentRange === null || parsedContentRange === void 0 ? void 0 : parsedContentRange.start})`);
    }
    if (requestedRange !== null && typeof requestedRange !== 'number' && ((parsedContentRange === null || parsedContentRange === void 0 ? void 0 : parsedContentRange.start) !== requestedRange[0] || (parsedContentRange === null || parsedContentRange === void 0 ? void 0 : parsedContentRange.end) !== requestedRange[1])) {
        throw new Error(`Range header (${requestedRange}) does not match content-range header (${parsedContentRange === null || parsedContentRange === void 0 ? void 0 : parsedContentRange.start})`);
    }
    return {
        supportsContentRange: true
    };
};
const makeFetchRequest = async ({ range, src, controller })=>{
    var _a;
    const resolvedUrl = (0, resolve_url_1.resolveUrl)(src);
    const resolvedUrlString = resolvedUrl.toString();
    if (!resolvedUrlString.startsWith('https://') && !resolvedUrlString.startsWith('blob:') && !resolvedUrlString.startsWith('data:') && !resolvedUrlString.startsWith('http://')) {
        return Promise.reject(new Error(`${resolvedUrlString} is not a URL - needs to start with http:// or https:// or blob:. If you want to read a local file, pass \`reader: nodeReader\` to parseMedia().`));
    }
    const ownController = new AbortController();
    const cache = typeof navigator !== 'undefined' && navigator.userAgent.includes('Cloudflare-Workers') ? undefined : 'no-store';
    const requestedRange = range === null ? 0 : range;
    const asString = typeof resolvedUrl === 'string' ? resolvedUrl : resolvedUrl.pathname;
    const requestWithoutRange = asString.endsWith('.m3u8');
    const canLiveWithoutContentLength = asString.endsWith('.m3u8') || asString.endsWith('.ts');
    const headers = requestedRange === 0 && requestWithoutRange ? {} : typeof requestedRange === 'number' ? {
        Range: `bytes=${requestedRange}-`
    } : {
        Range: `bytes=${`${requestedRange[0]}-${requestedRange[1]}`}`
    };
    const res = await fetch(resolvedUrl, {
        headers,
        signal: ownController.signal,
        cache
    });
    const contentRange = res.headers.get('content-range');
    const parsedContentRange = contentRange ? parseContentRange(contentRange) : null;
    if (!res.ok) {
        throw new Error(`Server returned status code ${res.status} for ${resolvedUrl} and range ${requestedRange}`);
    }
    const { supportsContentRange } = validateContentRangeAndDetectIfSupported({
        requestedRange,
        parsedContentRange,
        statusCode: res.status
    });
    if (controller) {
        controller._internals.signal.addEventListener('abort', ()=>{
            ownController.abort(new errors_1.MediaParserAbortError('Aborted by user'));
        }, {
            once: true
        });
    }
    const contentDisposition = res.headers.get('content-disposition');
    const name = (_a = contentDisposition === null || contentDisposition === void 0 ? void 0 : contentDisposition.match(/filename="([^"]+)"/)) === null || _a === void 0 ? void 0 : _a[1];
    const { contentLength, needsContentRange, reader } = await (0, get_body_and_reader_1.getLengthAndReader)({
        canLiveWithoutContentLength,
        res,
        ownController,
        requestedWithoutRange: requestWithoutRange
    });
    const contentType = res.headers.get('content-type');
    return {
        contentLength,
        needsContentRange,
        reader,
        name,
        contentType,
        supportsContentRange
    };
};
exports.makeFetchRequest = makeFetchRequest;
const cacheKey = ({ src, range })=>{
    return `${src}-${JSON.stringify(range)}`;
};
const makeFetchRequestOrGetCached = ({ range, src, controller, logLevel, prefetchCache })=>{
    const key = cacheKey({
        src,
        range
    });
    const cached = prefetchCache.get(key);
    if (cached) {
        log_1.Log.verbose(logLevel, `Reading from preload cache for ${key}`);
        return cached;
    }
    log_1.Log.verbose(logLevel, `Fetching ${key}`);
    const result = (0, exports.makeFetchRequest)({
        range,
        src,
        controller
    });
    prefetchCache.set(key, result);
    return result;
};
const fetchReadContent = async ({ src, range, controller, logLevel, prefetchCache })=>{
    if (typeof src !== 'string' && src instanceof URL === false) {
        throw new Error('src must be a string when using `fetchReader`');
    }
    const fallbackName = src.toString().split('/').pop();
    const res = makeFetchRequestOrGetCached({
        range,
        src,
        controller,
        logLevel,
        prefetchCache
    });
    const key = cacheKey({
        src,
        range
    });
    prefetchCache.delete(key);
    const { reader, contentLength, needsContentRange, name, supportsContentRange, contentType } = await res;
    if (controller) {
        controller._internals.signal.addEventListener('abort', ()=>{
            reader.reader.cancel().catch(()=>{
            // Prevent unhandled rejection in Firefox
            });
        }, {
            once: true
        });
    }
    return {
        reader,
        contentLength,
        contentType,
        name: name !== null && name !== void 0 ? name : fallbackName,
        supportsContentRange,
        needsContentRange
    };
};
exports.fetchReadContent = fetchReadContent;
const fetchPreload = ({ src, range, logLevel, prefetchCache })=>{
    if (typeof src !== 'string' && src instanceof URL === false) {
        throw new Error('src must be a string when using `fetchReader`');
    }
    const key = cacheKey({
        src,
        range
    });
    if (prefetchCache.has(key)) {
        return prefetchCache.get(key);
    }
    makeFetchRequestOrGetCached({
        range,
        src,
        controller: null,
        logLevel,
        prefetchCache
    });
};
exports.fetchPreload = fetchPreload;
const fetchReadWholeAsText = async (src)=>{
    if (typeof src !== 'string' && src instanceof URL === false) {
        throw new Error('src must be a string when using `fetchReader`');
    }
    const res = await fetch(src);
    if (!res.ok) {
        throw new Error(`Failed to fetch ${src} (HTTP code: ${res.status})`);
    }
    return res.text();
};
exports.fetchReadWholeAsText = fetchReadWholeAsText;
const fetchCreateAdjacentFileSource = (relativePath, src)=>{
    if (typeof src !== 'string' && src instanceof URL === false) {
        throw new Error('src must be a string or URL when using `fetchReader`');
    }
    return new URL(relativePath, src).toString();
};
exports.fetchCreateAdjacentFileSource = fetchCreateAdjacentFileSource;
exports.fetchReader = {
    read: exports.fetchReadContent,
    readWholeAsText: exports.fetchReadWholeAsText,
    createAdjacentFileSource: exports.fetchCreateAdjacentFileSource,
    preload: exports.fetchPreload
};
}),
"[project]/node_modules/@remotion/media-parser/dist/readers/from-web-file.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.webFileReader = exports.webFileCreateAdjacentFileSource = exports.webFileReadWholeAsText = exports.webFileReadContent = void 0;
const webFileReadContent = ({ src, range, controller })=>{
    if (typeof src === 'string' || src instanceof URL) {
        throw new Error('`inputTypeFileReader` only supports `File` objects');
    }
    const part = range === null ? src : typeof range === 'number' ? src.slice(range) : src.slice(range[0], range[1] + 1);
    const stream = part.stream();
    const streamReader = stream.getReader();
    if (controller) {
        controller._internals.signal.addEventListener('abort', ()=>{
            streamReader.cancel();
        }, {
            once: true
        });
    }
    return Promise.resolve({
        reader: {
            reader: streamReader,
            async abort () {
                try {
                    await streamReader.cancel();
                } catch (_a) {}
                return Promise.resolve();
            }
        },
        contentLength: src.size,
        name: src instanceof File ? src.name : src.toString(),
        supportsContentRange: true,
        contentType: src.type,
        needsContentRange: true
    });
};
exports.webFileReadContent = webFileReadContent;
const webFileReadWholeAsText = ()=>{
    throw new Error('`webFileReader` cannot read auxiliary files.');
};
exports.webFileReadWholeAsText = webFileReadWholeAsText;
const webFileCreateAdjacentFileSource = ()=>{
    throw new Error('`webFileReader` cannot create adjacent file sources.');
};
exports.webFileCreateAdjacentFileSource = webFileCreateAdjacentFileSource;
exports.webFileReader = {
    read: exports.webFileReadContent,
    readWholeAsText: exports.webFileReadWholeAsText,
    createAdjacentFileSource: exports.webFileCreateAdjacentFileSource,
    preload: ()=>{
    // doing nothing, it's just for when fetching over the network
    }
};
}),
"[project]/node_modules/@remotion/media-parser/dist/readers/web.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.webReader = void 0;
const from_fetch_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/readers/from-fetch.js [app-route] (ecmascript)");
const from_web_file_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/readers/from-web-file.js [app-route] (ecmascript)");
exports.webReader = {
    read: (params)=>{
        if (params.src instanceof Blob) {
            return (0, from_web_file_1.webFileReadContent)(params);
        }
        return (0, from_fetch_1.fetchReadContent)(params);
    },
    createAdjacentFileSource: (relativePath, src)=>{
        if (src instanceof Blob) {
            return (0, from_web_file_1.webFileCreateAdjacentFileSource)(relativePath, src);
        }
        return (0, from_fetch_1.fetchCreateAdjacentFileSource)(relativePath, src);
    },
    readWholeAsText: (src)=>{
        if (src instanceof Blob) {
            return (0, from_web_file_1.webFileReadWholeAsText)(src);
        }
        return (0, from_fetch_1.fetchReadWholeAsText)(src);
    },
    preload: ({ range, src, logLevel, prefetchCache })=>{
        if (src instanceof Blob) {
            return;
        }
        return (0, from_fetch_1.fetchPreload)({
            range,
            src,
            logLevel,
            prefetchCache
        });
    }
};
}),
"[project]/node_modules/@remotion/media-parser/dist/web.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.webReader = void 0;
var web_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/readers/web.js [app-route] (ecmascript)");
Object.defineProperty(exports, "webReader", {
    enumerable: true,
    get: function() {
        return web_1.webReader;
    }
});
}),
"[project]/node_modules/@remotion/media-parser/dist/parse-media.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMedia = void 0;
const select_stream_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/select-stream.js [app-route] (ecmascript)");
const internal_parse_media_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/internal-parse-media.js [app-route] (ecmascript)");
const web_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/web.js [app-route] (ecmascript)");
const parseMedia = (options)=>{
    var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v, _w, _x, _y, _z, _0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16;
    if (!options) {
        return Promise.reject(new Error('No options provided. See https://www.remotion.dev/media-parser for how to get started.'));
    }
    return (0, internal_parse_media_1.internalParseMedia)({
        fields: (_a = options.fields) !== null && _a !== void 0 ? _a : null,
        logLevel: (_b = options.logLevel) !== null && _b !== void 0 ? _b : 'info',
        onAudioCodec: (_c = options.onAudioCodec) !== null && _c !== void 0 ? _c : null,
        onAudioTrack: (_d = options.onAudioTrack) !== null && _d !== void 0 ? _d : null,
        onContainer: (_e = options.onContainer) !== null && _e !== void 0 ? _e : null,
        onDimensions: (_f = options.onDimensions) !== null && _f !== void 0 ? _f : null,
        onDurationInSeconds: (_g = options.onDurationInSeconds) !== null && _g !== void 0 ? _g : null,
        onFps: (_h = options.onFps) !== null && _h !== void 0 ? _h : null,
        onImages: (_j = options.onImages) !== null && _j !== void 0 ? _j : null,
        onInternalStats: (_k = options.onInternalStats) !== null && _k !== void 0 ? _k : null,
        onIsHdr: (_l = options.onIsHdr) !== null && _l !== void 0 ? _l : null,
        onKeyframes: (_m = options.onKeyframes) !== null && _m !== void 0 ? _m : null,
        onLocation: (_o = options.onLocation) !== null && _o !== void 0 ? _o : null,
        onMetadata: (_p = options.onMetadata) !== null && _p !== void 0 ? _p : null,
        onMimeType: (_q = options.onMimeType) !== null && _q !== void 0 ? _q : null,
        onName: (_r = options.onName) !== null && _r !== void 0 ? _r : null,
        onNumberOfAudioChannels: (_s = options.onNumberOfAudioChannels) !== null && _s !== void 0 ? _s : null,
        onParseProgress: (_t = options.onParseProgress) !== null && _t !== void 0 ? _t : null,
        onRotation: (_u = options.onRotation) !== null && _u !== void 0 ? _u : null,
        onSampleRate: (_v = options.onSampleRate) !== null && _v !== void 0 ? _v : null,
        onSize: (_w = options.onSize) !== null && _w !== void 0 ? _w : null,
        onSlowAudioBitrate: (_x = options.onSlowAudioBitrate) !== null && _x !== void 0 ? _x : null,
        onSlowDurationInSeconds: (_y = options.onSlowDurationInSeconds) !== null && _y !== void 0 ? _y : null,
        onSlowFps: (_z = options.onSlowFps) !== null && _z !== void 0 ? _z : null,
        onSlowKeyframes: (_0 = options.onSlowKeyframes) !== null && _0 !== void 0 ? _0 : null,
        onSlowNumberOfFrames: (_1 = options.onSlowNumberOfFrames) !== null && _1 !== void 0 ? _1 : null,
        onSlowVideoBitrate: (_2 = options.onSlowVideoBitrate) !== null && _2 !== void 0 ? _2 : null,
        onSlowStructure: (_3 = options.onSlowStructure) !== null && _3 !== void 0 ? _3 : null,
        onM3uStreams: (_4 = options.onM3uStreams) !== null && _4 !== void 0 ? _4 : null,
        onTracks: (_5 = options.onTracks) !== null && _5 !== void 0 ? _5 : null,
        onUnrotatedDimensions: (_6 = options.onUnrotatedDimensions) !== null && _6 !== void 0 ? _6 : null,
        onVideoCodec: (_7 = options.onVideoCodec) !== null && _7 !== void 0 ? _7 : null,
        onVideoTrack: (_8 = options.onVideoTrack) !== null && _8 !== void 0 ? _8 : null,
        progressIntervalInMs: (_9 = options.progressIntervalInMs) !== null && _9 !== void 0 ? _9 : null,
        reader: (_10 = options.reader) !== null && _10 !== void 0 ? _10 : web_1.webReader,
        controller: (_11 = options.controller) !== null && _11 !== void 0 ? _11 : undefined,
        selectM3uStream: (_12 = options.selectM3uStream) !== null && _12 !== void 0 ? _12 : select_stream_1.defaultSelectM3uStreamFn,
        selectM3uAssociatedPlaylists: (_13 = options.selectM3uAssociatedPlaylists) !== null && _13 !== void 0 ? _13 : select_stream_1.defaultSelectM3uAssociatedPlaylists,
        m3uPlaylistContext: (_14 = options.m3uPlaylistContext) !== null && _14 !== void 0 ? _14 : null,
        src: options.src,
        mode: 'query',
        onDiscardedData: null,
        onError: ()=>({
                action: 'fail'
            }),
        acknowledgeRemotionLicense: Boolean(options.acknowledgeRemotionLicense),
        apiName: 'parseMedia()',
        makeSamplesStartAtZero: (_15 = options.makeSamplesStartAtZero) !== null && _15 !== void 0 ? _15 : true,
        seekingHints: (_16 = options.seekingHints) !== null && _16 !== void 0 ? _16 : null
    });
};
exports.parseMedia = parseMedia;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/first-sample-in-m3u-chunk.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.considerSeekBasedOnChunk = void 0;
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const considerSeekBasedOnChunk = async ({ sample, parentController, childController, callback, m3uState, playlistUrl, subtractChunks, chunkIndex })=>{
    const pendingSeek = m3uState.getSeekToSecondsToProcess(playlistUrl);
    // If there is not even a seek to consider, just call the callback
    if (pendingSeek === null) {
        await callback(sample);
        return;
    }
    const timestamp = Math.min(sample.decodingTimestamp / webcodecs_timescale_1.WEBCODECS_TIMESCALE, sample.timestamp / webcodecs_timescale_1.WEBCODECS_TIMESCALE);
    // Already too far, now we should go to the previous chunk
    if (timestamp > pendingSeek.targetTime && chunkIndex !== null && chunkIndex > 0) {
        m3uState.setNextSeekShouldSubtractChunks(playlistUrl, subtractChunks + 1);
        parentController.seek(pendingSeek.targetTime);
        return;
    }
    // We are good, we have not gone too far! Don't emit sample and seek and clear pending seek
    childController.seek(pendingSeek.targetTime);
    m3uState.setNextSeekShouldSubtractChunks(playlistUrl, 0);
    m3uState.setSeekToSecondsToProcess(playlistUrl, null);
};
exports.considerSeekBasedOnChunk = considerSeekBasedOnChunk;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-chunks.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getChunks = void 0;
const getChunks = (playlist)=>{
    const chunks = [];
    for(let i = 0; i < playlist.boxes.length; i++){
        const box = playlist.boxes[i];
        if (box.type === 'm3u-map') {
            chunks.push({
                duration: 0,
                url: box.value,
                isHeader: true
            });
            continue;
        }
        if (box.type === 'm3u-extinf') {
            const nextBox = playlist.boxes[i + 1];
            i++;
            if (nextBox.type !== 'm3u-text-value') {
                throw new Error('Expected m3u-text-value');
            }
            chunks.push({
                duration: box.value,
                url: nextBox.value,
                isHeader: false
            });
        }
        continue;
    }
    return chunks;
};
exports.getChunks = getChunks;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/seek/get-chunk-to-seek-to.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getChunkToSeekTo = void 0;
const getChunkToSeekTo = ({ chunks, seekToSecondsToProcess })=>{
    let duration = 0;
    for(let i = 0; i < chunks.length; i++){
        if (duration >= seekToSecondsToProcess) {
            return Math.max(0, i - 1);
        }
        duration += chunks[i].duration;
    }
    return Math.max(0, chunks.length - 1);
};
exports.getChunkToSeekTo = getChunkToSeekTo;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/process-m3u-chunk.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.processM3uChunk = void 0;
const media_parser_controller_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/controller/media-parser-controller.js [app-route] (ecmascript)");
const forward_controller_pause_resume_abort_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/forward-controller-pause-resume-abort.js [app-route] (ecmascript)");
const parse_media_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/parse-media.js [app-route] (ecmascript)");
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const with_resolvers_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/with-resolvers.js [app-route] (ecmascript)");
const first_sample_in_m3u_chunk_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/first-sample-in-m3u-chunk.js [app-route] (ecmascript)");
const get_chunks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-chunks.js [app-route] (ecmascript)");
const get_playlist_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/get-playlist.js [app-route] (ecmascript)");
const get_chunk_to_seek_to_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/seek/get-chunk-to-seek-to.js [app-route] (ecmascript)");
const processM3uChunk = ({ playlistUrl, state, structure, audioDone, videoDone })=>{
    const { promise, reject, resolve } = (0, with_resolvers_1.withResolvers)();
    const onGlobalAudioTrack = audioDone ? null : async (track)=>{
        const existingTracks = state.callbacks.tracks.getTracks();
        let { trackId } = track;
        while(existingTracks.find((t)=>t.trackId === trackId)){
            trackId++;
        }
        const onAudioSample = await (0, register_track_1.registerAudioTrack)({
            container: 'm3u8',
            track: {
                ...track,
                trackId
            },
            registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,
            tracks: state.callbacks.tracks,
            logLevel: state.logLevel,
            onAudioTrack: state.onAudioTrack
        });
        state.m3u.sampleSorter.addToStreamWithTrack(playlistUrl);
        if (onAudioSample === null) {
            return null;
        }
        state.m3u.sampleSorter.addAudioStreamToConsider(playlistUrl, onAudioSample);
        return async (sample)=>{
            await state.m3u.sampleSorter.addAudioSample(playlistUrl, sample);
        };
    };
    const onGlobalVideoTrack = videoDone ? null : async (track)=>{
        const existingTracks = state.callbacks.tracks.getTracks();
        let { trackId } = track;
        while(existingTracks.find((t)=>t.trackId === trackId)){
            trackId++;
        }
        const onVideoSample = await (0, register_track_1.registerVideoTrack)({
            container: 'm3u8',
            track: {
                ...track,
                trackId
            },
            logLevel: state.logLevel,
            onVideoTrack: state.onVideoTrack,
            registerVideoSampleCallback: state.callbacks.registerVideoSampleCallback,
            tracks: state.callbacks.tracks
        });
        state.m3u.sampleSorter.addToStreamWithTrack(playlistUrl);
        if (onVideoSample === null) {
            return null;
        }
        state.m3u.sampleSorter.addVideoStreamToConsider(playlistUrl, onVideoSample);
        return async (sample)=>{
            await state.m3u.sampleSorter.addVideoSample(playlistUrl, sample);
        };
    };
    // This function will run through the whole playlist step by step, and pause itself
    // On the next run it will continue
    const pausableIterator = async ()=>{
        const playlist = (0, get_playlist_1.getPlaylist)(structure, playlistUrl);
        const chunks = (0, get_chunks_1.getChunks)(playlist);
        const seekToSecondsToProcess = state.m3u.getSeekToSecondsToProcess(playlistUrl);
        const chunksToSubtract = state.m3u.getNextSeekShouldSubtractChunks(playlistUrl);
        let chunkIndex = null;
        if (seekToSecondsToProcess !== null) {
            chunkIndex = Math.max(0, (0, get_chunk_to_seek_to_1.getChunkToSeekTo)({
                chunks,
                seekToSecondsToProcess: seekToSecondsToProcess.targetTime
            }) - chunksToSubtract);
        }
        const currentPromise = {
            resolver: ()=>undefined,
            rejector: reject
        };
        const requiresHeaderToBeFetched = chunks[0].isHeader;
        for (const chunk of chunks){
            const mp4HeaderSegment = state.m3u.getMp4HeaderSegment(playlistUrl);
            if (requiresHeaderToBeFetched && mp4HeaderSegment && chunk.isHeader) {
                continue;
            }
            if (chunkIndex !== null && chunks.indexOf(chunk) < chunkIndex && !chunk.isHeader) {
                continue;
            }
            currentPromise.resolver = (newRun)=>{
                state.m3u.setM3uStreamRun(playlistUrl, newRun);
                resolve();
            };
            currentPromise.rejector = reject;
            const childController = (0, media_parser_controller_1.mediaParserController)();
            const forwarded = (0, forward_controller_pause_resume_abort_1.forwardMediaParserControllerPauseResume)({
                childController,
                parentController: state.controller
            });
            const nextChunk = chunks[chunks.indexOf(chunk) + 1];
            if (nextChunk) {
                const nextChunkSource = state.readerInterface.createAdjacentFileSource(nextChunk.url, playlistUrl);
                state.readerInterface.preload({
                    logLevel: state.logLevel,
                    range: null,
                    src: nextChunkSource,
                    prefetchCache: state.prefetchCache
                });
            }
            const makeContinuationFn = ()=>{
                return {
                    continue () {
                        const resolver = (0, with_resolvers_1.withResolvers)();
                        currentPromise.resolver = resolver.resolve;
                        currentPromise.rejector = resolver.reject;
                        childController.resume();
                        return resolver.promise;
                    },
                    abort () {
                        childController.abort();
                    }
                };
            };
            const isLastChunk = chunk === chunks[chunks.length - 1];
            await childController._internals.checkForAbortAndPause();
            const src = state.readerInterface.createAdjacentFileSource(chunk.url, playlistUrl);
            try {
                const data = await (0, parse_media_1.parseMedia)({
                    src,
                    acknowledgeRemotionLicense: true,
                    logLevel: state.logLevel,
                    controller: childController,
                    progressIntervalInMs: 0,
                    onParseProgress: ()=>{
                        childController.pause();
                        currentPromise.resolver(makeContinuationFn());
                    },
                    fields: chunk.isHeader ? {
                        slowStructure: true
                    } : undefined,
                    onTracks: ()=>{
                        if (!state.m3u.hasEmittedDoneWithTracks(playlistUrl)) {
                            state.m3u.setHasEmittedDoneWithTracks(playlistUrl);
                            const allDone = state.m3u.setTracksDone(playlistUrl);
                            if (allDone) {
                                state.callbacks.tracks.setIsDone(state.logLevel);
                            }
                            return null;
                        }
                    },
                    onAudioTrack: onGlobalAudioTrack === null ? null : async ({ track })=>{
                        const callbackOrFalse = state.m3u.hasEmittedAudioTrack(playlistUrl);
                        if (callbackOrFalse === false) {
                            const callback = await onGlobalAudioTrack(track);
                            if (!callback) {
                                state.m3u.setHasEmittedAudioTrack(playlistUrl, null);
                                return null;
                            }
                            state.m3u.setHasEmittedAudioTrack(playlistUrl, callback);
                            return async (sample)=>{
                                await (0, first_sample_in_m3u_chunk_1.considerSeekBasedOnChunk)({
                                    sample,
                                    callback,
                                    parentController: state.controller,
                                    childController,
                                    m3uState: state.m3u,
                                    playlistUrl,
                                    subtractChunks: chunksToSubtract,
                                    chunkIndex
                                });
                            };
                        }
                        if (callbackOrFalse === null) {
                            return null;
                        }
                        return async (sample)=>{
                            await (0, first_sample_in_m3u_chunk_1.considerSeekBasedOnChunk)({
                                sample,
                                m3uState: state.m3u,
                                playlistUrl,
                                callback: callbackOrFalse,
                                parentController: state.controller,
                                childController,
                                subtractChunks: chunksToSubtract,
                                chunkIndex
                            });
                        };
                    },
                    onVideoTrack: onGlobalVideoTrack === null ? null : async ({ track })=>{
                        const callbackOrFalse = state.m3u.hasEmittedVideoTrack(playlistUrl);
                        if (callbackOrFalse === false) {
                            const callback = await onGlobalVideoTrack({
                                ...track,
                                m3uStreamFormat: chunk.isHeader || mp4HeaderSegment ? 'mp4' : 'ts'
                            });
                            if (!callback) {
                                state.m3u.setHasEmittedVideoTrack(playlistUrl, null);
                                return null;
                            }
                            state.m3u.setHasEmittedVideoTrack(playlistUrl, callback);
                            return async (sample)=>{
                                await (0, first_sample_in_m3u_chunk_1.considerSeekBasedOnChunk)({
                                    sample,
                                    m3uState: state.m3u,
                                    playlistUrl,
                                    callback,
                                    parentController: state.controller,
                                    childController,
                                    subtractChunks: chunksToSubtract,
                                    chunkIndex
                                });
                            };
                        }
                        if (callbackOrFalse === null) {
                            return null;
                        }
                        return async (sample)=>{
                            await (0, first_sample_in_m3u_chunk_1.considerSeekBasedOnChunk)({
                                sample,
                                m3uState: state.m3u,
                                playlistUrl,
                                callback: callbackOrFalse,
                                parentController: state.controller,
                                childController,
                                subtractChunks: chunksToSubtract,
                                chunkIndex
                            });
                        };
                    },
                    reader: state.readerInterface,
                    makeSamplesStartAtZero: false,
                    m3uPlaylistContext: {
                        mp4HeaderSegment,
                        isLastChunkInPlaylist: isLastChunk
                    }
                });
                if (chunk.isHeader) {
                    if (data.slowStructure.type !== 'iso-base-media') {
                        throw new Error('Expected an mp4 file');
                    }
                    state.m3u.setMp4HeaderSegment(playlistUrl, data.slowStructure);
                }
            } catch (e) {
                currentPromise.rejector(e);
                throw e;
            }
            forwarded.cleanup();
            if (!isLastChunk) {
                childController.pause();
                currentPromise.resolver(makeContinuationFn());
            }
        }
        currentPromise.resolver(null);
    };
    const run = pausableIterator();
    run.catch((err)=>{
        reject(err);
    });
    return promise;
};
exports.processM3uChunk = processM3uChunk;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/run-over-m3u.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.runOverM3u = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const process_m3u_chunk_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/process-m3u-chunk.js [app-route] (ecmascript)");
const runOverM3u = async ({ state, structure, playlistUrl, logLevel })=>{
    const tracksDone = state.m3u.getTrackDone(playlistUrl);
    const hasAudioStreamToConsider = state.m3u.sampleSorter.hasAudioStreamToConsider(playlistUrl);
    const hasVideoStreamToConsider = state.m3u.sampleSorter.hasVideoStreamToConsider(playlistUrl);
    const audioDone = !hasAudioStreamToConsider && tracksDone;
    const videoDone = !hasVideoStreamToConsider && tracksDone;
    const bothDone = audioDone && videoDone;
    if (bothDone) {
        state.m3u.setAllChunksProcessed(playlistUrl);
        return;
    }
    const existingRun = state.m3u.getM3uStreamRun(playlistUrl);
    if (existingRun) {
        log_1.Log.trace(logLevel, 'Existing M3U parsing process found for', playlistUrl);
        const run = await existingRun.continue();
        state.m3u.setM3uStreamRun(playlistUrl, run);
        if (!run) {
            state.m3u.setAllChunksProcessed(playlistUrl);
        }
        return;
    }
    log_1.Log.trace(logLevel, 'Starting new M3U parsing process for', playlistUrl);
    await (0, process_m3u_chunk_1.processM3uChunk)({
        playlistUrl,
        state,
        structure,
        audioDone,
        videoDone
    });
};
exports.runOverM3u = runOverM3u;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-m3u.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseM3u = void 0;
const after_manifest_fetch_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/after-manifest-fetch.js [app-route] (ecmascript)");
const parse_m3u_manifest_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-m3u-manifest.js [app-route] (ecmascript)");
const run_over_m3u_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/run-over-m3u.js [app-route] (ecmascript)");
const parseM3u = async ({ state })=>{
    const structure = state.structure.getM3uStructure();
    if (state.m3u.isReadyToIterateOverM3u()) {
        const selectedPlaylists = state.m3u.getSelectedPlaylists();
        const whichPlaylistToRunOver = state.m3u.sampleSorter.getNextStreamToRun(selectedPlaylists);
        await (0, run_over_m3u_1.runOverM3u)({
            state,
            structure,
            playlistUrl: whichPlaylistToRunOver,
            logLevel: state.logLevel
        });
        return null;
    }
    if (state.m3u.hasFinishedManifest()) {
        if (typeof state.src !== 'string' && !(state.src instanceof URL)) {
            throw new Error('Expected src to be a string');
        }
        state.mediaSection.addMediaSection({
            start: 0,
            // We do a pseudo-seek when seeking m3u, which will be the same byte
            // as we are currently in, which in most cases is the end of the file.
            size: state.contentLength + 1
        });
        await (0, after_manifest_fetch_1.afterManifestFetch)({
            structure,
            m3uState: state.m3u,
            src: state.src.toString(),
            selectM3uStreamFn: state.selectM3uStreamFn,
            logLevel: state.logLevel,
            selectAssociatedPlaylistsFn: state.selectM3uAssociatedPlaylistsFn,
            readerInterface: state.readerInterface,
            onAudioTrack: state.onAudioTrack,
            canSkipTracks: state.callbacks.canSkipTracksState
        });
        return null;
    }
    const box = await (0, parse_m3u_manifest_1.parseM3uManifest)({
        iterator: state.iterator,
        structure,
        contentLength: state.contentLength
    });
    const isDoneNow = state.iterator.counter.getOffset() === state.contentLength;
    if (isDoneNow) {
        state.m3u.setHasFinishedManifest();
    }
    return box;
};
exports.parseM3u = parseM3u;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/id3.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseId3 = void 0;
function combine28Bits(a, b, c, d) {
    // Mask each number to ignore first bit (& 0x7F)
    const val1 = a & 0x7f; // 7 bits from first byte
    const val2 = b & 0x7f; // 7 bits from second byte
    const val3 = c & 0x7f; // 7 bits from third byte
    const val4 = d & 0x7f; // 7 bits from fourth byte
    // Combine all values using bitwise operations
    return val1 << 21 | val2 << 14 | val3 << 7 | val4;
}
const parseId3 = ({ state })=>{
    const { iterator } = state;
    if (iterator.bytesRemaining() < 9) {
        return;
    }
    const { returnToCheckpoint } = iterator.startCheckpoint();
    iterator.discard(3);
    const versionMajor = iterator.getUint8();
    const versionMinor = iterator.getUint8();
    const flags = iterator.getUint8();
    const sizeArr = iterator.getSlice(4);
    const size = combine28Bits(sizeArr[0], sizeArr[1], sizeArr[2], sizeArr[3]);
    if (iterator.bytesRemaining() < size) {
        returnToCheckpoint();
        return;
    }
    const entries = [];
    const initial = iterator.counter.getOffset();
    while(iterator.counter.getOffset() < size + initial){
        const name = versionMajor === 3 || versionMajor === 4 ? iterator.getByteString(4, true) : iterator.getByteString(3, true);
        if (name === '') {
            iterator.discard(size + initial - iterator.counter.getOffset());
            break;
        }
        const s = versionMajor === 4 ? iterator.getSyncSafeInt32() : versionMajor === 3 ? iterator.getUint32() : iterator.getUint24();
        if (versionMajor === 3 || versionMajor === 4) {
            iterator.getUint16(); // flags
        }
        let subtract = 0;
        if (!name.startsWith('W')) {
            iterator.getUint8(); // encoding
            subtract += 1;
        }
        if (name === 'APIC') {
            const { discardRest } = iterator.planBytes(s - subtract);
            const mimeType = iterator.readUntilNullTerminator();
            iterator.getUint16(); // picture type
            const description = iterator.readUntilNullTerminator();
            iterator.discard(1);
            const data = discardRest();
            state.images.addImage({
                data,
                description,
                mimeType
            });
        } else {
            const information = iterator.getByteString(s - subtract, true);
            entries.push({
                key: name,
                value: information,
                trackId: null
            });
        }
    }
    state.structure.getMp3Structure().boxes.push({
        type: 'id3-header',
        flags,
        size,
        versionMajor,
        versionMinor,
        metatags: entries
    });
};
exports.parseId3 = parseId3;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/id3-v1.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseID3V1 = void 0;
const parseID3V1 = (iterator)=>{
    if (iterator.bytesRemaining() < 128) {
        return;
    }
    // we drop ID3v1 because usually there is also ID3v2 and ID3v3 which are superior.
    // Better than have duplicated data.
    iterator.discard(128);
};
exports.parseID3V1 = parseID3V1;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/parse-packet-header.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isMp3PacketHeaderHereAndInNext = exports.isMp3PacketHeaderHere = exports.parseMp3PacketHeader = void 0;
const get_frame_length_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-frame-length.js [app-route] (ecmascript)");
const samples_per_mpeg_file_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/samples-per-mpeg-file.js [app-route] (ecmascript)");
function getSamplingFrequency({ bits, mpegVersion }) {
    const samplingTable = {
        0b00: {
            MPEG1: 44100,
            MPEG2: 22050
        },
        0b01: {
            MPEG1: 48000,
            MPEG2: 24000
        },
        0b10: {
            MPEG1: 32000,
            MPEG2: 16000
        },
        0b11: {
            MPEG1: 'reserved',
            MPEG2: 'reserved'
        }
    };
    const key = `MPEG${mpegVersion}`;
    const value = samplingTable[bits][key];
    if (value === 'reserved') {
        throw new Error('Reserved sampling frequency');
    }
    if (!value) {
        throw new Error('Invalid sampling frequency for MPEG version: ' + JSON.stringify({
            bits,
            version: mpegVersion
        }));
    }
    return value;
}
function getBitrateKB({ bits, mpegVersion, level }) {
    const bitrateTable = {
        0b0000: {
            'V1,L1': 'free',
            'V1,L2': 'free',
            'V1,L3': 'free',
            'V2,L1': 'free',
            'V2,L2&L3': 'free'
        },
        0b0001: {
            'V1,L1': 32,
            'V1,L2': 32,
            'V1,L3': 32,
            'V2,L1': 32,
            'V2,L2&L3': 8
        },
        0b0010: {
            'V1,L1': 64,
            'V1,L2': 48,
            'V1,L3': 40,
            'V2,L1': 48,
            'V2,L2&L3': 16
        },
        0b0011: {
            'V1,L1': 96,
            'V1,L2': 56,
            'V1,L3': 48,
            'V2,L1': 56,
            'V2,L2&L3': 24
        },
        0b0100: {
            'V1,L1': 128,
            'V1,L2': 64,
            'V1,L3': 56,
            'V2,L1': 64,
            'V2,L2&L3': 32
        },
        0b0101: {
            'V1,L1': 160,
            'V1,L2': 80,
            'V1,L3': 64,
            'V2,L1': 80,
            'V2,L2&L3': 40
        },
        0b0110: {
            'V1,L1': 192,
            'V1,L2': 96,
            'V1,L3': 80,
            'V2,L1': 96,
            'V2,L2&L3': 48
        },
        0b0111: {
            'V1,L1': 224,
            'V1,L2': 112,
            'V1,L3': 96,
            'V2,L1': 112,
            'V2,L2&L3': 56
        },
        0b1000: {
            'V1,L1': 256,
            'V1,L2': 128,
            'V1,L3': 112,
            'V2,L1': 128,
            'V2,L2&L3': 64
        },
        0b1001: {
            'V1,L1': 288,
            'V1,L2': 160,
            'V1,L3': 128,
            'V2,L1': 144,
            'V2,L2&L3': 80
        },
        0b1010: {
            'V1,L1': 320,
            'V1,L2': 192,
            'V1,L3': 160,
            'V2,L1': 160,
            'V2,L2&L3': 96
        },
        0b1011: {
            'V1,L1': 352,
            'V1,L2': 224,
            'V1,L3': 192,
            'V2,L1': 176,
            'V2,L2&L3': 112
        },
        0b1100: {
            'V1,L1': 384,
            'V1,L2': 256,
            'V1,L3': 224,
            'V2,L1': 192,
            'V2,L2&L3': 128
        },
        0b1101: {
            'V1,L1': 416,
            'V1,L2': 320,
            'V1,L3': 256,
            'V2,L1': 224,
            'V2,L2&L3': 144
        },
        0b1110: {
            'V1,L1': 448,
            'V1,L2': 384,
            'V1,L3': 320,
            'V2,L1': 256,
            'V2,L2&L3': 160
        },
        0b1111: {
            'V1,L1': 'bad',
            'V1,L2': 'bad',
            'V1,L3': 'bad',
            'V2,L1': 'bad',
            'V2,L2&L3': 'bad'
        }
    };
    // Determine the correct key based on version and level
    let key;
    if (mpegVersion === 2 && (level === 2 || level === 3)) {
        key = 'V2,L2&L3';
    } else {
        key = `V${mpegVersion},L${level}`;
    }
    // Return the corresponding bitrate
    return bitrateTable[bits][key];
}
const innerParseMp3PacketHeader = (iterator)=>{
    for(let i = 0; i < 11; i++){
        const expectToBe1 = iterator.getBits(1);
        if (expectToBe1 !== 1) {
            throw new Error('Expected 1');
        }
    }
    const audioVersionId = iterator.getBits(2);
    /**
   * 00 - MPEG Version 2.5 (later extension of MPEG 2)
     01 - reserved
     10 - MPEG Version 2 (ISO/IEC 13818-3)
     11 - MPEG Version 1 (ISO/IEC 11172-3)
   */ if (audioVersionId !== 0b11 && audioVersionId !== 0b10 && audioVersionId !== 0b00) {
        throw new Error('Expected MPEG Version 1 or 2');
    }
    const mpegVersion = audioVersionId === 0b11 ? 1 : 2;
    const layerBits = iterator.getBits(2);
    /**
   * 00 - reserved
     01 - Layer III
     10 - Layer II
     11 - Layer I
   */ if (layerBits === 0b00) {
        throw new Error('Expected Layer I, II or III');
    }
    const layer = layerBits === 0b11 ? 1 : layerBits === 0b10 ? 2 : 3;
    iterator.getBits(1); // 0b1 means that there is no CRC, 0b0 means there is. Not validating checksum though
    const bitrateIndex = iterator.getBits(4);
    const bitrateInKbit = getBitrateKB({
        bits: bitrateIndex,
        mpegVersion,
        level: layer
    });
    if (bitrateInKbit === 'bad') {
        throw new Error('Invalid bitrate');
    }
    if (bitrateInKbit === 'free') {
        throw new Error('Free bitrate not supported');
    }
    const samplingFrequencyIndex = iterator.getBits(2);
    const baseSampleRate = getSamplingFrequency({
        bits: samplingFrequencyIndex,
        mpegVersion
    });
    const sampleRate = audioVersionId === 0b00 ? baseSampleRate / 2 : baseSampleRate;
    const padding = Boolean(iterator.getBits(1));
    iterator.getBits(1); // private bit
    const channelMode = iterator.getBits(2); // channel mode
    iterator.getBits(2); // mode extension
    iterator.getBits(1); // copyright
    iterator.getBits(1); // original
    iterator.getBits(2); // emphasis
    const numberOfChannels = channelMode === 0b11 ? 1 : 2;
    const samplesPerFrame = (0, samples_per_mpeg_file_1.getSamplesPerMpegFrame)({
        mpegVersion,
        layer
    });
    const frameLength = (0, get_frame_length_1.getMpegFrameLength)({
        bitrateKbit: bitrateInKbit,
        padding,
        samplesPerFrame,
        samplingFrequency: sampleRate,
        layer
    });
    return {
        frameLength,
        bitrateInKbit,
        layer,
        mpegVersion,
        numberOfChannels,
        sampleRate,
        samplesPerFrame
    };
};
const parseMp3PacketHeader = (iterator)=>{
    iterator.startReadingBits();
    const d = innerParseMp3PacketHeader(iterator);
    iterator.stopReadingBits();
    return d;
};
exports.parseMp3PacketHeader = parseMp3PacketHeader;
const isMp3PacketHeaderHere = (iterator)=>{
    const offset = iterator.counter.getOffset();
    iterator.startReadingBits();
    try {
        const res = innerParseMp3PacketHeader(iterator);
        iterator.stopReadingBits();
        iterator.counter.decrement(iterator.counter.getOffset() - offset);
        return res;
    } catch (_a) {
        iterator.stopReadingBits();
        iterator.counter.decrement(iterator.counter.getOffset() - offset);
        return false;
    }
};
exports.isMp3PacketHeaderHere = isMp3PacketHeaderHere;
const isMp3PacketHeaderHereAndInNext = (iterator)=>{
    const offset = iterator.counter.getOffset();
    const res = (0, exports.isMp3PacketHeaderHere)(iterator);
    if (!res) {
        return false;
    }
    // cannot check here because we don't have enough data, let's hope for the best
    if (iterator.bytesRemaining() <= res.frameLength) {
        return true;
    }
    iterator.counter.increment(res.frameLength);
    const isHere = (0, exports.isMp3PacketHeaderHere)(iterator);
    iterator.counter.decrement(iterator.counter.getOffset() - offset);
    return isHere;
};
exports.isMp3PacketHeaderHereAndInNext = isMp3PacketHeaderHereAndInNext;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/audio-sample-from-cbr.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getAudioSampleFromCbr = void 0;
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const get_frame_length_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-frame-length.js [app-route] (ecmascript)");
const getAudioSampleFromCbr = ({ bitrateInKbit, initialOffset, layer, sampleRate, samplesPerFrame, data, state })=>{
    const avgLength = (0, get_frame_length_1.getAverageMpegFrameLength)({
        bitrateKbit: bitrateInKbit,
        layer,
        samplesPerFrame,
        samplingFrequency: sampleRate
    });
    const mp3Info = state.mp3.getMp3Info();
    if (!mp3Info) {
        throw new Error('No MP3 info');
    }
    const nthFrame = Math.round((initialOffset - state.mediaSection.getMediaSectionAssertOnlyOne().start) / avgLength);
    const durationInSeconds = samplesPerFrame / sampleRate;
    const timeInSeconds = nthFrame * samplesPerFrame / sampleRate;
    // Important that we round down, otherwise WebCodecs might stall, e.g.
    // Last input = 30570667 Last output = 30570666 -> stuck
    const timestamp = Math.floor(timeInSeconds * webcodecs_timescale_1.WEBCODECS_TIMESCALE);
    const duration = Math.floor(durationInSeconds * webcodecs_timescale_1.WEBCODECS_TIMESCALE);
    const audioSample = {
        data,
        decodingTimestamp: timestamp,
        duration,
        offset: initialOffset,
        timestamp,
        type: 'key'
    };
    return {
        audioSample,
        timeInSeconds,
        durationInSeconds
    };
};
exports.getAudioSampleFromCbr = getAudioSampleFromCbr;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/audio-sample-from-vbr.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getAudioSampleFromVbr = void 0;
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const get_duration_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/get-duration.js [app-route] (ecmascript)");
const parse_xing_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/parse-xing.js [app-route] (ecmascript)");
const samples_per_mpeg_file_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/samples-per-mpeg-file.js [app-route] (ecmascript)");
const getAudioSampleFromVbr = ({ info, position, mp3Info, data })=>{
    if (!mp3Info) {
        throw new Error('No MP3 info');
    }
    const samplesPerFrame = (0, samples_per_mpeg_file_1.getSamplesPerMpegFrame)({
        layer: mp3Info.layer,
        mpegVersion: mp3Info.mpegVersion
    });
    const wholeFileDuration = (0, get_duration_1.getDurationFromMp3Xing)({
        samplesPerFrame,
        xingData: info.xingData
    });
    if (!info.xingData.fileSize) {
        throw new Error('file size');
    }
    if (!info.xingData.tableOfContents) {
        throw new Error('table of contents');
    }
    const timeInSeconds = (0, parse_xing_1.getTimeFromPosition)({
        durationInSeconds: wholeFileDuration,
        fileSize: info.xingData.fileSize,
        position,
        tableOfContents: info.xingData.tableOfContents
    });
    const durationInSeconds = samplesPerFrame / info.xingData.sampleRate;
    const timestamp = Math.floor(timeInSeconds * webcodecs_timescale_1.WEBCODECS_TIMESCALE);
    const duration = Math.floor(durationInSeconds * webcodecs_timescale_1.WEBCODECS_TIMESCALE);
    const audioSample = {
        data,
        decodingTimestamp: timestamp,
        duration,
        offset: position,
        timestamp,
        type: 'key'
    };
    return {
        timeInSeconds,
        audioSample,
        durationInSeconds
    };
};
exports.getAudioSampleFromVbr = getAudioSampleFromVbr;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/parse-mpeg-header.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

// spec: http://www.mp3-tech.org/programmer/frame_header.html
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMpegHeader = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const parse_packet_header_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/parse-packet-header.js [app-route] (ecmascript)");
const parse_xing_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/parse-xing.js [app-route] (ecmascript)");
const audio_sample_from_cbr_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/audio-sample-from-cbr.js [app-route] (ecmascript)");
const audio_sample_from_vbr_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/audio-sample-from-vbr.js [app-route] (ecmascript)");
const parseMpegHeader = async ({ state })=>{
    const { iterator } = state;
    const initialOffset = iterator.counter.getOffset();
    if (iterator.bytesRemaining() < 32) {
        return;
    }
    // parse header
    const { frameLength, bitrateInKbit, layer, mpegVersion, numberOfChannels, sampleRate, samplesPerFrame } = (0, parse_packet_header_1.parseMp3PacketHeader)(iterator);
    const cbrMp3Info = state.mp3.getMp3BitrateInfo();
    if (cbrMp3Info && cbrMp3Info.type === 'constant') {
        if (bitrateInKbit !== cbrMp3Info.bitrateInKbit) {
            throw new Error(`Bitrate mismatch at offset ${initialOffset}: ${bitrateInKbit} !== ${cbrMp3Info.bitrateInKbit}`);
        }
    }
    const offsetNow = iterator.counter.getOffset();
    iterator.counter.decrement(offsetNow - initialOffset);
    const data = iterator.getSlice(frameLength);
    if (state.callbacks.tracks.getTracks().length === 0) {
        const info = {
            layer,
            mpegVersion,
            sampleRate
        };
        const asText = new TextDecoder().decode(data);
        if (asText.includes('VBRI')) {
            throw new Error('MP3 files with VBRI are currently unsupported because we have no sample file. Submit this file at remotion.dev/report if you would like us to support this file.');
        }
        if (asText.includes('Info')) {
            return;
        }
        const isVbr = asText.includes('Xing');
        if (isVbr) {
            const xingData = (0, parse_xing_1.parseXing)(data);
            log_1.Log.verbose(state.logLevel, 'MP3 has variable bit rate. Requiring whole file to be read');
            state.mp3.setMp3BitrateInfo({
                type: 'variable',
                xingData
            });
            return;
        }
        if (!state.mp3.getMp3BitrateInfo()) {
            state.mp3.setMp3BitrateInfo({
                bitrateInKbit,
                type: 'constant'
            });
        }
        state.mp3.setMp3Info(info);
        await (0, register_track_1.registerAudioTrack)({
            container: 'mp3',
            track: {
                type: 'audio',
                codec: 'mp3',
                codecData: null,
                codecEnum: 'mp3',
                description: undefined,
                numberOfChannels,
                sampleRate,
                originalTimescale: 1000000,
                trackId: 0,
                startInSeconds: 0,
                timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
                trackMediaTimeOffsetInTrackTimescale: 0
            },
            registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,
            tracks: state.callbacks.tracks,
            logLevel: state.logLevel,
            onAudioTrack: state.onAudioTrack
        });
        state.callbacks.tracks.setIsDone(state.logLevel);
        state.mediaSection.addMediaSection({
            start: initialOffset,
            size: state.contentLength - initialOffset
        });
    }
    const bitrateInfo = state.mp3.getMp3BitrateInfo();
    if (!bitrateInfo) {
        throw new Error('No bitrate info');
    }
    const sample = bitrateInfo.type === 'constant' ? (0, audio_sample_from_cbr_1.getAudioSampleFromCbr)({
        bitrateInKbit,
        data,
        initialOffset,
        layer,
        sampleRate,
        samplesPerFrame,
        state
    }) : (0, audio_sample_from_vbr_1.getAudioSampleFromVbr)({
        data,
        info: bitrateInfo,
        mp3Info: state.mp3.getMp3Info(),
        position: initialOffset
    });
    const { audioSample, timeInSeconds, durationInSeconds } = sample;
    state.mp3.audioSamples.addSample({
        timeInSeconds,
        offset: initialOffset,
        durationInSeconds
    });
    await state.callbacks.onAudioSample({
        audioSample,
        trackId: 0
    });
};
exports.parseMpegHeader = parseMpegHeader;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/wait-until-syncword.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.discardUntilSyncword = void 0;
const parse_packet_header_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/parse-packet-header.js [app-route] (ecmascript)");
const discardUntilSyncword = ({ iterator })=>{
    while(true){
        const next2Bytes = iterator.getUint8();
        if (next2Bytes !== 0xff) {
            continue;
        }
        if (iterator.bytesRemaining() === 0) {
            break;
        }
        const nextByte = iterator.getUint8();
        const mask = 0xe0; // 1110 0000
        if ((nextByte & mask) !== mask) {
            continue;
        }
        iterator.counter.decrement(2);
        if ((0, parse_packet_header_1.isMp3PacketHeaderHereAndInNext)(iterator)) {
            break;
        } else {
            iterator.counter.increment(2);
        }
    }
};
exports.discardUntilSyncword = discardUntilSyncword;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/mp3/parse-mp3.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMp3 = void 0;
const id3_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/id3.js [app-route] (ecmascript)");
const id3_v1_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/id3-v1.js [app-route] (ecmascript)");
const parse_mpeg_header_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/parse-mpeg-header.js [app-route] (ecmascript)");
const wait_until_syncword_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seek/wait-until-syncword.js [app-route] (ecmascript)");
const parseMp3 = async (state)=>{
    const { iterator } = state;
    if (iterator.bytesRemaining() < 3) {
        return null;
    }
    // When coming from a seek, we need to discard until the syncword
    if (state.mediaSection.isCurrentByteInMediaSection(iterator) === 'in-section') {
        (0, wait_until_syncword_1.discardUntilSyncword)({
            iterator
        });
        await (0, parse_mpeg_header_1.parseMpegHeader)({
            state
        });
        return null;
    }
    const { returnToCheckpoint } = iterator.startCheckpoint();
    const bytes = iterator.getSlice(3);
    returnToCheckpoint();
    // ID3 v1
    if (bytes[0] === 0x54 && bytes[1] === 0x41 && bytes[2] === 0x47) {
        (0, id3_v1_1.parseID3V1)(iterator);
        return null;
    }
    // ID3 v2 or v3
    if (bytes[0] === 0x49 && bytes[1] === 0x44 && bytes[2] === 0x33) {
        (0, id3_1.parseId3)({
            state
        });
        return null;
    }
    if (bytes[0] === 0xff) {
        await (0, parse_mpeg_header_1.parseMpegHeader)({
            state
        });
        return null;
    }
    throw new Error('Unknown MP3 header ' + JSON.stringify(bytes));
};
exports.parseMp3 = parseMp3;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/get-strh-for-index.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getStrhForIndex = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/traversal.js [app-route] (ecmascript)");
const getStrhForIndex = (structure, trackId)=>{
    const boxes = (0, traversal_1.getStrlBoxes)(structure);
    const box = boxes[trackId];
    if (!box) {
        throw new Error('Expected box');
    }
    const strh = (0, traversal_1.getStrhBox)(box.children);
    if (!strh) {
        throw new Error('strh');
    }
    return strh;
};
exports.getStrhForIndex = getStrhForIndex;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/convert-queued-sample-to-mediaparser-sample.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.convertQueuedSampleToMediaParserSample = void 0;
const convert_audio_or_video_sample_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/convert-audio-or-video-sample.js [app-route] (ecmascript)");
const get_strh_for_index_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/get-strh-for-index.js [app-route] (ecmascript)");
const getKeyFrameOffsetAndPocs = ({ state, sample, trackId })=>{
    var _a, _b;
    if (sample.type === 'key') {
        const sampleOffset = state.riff.sampleCounter.getSampleCountForTrack({
            trackId
        });
        return {
            sampleOffsetAtKeyframe: sampleOffset,
            pocsAtKeyframeOffset: [
                (_b = (_a = sample.avc) === null || _a === void 0 ? void 0 : _a.poc) !== null && _b !== void 0 ? _b : 0
            ]
        };
    }
    const riffKeyframes = state.riff.sampleCounter.riffKeys.getKeyframes();
    const keyframeAtOffset = riffKeyframes.findLast((k)=>k.positionInBytes <= sample.offset);
    if (!keyframeAtOffset) {
        throw new Error('no keyframe at offset');
    }
    const sampleOffsetAtKeyframe = keyframeAtOffset.sampleCounts[trackId];
    const pocsAtKeyframeOffset = state.riff.sampleCounter.getPocAtKeyframeOffset({
        keyframeOffset: keyframeAtOffset.positionInBytes
    });
    return {
        sampleOffsetAtKeyframe,
        pocsAtKeyframeOffset
    };
};
const convertQueuedSampleToMediaParserSample = ({ sample, state, trackId })=>{
    const strh = (0, get_strh_for_index_1.getStrhForIndex)(state.structure.getRiffStructure(), trackId);
    const samplesPerSecond = strh.rate / strh.scale;
    const { sampleOffsetAtKeyframe, pocsAtKeyframeOffset } = getKeyFrameOffsetAndPocs({
        sample,
        state,
        trackId
    });
    const indexOfPoc = pocsAtKeyframeOffset.findIndex((poc)=>{
        var _a;
        return poc === ((_a = sample.avc) === null || _a === void 0 ? void 0 : _a.poc);
    });
    if (indexOfPoc === -1) {
        throw new Error('poc not found');
    }
    const nthSample = indexOfPoc + sampleOffsetAtKeyframe;
    const timestamp = nthSample / samplesPerSecond;
    const videoSample = (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
        sample: {
            ...sample,
            timestamp,
            decodingTimestamp: timestamp
        },
        timescale: 1
    });
    return videoSample;
};
exports.convertQueuedSampleToMediaParserSample = convertQueuedSampleToMediaParserSample;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/is-movi.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isMoviAtom = void 0;
const isMoviAtom = (iterator, ckId)=>{
    if (ckId !== 'LIST') {
        return false;
    }
    const listType = iterator.getByteString(4, false);
    iterator.counter.decrement(4);
    return listType === 'movi';
};
exports.isMoviAtom = isMoviAtom;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-avih.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseAvih = void 0;
const AVIF_HAS_INDEX = 0x00000010;
const parseAvih = ({ iterator, size })=>{
    const { expectNoMoreBytes } = iterator.startBox(size);
    const dwMicroSecPerFrame = iterator.getUint32Le();
    const dwMaxBytesPerSec = iterator.getUint32Le();
    const paddingGranularity = iterator.getUint32Le();
    const flags = iterator.getUint32Le();
    const totalFrames = iterator.getUint32Le();
    const initialFrames = iterator.getUint32Le();
    const streams = iterator.getUint32Le();
    const suggestedBufferSize = iterator.getUint32Le();
    const width = iterator.getUint32Le();
    const height = iterator.getUint32Le();
    const hasIndex = (flags & AVIF_HAS_INDEX) !== 0;
    iterator.discard(16);
    expectNoMoreBytes();
    return {
        type: 'avih-box',
        hasIndex,
        microSecPerFrame: dwMicroSecPerFrame,
        maxBytesPerSecond: dwMaxBytesPerSec,
        paddingGranularity,
        flags,
        totalFrames,
        initialFrames,
        streams,
        suggestedBufferSize,
        height,
        width
    };
};
exports.parseAvih = parseAvih;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-idx1.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseIdx1 = void 0;
const AVIIF_KEYFRAME = 0x00000010;
const parseIdx1 = ({ iterator, size })=>{
    const box = iterator.startBox(size);
    const offset = iterator.counter.getOffset();
    const entries = [];
    const sampleCounts = {};
    let videoTrackIndex = null;
    while(iterator.counter.getOffset() < offset + size){
        const chunkId = iterator.getByteString(4, false);
        const flags = iterator.getUint32Le();
        const moffset = iterator.getUint32Le();
        const msize = iterator.getUint32Le();
        const chunk = chunkId.match(/^([0-9]{2})(wb|dc)$/);
        const isVideo = chunkId.endsWith('dc');
        if (isVideo) {
            videoTrackIndex = chunk ? parseInt(chunk[1], 10) : null;
        }
        const trackId = chunk ? parseInt(chunk[1], 10) : null;
        if (trackId === null) {
            continue;
        }
        if (!sampleCounts[trackId]) {
            sampleCounts[trackId] = 0;
        }
        const isKeyFrame = (flags & AVIIF_KEYFRAME) !== 0;
        if (isKeyFrame) {
            entries.push({
                flags,
                id: chunkId,
                offset: moffset,
                size: msize,
                sampleCounts: {
                    ...sampleCounts
                }
            });
        }
        sampleCounts[trackId]++;
    }
    box.expectNoMoreBytes();
    return {
        type: 'idx1-box',
        entries,
        videoTrackIndex
    };
};
exports.parseIdx1 = parseIdx1;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-isft.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseIsft = void 0;
const parseIsft = ({ iterator, size })=>{
    const { expectNoMoreBytes } = iterator.startBox(size);
    const software = iterator.getByteString(size - 1, false);
    const last = iterator.getUint8();
    if (last !== 0) {
        throw new Error(`Expected 0 byte, got ${last}`);
    }
    expectNoMoreBytes();
    return {
        type: 'isft-box',
        software
    };
};
exports.parseIsft = parseIsft;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-list-box.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseListBox = void 0;
const expect_riff_box_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/expect-riff-box.js [app-route] (ecmascript)");
const parseListBox = async ({ size, iterator, stateIfExpectingSideEffects })=>{
    const counter = iterator.counter.getOffset();
    const listType = iterator.getByteString(4, false);
    if (listType === 'movi') {
        throw new Error('should not be handled here');
    }
    const boxes = [];
    const maxOffset = counter + size;
    while(iterator.counter.getOffset() < maxOffset){
        const box = await (0, expect_riff_box_1.expectRiffBox)({
            iterator,
            stateIfExpectingSideEffects
        });
        if (box === null) {
            throw new Error('Unexpected result');
        }
        if (stateIfExpectingSideEffects) {
            await (0, expect_riff_box_1.postProcessRiffBox)(stateIfExpectingSideEffects, box);
        }
        boxes.push(box);
    }
    return {
        type: 'list-box',
        listType,
        children: boxes
    };
};
exports.parseListBox = parseListBox;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-strf.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseStrf = void 0;
const parseStrfAudio = ({ iterator, size })=>{
    const box = iterator.startBox(size);
    const formatTag = iterator.getUint16Le();
    const numberOfChannels = iterator.getUint16Le();
    const samplesPerSec = iterator.getUint32Le();
    const avgBytesPerSec = iterator.getUint32Le();
    const blockAlign = iterator.getUint16Le();
    const bitsPerSample = iterator.getUint16Le();
    const cbSize = iterator.getUint16Le();
    box.expectNoMoreBytes();
    return {
        type: 'strf-box-audio',
        avgBytesPerSecond: avgBytesPerSec,
        bitsPerSample,
        blockAlign,
        cbSize,
        formatTag,
        numberOfChannels,
        sampleRate: samplesPerSec
    };
};
const parseStrfVideo = ({ iterator, size })=>{
    const box = iterator.startBox(size);
    const biSize = iterator.getUint32Le();
    const width = iterator.getInt32Le();
    const height = iterator.getInt32Le();
    const planes = iterator.getUint16Le();
    const bitCount = iterator.getUint16Le();
    const compression = iterator.getByteString(4, false);
    const sizeImage = iterator.getUint32Le();
    const xPelsPerMeter = iterator.getInt32Le();
    const yPelsPerMeter = iterator.getInt32Le();
    const clrUsed = iterator.getUint32Le();
    const clrImportant = iterator.getUint32Le();
    box.expectNoMoreBytes();
    return {
        type: 'strf-box-video',
        biSize,
        bitCount,
        clrImportant,
        clrUsed,
        compression,
        height,
        planes,
        sizeImage,
        width,
        xPelsPerMeter,
        yPelsPerMeter
    };
};
const parseStrf = ({ iterator, size, fccType })=>{
    if (fccType === 'vids') {
        return parseStrfVideo({
            iterator,
            size
        });
    }
    if (fccType === 'auds') {
        return parseStrfAudio({
            iterator,
            size
        });
    }
    throw new Error(`Unsupported fccType: ${fccType}`);
};
exports.parseStrf = parseStrf;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-strh.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseStrh = void 0;
const parse_strf_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-strf.js [app-route] (ecmascript)");
const parseStrh = ({ iterator, size })=>{
    const box = iterator.startBox(size);
    const fccType = iterator.getByteString(4, false);
    if (fccType !== 'vids' && fccType !== 'auds') {
        throw new Error('Expected AVI handler to be vids / auds');
    }
    const handler = fccType === 'vids' ? iterator.getByteString(4, false) : iterator.getUint32Le();
    if (typeof handler === 'string' && handler !== 'H264') {
        throw new Error(`Only H264 is supported as a stream type in .avi, got ${handler}`);
    }
    if (fccType === 'auds' && handler !== 1) {
        throw new Error(`Only "1" is supported as a stream type in .avi, got ${handler}`);
    }
    const flags = iterator.getUint32Le();
    const priority = iterator.getUint16Le();
    const language = iterator.getUint16Le();
    const initialFrames = iterator.getUint32Le();
    const scale = iterator.getUint32Le();
    const rate = iterator.getUint32Le();
    const start = iterator.getUint32Le();
    const length = iterator.getUint32Le();
    const suggestedBufferSize = iterator.getUint32Le();
    const quality = iterator.getUint32Le();
    const sampleSize = iterator.getUint32Le();
    box.discardRest();
    const ckId = iterator.getByteString(4, false);
    const ckSize = iterator.getUint32Le();
    if (ckId !== 'strf') {
        throw new Error(`Expected strf, got ${JSON.stringify(ckId)}`);
    }
    if (iterator.bytesRemaining() < ckSize) {
        throw new Error('Expected strf to be complete');
    }
    const strf = (0, parse_strf_1.parseStrf)({
        iterator,
        size: ckSize,
        fccType
    });
    return {
        type: 'strh-box',
        fccType,
        handler,
        flags,
        priority,
        initialFrames,
        length,
        quality,
        rate,
        sampleSize,
        scale,
        start,
        suggestedBufferSize,
        language,
        strf
    };
};
exports.parseStrh = parseStrh;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-riff-box.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseRiffBox = void 0;
const parse_avih_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-avih.js [app-route] (ecmascript)");
const parse_idx1_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-idx1.js [app-route] (ecmascript)");
const parse_isft_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-isft.js [app-route] (ecmascript)");
const parse_list_box_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-list-box.js [app-route] (ecmascript)");
const parse_strh_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-strh.js [app-route] (ecmascript)");
const parseRiffBox = ({ size, id, iterator, stateIfExpectingSideEffects })=>{
    if (id === 'LIST') {
        return (0, parse_list_box_1.parseListBox)({
            size,
            iterator,
            stateIfExpectingSideEffects
        });
    }
    if (id === 'ISFT') {
        return Promise.resolve((0, parse_isft_1.parseIsft)({
            iterator,
            size
        }));
    }
    if (id === 'avih') {
        return Promise.resolve((0, parse_avih_1.parseAvih)({
            iterator,
            size
        }));
    }
    if (id === 'strh') {
        return Promise.resolve((0, parse_strh_1.parseStrh)({
            iterator,
            size
        }));
    }
    if (id === 'idx1') {
        return Promise.resolve((0, parse_idx1_1.parseIdx1)({
            iterator,
            size
        }));
    }
    iterator.discard(size);
    const box = {
        type: 'riff-box',
        size,
        id
    };
    return Promise.resolve(box);
};
exports.parseRiffBox = parseRiffBox;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/expect-riff-box.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.expectRiffBox = exports.postProcessRiffBox = void 0;
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const get_tracks_from_avi_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/get-tracks-from-avi.js [app-route] (ecmascript)");
const has_index_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/has-index.js [app-route] (ecmascript)");
const is_movi_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/is-movi.js [app-route] (ecmascript)");
const parse_riff_box_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-riff-box.js [app-route] (ecmascript)");
const postProcessRiffBox = async (state, box)=>{
    if (box.type === 'strh-box') {
        if (box.strf.type === 'strf-box-audio' && state.onAudioTrack) {
            const audioTrack = (0, get_tracks_from_avi_1.makeAviAudioTrack)({
                index: state.riff.getNextTrackIndex(),
                strf: box.strf
            });
            await (0, register_track_1.registerAudioTrack)({
                track: audioTrack,
                container: 'avi',
                registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,
                tracks: state.callbacks.tracks,
                logLevel: state.logLevel,
                onAudioTrack: state.onAudioTrack
            });
        }
        if (state.onVideoTrack && box.strf.type === 'strf-box-video') {
            const videoTrack = (0, get_tracks_from_avi_1.makeAviVideoTrack)({
                strh: box,
                index: state.riff.getNextTrackIndex(),
                strf: box.strf
            });
            (0, register_track_1.registerVideoTrackWhenProfileIsAvailable)({
                state,
                track: videoTrack,
                container: 'avi'
            });
        }
        state.riff.incrementNextTrackIndex();
    }
};
exports.postProcessRiffBox = postProcessRiffBox;
const expectRiffBox = async ({ iterator, stateIfExpectingSideEffects })=>{
    // Need at least 16 bytes to read LIST,size,movi,size
    if (iterator.bytesRemaining() < 16) {
        return null;
    }
    const checkpoint = iterator.startCheckpoint();
    const ckId = iterator.getByteString(4, false);
    const ckSize = iterator.getUint32Le();
    if ((0, is_movi_1.isMoviAtom)(iterator, ckId)) {
        iterator.discard(4);
        if (!stateIfExpectingSideEffects) {
            throw new Error('No state if expecting side effects');
        }
        stateIfExpectingSideEffects.mediaSection.addMediaSection({
            start: iterator.counter.getOffset(),
            size: ckSize - 4
        });
        if ((0, has_index_1.riffHasIndex)(stateIfExpectingSideEffects.structure.getRiffStructure())) {
            stateIfExpectingSideEffects.riff.lazyIdx1.triggerLoad(iterator.counter.getOffset() + ckSize - 4);
        }
        return null;
    }
    if (iterator.bytesRemaining() < ckSize) {
        checkpoint.returnToCheckpoint();
        return null;
    }
    const box = await (0, parse_riff_box_1.parseRiffBox)({
        id: ckId,
        size: ckSize,
        iterator,
        stateIfExpectingSideEffects
    });
    return box;
};
exports.expectRiffBox = expectRiffBox;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-movi.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMovi = exports.handleChunk = void 0;
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const key_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/key.js [app-route] (ecmascript)");
const parse_avc_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/parse-avc.js [app-route] (ecmascript)");
const convert_queued_sample_to_mediaparser_sample_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/convert-queued-sample-to-mediaparser-sample.js [app-route] (ecmascript)");
const get_strh_for_index_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/get-strh-for-index.js [app-route] (ecmascript)");
const handleChunk = async ({ state, ckId, ckSize })=>{
    var _a;
    const { iterator } = state;
    const offset = iterator.counter.getOffset() - 8;
    const videoChunk = ckId.match(/^([0-9]{2})dc$/);
    if (videoChunk) {
        const trackId = parseInt(videoChunk[1], 10);
        const strh = (0, get_strh_for_index_1.getStrhForIndex)(state.structure.getRiffStructure(), trackId);
        const samplesPerSecond = strh.rate / strh.scale;
        const data = iterator.getSlice(ckSize);
        const infos = (0, parse_avc_1.parseAvc)(data, state.avc);
        const keyOrDelta = (0, key_1.getKeyFrameOrDeltaFromAvcInfo)(infos);
        const info = infos.find((i)=>i.type === 'keyframe' || i.type === 'delta-frame');
        const avcProfile = infos.find((i)=>i.type === 'avc-profile');
        const ppsProfile = infos.find((i)=>i.type === 'avc-pps');
        if (avcProfile && ppsProfile && !state.riff.getAvcProfile()) {
            await state.riff.onProfile({
                pps: ppsProfile,
                sps: avcProfile
            });
            state.callbacks.tracks.setIsDone(state.logLevel);
        }
        const rawSample = {
            data,
            // We must also NOT pass a duration because if the the next sample is 0,
            // this sample would be longer. Chrome will pad it with silence.
            // If we'd pass a duration instead, it would shift the audio and we think that audio is not finished
            duration: 1 / samplesPerSecond,
            type: keyOrDelta === 'bidirectional' ? 'delta' : keyOrDelta,
            offset,
            avc: info
        };
        const maxFramesInBuffer = state.avc.getMaxFramesInBuffer();
        if (maxFramesInBuffer === null) {
            throw new Error('maxFramesInBuffer is null');
        }
        if (((_a = info === null || info === void 0 ? void 0 : info.poc) !== null && _a !== void 0 ? _a : null) === null) {
            throw new Error('poc is null');
        }
        const keyframeOffset = state.riff.sampleCounter.getKeyframeAtOffset(rawSample);
        if (keyframeOffset !== null) {
            state.riff.sampleCounter.setPocAtKeyframeOffset({
                keyframeOffset,
                poc: info.poc
            });
        }
        state.riff.queuedBFrames.addFrame({
            frame: rawSample,
            trackId,
            maxFramesInBuffer,
            timescale: samplesPerSecond
        });
        const releasedFrame = state.riff.queuedBFrames.getReleasedFrame();
        if (!releasedFrame) {
            return;
        }
        const videoSample = (0, convert_queued_sample_to_mediaparser_sample_1.convertQueuedSampleToMediaParserSample)({
            sample: releasedFrame.sample,
            state,
            trackId: releasedFrame.trackId
        });
        state.riff.sampleCounter.onVideoSample({
            trackId,
            videoSample
        });
        await state.callbacks.onVideoSample({
            videoSample,
            trackId
        });
    }
    const audioChunk = ckId.match(/^([0-9]{2})wb$/);
    if (audioChunk) {
        const trackId = parseInt(audioChunk[1], 10);
        const strh = (0, get_strh_for_index_1.getStrhForIndex)(state.structure.getRiffStructure(), trackId);
        const { strf } = strh;
        if (strf.type !== 'strf-box-audio') {
            throw new Error('audio');
        }
        const samplesPerSecond = strh.rate / strh.scale * strf.numberOfChannels;
        const nthSample = state.riff.sampleCounter.getSampleCountForTrack({
            trackId
        });
        const timeInSec = nthSample / samplesPerSecond;
        const timestamp = Math.floor(timeInSec * webcodecs_timescale_1.WEBCODECS_TIMESCALE);
        const data = iterator.getSlice(ckSize);
        const audioSample = {
            decodingTimestamp: timestamp,
            data,
            // this sample would be longer. Chrome will pad it with silence.
            // If we'd pass a duration instead, it would shift the audio and we think that audio is not finished
            duration: undefined,
            timestamp,
            type: 'key',
            offset
        };
        state.riff.sampleCounter.onAudioSample(trackId, audioSample);
        // In example.avi, we have samples with 0 data
        // Chrome fails on these
        await state.callbacks.onAudioSample({
            audioSample,
            trackId
        });
    }
};
exports.handleChunk = handleChunk;
const parseMovi = async ({ state })=>{
    const { iterator } = state;
    if (iterator.bytesRemaining() < 8) {
        return Promise.resolve();
    }
    const checkpoint = iterator.startCheckpoint();
    const ckId = iterator.getByteString(4, false);
    const ckSize = iterator.getUint32Le();
    if (iterator.bytesRemaining() < ckSize) {
        checkpoint.returnToCheckpoint();
        return Promise.resolve();
    }
    await (0, exports.handleChunk)({
        state,
        ckId,
        ckSize
    });
    const mediaSection = state.mediaSection.getMediaSectionAssertOnlyOne();
    const maxOffset = mediaSection.start + mediaSection.size;
    // Discard added zeroes
    while(iterator.counter.getOffset() < maxOffset && iterator.bytesRemaining() > 0){
        if (iterator.getUint8() !== 0) {
            iterator.counter.decrement(1);
            break;
        }
    }
};
exports.parseMovi = parseMovi;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-video-section.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMediaSection = void 0;
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const get_tracks_from_avi_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/get-tracks-from-avi.js [app-route] (ecmascript)");
const parse_movi_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-movi.js [app-route] (ecmascript)");
const parseMediaSection = async (state)=>{
    await (0, parse_movi_1.parseMovi)({
        state
    });
    const tracks = (0, get_tracks_1.getTracks)(state, false);
    if (!tracks.some((t)=>t.type === 'video' && t.codec === get_tracks_from_avi_1.TO_BE_OVERRIDDEN_LATER) && !state.callbacks.tracks.getIsDone()) {
        state.callbacks.tracks.setIsDone(state.logLevel);
    }
};
exports.parseMediaSection = parseMediaSection;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-riff-body.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseRiffBody = void 0;
const skip_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/skip.js [app-route] (ecmascript)");
const may_skip_video_data_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/may-skip-video-data.js [app-route] (ecmascript)");
const video_section_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/video-section.js [app-route] (ecmascript)");
const convert_queued_sample_to_mediaparser_sample_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/convert-queued-sample-to-mediaparser-sample.js [app-route] (ecmascript)");
const expect_riff_box_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/expect-riff-box.js [app-route] (ecmascript)");
const parse_video_section_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-video-section.js [app-route] (ecmascript)");
const parseRiffBody = async (state)=>{
    const releasedFrame = state.riff.queuedBFrames.getReleasedFrame();
    if (releasedFrame) {
        const converted = (0, convert_queued_sample_to_mediaparser_sample_1.convertQueuedSampleToMediaParserSample)({
            sample: releasedFrame.sample,
            state,
            trackId: releasedFrame.trackId
        });
        state.riff.sampleCounter.onVideoSample({
            trackId: releasedFrame.trackId,
            videoSample: converted
        });
        await state.callbacks.onVideoSample({
            videoSample: converted,
            trackId: releasedFrame.trackId
        });
        return null;
    }
    if (state.mediaSection.isCurrentByteInMediaSection(state.iterator) === 'in-section') {
        if ((0, may_skip_video_data_1.maySkipVideoData)({
            state
        }) && state.riff.getAvcProfile()) {
            const mediaSection = (0, video_section_1.getCurrentMediaSection)({
                offset: state.iterator.counter.getOffset(),
                mediaSections: state.mediaSection.getMediaSections()
            });
            if (!mediaSection) {
                throw new Error('No video section defined');
            }
            // only skipping forward in query mode
            return Promise.resolve((0, skip_1.makeSkip)(mediaSection.start + mediaSection.size));
        }
        await (0, parse_video_section_1.parseMediaSection)(state);
        return null;
    }
    const box = await (0, expect_riff_box_1.expectRiffBox)({
        iterator: state.iterator,
        stateIfExpectingSideEffects: state
    });
    if (box !== null) {
        await (0, expect_riff_box_1.postProcessRiffBox)(state, box);
        const structure = state.structure.getRiffStructure();
        structure.boxes.push(box);
    }
    return null;
};
exports.parseRiffBody = parseRiffBody;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-riff-header.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseRiffHeader = void 0;
const parseRiffHeader = (state)=>{
    const riff = state.iterator.getByteString(4, false);
    if (riff !== 'RIFF') {
        throw new Error('Not a RIFF file');
    }
    const structure = state.structure.getRiffStructure();
    const size = state.iterator.getUint32Le();
    const fileType = state.iterator.getByteString(4, false);
    if (fileType !== 'WAVE' && fileType !== 'AVI') {
        throw new Error(`File type ${fileType} not supported`);
    }
    structure.boxes.push({
        type: 'riff-header',
        fileSize: size,
        fileType
    });
    return null;
};
exports.parseRiffHeader = parseRiffHeader;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-riff.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseRiff = void 0;
const parse_riff_body_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-riff-body.js [app-route] (ecmascript)");
const parse_riff_header_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-riff-header.js [app-route] (ecmascript)");
const parseRiff = (state)=>{
    if (state.iterator.counter.getOffset() === 0) {
        return Promise.resolve((0, parse_riff_header_1.parseRiffHeader)(state));
    }
    return (0, parse_riff_body_1.parseRiffBody)(state);
};
exports.parseRiff = parseRiff;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/discard-rest-of-packet.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getRestOfPacket = exports.discardRestOfPacket = void 0;
const discardRestOfPacket = (iterator)=>{
    const next188 = 188 - iterator.counter.getOffset() % 188;
    iterator.discard(next188);
};
exports.discardRestOfPacket = discardRestOfPacket;
const getRestOfPacket = (iterator)=>{
    const next188 = 188 - iterator.counter.getOffset() % 188;
    return iterator.getSlice(next188);
};
exports.getRestOfPacket = getRestOfPacket;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-pat.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

// https://en.wikipedia.org/wiki/Program-specific_information
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseSdt = exports.parsePat = void 0;
const discard_rest_of_packet_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/discard-rest-of-packet.js [app-route] (ecmascript)");
const parsePatTable = (iterator, tableId)=>{
    iterator.getUint16(); // table ID extension
    iterator.startReadingBits();
    iterator.getBits(7); // reserved
    iterator.getBits(1); // current / next indicator;
    const sectionNumber = iterator.getBits(8);
    const lastSectionNumber = iterator.getBits(8);
    if (tableId !== 0) {
        throw new Error('Invalid table ID: ' + tableId);
    }
    const tables = [];
    for(let i = sectionNumber; i <= lastSectionNumber; i++){
        const programNumber = iterator.getBits(16); // program number
        iterator.getBits(3); // reserved
        const programMapIdentifier = iterator.getBits(13); // program map PID
        tables.push({
            type: 'transport-stream-program-association-table',
            programNumber,
            programMapIdentifier
        });
    }
    iterator.stopReadingBits();
    return {
        type: 'transport-stream-pat-box',
        tableId: tableId.toString(16),
        pat: tables
    };
};
const parsePat = (iterator)=>{
    iterator.startReadingBits();
    const tableId = iterator.getBits(8);
    iterator.getBits(1); // syntax indicator
    iterator.getBits(1); // private bit
    iterator.getBits(4);
    const sectionLength = iterator.getBits(10);
    if (sectionLength > 1021) {
        throw new Error('Invalid section length');
    }
    iterator.stopReadingBits();
    const tables = parsePatTable(iterator, tableId);
    (0, discard_rest_of_packet_1.discardRestOfPacket)(iterator);
    return tables;
};
exports.parsePat = parsePat;
const parseSdt = (iterator)=>{
    iterator.startReadingBits();
    iterator.getBits(8); // table ID
    iterator.getBits(1); // section syntax indicator
    iterator.getBits(1); // private bit
    iterator.getBits(2); // reserved
    const sectionLength = iterator.getBits(12);
    iterator.stopReadingBits();
    iterator.discard(sectionLength);
    (0, discard_rest_of_packet_1.discardRestOfPacket)(iterator);
    return {
        type: 'transport-stream-sdt-box'
    };
};
exports.parseSdt = parseSdt;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-pes.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parsePes = void 0;
const parsePes = ({ iterator, offset })=>{
    const ident = iterator.getUint24();
    if (ident !== 0x000001) {
        throw new Error(`Unexpected PES packet start code: ${ident.toString(16)}`);
    }
    const streamId = iterator.getUint8();
    iterator.getUint16(); // PES packet length, is most of the time 0, so useless
    iterator.startReadingBits();
    const markerBits = iterator.getBits(2);
    if (markerBits !== 0b10) {
        throw new Error(`Invalid marker bits: ${markerBits}`);
    }
    const scrambled = iterator.getBits(2);
    if (scrambled !== 0b00) {
        throw new Error(`Only supporting non-scrambled streams`);
    }
    const priority = iterator.getBits(1);
    iterator.getBits(1); // data alignment indicator
    iterator.getBits(1); // copy right
    iterator.getBits(1); // original or copy
    const ptsPresent = iterator.getBits(1);
    const dtsPresent = iterator.getBits(1);
    if (!ptsPresent && dtsPresent) {
        throw new Error(`DTS is present but not PTS, this is not allowed in the spec`);
    }
    iterator.getBits(1); // escr flag
    iterator.getBits(1); // es rate flag
    iterator.getBits(1); // dsm trick mode flag
    iterator.getBits(1); // additional copy info flag
    iterator.getBits(1); // crc flag
    iterator.getBits(1); // extension flag
    const pesHeaderLength = iterator.getBits(8);
    const offsetAfterHeader = iterator.counter.getOffset();
    let pts = null;
    if (!ptsPresent) {
        throw new Error(`PTS is required`);
    }
    const fourBits = iterator.getBits(4);
    if (fourBits !== 0b0011 && fourBits !== 0b0010) {
        throw new Error(`Invalid PTS marker bits: ${fourBits}`);
    }
    const pts1 = iterator.getBits(3);
    iterator.getBits(1); // marker bit
    const pts2 = iterator.getBits(15);
    iterator.getBits(1); // marker bit
    const pts3 = iterator.getBits(15);
    iterator.getBits(1); // marker bit
    pts = pts1 << 30 | pts2 << 15 | pts3;
    let dts = null;
    if (dtsPresent) {
        const _fourBits = iterator.getBits(4);
        if (_fourBits !== 0b0001) {
            throw new Error(`Invalid DTS marker bits: ${_fourBits}`);
        }
        const dts1 = iterator.getBits(3);
        iterator.getBits(1); // marker bit
        const dts2 = iterator.getBits(15);
        iterator.getBits(1); // marker bit
        const dts3 = iterator.getBits(15);
        iterator.getBits(1); // marker bit
        dts = dts1 << 30 | dts2 << 15 | dts3;
    }
    iterator.stopReadingBits();
    iterator.discard(pesHeaderLength - (iterator.counter.getOffset() - offsetAfterHeader));
    const packet = {
        dts,
        pts,
        streamId,
        priority,
        offset
    };
    return packet;
};
exports.parsePes = parsePes;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-pmt.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parsePmt = void 0;
const discard_rest_of_packet_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/discard-rest-of-packet.js [app-route] (ecmascript)");
const parsePmtTable = ({ iterator, tableId, sectionLength })=>{
    const start = iterator.counter.getOffset();
    iterator.getUint16(); // table ID extension
    iterator.startReadingBits();
    iterator.getBits(7); // reserved
    iterator.getBits(1); // current / next indicator;
    const sectionNumber = iterator.getBits(8);
    const lastSectionNumber = iterator.getBits(8);
    const tables = [];
    iterator.getBits(3); // reserved
    iterator.getBits(13); // PCR PID
    iterator.getBits(4); // reserved
    const programInfoLength = iterator.getBits(12);
    iterator.getBits(programInfoLength * 8); // program descriptor
    for(let i = sectionNumber; i <= lastSectionNumber; i++){
        const streams = [];
        while(true){
            const streamType = iterator.getBits(8);
            iterator.getBits(3); // reserved
            const elementaryPid = iterator.getBits(13);
            iterator.getBits(4); // reserved
            const esInfoLength = iterator.getBits(12);
            iterator.getBits(esInfoLength * 8);
            streams.push({
                streamType,
                pid: elementaryPid
            });
            const remaining = sectionLength - (iterator.counter.getOffset() - start);
            if (remaining <= 4) {
                break;
            }
        }
        tables.push({
            type: 'transport-stream-program-map-table',
            streams
        });
    }
    if (tables.length !== 1) {
        throw new Error('Does not PMT table with more than 1 entry, uncommon');
    }
    iterator.stopReadingBits();
    return {
        type: 'transport-stream-pmt-box',
        tableId,
        streams: tables[0].streams
    };
};
const parsePmt = (iterator)=>{
    iterator.startReadingBits();
    const tableId = iterator.getBits(8);
    iterator.getBits(1); // syntax indicator
    iterator.getBits(1); // private bit
    iterator.getBits(4);
    const sectionLength = iterator.getBits(10);
    if (sectionLength > 1021) {
        throw new Error('Invalid section length');
    }
    iterator.stopReadingBits();
    const tables = parsePmtTable({
        iterator,
        tableId,
        sectionLength
    });
    (0, discard_rest_of_packet_1.discardRestOfPacket)(iterator);
    return tables;
};
exports.parsePmt = parsePmt;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/find-separator.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.findNthSubarrayIndex = findNthSubarrayIndex;
function findNthSubarrayIndex({ array, subarray, n, startIndex, startCount }) {
    const subarrayLength = subarray.length;
    const arrayLength = array.length;
    let count = startCount;
    let i = startIndex;
    for(i; i <= arrayLength - subarrayLength; i++){
        let match = true;
        for(let j = 0; j < subarrayLength; j++){
            if (array[i + j] !== subarray[j]) {
                match = false;
                break;
            }
        }
        if (match) {
            count++;
            if (count === n) {
                return {
                    type: 'found',
                    index: i
                }; // Return the starting index of the nth subarray
            }
        }
    }
    return {
        type: 'not-found',
        index: i,
        count
    }; // Return -1 if nth subarray is not found
}
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/adts-header.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.readAdtsHeader = void 0;
const aac_codecprivate_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/aac-codecprivate.js [app-route] (ecmascript)");
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const readAdtsHeader = (buffer)=>{
    if (buffer.byteLength < 9) {
        return null;
    }
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: buffer,
        maxBytes: buffer.byteLength,
        logLevel: 'error'
    });
    iterator.startReadingBits();
    const bits = iterator.getBits(12);
    if (bits !== 0xfff) {
        throw new Error('Invalid ADTS header ');
    }
    // MPEG Version, set to 0 for MPEG-4 and 1 for MPEG-2.
    const id = iterator.getBits(1);
    if (id !== 0) {
        throw new Error('Only supporting MPEG-4 for .ts');
    }
    const layer = iterator.getBits(2);
    if (layer !== 0) {
        throw new Error('Only supporting layer 0 for .ts');
    }
    const protectionAbsent = iterator.getBits(1); // protection absent
    const audioObjectType = iterator.getBits(2); // 1 = 'AAC-LC'
    const samplingFrequencyIndex = iterator.getBits(4);
    const sampleRate = (0, aac_codecprivate_1.getSampleRateFromSampleFrequencyIndex)(samplingFrequencyIndex);
    iterator.getBits(1); // private bit
    const channelConfiguration = iterator.getBits(3);
    const codecPrivate = (0, aac_codecprivate_1.createAacCodecPrivate)({
        audioObjectType,
        sampleRate,
        channelConfiguration,
        codecPrivate: null
    });
    iterator.getBits(1); // originality
    iterator.getBits(1); // home
    iterator.getBits(1); // copyright bit
    iterator.getBits(1); // copy start
    const frameLength = iterator.getBits(13); // frame length
    iterator.getBits(11); // buffer fullness
    iterator.getBits(2); // number of AAC frames minus 1
    if (!protectionAbsent) {
        iterator.getBits(16); // crc
    }
    iterator.stopReadingBits();
    iterator.destroy();
    return {
        frameLength,
        codecPrivate,
        channelConfiguration,
        sampleRate,
        audioObjectType
    };
};
exports.readAdtsHeader = readAdtsHeader;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/handle-aac-packet.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.handleAacPacket = void 0;
const aac_codecprivate_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/aac-codecprivate.js [app-route] (ecmascript)");
const convert_audio_or_video_sample_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/convert-audio-or-video-sample.js [app-route] (ecmascript)");
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const adts_header_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/adts-header.js [app-route] (ecmascript)");
const handle_avc_packet_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/handle-avc-packet.js [app-route] (ecmascript)");
const handleAacPacket = async ({ streamBuffer, programId, offset, sampleCallbacks, logLevel, onAudioTrack, transportStream, makeSamplesStartAtZero })=>{
    var _a, _b;
    const adtsHeader = (0, adts_header_1.readAdtsHeader)(streamBuffer.getBuffer());
    if (!adtsHeader) {
        throw new Error('Invalid ADTS header - too short');
    }
    const { channelConfiguration, codecPrivate, sampleRate, audioObjectType } = adtsHeader;
    const isTrackRegistered = sampleCallbacks.tracks.getTracks().find((t)=>{
        return t.trackId === programId;
    });
    if (!isTrackRegistered) {
        const startOffset = makeSamplesStartAtZero ? Math.min(streamBuffer.pesHeader.pts, (_a = streamBuffer.pesHeader.dts) !== null && _a !== void 0 ? _a : Infinity) : 0;
        transportStream.startOffset.setOffset({
            trackId: programId,
            newOffset: startOffset
        });
        const track = {
            type: 'audio',
            codecData: {
                type: 'aac-config',
                data: codecPrivate
            },
            trackId: programId,
            originalTimescale: handle_avc_packet_1.MPEG_TIMESCALE,
            codecEnum: 'aac',
            codec: (0, aac_codecprivate_1.mapAudioObjectTypeToCodecString)(audioObjectType),
            // https://www.w3.org/TR/webcodecs-aac-codec-registration/
            // WebCodecs spec says that description should be given for AAC format
            // ChatGPT says that Transport Streams are always AAC, not ADTS
            description: codecPrivate,
            numberOfChannels: channelConfiguration,
            sampleRate,
            startInSeconds: 0,
            timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
            trackMediaTimeOffsetInTrackTimescale: 0
        };
        await (0, register_track_1.registerAudioTrack)({
            track,
            container: 'transport-stream',
            registerAudioSampleCallback: sampleCallbacks.registerAudioSampleCallback,
            tracks: sampleCallbacks.tracks,
            logLevel,
            onAudioTrack
        });
    }
    const sample = {
        decodingTimestamp: ((_b = streamBuffer.pesHeader.dts) !== null && _b !== void 0 ? _b : streamBuffer.pesHeader.pts) - transportStream.startOffset.getOffset(programId),
        timestamp: streamBuffer.pesHeader.pts - transportStream.startOffset.getOffset(programId),
        duration: undefined,
        data: streamBuffer.getBuffer(),
        type: 'key',
        offset
    };
    const audioSample = (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
        sample,
        timescale: handle_avc_packet_1.MPEG_TIMESCALE
    });
    await sampleCallbacks.onAudioSample({
        audioSample,
        trackId: programId
    });
    transportStream.lastEmittedSample.setLastEmittedSample(sample);
};
exports.handleAacPacket = handleAacPacket;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-stream-buffers.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.processFinalStreamBuffers = exports.processStreamBuffer = exports.makeTransportStreamPacketBuffer = void 0;
const combine_uint8_arrays_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/combine-uint8-arrays.js [app-route] (ecmascript)");
const find_separator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/find-separator.js [app-route] (ecmascript)");
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/get-tracks.js [app-route] (ecmascript)");
const handle_aac_packet_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/handle-aac-packet.js [app-route] (ecmascript)");
const handle_avc_packet_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/handle-avc-packet.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/traversal.js [app-route] (ecmascript)");
const makeTransportStreamPacketBuffer = ({ buffers, pesHeader, offset })=>{
    let currentBuf = buffers ? [
        buffers
    ] : [];
    let subarrayIndex = null;
    const getBuffer = ()=>{
        if (currentBuf.length === 0) {
            return new Uint8Array();
        }
        if (currentBuf.length === 1) {
            return currentBuf[0];
        }
        currentBuf = [
            (0, combine_uint8_arrays_1.combineUint8Arrays)(currentBuf)
        ];
        return currentBuf[0];
    };
    let fastFind = null;
    return {
        pesHeader,
        offset,
        getBuffer,
        addBuffer: (buffer)=>{
            currentBuf.push(buffer);
            subarrayIndex = null;
        },
        get2ndSubArrayIndex: ()=>{
            var _a, _b;
            if (subarrayIndex === null) {
                const result = (0, find_separator_1.findNthSubarrayIndex)({
                    array: getBuffer(),
                    subarray: new Uint8Array([
                        0,
                        0,
                        1,
                        9
                    ]),
                    n: 2,
                    startIndex: (_a = fastFind === null || fastFind === void 0 ? void 0 : fastFind.index) !== null && _a !== void 0 ? _a : 0,
                    startCount: (_b = fastFind === null || fastFind === void 0 ? void 0 : fastFind.count) !== null && _b !== void 0 ? _b : 0
                });
                if (result.type === 'found') {
                    subarrayIndex = result.index;
                    fastFind = null;
                } else {
                    fastFind = result;
                    return -1;
                }
            }
            return subarrayIndex;
        }
    };
};
exports.makeTransportStreamPacketBuffer = makeTransportStreamPacketBuffer;
const processStreamBuffer = async ({ streamBuffer, programId, structure, sampleCallbacks, logLevel, onAudioTrack, onVideoTrack, transportStream, makeSamplesStartAtZero, avcState })=>{
    const stream = (0, traversal_1.getStreamForId)(structure, programId);
    if (!stream) {
        throw new Error('No stream found');
    }
    // 2 = ITU-T Rec. H.262 | ISO/IEC 13818-2 Video or ISO/IEC 11172-2 constrained parameter video stream
    if (stream.streamType === 2) {
        throw new Error('H.262 video stream not supported');
    }
    // 27 = AVC / H.264 Video
    if (stream.streamType === 27) {
        await (0, handle_avc_packet_1.handleAvcPacket)({
            programId,
            streamBuffer,
            sampleCallbacks,
            logLevel,
            onVideoTrack,
            offset: streamBuffer.offset,
            transportStream,
            makeSamplesStartAtZero,
            avcState
        });
    } else if (stream.streamType === 15) {
        await (0, handle_aac_packet_1.handleAacPacket)({
            streamBuffer,
            programId,
            offset: streamBuffer.offset,
            sampleCallbacks,
            logLevel,
            onAudioTrack,
            transportStream,
            makeSamplesStartAtZero
        });
    }
    if (!sampleCallbacks.tracks.hasAllTracks()) {
        const tracksRegistered = sampleCallbacks.tracks.getTracks().length;
        const { streams } = (0, traversal_1.findProgramMapTableOrThrow)(structure);
        if ((0, get_tracks_1.filterStreamsBySupportedTypes)(streams).length === tracksRegistered) {
            sampleCallbacks.tracks.setIsDone(logLevel);
        }
    }
};
exports.processStreamBuffer = processStreamBuffer;
const processFinalStreamBuffers = async ({ structure, sampleCallbacks, logLevel, onAudioTrack, onVideoTrack, transportStream, makeSamplesStartAtZero, avcState })=>{
    for (const [programId, buffer] of transportStream.streamBuffers){
        if (buffer.getBuffer().byteLength > 0) {
            await (0, exports.processStreamBuffer)({
                streamBuffer: buffer,
                programId,
                structure,
                sampleCallbacks,
                logLevel,
                onAudioTrack,
                onVideoTrack,
                transportStream,
                makeSamplesStartAtZero,
                avcState
            });
            transportStream.streamBuffers.delete(programId);
        }
    }
};
exports.processFinalStreamBuffers = processFinalStreamBuffers;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-stream-packet.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseStream = void 0;
const discard_rest_of_packet_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/discard-rest-of-packet.js [app-route] (ecmascript)");
const process_stream_buffers_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-stream-buffers.js [app-route] (ecmascript)");
const parseStream = ({ transportStreamEntry, programId, iterator, transportStream })=>{
    const restOfPacket = (0, discard_rest_of_packet_1.getRestOfPacket)(iterator);
    const offset = iterator.counter.getOffset();
    const { streamBuffers, nextPesHeaderStore: nextPesHeader } = transportStream;
    if (!streamBuffers.has(transportStreamEntry.pid)) {
        streamBuffers.set(programId, (0, process_stream_buffers_1.makeTransportStreamPacketBuffer)({
            pesHeader: nextPesHeader.getNextPesHeader(),
            buffers: null,
            offset
        }));
    }
    const streamBuffer = streamBuffers.get(transportStreamEntry.pid);
    streamBuffer.addBuffer(restOfPacket);
};
exports.parseStream = parseStream;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-packet.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parsePacket = void 0;
const parse_pat_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-pat.js [app-route] (ecmascript)");
const parse_pes_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-pes.js [app-route] (ecmascript)");
const parse_pmt_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-pmt.js [app-route] (ecmascript)");
const parse_stream_packet_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-stream-packet.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/traversal.js [app-route] (ecmascript)");
const parsePacket = ({ iterator, structure, transportStream })=>{
    const offset = iterator.counter.getOffset();
    const syncByte = iterator.getUint8();
    if (syncByte !== 0x47) {
        throw new Error('Invalid sync byte');
    }
    iterator.startReadingBits();
    iterator.getBits(1); // transport error indicator
    const payloadUnitStartIndicator = iterator.getBits(1);
    iterator.getBits(1); // transport priority
    const programId = iterator.getBits(13);
    iterator.getBits(2); // transport scrambling control
    const adaptationFieldControl1 = iterator.getBits(1); // adaptation field control 1
    iterator.getBits(1); // adaptation field control 2
    iterator.getBits(4); // continuity counter
    iterator.stopReadingBits();
    if (adaptationFieldControl1 === 1) {
        iterator.startReadingBits();
        const adaptationFieldLength = iterator.getBits(8);
        const headerOffset = iterator.counter.getOffset();
        if (adaptationFieldLength > 0) {
            iterator.getBits(1); // discontinuity indicator
            iterator.getBits(1); // random access indicator
            iterator.getBits(1); // elementary stream priority indicator
            iterator.getBits(1); // PCR flag
            iterator.getBits(1); // OPCR flag
            iterator.getBits(1); // splicing point flag
            iterator.getBits(1); // transport private data flag
            iterator.getBits(1); // adaptation field extension flag
        }
        const remaining = adaptationFieldLength - (iterator.counter.getOffset() - headerOffset);
        iterator.stopReadingBits();
        const toDiscard = Math.max(0, remaining);
        iterator.discard(toDiscard);
    }
    const read = iterator.counter.getOffset() - offset;
    if (read === 188) {
        return null;
    }
    const pat = structure.boxes.find((b)=>b.type === 'transport-stream-pmt-box');
    const isPes = payloadUnitStartIndicator && (pat === null || pat === void 0 ? void 0 : pat.streams.find((e)=>e.pid === programId));
    if (isPes) {
        const packetPes = (0, parse_pes_1.parsePes)({
            iterator,
            offset
        });
        transportStream.nextPesHeaderStore.setNextPesHeader(packetPes);
        transportStream.observedPesHeaders.addPesHeader(packetPes);
    } else if (payloadUnitStartIndicator === 1) {
        iterator.getUint8(); // pointerField
    }
    if (programId === 0) {
        return (0, parse_pat_1.parsePat)(iterator);
    }
    if (programId === 17) {
        return (0, parse_pat_1.parseSdt)(iterator);
    }
    // PID 17 is SDT
    // https://de.wikipedia.org/wiki/MPEG-Transportstrom
    // Die Service Description Table nennt den Programmnamen (z. B. â€žZDFâ€œ) und gibt weitere Informationen der einzelnen Programme (Services); sie wird auf PID 17 Ã¼bertragen.
    const program = programId === 17 ? null : (0, traversal_1.getProgramForId)(structure, programId);
    if (program) {
        const pmt = (0, parse_pmt_1.parsePmt)(iterator);
        return pmt;
    }
    const transportStreamEntry = (0, traversal_1.getStreamForId)(structure, programId);
    if (transportStreamEntry) {
        (0, parse_stream_packet_1.parseStream)({
            transportStreamEntry,
            iterator,
            transportStream,
            programId
        });
        return null;
    }
    throw new Error('Unknown packet identifier');
};
exports.parsePacket = parsePacket;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-audio.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.processAudio = exports.canProcessAudio = void 0;
const adts_header_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/adts-header.js [app-route] (ecmascript)");
const process_stream_buffers_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-stream-buffers.js [app-route] (ecmascript)");
const canProcessAudio = ({ streamBuffer })=>{
    var _a, _b;
    const expectedLength = (_b = (_a = (0, adts_header_1.readAdtsHeader)(streamBuffer.getBuffer())) === null || _a === void 0 ? void 0 : _a.frameLength) !== null && _b !== void 0 ? _b : null;
    if (expectedLength === null) {
        return false;
    }
    if (expectedLength > streamBuffer.getBuffer().length) {
        return false;
    }
    return true;
};
exports.canProcessAudio = canProcessAudio;
const processAudio = async ({ transportStreamEntry, structure, offset, sampleCallbacks, logLevel, onAudioTrack, onVideoTrack, transportStream, makeSamplesStartAtZero, avcState })=>{
    var _a, _b;
    const { streamBuffers, nextPesHeaderStore: nextPesHeader } = transportStream;
    const streamBuffer = streamBuffers.get(transportStreamEntry.pid);
    if (!streamBuffer) {
        throw new Error('Stream buffer not found');
    }
    const expectedLength = (_b = (_a = (0, adts_header_1.readAdtsHeader)(streamBuffer.getBuffer())) === null || _a === void 0 ? void 0 : _a.frameLength) !== null && _b !== void 0 ? _b : null;
    if (expectedLength === null) {
        throw new Error('Expected length is null');
    }
    if (expectedLength > streamBuffer.getBuffer().length) {
        throw new Error('Expected length is greater than stream buffer length');
    }
    await (0, process_stream_buffers_1.processStreamBuffer)({
        streamBuffer: (0, process_stream_buffers_1.makeTransportStreamPacketBuffer)({
            buffers: streamBuffer.getBuffer().slice(0, expectedLength),
            offset,
            pesHeader: streamBuffer.pesHeader
        }),
        programId: transportStreamEntry.pid,
        structure,
        sampleCallbacks,
        logLevel,
        onAudioTrack,
        onVideoTrack,
        transportStream,
        makeSamplesStartAtZero,
        avcState
    });
    const rest = streamBuffer.getBuffer().slice(expectedLength);
    streamBuffers.set(transportStreamEntry.pid, (0, process_stream_buffers_1.makeTransportStreamPacketBuffer)({
        buffers: rest,
        pesHeader: nextPesHeader.getNextPesHeader(),
        offset
    }));
};
exports.processAudio = processAudio;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-video.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.processVideo = exports.canProcessVideo = void 0;
const process_stream_buffers_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-stream-buffers.js [app-route] (ecmascript)");
const canProcessVideo = ({ streamBuffer })=>{
    const indexOfSeparator = streamBuffer.get2ndSubArrayIndex();
    if (indexOfSeparator === -1 || indexOfSeparator === 0) {
        return false;
    }
    return true;
};
exports.canProcessVideo = canProcessVideo;
const processVideo = async ({ programId, structure, streamBuffer, sampleCallbacks, logLevel, onAudioTrack, onVideoTrack, transportStream, makeSamplesStartAtZero, avcState })=>{
    const indexOfSeparator = streamBuffer.get2ndSubArrayIndex();
    if (indexOfSeparator === -1 || indexOfSeparator === 0) {
        throw new Error('cannot process avc stream');
    }
    const buf = streamBuffer.getBuffer();
    const packet = buf.slice(0, indexOfSeparator);
    const rest = buf.slice(indexOfSeparator);
    await (0, process_stream_buffers_1.processStreamBuffer)({
        streamBuffer: (0, process_stream_buffers_1.makeTransportStreamPacketBuffer)({
            offset: streamBuffer.offset,
            pesHeader: streamBuffer.pesHeader,
            // Replace the regular 0x00000001 with 0x00000002 to avoid confusion with other 0x00000001 (?)
            buffers: packet
        }),
        programId,
        structure,
        sampleCallbacks,
        logLevel,
        onAudioTrack,
        onVideoTrack,
        transportStream,
        makeSamplesStartAtZero,
        avcState
    });
    return rest;
};
exports.processVideo = processVideo;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-sample-if-possible.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.processSampleIfPossible = void 0;
const process_audio_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-audio.js [app-route] (ecmascript)");
const process_stream_buffers_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-stream-buffers.js [app-route] (ecmascript)");
const process_video_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-video.js [app-route] (ecmascript)");
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/traversal.js [app-route] (ecmascript)");
const processSampleIfPossible = async (state)=>{
    const programMap = (0, traversal_1.findProgramMapOrNull)(state.structure.getTsStructure());
    if (!programMap) {
        return;
    }
    let processed = false;
    for (const stream of programMap.streams){
        const streamBuffer = state.transportStream.streamBuffers.get(stream.pid);
        if (!streamBuffer) {
            continue;
        }
        if (stream.streamType === 27) {
            if ((0, process_video_1.canProcessVideo)({
                streamBuffer
            })) {
                const rest = await (0, process_video_1.processVideo)({
                    programId: stream.pid,
                    structure: state.structure.getTsStructure(),
                    streamBuffer,
                    sampleCallbacks: state.callbacks,
                    logLevel: state.logLevel,
                    onAudioTrack: state.onAudioTrack,
                    onVideoTrack: state.onVideoTrack,
                    transportStream: state.transportStream,
                    makeSamplesStartAtZero: state.makeSamplesStartAtZero,
                    avcState: state.avc
                });
                state.transportStream.streamBuffers.delete(stream.pid);
                state.transportStream.streamBuffers.set(stream.pid, (0, process_stream_buffers_1.makeTransportStreamPacketBuffer)({
                    pesHeader: state.transportStream.nextPesHeaderStore.getNextPesHeader(),
                    buffers: rest,
                    offset: state.iterator.counter.getOffset()
                }));
                processed = true;
                break;
            }
        }
        if (stream.streamType === 15) {
            if ((0, process_audio_1.canProcessAudio)({
                streamBuffer
            })) {
                await (0, process_audio_1.processAudio)({
                    structure: state.structure.getTsStructure(),
                    offset: state.iterator.counter.getOffset(),
                    sampleCallbacks: state.callbacks,
                    logLevel: state.logLevel,
                    onAudioTrack: state.onAudioTrack,
                    onVideoTrack: state.onVideoTrack,
                    transportStream: state.transportStream,
                    makeSamplesStartAtZero: state.makeSamplesStartAtZero,
                    transportStreamEntry: stream,
                    avcState: state.avc
                });
                processed = true;
                break;
            }
        }
    }
    return processed;
};
exports.processSampleIfPossible = processSampleIfPossible;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-transport-stream.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseTransportStream = void 0;
const parse_packet_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-packet.js [app-route] (ecmascript)");
const process_sample_if_possible_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-sample-if-possible.js [app-route] (ecmascript)");
const process_stream_buffers_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/process-stream-buffers.js [app-route] (ecmascript)");
const parseTransportStream = async (state)=>{
    const structure = state.structure.getTsStructure();
    const processed = await (0, process_sample_if_possible_1.processSampleIfPossible)(state);
    if (processed) {
        return Promise.resolve(null);
    }
    const { iterator } = state;
    if (iterator.bytesRemaining() < 188) {
        return Promise.resolve(null);
    }
    const packet = (0, parse_packet_1.parsePacket)({
        iterator,
        structure,
        transportStream: state.transportStream
    });
    if (packet) {
        structure.boxes.push(packet);
    }
    if (iterator.bytesRemaining() === 0) {
        await (0, process_stream_buffers_1.processFinalStreamBuffers)({
            transportStream: state.transportStream,
            structure,
            sampleCallbacks: state.callbacks,
            logLevel: state.logLevel,
            onAudioTrack: state.onAudioTrack,
            onVideoTrack: state.onVideoTrack,
            makeSamplesStartAtZero: state.makeSamplesStartAtZero,
            avcState: state.avc
        });
    }
    return Promise.resolve(null);
};
exports.parseTransportStream = parseTransportStream;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-data.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseData = void 0;
const skip_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/skip.js [app-route] (ecmascript)");
const may_skip_video_data_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/may-skip-video-data.js [app-route] (ecmascript)");
const parseData = ({ state })=>{
    const { iterator } = state;
    const ckSize = iterator.getUint32Le(); // chunkSize
    const box = {
        type: 'wav-data',
        dataSize: ckSize
    };
    state.structure.getWavStructure().boxes.push(box);
    state.callbacks.tracks.setIsDone(state.logLevel);
    state.mediaSection.addMediaSection({
        size: ckSize,
        start: iterator.counter.getOffset()
    });
    if ((0, may_skip_video_data_1.maySkipVideoData)({
        state
    })) {
        // Skipping only in query mode
        return Promise.resolve((0, skip_1.makeSkip)(iterator.counter.getOffset() + ckSize));
    }
    return Promise.resolve(null);
};
exports.parseData = parseData;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-fact.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseFact = void 0;
const parseFact = ({ state })=>{
    const { iterator } = state;
    const size = iterator.getUint32Le();
    if (size !== 4) {
        throw new Error(`Expected size 4 for fact box, got ${size}`);
    }
    const numberOfSamplesPerChannel = iterator.getUint32Le();
    const factBox = {
        type: 'wav-fact',
        numberOfSamplesPerChannel
    };
    state.structure.getWavStructure().boxes.push(factBox);
    return Promise.resolve(null);
};
exports.parseFact = parseFact;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/subformats.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.subformatIsIeeeFloat = exports.subformatIsPcm = exports.KSDATAFORMAT_SUBTYPE_IEEE_FLOAT = exports.WMMEDIASUBTYPE_PCM = void 0;
exports.WMMEDIASUBTYPE_PCM = [
    1,
    0,
    0,
    0,
    0,
    0,
    16,
    0,
    128,
    0,
    0,
    170,
    0,
    56,
    155,
    113
];
exports.KSDATAFORMAT_SUBTYPE_IEEE_FLOAT = [
    3,
    0,
    0,
    0,
    0,
    0,
    16,
    0,
    128,
    0,
    0,
    170,
    0,
    56,
    155,
    113
];
const subformatIsPcm = (subformat)=>{
    return subformat.every((value, index)=>value === exports.WMMEDIASUBTYPE_PCM[index]);
};
exports.subformatIsPcm = subformatIsPcm;
const subformatIsIeeeFloat = (subformat)=>{
    return subformat.every((value, index)=>value === exports.KSDATAFORMAT_SUBTYPE_IEEE_FLOAT[index]);
};
exports.subformatIsIeeeFloat = subformatIsIeeeFloat;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-fmt.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseFmt = void 0;
exports.getChannelsFromMask = getChannelsFromMask;
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const subformats_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/subformats.js [app-route] (ecmascript)");
const CHANNELS = {
    0: 'Front Left',
    1: 'Front Right',
    2: 'Front Center',
    3: 'Low Frequency',
    4: 'Back Left',
    5: 'Back Right',
    6: 'Front Left of Center',
    7: 'Front Right of Center',
    8: 'Back Center',
    9: 'Side Left',
    10: 'Side Right',
    11: 'Top Center',
    12: 'Top Front Left',
    13: 'Top Front Center',
    14: 'Top Front Right',
    15: 'Top Back Left',
    16: 'Top Back Center',
    17: 'Top Back Right'
};
function getChannelsFromMask(channelMask) {
    const channels = [];
    for(let bit = 0; bit < 18; bit++){
        if ((channelMask & 1 << bit) !== 0) {
            const channelName = CHANNELS[bit];
            if (channelName) {
                channels.push(channelName);
            } else {
                channels.push(`Unknown Channel (bit ${bit})`);
            }
        }
    }
    return channels;
}
const parseFmt = async ({ state })=>{
    const { iterator } = state;
    const ckSize = iterator.getUint32Le(); // chunkSize
    const box = iterator.startBox(ckSize);
    const audioFormat = iterator.getUint16Le();
    if (audioFormat !== 1 && audioFormat !== 65534) {
        throw new Error(`Only supporting WAVE with PCM audio format, but got ${audioFormat}`);
    }
    const numberOfChannels = iterator.getUint16Le();
    const sampleRate = iterator.getUint32Le();
    const byteRate = iterator.getUint32Le();
    const blockAlign = iterator.getUint16Le();
    const bitsPerSample = iterator.getUint16Le();
    const format = bitsPerSample === 16 ? 'pcm-s16' : bitsPerSample === 32 ? 'pcm-s32' : bitsPerSample === 24 ? 'pcm-s24' : null;
    if (format === null) {
        throw new Error(`Unsupported bits per sample: ${bitsPerSample}`);
    }
    const wavHeader = {
        bitsPerSample,
        blockAlign,
        byteRate,
        numberOfChannels,
        sampleRate,
        type: 'wav-fmt'
    };
    state.structure.getWavStructure().boxes.push(wavHeader);
    if (audioFormat === 65534) {
        const extraSize = iterator.getUint16Le();
        if (extraSize !== 22) {
            throw new Error(`Only supporting WAVE with 22 extra bytes, but got ${extraSize} bytes extra size`);
        }
        iterator.getUint16Le(); // valid bits per sample
        const channelMask = iterator.getUint32Le();
        const subFormat = iterator.getSlice(16);
        // check if same as [ 1, 0, 0, 0, 0, 0, 16, 0, 128, 0, 0, 170, 0, 56, 155, 113 ]
        if (subFormat.length !== 16) {
            throw new Error(`Only supporting WAVE with PCM audio format, but got ${subFormat.length}`);
        }
        if ((0, subformats_1.subformatIsPcm)(subFormat)) {
        // is pcm
        } else if ((0, subformats_1.subformatIsIeeeFloat)(subFormat)) {
        // is ieee float
        } else {
            throw new Error(`Unsupported subformat: ${subFormat}`);
        }
        const channels = getChannelsFromMask(channelMask);
        wavHeader.numberOfChannels = channels.length;
    }
    await (0, register_track_1.registerAudioTrack)({
        track: {
            type: 'audio',
            codec: format,
            codecData: null,
            description: undefined,
            codecEnum: format,
            numberOfChannels,
            sampleRate,
            originalTimescale: 1000000,
            trackId: 0,
            startInSeconds: 0,
            timescale: webcodecs_timescale_1.WEBCODECS_TIMESCALE,
            trackMediaTimeOffsetInTrackTimescale: 0
        },
        container: 'wav',
        registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,
        tracks: state.callbacks.tracks,
        logLevel: state.logLevel,
        onAudioTrack: state.onAudioTrack
    });
    box.expectNoMoreBytes();
    return Promise.resolve(null);
};
exports.parseFmt = parseFmt;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-header.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseHeader = void 0;
const parseHeader = ({ state })=>{
    const fileSize = state.iterator.getUint32Le();
    const fileType = state.iterator.getByteString(4, false);
    if (fileType !== 'WAVE') {
        throw new Error(`Expected WAVE, got ${fileType}`);
    }
    const header = {
        type: 'wav-header',
        fileSize
    };
    state.structure.getWavStructure().boxes.push(header);
    return Promise.resolve(null);
};
exports.parseHeader = parseHeader;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-id3.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseId3 = void 0;
// non-standard, we discard it in favor of LIST boxes
const parseId3 = ({ state })=>{
    const { iterator } = state;
    const id3Size = iterator.getUint32Le();
    iterator.discard(id3Size);
    const id3Box = {
        type: 'wav-id3'
    };
    state.structure.getWavStructure().boxes.push(id3Box);
    return Promise.resolve(null);
};
exports.parseId3 = parseId3;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-junk.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseJunk = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const parseJunk = ({ state })=>{
    const { iterator } = state;
    const ckSize = iterator.getUint32Le(); // chunkSize
    log_1.Log.trace(state.logLevel, `Skipping JUNK chunk of size ${ckSize}`);
    iterator.discard(ckSize);
    return Promise.resolve(null);
};
exports.parseJunk = parseJunk;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-list.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseList = void 0;
const parseList = ({ state })=>{
    const { iterator } = state;
    const ckSize = iterator.getUint32Le(); // chunkSize
    const box = iterator.startBox(ckSize);
    const startOffset = iterator.counter.getOffset();
    const type = iterator.getByteString(4, false);
    if (type !== 'INFO') {
        iterator.discard(ckSize - 4);
        return Promise.resolve(null);
    }
    const metadata = [];
    const remainingBytes = ()=>ckSize - (iterator.counter.getOffset() - startOffset);
    while(remainingBytes() > 0){
        // Padding
        // https://discord.com/channels/809501355504959528/1308803317480292482/1343979547246333983
        // Indie_Hacker_Podcast (2).wav
        const byte = iterator.getUint8();
        if (byte === 0) {
            continue;
        }
        iterator.counter.decrement(1);
        const key = iterator.getByteString(4, false);
        const size = iterator.getUint32Le();
        const value = iterator.getByteString(size, true);
        metadata.push({
            key,
            trackId: null,
            value
        });
    }
    const wavList = {
        type: 'wav-list',
        metadata
    };
    state.structure.getWavStructure().boxes.push(wavList);
    box.expectNoMoreBytes();
    return Promise.resolve(null);
};
exports.parseList = parseList;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-media-section.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseMediaSection = void 0;
const convert_audio_or_video_sample_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/convert-audio-or-video-sample.js [app-route] (ecmascript)");
const get_seeking_byte_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/get-seeking-byte.js [app-route] (ecmascript)");
const parseMediaSection = async ({ state })=>{
    const { iterator } = state;
    const structure = state.structure.getWavStructure();
    const videoSection = state.mediaSection.getMediaSectionAssertOnlyOne();
    const maxOffset = videoSection.start + videoSection.size;
    const maxRead = maxOffset - iterator.counter.getOffset();
    const offset = iterator.counter.getOffset();
    const fmtBox = structure.boxes.find((box)=>box.type === 'wav-fmt');
    if (!fmtBox) {
        throw new Error('Expected fmt box');
    }
    const toRead = Math.min(maxRead, fmtBox.sampleRate * fmtBox.blockAlign / get_seeking_byte_1.WAVE_SAMPLES_PER_SECOND);
    const duration = toRead / (fmtBox.sampleRate * fmtBox.blockAlign);
    const timestamp = (offset - videoSection.start) / (fmtBox.sampleRate * fmtBox.blockAlign);
    const data = iterator.getSlice(toRead);
    const audioSample = (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
        sample: {
            decodingTimestamp: timestamp,
            data,
            duration,
            timestamp,
            type: 'key',
            offset
        },
        timescale: 1
    });
    await state.callbacks.onAudioSample({
        audioSample,
        trackId: 0
    });
    return null;
};
exports.parseMediaSection = parseMediaSection;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-wav.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseWav = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const parse_data_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-data.js [app-route] (ecmascript)");
const parse_fact_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-fact.js [app-route] (ecmascript)");
const parse_fmt_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-fmt.js [app-route] (ecmascript)");
const parse_header_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-header.js [app-route] (ecmascript)");
const parse_id3_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-id3.js [app-route] (ecmascript)");
const parse_junk_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-junk.js [app-route] (ecmascript)");
const parse_list_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-list.js [app-route] (ecmascript)");
const parse_media_section_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-media-section.js [app-route] (ecmascript)");
const parseWav = (state)=>{
    const { iterator } = state;
    const insideMediaSection = state.mediaSection.isCurrentByteInMediaSection(iterator);
    if (insideMediaSection === 'in-section') {
        return (0, parse_media_section_1.parseMediaSection)({
            state
        });
    }
    const type = iterator.getByteString(4, false).toLowerCase();
    log_1.Log.trace(state.logLevel, `Processing box type ${type}`);
    if (type === 'riff') {
        return (0, parse_header_1.parseHeader)({
            state
        });
    }
    if (type === 'fmt') {
        return (0, parse_fmt_1.parseFmt)({
            state
        });
    }
    if (type === 'data') {
        return (0, parse_data_1.parseData)({
            state
        });
    }
    if (type === 'list') {
        return (0, parse_list_1.parseList)({
            state
        });
    }
    if (type === 'id3') {
        return (0, parse_id3_1.parseId3)({
            state
        });
    }
    if (type === 'junk' || type === 'fllr' || type === 'bext' || type === 'cue') {
        return (0, parse_junk_1.parseJunk)({
            state
        });
    }
    if (type === 'fact') {
        return (0, parse_fact_1.parseFact)({
            state
        });
    }
    if (type === '\u0000') {
        return Promise.resolve(null);
    }
    throw new Error(`Unknown WAV box type ${type}`);
};
exports.parseWav = parseWav;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/get-byte-for-cues.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getByteForSeek = void 0;
const truthy_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/truthy.js [app-route] (ecmascript)");
const all_segments_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/all-segments.js [app-route] (ecmascript)");
const getByteForSeek = ({ seekHeadSegment, offset })=>{
    const value = seekHeadSegment.value.map((v)=>{
        if (v.type !== 'Seek') {
            return null;
        }
        const seekId = v.value.find((_v)=>{
            // cues
            return _v.type === 'SeekID' && _v.value === all_segments_1.matroskaElements.Cues;
        });
        if (!seekId) {
            return null;
        }
        const seekPosition = v.value.find((_v)=>{
            return _v.type === 'SeekPosition';
        });
        if (!seekPosition) {
            return false;
        }
        return seekPosition.value;
    }).filter(truthy_1.truthy);
    if (value.length === 0) {
        return null;
    }
    return value[0].value + offset;
};
exports.getByteForSeek = getByteForSeek;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.expectSegment = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const parse_ebml_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/parse-ebml.js [app-route] (ecmascript)");
const all_segments_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/all-segments.js [app-route] (ecmascript)");
const expectSegment = async ({ statesForProcessing, isInsideSegment, iterator, logLevel, mediaSectionState })=>{
    var _a;
    if (iterator.bytesRemaining() === 0) {
        throw new Error('has no bytes');
    }
    const offset = iterator.counter.getOffset();
    const { returnToCheckpoint } = iterator.startCheckpoint();
    const segmentId = iterator.getMatroskaSegmentId();
    if (segmentId === null) {
        returnToCheckpoint();
        return null;
    }
    const offsetBeforeVInt = iterator.counter.getOffset();
    const size = iterator.getVint();
    const offsetAfterVInt = iterator.counter.getOffset();
    if (size === null) {
        returnToCheckpoint();
        return null;
    }
    const bytesRemainingNow = iterator.bytesRemaining();
    log_1.Log.trace(logLevel, 'Segment ID:', (_a = all_segments_1.ebmlMap[segmentId]) === null || _a === void 0 ? void 0 : _a.name, 'Size:' + size, bytesRemainingNow);
    if (segmentId === all_segments_1.matroskaElements.Segment) {
        if (!statesForProcessing) {
            throw new Error('States for processing are required');
        }
        statesForProcessing.webmState.addSegment({
            start: offset,
            size
        });
        const newSegment = {
            type: 'Segment',
            minVintWidth: offsetAfterVInt - offsetBeforeVInt,
            value: []
        };
        return newSegment;
    }
    if (segmentId === all_segments_1.matroskaElements.Cluster) {
        if (isInsideSegment === null) {
            throw new Error('Expected to be inside segment');
        }
        if (!statesForProcessing) {
            throw new Error('States for processing are required');
        }
        if (mediaSectionState) {
            mediaSectionState.addMediaSection({
                start: offset,
                size
            });
        }
        statesForProcessing.webmState.addCluster({
            start: offset,
            size: size + (offsetAfterVInt - offset),
            segment: isInsideSegment.index
        });
        const newSegment = {
            type: 'Cluster',
            minVintWidth: offsetAfterVInt - offsetBeforeVInt,
            value: []
        };
        return newSegment;
    }
    if (bytesRemainingNow < size) {
        returnToCheckpoint();
        return null;
    }
    const segment = await parseSegment({
        segmentId,
        length: size,
        headerReadSoFar: iterator.counter.getOffset() - offset,
        statesForProcessing,
        iterator,
        logLevel
    });
    return segment;
};
exports.expectSegment = expectSegment;
const parseSegment = async ({ segmentId, length, iterator, headerReadSoFar, statesForProcessing, logLevel })=>{
    if (length < 0) {
        throw new Error(`Expected length of ${segmentId} to be greater or equal 0`);
    }
    iterator.counter.decrement(headerReadSoFar);
    const offset = iterator.counter.getOffset();
    const ebml = await (0, parse_ebml_1.parseEbml)(iterator, statesForProcessing, logLevel);
    if (ebml === null) {
        return null;
    }
    if (!statesForProcessing) {
        return ebml;
    }
    const remapped = await (0, parse_ebml_1.postprocessEbml)({
        offset,
        ebml,
        statesForProcessing
    });
    return remapped;
};
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/state-for-processing.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.selectStatesForProcessing = void 0;
const selectStatesForProcessing = ({ callbacks, logLevel, onAudioTrack, onVideoTrack, structure, webm, avc })=>{
    return {
        webmState: webm,
        callbacks,
        logLevel,
        onAudioTrack,
        onVideoTrack,
        structureState: structure,
        avcState: avc
    };
};
exports.selectStatesForProcessing = selectStatesForProcessing;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/parse-webm-header.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseWebm = void 0;
const skip_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/skip.js [app-route] (ecmascript)");
const may_skip_video_data_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/may-skip-video-data.js [app-route] (ecmascript)");
const get_byte_for_cues_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/get-byte-for-cues.js [app-route] (ecmascript)");
const segments_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments.js [app-route] (ecmascript)");
const state_for_processing_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/state-for-processing.js [app-route] (ecmascript)");
// Parsing according to https://darkcoding.net/software/reading-mediarecorders-webm-opus-output/
const parseWebm = async (state)=>{
    const structure = state.structure.getMatroskaStructure();
    const { iterator } = state;
    const offset = iterator.counter.getOffset();
    const isInsideSegment = state.webm.isInsideSegment(iterator);
    const isInsideCluster = state.webm.isInsideCluster(offset);
    const results = await (0, segments_1.expectSegment)({
        iterator,
        logLevel: state.logLevel,
        statesForProcessing: (0, state_for_processing_1.selectStatesForProcessing)(state),
        isInsideSegment,
        mediaSectionState: state.mediaSection
    });
    if ((results === null || results === void 0 ? void 0 : results.type) === 'SeekHead') {
        const position = (0, get_byte_for_cues_1.getByteForSeek)({
            seekHeadSegment: results,
            offset
        });
        if (position !== null) {
            state.webm.cues.triggerLoad(position, offset);
        }
    }
    if (results === null) {
        return null;
    }
    if (isInsideCluster) {
        if ((0, may_skip_video_data_1.maySkipVideoData)({
            state
        })) {
            return (0, skip_1.makeSkip)(Math.min(state.contentLength, isInsideCluster.size + isInsideCluster.start));
        }
        const segments = structure.boxes.filter((box)=>box.type === 'Segment');
        const segment = segments[isInsideCluster.segment];
        if (!segment) {
            throw new Error('Expected segment');
        }
        const clusters = segment.value.find((box)=>box.type === 'Cluster');
        if (!clusters) {
            throw new Error('Expected cluster');
        }
        // let's not add it to the cluster
        if (results.type !== 'Block' && results.type !== 'SimpleBlock') {
            clusters.value.push(results);
        }
    } else if (isInsideSegment) {
        const segments = structure.boxes.filter((box)=>box.type === 'Segment');
        const segment = segments[isInsideSegment.index];
        if (!segment) {
            throw new Error('Expected segment');
        }
        segment.value.push(results);
    } else {
        structure.boxes.push(results);
    }
    return null;
};
exports.parseWebm = parseWebm;
}),
"[project]/node_modules/@remotion/media-parser/dist/init-video.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.initVideo = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/traversal.js [app-route] (ecmascript)");
const errors_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/errors.js [app-route] (ecmascript)");
const get_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-tracks.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const register_track_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/register-track.js [app-route] (ecmascript)");
const initVideo = async ({ state })=>{
    var _a;
    const fileType = state.iterator.detectFileType();
    const { mimeType, name, contentLength } = state;
    if (fileType.type === 'riff') {
        log_1.Log.verbose(state.logLevel, 'Detected RIFF container');
        state.structure.setStructure({
            type: 'riff',
            boxes: []
        });
        return;
    }
    if ((_a = state.m3uPlaylistContext) === null || _a === void 0 ? void 0 : _a.mp4HeaderSegment) {
        log_1.Log.verbose(state.logLevel, 'Detected ISO Base Media segment');
        const moovAtom = (0, traversal_1.getMoovFromFromIsoStructure)(state.m3uPlaylistContext.mp4HeaderSegment);
        if (!moovAtom) {
            throw new Error('No moov box found');
        }
        const tracks = (0, get_tracks_1.getTracksFromMoovBox)(moovAtom);
        for (const track of tracks.filter((t)=>t.type === 'video')){
            await (0, register_track_1.registerVideoTrack)({
                track,
                container: 'mp4',
                logLevel: state.logLevel,
                onVideoTrack: state.onVideoTrack,
                registerVideoSampleCallback: state.callbacks.registerVideoSampleCallback,
                tracks: state.callbacks.tracks
            });
        }
        for (const track of tracks.filter((t)=>t.type === 'audio')){
            await (0, register_track_1.registerAudioTrack)({
                track,
                container: 'mp4',
                registerAudioSampleCallback: state.callbacks.registerAudioSampleCallback,
                tracks: state.callbacks.tracks,
                logLevel: state.logLevel,
                onAudioTrack: state.onAudioTrack
            });
        }
        state.callbacks.tracks.setIsDone(state.logLevel);
        state.structure.setStructure({
            type: 'iso-base-media',
            boxes: []
        });
        return;
    }
    if (fileType.type === 'iso-base-media') {
        log_1.Log.verbose(state.logLevel, 'Detected ISO Base Media container');
        state.structure.setStructure({
            type: 'iso-base-media',
            boxes: []
        });
        return;
    }
    if (fileType.type === 'webm') {
        log_1.Log.verbose(state.logLevel, 'Detected Matroska container');
        state.structure.setStructure({
            boxes: [],
            type: 'matroska'
        });
        return;
    }
    if (fileType.type === 'transport-stream') {
        log_1.Log.verbose(state.logLevel, 'Detected MPEG-2 Transport Stream');
        state.mediaSection.addMediaSection({
            start: 0,
            size: contentLength
        });
        state.structure.setStructure({
            boxes: [],
            type: 'transport-stream'
        });
        return;
    }
    if (fileType.type === 'mp3') {
        log_1.Log.verbose(state.logLevel, 'Detected MP3');
        const structure = {
            boxes: [],
            type: 'mp3'
        };
        state.structure.setStructure(structure);
        return;
    }
    if (fileType.type === 'wav') {
        log_1.Log.verbose(state.logLevel, 'Detected WAV');
        const structure = {
            boxes: [],
            type: 'wav'
        };
        state.structure.setStructure(structure);
        return;
    }
    if (fileType.type === 'flac') {
        log_1.Log.verbose(state.logLevel, 'Detected FLAC');
        const structure = {
            boxes: [],
            type: 'flac'
        };
        state.structure.setStructure(structure);
        return;
    }
    if (fileType.type === 'aac') {
        log_1.Log.verbose(state.logLevel, 'Detected AAC');
        state.structure.setStructure({
            type: 'aac',
            boxes: []
        });
        return;
    }
    if (fileType.type === 'm3u') {
        log_1.Log.verbose(state.logLevel, 'Detected M3U');
        state.structure.setStructure({
            type: 'm3u',
            boxes: []
        });
        return;
    }
    if (fileType.type === 'pdf') {
        return Promise.reject(new errors_1.IsAPdfError({
            message: 'GIF files are not supported',
            mimeType,
            sizeInBytes: contentLength,
            fileName: name
        }));
    }
    if (fileType.type === 'bmp' || fileType.type === 'jpeg' || fileType.type === 'png' || fileType.type === 'webp' || fileType.type === 'gif') {
        return Promise.reject(new errors_1.IsAnImageError({
            message: 'Image files are not supported',
            imageType: fileType.type,
            dimensions: fileType.dimensions,
            mimeType,
            sizeInBytes: contentLength,
            fileName: name
        }));
    }
    if (fileType.type === 'unknown') {
        return Promise.reject(new errors_1.IsAnUnsupportedFileTypeError({
            message: 'Unknown file format',
            mimeType,
            sizeInBytes: contentLength,
            fileName: name
        }));
    }
    return Promise.reject(new Error('Unknown video format ' + fileType));
};
exports.initVideo = initVideo;
}),
"[project]/node_modules/@remotion/media-parser/dist/run-parse-iteration.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.runParseIteration = void 0;
const parse_aac_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/aac/parse-aac.js [app-route] (ecmascript)");
const parse_flac_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/parse-flac.js [app-route] (ecmascript)");
const parse_boxes_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/parse-boxes.js [app-route] (ecmascript)");
const parse_m3u_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/parse-m3u.js [app-route] (ecmascript)");
const parse_mp3_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/parse-mp3.js [app-route] (ecmascript)");
const parse_riff_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/parse-riff.js [app-route] (ecmascript)");
const parse_transport_stream_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/parse-transport-stream.js [app-route] (ecmascript)");
const parse_wav_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/parse-wav.js [app-route] (ecmascript)");
const parse_webm_header_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/parse-webm-header.js [app-route] (ecmascript)");
const init_video_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/init-video.js [app-route] (ecmascript)");
const runParseIteration = async ({ state })=>{
    const structure = state.structure.getStructureOrNull();
    // m3u8 is busy parsing the chunks once the manifest has been read
    if (structure && structure.type === 'm3u') {
        return (0, parse_m3u_1.parseM3u)({
            state
        });
    }
    if (structure === null) {
        await (0, init_video_1.initVideo)({
            state
        });
        return null;
    }
    if (structure.type === 'riff') {
        return (0, parse_riff_1.parseRiff)(state);
    }
    if (structure.type === 'mp3') {
        return (0, parse_mp3_1.parseMp3)(state);
    }
    if (structure.type === 'iso-base-media') {
        return (0, parse_boxes_1.parseIsoBaseMedia)(state);
    }
    if (structure.type === 'matroska') {
        return (0, parse_webm_header_1.parseWebm)(state);
    }
    if (structure.type === 'transport-stream') {
        return (0, parse_transport_stream_1.parseTransportStream)(state);
    }
    if (structure.type === 'wav') {
        return (0, parse_wav_1.parseWav)(state);
    }
    if (structure.type === 'aac') {
        return (0, parse_aac_1.parseAac)(state);
    }
    if (structure.type === 'flac') {
        return (0, parse_flac_1.parseFlac)({
            state,
            iterator: state.iterator
        });
    }
    return Promise.reject(new Error('Unknown video format ' + structure));
};
exports.runParseIteration = runParseIteration;
}),
"[project]/node_modules/@remotion/media-parser/dist/parse-loop.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.parseLoop = void 0;
const check_if_done_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/check-if-done.js [app-route] (ecmascript)");
const emit_all_info_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/emit-all-info.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const make_progress_object_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/make-progress-object.js [app-route] (ecmascript)");
const perform_seek_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/perform-seek.js [app-route] (ecmascript)");
const run_parse_iteration_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/run-parse-iteration.js [app-route] (ecmascript)");
const work_on_seek_request_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/work-on-seek-request.js [app-route] (ecmascript)");
const fetchMoreData = async (state)=>{
    await state.controller._internals.checkForAbortAndPause();
    const result = await state.currentReader.getCurrent().reader.read();
    if (result.value) {
        state.iterator.addData(result.value);
    }
    return result.done;
};
const parseLoop = async ({ state, throttledState, onError })=>{
    var _a;
    let iterationWithThisOffset = 0;
    while(!await (0, check_if_done_1.checkIfDone)(state)){
        await state.controller._internals.checkForAbortAndPause();
        await (0, work_on_seek_request_1.workOnSeekRequest)((0, work_on_seek_request_1.getWorkOnSeekRequestOptions)(state));
        const offsetBefore = state.iterator.counter.getOffset();
        const readStart = Date.now();
        while(state.iterator.bytesRemaining() < 0){
            const done = await fetchMoreData(state);
            if (done) {
                break;
            }
        }
        if (iterationWithThisOffset > 0 || state.iterator.bytesRemaining() <= 100000) {
            await fetchMoreData(state);
        }
        state.timings.timeReadingData += Date.now() - readStart;
        (_a = throttledState.update) === null || _a === void 0 ? void 0 : _a.call(throttledState, ()=>(0, make_progress_object_1.makeProgressObject)(state));
        if (!state.errored) {
            log_1.Log.trace(state.logLevel, `Continuing parsing of file, currently at position ${state.iterator.counter.getOffset()}/${state.contentLength} (0x${state.iterator.counter.getOffset().toString(16)})`);
            if (iterationWithThisOffset > 300 && state.structure.getStructure().type !== 'm3u') {
                throw new Error('Infinite loop detected. The parser is not progressing. This is likely a bug in the parser. You can report this at https://remotion.dev/report and we will fix it as soon as possible.');
            }
            try {
                await (0, emit_all_info_1.triggerInfoEmit)(state);
                await state.controller._internals.checkForAbortAndPause();
                const parseLoopStart = Date.now();
                const result = await (0, run_parse_iteration_1.runParseIteration)({
                    state
                });
                state.timings.timeInParseLoop += Date.now() - parseLoopStart;
                if (result !== null && result.action === 'fetch-more-data') {
                    log_1.Log.verbose(state.logLevel, `Need to fetch ${result.bytesNeeded} more bytes before we can continue`);
                    const startBytesRemaining = state.iterator.bytesRemaining();
                    while(true){
                        const done = await fetchMoreData(state);
                        if (done) {
                            break;
                        }
                        if (state.iterator.bytesRemaining() - startBytesRemaining >= result.bytesNeeded) {
                            break;
                        }
                    }
                    continue;
                }
                if (result !== null && result.action === 'skip') {
                    state.increaseSkippedBytes(result.skipTo - state.iterator.counter.getOffset());
                    if (result.skipTo === state.contentLength) {
                        state.iterator.discard(result.skipTo - state.iterator.counter.getOffset());
                        log_1.Log.verbose(state.logLevel, 'Skipped to end of file, not fetching.');
                        break;
                    }
                    const seekStart = Date.now();
                    await (0, perform_seek_1.performSeek)({
                        seekTo: result.skipTo,
                        userInitiated: false,
                        controller: state.controller,
                        mediaSection: state.mediaSection,
                        iterator: state.iterator,
                        logLevel: state.logLevel,
                        mode: state.mode,
                        contentLength: state.contentLength,
                        seekInfiniteLoop: state.seekInfiniteLoop,
                        currentReader: state.currentReader,
                        readerInterface: state.readerInterface,
                        fields: state.fields,
                        src: state.src,
                        discardReadBytes: state.discardReadBytes,
                        prefetchCache: state.prefetchCache,
                        isoState: state.iso
                    });
                    state.timings.timeSeeking += Date.now() - seekStart;
                }
            } catch (e) {
                const err = await onError(e);
                if (!err.action) {
                    throw new Error('onError was used but did not return an "action" field. See docs for this API on how to use onError.');
                }
                if (err.action === 'fail') {
                    throw e;
                }
                if (err.action === 'download') {
                    state.errored = e;
                    log_1.Log.verbose(state.logLevel, 'Error was handled by onError and deciding to continue.');
                }
            }
        }
        const timeFreeStart = Date.now();
        await state.discardReadBytes(false);
        state.timings.timeFreeingData += Date.now() - timeFreeStart;
        const didProgress = state.iterator.counter.getOffset() > offsetBefore;
        if (!didProgress) {
            iterationWithThisOffset++;
        } else {
            iterationWithThisOffset = 0;
        }
    }
    state.samplesObserved.setLastSampleObserved();
    await state.callbacks.callTracksDoneCallback();
    // After the last sample, you might queue a last seek again.
    if (state.controller._internals.seekSignal.getSeek() !== null) {
        log_1.Log.verbose(state.logLevel, 'Reached end of samples, but there is a pending seek. Trying to seek...');
        await (0, work_on_seek_request_1.workOnSeekRequest)((0, work_on_seek_request_1.getWorkOnSeekRequestOptions)(state));
        if (state.controller._internals.seekSignal.getSeek() !== null) {
            throw new Error('Reached the end of the file even though a seek was requested. This is likely a bug in the parser. You can report this at https://remotion.dev/report and we will fix it as soon as possible.');
        }
        await (0, exports.parseLoop)({
            onError,
            throttledState,
            state
        });
    }
};
exports.parseLoop = parseLoop;
}),
"[project]/node_modules/@remotion/media-parser/dist/print-timings.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.printTimings = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const printTimings = (state)=>{
    log_1.Log.verbose(state.logLevel, `Time iterating over file: ${state.timings.timeIterating}ms`);
    log_1.Log.verbose(state.logLevel, `Time fetching data: ${state.timings.timeReadingData}ms`);
    log_1.Log.verbose(state.logLevel, `Time seeking: ${state.timings.timeSeeking}ms`);
    log_1.Log.verbose(state.logLevel, `Time checking if done: ${state.timings.timeCheckingIfDone}ms`);
    log_1.Log.verbose(state.logLevel, `Time freeing data: ${state.timings.timeFreeingData}ms`);
    log_1.Log.verbose(state.logLevel, `Time in parse loop: ${state.timings.timeInParseLoop}ms`);
};
exports.printTimings = printTimings;
}),
"[project]/node_modules/@remotion/media-parser/dist/remotion-license-acknowledge.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.warnIfRemotionLicenseNotAcknowledged = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
let warningShown = false;
const warnIfRemotionLicenseNotAcknowledged = ({ acknowledgeRemotionLicense, logLevel, apiName })=>{
    if (acknowledgeRemotionLicense) {
        return;
    }
    if (warningShown) {
        return;
    }
    warningShown = true;
    log_1.Log.warn(logLevel, `Note: Some companies are required to obtain a license to use @remotion/media-parser. See: https://remotion.dev/license\nPass \`acknowledgeRemotionLicense: true\` to \`${apiName}\` function to make this message disappear.`);
};
exports.warnIfRemotionLicenseNotAcknowledged = warnIfRemotionLicenseNotAcknowledged;
}),
"[project]/node_modules/@remotion/media-parser/dist/set-seeking-hints.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.setSeekingHints = void 0;
const seeking_hints_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/aac/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_2 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/flac/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_3 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_4 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/mp3/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_5 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_6 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/transport-stream/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_7 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/wav/seeking-hints.js [app-route] (ecmascript)");
const seeking_hints_8 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/seek/seeking-hints.js [app-route] (ecmascript)");
const setSeekingHints = ({ hints, state })=>{
    if (hints.type === 'iso-base-media-seeking-hints') {
        (0, seeking_hints_3.setSeekingHintsForMp4)({
            hints,
            state
        });
        return;
    }
    if (hints.type === 'wav-seeking-hints') {
        (0, seeking_hints_7.setSeekingHintsForWav)({
            hints,
            state
        });
        return;
    }
    if (hints.type === 'transport-stream-seeking-hints') {
        (0, seeking_hints_6.setSeekingHintsForTransportStream)({
            hints,
            state
        });
        return;
    }
    if (hints.type === 'webm-seeking-hints') {
        (0, seeking_hints_8.setSeekingHintsForWebm)({
            hints,
            state
        });
        return;
    }
    if (hints.type === 'flac-seeking-hints') {
        (0, seeking_hints_2.setSeekingHintsForFlac)({
            hints,
            state
        });
        return;
    }
    if (hints.type === 'riff-seeking-hints') {
        (0, seeking_hints_5.setSeekingHintsForRiff)({
            hints,
            state
        });
        return;
    }
    if (hints.type === 'mp3-seeking-hints') {
        (0, seeking_hints_4.setSeekingHintsForMp3)({
            hints,
            state
        });
        return;
    }
    if (hints.type === 'aac-seeking-hints') {
        (0, seeking_hints_1.setSeekingHintsForAac)();
        return;
    }
    if (hints.type === 'm3u8-seeking-hints') {
        // TODO: Implement
        return;
    }
    throw new Error(`Unknown seeking hints type: ${hints}`);
};
exports.setSeekingHints = setSeekingHints;
}),
"[project]/node_modules/@remotion/media-parser/dist/get-fields-from-callbacks.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getFieldsFromCallback = void 0;
const getFieldsFromCallback = ({ fields, callbacks })=>{
    const newFields = {
        audioCodec: Boolean(callbacks.onAudioCodec),
        container: Boolean(callbacks.onContainer),
        dimensions: Boolean(callbacks.onDimensions),
        durationInSeconds: Boolean(callbacks.onDurationInSeconds),
        fps: Boolean(callbacks.onFps),
        internalStats: Boolean(callbacks.onInternalStats),
        isHdr: Boolean(callbacks.onIsHdr),
        location: Boolean(callbacks.onLocation),
        metadata: Boolean(callbacks.onMetadata),
        mimeType: Boolean(callbacks.onMimeType),
        name: Boolean(callbacks.onName),
        rotation: Boolean(callbacks.onRotation),
        size: Boolean(callbacks.onSize),
        slowStructure: Boolean(callbacks.onSlowStructure),
        tracks: Boolean(callbacks.onTracks),
        unrotatedDimensions: Boolean(callbacks.onUnrotatedDimensions),
        videoCodec: Boolean(callbacks.onVideoCodec),
        slowKeyframes: Boolean(callbacks.onSlowKeyframes),
        slowDurationInSeconds: Boolean(callbacks.onSlowDurationInSeconds),
        slowFps: Boolean(callbacks.onSlowFps),
        slowNumberOfFrames: Boolean(callbacks.onSlowNumberOfFrames),
        keyframes: Boolean(callbacks.onKeyframes),
        images: Boolean(callbacks.onImages),
        numberOfAudioChannels: Boolean(callbacks.onNumberOfAudioChannels),
        sampleRate: Boolean(callbacks.onSampleRate),
        slowAudioBitrate: Boolean(callbacks.onSlowAudioBitrate),
        slowVideoBitrate: Boolean(callbacks.onSlowVideoBitrate),
        m3uStreams: Boolean(callbacks.onM3uStreams),
        ...fields
    };
    return newFields;
};
exports.getFieldsFromCallback = getFieldsFromCallback;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/audio-sample-map.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.audioSampleMapState = void 0;
const audioSampleMapState = ()=>{
    // {[]}
    let map = [];
    const addSample = (audioSampleOffset)=>{
        if (map.find((m)=>m.offset === audioSampleOffset.offset)) {
            return;
        }
        map.push(audioSampleOffset);
    };
    return {
        addSample,
        getSamples: ()=>map,
        setFromSeekingHints: (newMap)=>{
            map = newMap;
        }
    };
};
exports.audioSampleMapState = audioSampleMapState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/aac-state.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.aacState = void 0;
const audio_sample_map_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/audio-sample-map.js [app-route] (ecmascript)");
const aacState = ()=>{
    const samples = [];
    // seems redunant, we could deduplicate this
    const audioSamples = (0, audio_sample_map_1.audioSampleMapState)();
    return {
        addSample: ({ offset, size })=>{
            const index = samples.findIndex((s)=>s.offset === offset);
            if (index !== -1) {
                return samples[index];
            }
            samples.push({
                offset,
                index: samples.length,
                size
            });
            return samples[samples.length - 1];
        },
        getSamples: ()=>samples,
        audioSamples
    };
};
exports.aacState = aacState;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/avc/max-buffer-size.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.maxMacroblockBufferSize = exports.macroBlocksPerFrame = void 0;
// https://www.itu.int/rec/T-REC-H.264-202408-I
// Table A-1 â€“ Level limits
const maxMacroblocksByLevel = {
    10: 396,
    11: 900,
    12: 2376,
    13: 2376,
    20: 2376,
    21: 4752,
    22: 8100,
    30: 8100,
    31: 18000,
    32: 20480,
    40: 32768,
    41: 32768,
    42: 34816,
    50: 110400,
    51: 184320,
    52: 184320,
    60: 696320,
    61: 696320,
    62: 696320
};
const macroBlocksPerFrame = (sps)=>{
    const { pic_width_in_mbs_minus1, pic_height_in_map_units_minus1 } = sps;
    return (pic_width_in_mbs_minus1 + 1) * (pic_height_in_map_units_minus1 + 1);
};
exports.macroBlocksPerFrame = macroBlocksPerFrame;
const maxMacroblockBufferSize = (sps)=>{
    const { level } = sps;
    const maxMacroblocks = maxMacroblocksByLevel[level];
    if (maxMacroblocks === undefined) {
        throw new Error(`Unsupported level: ${level.toString(16)}`);
    }
    return maxMacroblocks;
};
exports.maxMacroblockBufferSize = maxMacroblockBufferSize;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/avc/avc-state.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.avcState = void 0;
const max_buffer_size_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/avc/max-buffer-size.js [app-route] (ecmascript)");
const avcState = ()=>{
    let prevPicOrderCntLsb = 0;
    let prevPicOrderCntMsb = 0;
    let sps = null;
    let maxFramesInBuffer = null;
    return {
        getPrevPicOrderCntLsb () {
            return prevPicOrderCntLsb;
        },
        getPrevPicOrderCntMsb () {
            return prevPicOrderCntMsb;
        },
        setPrevPicOrderCntLsb (value) {
            prevPicOrderCntLsb = value;
        },
        setPrevPicOrderCntMsb (value) {
            prevPicOrderCntMsb = value;
        },
        setSps (value) {
            const macroblockBufferSize = (0, max_buffer_size_1.macroBlocksPerFrame)(value);
            const maxBufferSize = (0, max_buffer_size_1.maxMacroblockBufferSize)(value);
            const maxFrames = Math.min(16, Math.floor(maxBufferSize / macroblockBufferSize));
            maxFramesInBuffer = maxFrames;
            sps = value;
        },
        getSps () {
            return sps;
        },
        getMaxFramesInBuffer () {
            return maxFramesInBuffer;
        },
        clear () {
            maxFramesInBuffer = null;
            sps = null;
            prevPicOrderCntLsb = 0;
            prevPicOrderCntMsb = 0;
        }
    };
};
exports.avcState = avcState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/current-reader.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.currentReader = void 0;
const currentReader = (initialReader)=>{
    let current = initialReader;
    return {
        getCurrent: ()=>current,
        setCurrent: (newReader)=>{
            current = newReader;
        }
    };
};
exports.currentReader = currentReader;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/emitted-fields.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.emittedState = void 0;
const emittedState = ()=>{
    const emittedFields = {
        audioCodec: false,
        container: false,
        dimensions: false,
        durationInSeconds: false,
        fps: false,
        internalStats: false,
        isHdr: false,
        location: false,
        metadata: false,
        mimeType: false,
        name: false,
        rotation: false,
        size: false,
        slowStructure: false,
        tracks: false,
        videoCodec: false,
        unrotatedDimensions: false,
        slowDurationInSeconds: false,
        slowFps: false,
        slowKeyframes: false,
        slowNumberOfFrames: false,
        keyframes: false,
        images: false,
        numberOfAudioChannels: false,
        sampleRate: false,
        slowAudioBitrate: false,
        slowVideoBitrate: false,
        m3uStreams: false
    };
    return emittedFields;
};
exports.emittedState = emittedState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/flac-state.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.flacState = void 0;
const audio_sample_map_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/audio-sample-map.js [app-route] (ecmascript)");
const flacState = ()=>{
    let blockingBitStrategy;
    const audioSamples = (0, audio_sample_map_1.audioSampleMapState)();
    return {
        setBlockingBitStrategy: (strategy)=>{
            blockingBitStrategy = strategy;
        },
        getBlockingBitStrategy: ()=>blockingBitStrategy,
        audioSamples
    };
};
exports.flacState = flacState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/images.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.imagesState = void 0;
const imagesState = ()=>{
    const images = [];
    const addImage = (image)=>{
        images.push(image);
    };
    return {
        images,
        addImage
    };
};
exports.imagesState = imagesState;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mfra/get-mfra-atom.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMfraAtom = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const getMfraAtom = async ({ src, contentLength, readerInterface, controller, parentSize, logLevel, prefetchCache })=>{
    const result = await readerInterface.read({
        controller,
        range: [
            contentLength - parentSize,
            contentLength - 1
        ],
        src,
        logLevel,
        prefetchCache
    });
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: new Uint8Array(),
        maxBytes: parentSize,
        logLevel: 'error'
    });
    while(true){
        const res = await result.reader.reader.read();
        if (res.value) {
            iterator.addData(res.value);
        }
        if (res.done) {
            break;
        }
    }
    return iterator;
};
exports.getMfraAtom = getMfraAtom;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mfra/get-mfro-atom.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMfroAtom = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const getMfroAtom = async ({ src, contentLength, readerInterface, controller, logLevel, prefetchCache })=>{
    const result = await readerInterface.read({
        controller,
        range: [
            contentLength - 16,
            contentLength - 1
        ],
        src,
        logLevel,
        prefetchCache
    });
    const { value } = await result.reader.reader.read();
    if (!value) {
        return null;
    }
    result.reader.abort();
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: value,
        maxBytes: value.length,
        logLevel: 'error'
    });
    const size = iterator.getUint32();
    if (size !== 16) {
        iterator.destroy();
        return null;
    }
    const atom = iterator.getByteString(4, false);
    if (atom !== 'mfro') {
        iterator.destroy();
        return null;
    }
    const version = iterator.getUint8();
    if (version !== 0) {
        iterator.destroy();
        return null;
    }
    // flags
    iterator.discard(3);
    const parentSize = iterator.getUint32();
    iterator.destroy();
    return parentSize;
};
exports.getMfroAtom = getMfroAtom;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-mfra-seeking-box.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getMfraSeekingBox = void 0;
const get_children_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-children.js [app-route] (ecmascript)");
const get_mfra_atom_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mfra/get-mfra-atom.js [app-route] (ecmascript)");
const get_mfro_atom_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/mfra/get-mfro-atom.js [app-route] (ecmascript)");
const getMfraSeekingBox = async ({ contentLength, controller, readerInterface, src, logLevel, prefetchCache })=>{
    const parentSize = await (0, get_mfro_atom_1.getMfroAtom)({
        contentLength,
        controller,
        readerInterface,
        src,
        logLevel,
        prefetchCache
    });
    if (!parentSize) {
        return null;
    }
    const mfraAtom = await (0, get_mfra_atom_1.getMfraAtom)({
        contentLength,
        controller,
        readerInterface,
        src,
        parentSize,
        logLevel,
        prefetchCache
    });
    mfraAtom.discard(8);
    return (0, get_children_1.getIsoBaseMediaChildren)({
        iterator: mfraAtom,
        logLevel,
        size: parentSize - 8,
        onlyIfMoovAtomExpected: null,
        contentLength
    });
};
exports.getMfraSeekingBox = getMfraSeekingBox;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/lazy-mfra-load.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.lazyMfraLoad = void 0;
const get_mfra_seeking_box_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/get-mfra-seeking-box.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const lazyMfraLoad = ({ contentLength, controller, readerInterface, src, logLevel, prefetchCache })=>{
    let prom = null;
    let result = null;
    const triggerLoad = ()=>{
        if (prom) {
            return prom;
        }
        log_1.Log.verbose(logLevel, 'Moof box found, trying to lazy load mfra');
        prom = (0, get_mfra_seeking_box_1.getMfraSeekingBox)({
            contentLength,
            controller,
            readerInterface,
            src,
            logLevel,
            prefetchCache
        }).then((boxes)=>{
            log_1.Log.verbose(logLevel, boxes ? 'Lazily found mfra atom.' : 'No mfra atom found.');
            result = boxes;
            return boxes;
        });
        return prom;
    };
    const getIfAlreadyLoaded = ()=>{
        if (result) {
            return result;
        }
        return null;
    };
    const setFromSeekingHints = (hints)=>{
        result = hints.mfraAlreadyLoaded;
    };
    return {
        triggerLoad,
        getIfAlreadyLoaded,
        setFromSeekingHints
    };
};
exports.lazyMfraLoad = lazyMfraLoad;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/moov-box.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.moovState = void 0;
const moovState = ()=>{
    let moovBox = null;
    return {
        setMoovBox: (moov)=>{
            moovBox = moov;
        },
        getMoovBoxAndPrecomputed: ()=>moovBox
    };
};
exports.moovState = moovState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/timescale-state.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.movieTimeScaleState = void 0;
const movieTimeScaleState = ()=>{
    let trackTimescale = null;
    return {
        getTrackTimescale: ()=>trackTimescale,
        setTrackTimescale: (timescale)=>{
            trackTimescale = timescale;
        }
    };
};
exports.movieTimeScaleState = movieTimeScaleState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/iso-state.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isoBaseMediaState = void 0;
const cached_sample_positions_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/cached-sample-positions.js [app-route] (ecmascript)");
const lazy_mfra_load_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/lazy-mfra-load.js [app-route] (ecmascript)");
const moov_box_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/moov-box.js [app-route] (ecmascript)");
const precomputed_moof_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/precomputed-moof.js [app-route] (ecmascript)");
const precomputed_tfra_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/precomputed-tfra.js [app-route] (ecmascript)");
const timescale_state_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/timescale-state.js [app-route] (ecmascript)");
const isoBaseMediaState = ({ contentLength, controller, readerInterface, src, logLevel, prefetchCache })=>{
    return {
        flatSamples: (0, cached_sample_positions_1.cachedSamplePositionsState)(),
        moov: (0, moov_box_1.moovState)(),
        mfra: (0, lazy_mfra_load_1.lazyMfraLoad)({
            contentLength,
            controller,
            readerInterface,
            src,
            logLevel,
            prefetchCache
        }),
        moof: (0, precomputed_moof_1.precomputedMoofState)(),
        tfra: (0, precomputed_tfra_1.precomputedTfraState)(),
        movieTimeScale: (0, timescale_state_1.movieTimeScaleState)()
    };
};
exports.isoBaseMediaState = isoBaseMediaState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/keyframes.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.keyframesState = void 0;
const keyframesState = ()=>{
    const keyframes = [];
    const addKeyframe = (keyframe)=>{
        if (keyframes.find((k)=>k.positionInBytes === keyframe.positionInBytes)) {
            return;
        }
        keyframes.push(keyframe);
    };
    const getKeyframes = ()=>{
        keyframes.sort((a, b)=>a.positionInBytes - b.positionInBytes);
        return keyframes;
    };
    const setFromSeekingHints = (keyframesFromHints)=>{
        for (const keyframe of keyframesFromHints){
            addKeyframe(keyframe);
        }
    };
    return {
        addKeyframe,
        getKeyframes,
        setFromSeekingHints
    };
};
exports.keyframesState = keyframesState;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/m3u/sample-sorter.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.sampleSorter = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const sampleSorter = ({ logLevel, getAllChunksProcessedForPlaylist })=>{
    const streamsWithTracks = [];
    const audioCallbacks = {};
    const videoCallbacks = {};
    let latestSample = {};
    return {
        clearSamples: ()=>{
            latestSample = {};
        },
        addToStreamWithTrack: (src)=>{
            streamsWithTracks.push(src);
        },
        addVideoStreamToConsider: (src, callback)=>{
            videoCallbacks[src] = callback;
        },
        addAudioStreamToConsider: (src, callback)=>{
            audioCallbacks[src] = callback;
        },
        hasAudioStreamToConsider: (src)=>{
            return Boolean(audioCallbacks[src]);
        },
        hasVideoStreamToConsider: (src)=>{
            return Boolean(videoCallbacks[src]);
        },
        addAudioSample: async (src, sample)=>{
            const callback = audioCallbacks[src];
            if (!callback) {
                throw new Error('No callback found for audio sample');
            }
            latestSample[src] = sample.decodingTimestamp;
            await callback(sample);
        },
        addVideoSample: async (src, sample)=>{
            const callback = videoCallbacks[src];
            if (!callback) {
                throw new Error('No callback found for video sample.');
            }
            latestSample[src] = sample.decodingTimestamp;
            await callback(sample);
        },
        getNextStreamToRun: (streams)=>{
            var _a, _b, _c;
            for (const stream of streams){
                if (getAllChunksProcessedForPlaylist(stream)) {
                    continue;
                }
                // If a stream does not have a track yet, work on that
                if (!streamsWithTracks.includes(stream)) {
                    log_1.Log.trace(logLevel, `Did not yet detect track of ${stream}, working on that`);
                    return stream;
                }
            }
            let smallestDts = Infinity;
            for (const stream of streams){
                if (getAllChunksProcessedForPlaylist(stream)) {
                    continue;
                }
                if (((_a = latestSample[stream]) !== null && _a !== void 0 ? _a : 0) < smallestDts) {
                    smallestDts = (_b = latestSample[stream]) !== null && _b !== void 0 ? _b : 0;
                }
            }
            for (const stream of streams){
                if (getAllChunksProcessedForPlaylist(stream)) {
                    continue;
                }
                if (((_c = latestSample[stream]) !== null && _c !== void 0 ? _c : 0) === smallestDts) {
                    log_1.Log.trace(logLevel, `Working on ${stream} because it has the smallest DTS`);
                    return stream;
                }
            }
            throw new Error('should be done with parsing now');
        }
    };
};
exports.sampleSorter = sampleSorter;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/m3u-state.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.m3uState = void 0;
const sample_sorter_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/sample-sorter.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const m3uState = (logLevel)=>{
    let selectedMainPlaylist = null;
    let associatedPlaylists = null;
    const hasEmittedVideoTrack = {};
    const hasEmittedAudioTrack = {};
    const hasEmittedDoneWithTracks = {};
    let hasFinishedManifest = false;
    const seekToSecondsToProcess = {};
    const nextSeekShouldSubtractChunks = {};
    let readyToIterateOverM3u = false;
    const allChunksProcessed = {};
    const m3uStreamRuns = {};
    const tracksDone = {};
    const getMainPlaylistUrl = ()=>{
        if (!selectedMainPlaylist) {
            throw new Error('No main playlist selected');
        }
        const playlistUrl = selectedMainPlaylist.type === 'initial-url' ? selectedMainPlaylist.url : selectedMainPlaylist.stream.src;
        return playlistUrl;
    };
    const getSelectedPlaylists = ()=>{
        return [
            getMainPlaylistUrl(),
            ...(associatedPlaylists !== null && associatedPlaylists !== void 0 ? associatedPlaylists : []).map((p)=>p.src)
        ];
    };
    const getAllChunksProcessedForPlaylist = (src)=>allChunksProcessed[src];
    const mp4HeaderSegments = {};
    const setMp4HeaderSegment = (playlistUrl, structure)=>{
        mp4HeaderSegments[playlistUrl] = structure;
    };
    const getMp4HeaderSegment = (playlistUrl)=>{
        return mp4HeaderSegments[playlistUrl];
    };
    return {
        setSelectedMainPlaylist: (stream)=>{
            selectedMainPlaylist = stream;
        },
        getSelectedMainPlaylist: ()=>selectedMainPlaylist,
        setHasEmittedVideoTrack: (src, callback)=>{
            hasEmittedVideoTrack[src] = callback;
        },
        hasEmittedVideoTrack: (src)=>{
            const value = hasEmittedVideoTrack[src];
            if (value === undefined) {
                return false;
            }
            return value;
        },
        setHasEmittedAudioTrack: (src, callback)=>{
            hasEmittedAudioTrack[src] = callback;
        },
        hasEmittedAudioTrack: (src)=>{
            const value = hasEmittedAudioTrack[src];
            if (value === undefined) {
                return false;
            }
            return value;
        },
        setHasEmittedDoneWithTracks: (src)=>{
            hasEmittedDoneWithTracks[src] = true;
        },
        hasEmittedDoneWithTracks: (src)=>hasEmittedDoneWithTracks[src] !== undefined,
        setReadyToIterateOverM3u: ()=>{
            readyToIterateOverM3u = true;
        },
        isReadyToIterateOverM3u: ()=>readyToIterateOverM3u,
        setAllChunksProcessed: (src)=>{
            allChunksProcessed[src] = true;
        },
        clearAllChunksProcessed: ()=>{
            Object.keys(allChunksProcessed).forEach((key)=>{
                delete allChunksProcessed[key];
            });
        },
        getAllChunksProcessedForPlaylist,
        getAllChunksProcessedOverall: ()=>{
            if (!selectedMainPlaylist) {
                return false;
            }
            const selectedPlaylists = getSelectedPlaylists();
            return selectedPlaylists.every((url)=>allChunksProcessed[url]);
        },
        setHasFinishedManifest: ()=>{
            hasFinishedManifest = true;
        },
        hasFinishedManifest: ()=>hasFinishedManifest,
        setM3uStreamRun: (playlistUrl, run)=>{
            if (!run) {
                delete m3uStreamRuns[playlistUrl];
                return;
            }
            m3uStreamRuns[playlistUrl] = run;
        },
        setTracksDone: (playlistUrl)=>{
            tracksDone[playlistUrl] = true;
            const selectedPlaylists = getSelectedPlaylists();
            return selectedPlaylists.every((url)=>tracksDone[url]);
        },
        getTrackDone: (playlistUrl)=>{
            return tracksDone[playlistUrl];
        },
        clearTracksDone: ()=>{
            Object.keys(tracksDone).forEach((key)=>{
                delete tracksDone[key];
            });
        },
        getM3uStreamRun: (playlistUrl)=>{
            var _a;
            return (_a = m3uStreamRuns[playlistUrl]) !== null && _a !== void 0 ? _a : null;
        },
        abortM3UStreamRuns: ()=>{
            const values = Object.values(m3uStreamRuns);
            if (values.length === 0) {
                return;
            }
            log_1.Log.trace(logLevel, `Aborting ${values.length} M3U stream runs`);
            values.forEach((run)=>{
                run.abort();
            });
        },
        setAssociatedPlaylists: (playlists)=>{
            associatedPlaylists = playlists;
        },
        getAssociatedPlaylists: ()=>associatedPlaylists,
        getSelectedPlaylists,
        sampleSorter: (0, sample_sorter_1.sampleSorter)({
            logLevel,
            getAllChunksProcessedForPlaylist
        }),
        setMp4HeaderSegment,
        getMp4HeaderSegment,
        setSeekToSecondsToProcess: (playlistUrl, m3uSeek)=>{
            seekToSecondsToProcess[playlistUrl] = m3uSeek;
        },
        getSeekToSecondsToProcess: (playlistUrl)=>{
            var _a;
            return (_a = seekToSecondsToProcess[playlistUrl]) !== null && _a !== void 0 ? _a : null;
        },
        setNextSeekShouldSubtractChunks: (playlistUrl, chunks)=>{
            nextSeekShouldSubtractChunks[playlistUrl] = chunks;
        },
        getNextSeekShouldSubtractChunks: (playlistUrl)=>{
            var _a;
            return (_a = nextSeekShouldSubtractChunks[playlistUrl]) !== null && _a !== void 0 ? _a : 0;
        }
    };
};
exports.m3uState = m3uState;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/seek/format-cues.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.formatCues = void 0;
const formatCues = (cues)=>{
    var _a;
    const matroskaCues = [];
    for (const cue of cues){
        if (cue.type === 'Crc32') {
            continue;
        }
        if (cue.type !== 'CuePoint') {
            throw new Error('Expected CuePoint');
        }
        const cueTime = cue.value.find((_cue)=>_cue.type === 'CueTime');
        if (!cueTime) {
            throw new Error('Expected CueTime');
        }
        const cueTrackPositions = cue.value.find((c)=>c.type === 'CueTrackPositions');
        if (!cueTrackPositions) {
            throw new Error('Expected CueTrackPositions');
        }
        const cueTimeValue = cueTime.value.value;
        const cueTrack = cueTrackPositions.value.find((_c)=>_c.type === 'CueTrack');
        if (!cueTrack) {
            throw new Error('Expected CueTrack');
        }
        const cueClusterPosition = cueTrackPositions.value.find((_c)=>_c.type === 'CueClusterPosition');
        if (!cueClusterPosition) {
            throw new Error('Expected CueClusterPosition');
        }
        const cueRelativePosition = cueTrackPositions.value.find((_c)=>_c.type === 'CueRelativePosition');
        const matroskaCue = {
            trackId: cueTrack.value.value,
            timeInTimescale: cueTimeValue,
            clusterPositionInSegment: cueClusterPosition.value.value,
            relativePosition: (_a = cueRelativePosition === null || cueRelativePosition === void 0 ? void 0 : cueRelativePosition.value.value) !== null && _a !== void 0 ? _a : 0
        };
        matroskaCues.push(matroskaCue);
    }
    return matroskaCues;
};
exports.formatCues = formatCues;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/webm/seek/fetch-web-cues.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.fetchWebmCues = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const segments_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments.js [app-route] (ecmascript)");
const format_cues_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/seek/format-cues.js [app-route] (ecmascript)");
const fetchWebmCues = async ({ src, readerInterface, controller, position, logLevel, prefetchCache })=>{
    const result = await readerInterface.read({
        controller,
        range: position,
        src,
        logLevel,
        prefetchCache
    });
    const { value } = await result.reader.reader.read();
    if (!value) {
        return null;
    }
    result.reader.abort();
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: value,
        maxBytes: value.length,
        logLevel: 'error'
    });
    const segment = await (0, segments_1.expectSegment)({
        iterator,
        logLevel,
        statesForProcessing: null,
        isInsideSegment: null,
        mediaSectionState: null
    });
    iterator.destroy();
    if (!(segment === null || segment === void 0 ? void 0 : segment.value)) {
        return null;
    }
    return (0, format_cues_1.formatCues)(segment.value);
};
exports.fetchWebmCues = fetchWebmCues;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/matroska/lazy-cues-fetch.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.lazyCuesFetch = void 0;
const fetch_web_cues_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/seek/fetch-web-cues.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const lazyCuesFetch = ({ controller, logLevel, readerInterface, src, prefetchCache })=>{
    let prom = null;
    let sOffset = null;
    let result = null;
    const triggerLoad = (position, segmentOffset)=>{
        if (result) {
            return Promise.resolve(result);
        }
        if (prom) {
            return prom;
        }
        if (sOffset && sOffset !== segmentOffset) {
            throw new Error('Segment offset mismatch');
        }
        sOffset = segmentOffset;
        log_1.Log.verbose(logLevel, 'Cues box found, trying to lazy load cues');
        prom = (0, fetch_web_cues_1.fetchWebmCues)({
            controller,
            logLevel,
            position,
            readerInterface,
            src,
            prefetchCache
        }).then((cues)=>{
            log_1.Log.verbose(logLevel, 'Cues loaded');
            result = cues;
            return cues;
        });
        return prom;
    };
    const getLoadedCues = async ()=>{
        if (!prom) {
            return null;
        }
        if (result) {
            if (!sOffset) {
                throw new Error('Segment offset not set');
            }
            return {
                cues: result,
                segmentOffset: sOffset
            };
        }
        const cues = await prom;
        if (!cues) {
            return null;
        }
        if (!sOffset) {
            throw new Error('Segment offset not set');
        }
        return {
            cues,
            segmentOffset: sOffset
        };
    };
    const getIfAlreadyLoaded = ()=>{
        if (result) {
            if (sOffset === null) {
                throw new Error('Segment offset not set');
            }
            return {
                cues: result,
                segmentOffset: sOffset
            };
        }
        return null;
    };
    const setFromSeekingHints = (hints)=>{
        var _a, _b, _c, _d;
        result = (_b = (_a = hints.loadedCues) === null || _a === void 0 ? void 0 : _a.cues) !== null && _b !== void 0 ? _b : null;
        sOffset = (_d = (_c = hints.loadedCues) === null || _c === void 0 ? void 0 : _c.segmentOffset) !== null && _d !== void 0 ? _d : null;
    };
    return {
        triggerLoad,
        getLoadedCues,
        getIfAlreadyLoaded,
        setFromSeekingHints
    };
};
exports.lazyCuesFetch = lazyCuesFetch;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/matroska/webm.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.webmState = void 0;
const traversal_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/traversal.js [app-route] (ecmascript)");
const lazy_cues_fetch_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/matroska/lazy-cues-fetch.js [app-route] (ecmascript)");
const webmState = ({ controller, logLevel, readerInterface, src, prefetchCache })=>{
    const trackEntries = {};
    const onTrackEntrySegment = (trackEntry)=>{
        var _a;
        const trackId = (0, traversal_1.getTrackId)(trackEntry);
        if (!trackId) {
            throw new Error('Expected track id');
        }
        if (trackEntries[trackId]) {
            return;
        }
        const codec = (0, traversal_1.getTrackCodec)(trackEntry);
        if (!codec) {
            throw new Error('Expected codec');
        }
        const trackTimescale = (0, traversal_1.getTrackTimestampScale)(trackEntry);
        trackEntries[trackId] = {
            codec: codec.value,
            trackTimescale: (_a = trackTimescale === null || trackTimescale === void 0 ? void 0 : trackTimescale.value) !== null && _a !== void 0 ? _a : null
        };
    };
    let timestampMap = new Map();
    const getTimestampOffsetForByteOffset = (byteOffset)=>{
        const entries = Array.from(timestampMap.entries());
        const sortedByByteOffset = entries.sort((a, b)=>{
            return a[0] - b[0];
        }).reverse();
        for (const [offset, timestamp] of sortedByByteOffset){
            if (offset >= byteOffset) {
                continue;
            }
            return timestamp;
        }
        return timestampMap.get(byteOffset);
    };
    const setTimestampOffset = (byteOffset, timestamp)=>{
        timestampMap.set(byteOffset, timestamp);
    };
    let timescale = null;
    const setTimescale = (newTimescale)=>{
        timescale = newTimescale;
    };
    const getTimescale = ()=>{
        // https://www.matroska.org/technical/notes.html
        // When using the default value of TimestampScale of â€œ1,000,000â€, one Segment Tick represents one millisecond.
        if (timescale === null) {
            return 1000000;
        }
        return timescale;
    };
    const segments = [];
    const clusters = [];
    const avcProfilesMap = {};
    const setAvcProfileForTrackNumber = (trackNumber, avcProfile)=>{
        avcProfilesMap[trackNumber] = avcProfile;
    };
    const getAvcProfileForTrackNumber = (trackNumber)=>{
        var _a;
        return (_a = avcProfilesMap[trackNumber]) !== null && _a !== void 0 ? _a : null;
    };
    const cues = (0, lazy_cues_fetch_1.lazyCuesFetch)({
        controller,
        logLevel,
        readerInterface,
        src,
        prefetchCache
    });
    const getTimeStampMapForSeekingHints = ()=>{
        return timestampMap;
    };
    const setTimeStampMapForSeekingHints = (newTimestampMap)=>{
        timestampMap = newTimestampMap;
    };
    return {
        cues,
        onTrackEntrySegment,
        getTrackInfoByNumber: (id)=>trackEntries[id],
        setTimestampOffset,
        getTimestampOffsetForByteOffset,
        getTimeStampMapForSeekingHints,
        setTimeStampMapForSeekingHints,
        getTimescale,
        setTimescale,
        addSegment: (seg)=>{
            const segment = {
                ...seg,
                index: segments.length
            };
            segments.push(segment);
        },
        addCluster: (cluster)=>{
            const exists = clusters.some((existingCluster)=>existingCluster.start === cluster.start);
            if (!exists) {
                clusters.push(cluster);
            }
        },
        getFirstCluster: ()=>{
            return clusters.find((cluster)=>cluster.segment === 0);
        },
        isInsideSegment: (iterator)=>{
            var _a;
            const offset = iterator.counter.getOffset();
            const insideClusters = segments.filter((cluster)=>{
                return offset >= cluster.start && offset <= cluster.start + cluster.size;
            });
            if (insideClusters.length > 1) {
                throw new Error('Expected to only be inside 1 cluster');
            }
            return (_a = insideClusters[0]) !== null && _a !== void 0 ? _a : null;
        },
        isInsideCluster: (offset)=>{
            for (const cluster of clusters){
                if (offset >= cluster.start && offset < cluster.start + cluster.size) {
                    return cluster;
                }
            }
            return null;
        },
        setAvcProfileForTrackNumber,
        getAvcProfileForTrackNumber
    };
};
exports.webmState = webmState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/mp3.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makeMp3State = void 0;
const audio_sample_map_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/audio-sample-map.js [app-route] (ecmascript)");
const makeMp3State = ()=>{
    let mp3Info = null;
    let bitrateInfo = null;
    const audioSamples = (0, audio_sample_map_1.audioSampleMapState)();
    return {
        getMp3Info: ()=>mp3Info,
        setMp3Info: (info)=>{
            mp3Info = info;
        },
        getMp3BitrateInfo: ()=>bitrateInfo,
        setMp3BitrateInfo: (info)=>{
            bitrateInfo = info;
        },
        audioSamples
    };
};
exports.makeMp3State = makeMp3State;
}),
"[project]/node_modules/@remotion/media-parser/dist/containers/riff/seek/fetch-idx1.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.fetchIdx1 = void 0;
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const expect_riff_box_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/expect-riff-box.js [app-route] (ecmascript)");
const fetchIdx1 = async ({ src, readerInterface, controller, position, logLevel, prefetchCache, contentLength })=>{
    log_1.Log.verbose(logLevel, 'Making request to fetch idx1 from ', src, 'position', position);
    const result = await readerInterface.read({
        controller,
        range: position,
        src,
        logLevel,
        prefetchCache
    });
    if (result.contentLength === null) {
        throw new Error('Content length is null');
    }
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: new Uint8Array(),
        maxBytes: contentLength - position + 1,
        logLevel: 'error'
    });
    while(true){
        const res = await result.reader.reader.read();
        if (res.value) {
            iterator.addData(res.value);
        }
        if (res.done) {
            break;
        }
    }
    const box = await (0, expect_riff_box_1.expectRiffBox)({
        iterator,
        stateIfExpectingSideEffects: null
    });
    iterator.destroy();
    if (box === null || box.type !== 'idx1-box') {
        throw new Error('Expected idx1-box');
    }
    // only store video chunks, those end with "dc", e.g. "01dc"
    return {
        entries: box.entries.filter((entry)=>entry.id.endsWith('dc')),
        videoTrackIndex: box.videoTrackIndex
    };
};
exports.fetchIdx1 = fetchIdx1;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/riff/lazy-idx1-fetch.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.lazyIdx1Fetch = void 0;
const fetch_idx1_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/riff/seek/fetch-idx1.js [app-route] (ecmascript)");
const lazyIdx1Fetch = ({ controller, logLevel, readerInterface, src, prefetchCache, contentLength })=>{
    let prom = null;
    let result = null;
    const triggerLoad = (position)=>{
        if (result) {
            return Promise.resolve(result);
        }
        if (prom) {
            return prom;
        }
        prom = (0, fetch_idx1_1.fetchIdx1)({
            controller,
            logLevel,
            position,
            readerInterface,
            src,
            prefetchCache,
            contentLength
        }).then((entries)=>{
            prom = null;
            result = entries;
            return entries;
        });
        return prom;
    };
    const getLoadedIdx1 = async ()=>{
        if (!prom) {
            return null;
        }
        const entries = await prom;
        return entries;
    };
    const getIfAlreadyLoaded = ()=>{
        if (result) {
            return result;
        }
        return null;
    };
    const setFromSeekingHints = (hints)=>{
        if (hints.idx1Entries) {
            result = hints.idx1Entries;
        }
    };
    const waitForLoaded = ()=>{
        if (result) {
            return Promise.resolve(result);
        }
        if (prom) {
            return prom;
        }
        return Promise.resolve(null);
    };
    return {
        triggerLoad,
        getLoadedIdx1,
        getIfAlreadyLoaded,
        setFromSeekingHints,
        waitForLoaded
    };
};
exports.lazyIdx1Fetch = lazyIdx1Fetch;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/riff/queued-frames.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.queuedBFramesState = void 0;
const queuedBFramesState = ()=>{
    const queuedFrames = [];
    const releasedFrames = [];
    const flush = ()=>{
        releasedFrames.push(...queuedFrames);
        queuedFrames.length = 0;
    };
    return {
        addFrame: ({ frame, maxFramesInBuffer, trackId, timescale })=>{
            if (frame.type === 'key') {
                flush();
                releasedFrames.push({
                    sample: frame,
                    trackId,
                    timescale
                });
                return;
            }
            queuedFrames.push({
                sample: frame,
                trackId,
                timescale
            });
            if (queuedFrames.length > maxFramesInBuffer) {
                releasedFrames.push(queuedFrames.shift());
            }
        },
        flush,
        getReleasedFrame: ()=>{
            if (releasedFrames.length === 0) {
                return null;
            }
            return releasedFrames.shift();
        },
        hasReleasedFrames: ()=>{
            return releasedFrames.length > 0;
        },
        clear: ()=>{
            releasedFrames.length = 0;
            queuedFrames.length = 0;
        }
    };
};
exports.queuedBFramesState = queuedBFramesState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/riff/riff-keyframes.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.riffKeyframesState = void 0;
const riffKeyframesState = ()=>{
    const keyframes = [];
    const addKeyframe = (keyframe)=>{
        if (keyframes.find((k)=>k.positionInBytes === keyframe.positionInBytes)) {
            return;
        }
        keyframes.push(keyframe);
        keyframes.sort((a, b)=>a.positionInBytes - b.positionInBytes);
    };
    const getKeyframes = ()=>{
        return keyframes;
    };
    const setFromSeekingHints = (keyframesFromHints)=>{
        for (const keyframe of keyframesFromHints){
            addKeyframe(keyframe);
        }
    };
    return {
        addKeyframe,
        getKeyframes,
        setFromSeekingHints
    };
};
exports.riffKeyframesState = riffKeyframesState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/riff/sample-counter.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.riffSampleCounter = void 0;
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const riff_keyframes_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/riff/riff-keyframes.js [app-route] (ecmascript)");
const riffSampleCounter = ()=>{
    const samplesForTrack = {};
    // keyframe offset -> poc[]
    const pocsAtKeyframeOffset = {};
    const riffKeys = (0, riff_keyframes_1.riffKeyframesState)();
    const onAudioSample = (trackId, audioSample)=>{
        if (typeof samplesForTrack[trackId] === 'undefined') {
            samplesForTrack[trackId] = 0;
        }
        if (audioSample.data.length > 0) {
            samplesForTrack[trackId]++;
        }
        samplesForTrack[trackId]++;
    };
    const onVideoSample = ({ trackId, videoSample })=>{
        if (typeof samplesForTrack[trackId] === 'undefined') {
            samplesForTrack[trackId] = 0;
        }
        if (videoSample.type === 'key') {
            riffKeys.addKeyframe({
                trackId,
                decodingTimeInSeconds: videoSample.decodingTimestamp / webcodecs_timescale_1.WEBCODECS_TIMESCALE,
                positionInBytes: videoSample.offset,
                presentationTimeInSeconds: videoSample.timestamp / webcodecs_timescale_1.WEBCODECS_TIMESCALE,
                sizeInBytes: videoSample.data.length,
                sampleCounts: {
                    ...samplesForTrack
                }
            });
        }
        if (videoSample.data.length > 0) {
            samplesForTrack[trackId]++;
        }
    };
    const getSampleCountForTrack = ({ trackId })=>{
        var _a;
        return (_a = samplesForTrack[trackId]) !== null && _a !== void 0 ? _a : 0;
    };
    const setSamplesFromSeek = (samples)=>{
        for(const trackId in samples){
            samplesForTrack[trackId] = samples[trackId];
        }
    };
    const setPocAtKeyframeOffset = ({ keyframeOffset, poc })=>{
        if (typeof pocsAtKeyframeOffset[keyframeOffset] === 'undefined') {
            pocsAtKeyframeOffset[keyframeOffset] = [];
        }
        if (pocsAtKeyframeOffset[keyframeOffset].includes(poc)) {
            return;
        }
        pocsAtKeyframeOffset[keyframeOffset].push(poc);
        pocsAtKeyframeOffset[keyframeOffset].sort((a, b)=>a - b);
    };
    const getPocAtKeyframeOffset = ({ keyframeOffset })=>{
        return pocsAtKeyframeOffset[keyframeOffset];
    };
    const getKeyframeAtOffset = (sample)=>{
        var _a, _b;
        if (sample.type === 'key') {
            return sample.offset;
        }
        return (_b = (_a = riffKeys.getKeyframes().findLast((k)=>k.positionInBytes <= sample.offset)) === null || _a === void 0 ? void 0 : _a.positionInBytes) !== null && _b !== void 0 ? _b : null;
    };
    return {
        onAudioSample,
        onVideoSample,
        getSampleCountForTrack,
        setSamplesFromSeek,
        riffKeys,
        setPocAtKeyframeOffset,
        getPocAtKeyframeOffset,
        getKeyframeAtOffset
    };
};
exports.riffSampleCounter = riffSampleCounter;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/riff.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.riffSpecificState = void 0;
const lazy_idx1_fetch_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/riff/lazy-idx1-fetch.js [app-route] (ecmascript)");
const queued_frames_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/riff/queued-frames.js [app-route] (ecmascript)");
const sample_counter_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/riff/sample-counter.js [app-route] (ecmascript)");
const riffSpecificState = ({ controller, logLevel, readerInterface, src, prefetchCache, contentLength })=>{
    let avcProfile = null;
    let nextTrackIndex = 0;
    const profileCallbacks = [];
    const registerOnAvcProfileCallback = (callback)=>{
        profileCallbacks.push(callback);
    };
    const onProfile = async (profile)=>{
        avcProfile = profile;
        for (const callback of profileCallbacks){
            await callback(profile);
        }
        profileCallbacks.length = 0;
    };
    const lazyIdx1 = (0, lazy_idx1_fetch_1.lazyIdx1Fetch)({
        controller,
        logLevel,
        readerInterface,
        src,
        prefetchCache,
        contentLength
    });
    const sampleCounter = (0, sample_counter_1.riffSampleCounter)();
    const queuedBFrames = (0, queued_frames_1.queuedBFramesState)();
    return {
        getAvcProfile: ()=>{
            return avcProfile;
        },
        onProfile,
        registerOnAvcProfileCallback,
        getNextTrackIndex: ()=>{
            return nextTrackIndex;
        },
        queuedBFrames,
        incrementNextTrackIndex: ()=>{
            nextTrackIndex++;
        },
        lazyIdx1,
        sampleCounter
    };
};
exports.riffSpecificState = riffSpecificState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/sample-callbacks.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.callbacksState = void 0;
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const can_skip_tracks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/can-skip-tracks.js [app-route] (ecmascript)");
const has_tracks_section_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/has-tracks-section.js [app-route] (ecmascript)");
const need_samples_for_fields_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/need-samples-for-fields.js [app-route] (ecmascript)");
const callbacksState = ({ controller, hasAudioTrackHandlers, hasVideoTrackHandlers, fields, keyframes, emittedFields, samplesObserved, structure, src, seekSignal, logLevel })=>{
    const videoSampleCallbacks = {};
    const audioSampleCallbacks = {};
    const onTrackDoneCallback = {};
    const queuedAudioSamples = {};
    const queuedVideoSamples = {};
    const canSkipTracksState = (0, can_skip_tracks_1.makeCanSkipTracksState)({
        hasAudioTrackHandlers,
        fields,
        hasVideoTrackHandlers,
        structure
    });
    const tracksState = (0, has_tracks_section_1.makeTracksSectionState)(canSkipTracksState, src);
    return {
        registerVideoSampleCallback: async (id, callback)=>{
            var _a;
            if (callback === null) {
                delete videoSampleCallbacks[id];
                return;
            }
            videoSampleCallbacks[id] = callback;
            for (const queued of (_a = queuedVideoSamples[id]) !== null && _a !== void 0 ? _a : []){
                await callback(queued);
            }
            queuedVideoSamples[id] = [];
        },
        onAudioSample: async ({ audioSample, trackId })=>{
            if (controller._internals.signal.aborted) {
                throw new Error('Aborted');
            }
            const callback = audioSampleCallbacks[trackId];
            if (audioSample.data.length > 0) {
                // If we emit samples with data length 0, Chrome will fail
                if (callback) {
                    if (seekSignal.getSeek() !== null) {
                        log_1.Log.trace(logLevel, 'Not emitting sample because seek is processing');
                    } else {
                        const trackDoneCallback = await callback(audioSample);
                        onTrackDoneCallback[trackId] = trackDoneCallback !== null && trackDoneCallback !== void 0 ? trackDoneCallback : null;
                    }
                }
            }
            if ((0, need_samples_for_fields_1.needsToIterateOverSamples)({
                emittedFields,
                fields
            })) {
                samplesObserved.addAudioSample(audioSample);
            }
        },
        onVideoSample: async ({ trackId, videoSample })=>{
            if (controller._internals.signal.aborted) {
                throw new Error('Aborted');
            }
            if (videoSample.data.length > 0) {
                const callback = videoSampleCallbacks[trackId];
                // If we emit samples with data 0, Chrome will fail
                if (callback) {
                    if (seekSignal.getSeek() !== null) {
                        log_1.Log.trace(logLevel, 'Not emitting sample because seek is processing');
                    } else {
                        const trackDoneCallback = await callback(videoSample);
                        onTrackDoneCallback[trackId] = trackDoneCallback !== null && trackDoneCallback !== void 0 ? trackDoneCallback : null;
                    }
                }
            }
            if (videoSample.type === 'key') {
                keyframes.addKeyframe({
                    trackId,
                    decodingTimeInSeconds: videoSample.decodingTimestamp / webcodecs_timescale_1.WEBCODECS_TIMESCALE,
                    positionInBytes: videoSample.offset,
                    presentationTimeInSeconds: videoSample.timestamp / webcodecs_timescale_1.WEBCODECS_TIMESCALE,
                    sizeInBytes: videoSample.data.length
                });
            }
            if ((0, need_samples_for_fields_1.needsToIterateOverSamples)({
                fields,
                emittedFields
            })) {
                samplesObserved.addVideoSample(videoSample);
            }
        },
        canSkipTracksState,
        registerAudioSampleCallback: async (id, callback)=>{
            var _a;
            if (callback === null) {
                delete audioSampleCallbacks[id];
                return;
            }
            audioSampleCallbacks[id] = callback;
            for (const queued of (_a = queuedAudioSamples[id]) !== null && _a !== void 0 ? _a : []){
                await callback(queued);
            }
            queuedAudioSamples[id] = [];
        },
        tracks: tracksState,
        audioSampleCallbacks,
        videoSampleCallbacks,
        hasAudioTrackHandlers,
        hasVideoTrackHandlers,
        callTracksDoneCallback: async ()=>{
            for (const callback of Object.values(onTrackDoneCallback)){
                if (callback) {
                    await callback();
                }
            }
        }
    };
};
exports.callbacksState = callbacksState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/samples-observed/slow-duration-fps.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.samplesObservedState = void 0;
const webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
const samplesObservedState = ()=>{
    let smallestVideoSample;
    let largestVideoSample;
    let smallestAudioSample;
    let largestAudioSample;
    let lastSampleObserved = false;
    const videoSamples = new Map();
    const audioSamples = new Map();
    const getSlowVideoDurationInSeconds = ()=>{
        return (largestVideoSample !== null && largestVideoSample !== void 0 ? largestVideoSample : 0) - (smallestVideoSample !== null && smallestVideoSample !== void 0 ? smallestVideoSample : 0);
    };
    const getSlowAudioDurationInSeconds = ()=>{
        return (largestAudioSample !== null && largestAudioSample !== void 0 ? largestAudioSample : 0) - (smallestAudioSample !== null && smallestAudioSample !== void 0 ? smallestAudioSample : 0);
    };
    const getSlowDurationInSeconds = ()=>{
        const smallestSample = Math.min(smallestAudioSample !== null && smallestAudioSample !== void 0 ? smallestAudioSample : Infinity, smallestVideoSample !== null && smallestVideoSample !== void 0 ? smallestVideoSample : Infinity);
        const largestSample = Math.max(largestAudioSample !== null && largestAudioSample !== void 0 ? largestAudioSample : 0, largestVideoSample !== null && largestVideoSample !== void 0 ? largestVideoSample : 0);
        if (smallestSample === Infinity || largestSample === Infinity) {
            return 0;
        }
        return largestSample - smallestSample;
    };
    const addVideoSample = (videoSample)=>{
        var _a;
        videoSamples.set(videoSample.timestamp, videoSample.data.byteLength);
        const presentationTimeInSeconds = videoSample.timestamp / webcodecs_timescale_1.WEBCODECS_TIMESCALE;
        const duration = ((_a = videoSample.duration) !== null && _a !== void 0 ? _a : 0) / webcodecs_timescale_1.WEBCODECS_TIMESCALE;
        if (largestVideoSample === undefined || presentationTimeInSeconds > largestVideoSample) {
            largestVideoSample = presentationTimeInSeconds + duration;
        }
        if (smallestVideoSample === undefined || presentationTimeInSeconds < smallestVideoSample) {
            smallestVideoSample = presentationTimeInSeconds;
        }
    };
    const addAudioSample = (audioSample)=>{
        var _a;
        audioSamples.set(audioSample.timestamp, audioSample.data.byteLength);
        const presentationTimeInSeconds = audioSample.timestamp / webcodecs_timescale_1.WEBCODECS_TIMESCALE;
        const duration = ((_a = audioSample.duration) !== null && _a !== void 0 ? _a : 0) / webcodecs_timescale_1.WEBCODECS_TIMESCALE;
        if (largestAudioSample === undefined || presentationTimeInSeconds > largestAudioSample) {
            largestAudioSample = presentationTimeInSeconds + duration;
        }
        if (smallestAudioSample === undefined || presentationTimeInSeconds < smallestAudioSample) {
            smallestAudioSample = presentationTimeInSeconds;
        }
    };
    const getFps = ()=>{
        const videoDuration = (largestVideoSample !== null && largestVideoSample !== void 0 ? largestVideoSample : 0) - (smallestVideoSample !== null && smallestVideoSample !== void 0 ? smallestVideoSample : 0);
        if (videoDuration === 0) {
            return 0;
        }
        return (videoSamples.size - 1) / videoDuration;
    };
    const getSlowNumberOfFrames = ()=>videoSamples.size;
    const getAudioBitrate = ()=>{
        const audioDuration = getSlowAudioDurationInSeconds();
        if (audioDuration === 0 || audioSamples.size === 0) {
            return null;
        }
        const audioSizesInBytes = Array.from(audioSamples.values()).reduce((acc, size)=>acc + size, 0);
        return audioSizesInBytes * 8 / audioDuration;
    };
    const getVideoBitrate = ()=>{
        const videoDuration = getSlowVideoDurationInSeconds();
        if (videoDuration === 0 || videoSamples.size === 0) {
            return null;
        }
        const videoSizesInBytes = Array.from(videoSamples.values()).reduce((acc, size)=>acc + size, 0);
        return videoSizesInBytes * 8 / videoDuration;
    };
    const getLastSampleObserved = ()=>lastSampleObserved;
    const setLastSampleObserved = ()=>{
        lastSampleObserved = true;
    };
    return {
        addVideoSample,
        addAudioSample,
        getSlowDurationInSeconds,
        getFps,
        getSlowNumberOfFrames,
        getAudioBitrate,
        getVideoBitrate,
        getLastSampleObserved,
        setLastSampleObserved,
        getAmountOfSamplesObserved: ()=>videoSamples.size + audioSamples.size
    };
};
exports.samplesObservedState = samplesObservedState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/seek-infinite-loop.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.seekInfiniteLoopDetectionState = void 0;
const seekInfiniteLoopDetectionState = ()=>{
    let lastSeek = null;
    let firstSeekTime = null;
    return {
        registerSeek: (byte)=>{
            const now = Date.now();
            if (!lastSeek || lastSeek.byte !== byte) {
                lastSeek = {
                    byte,
                    numberOfTimes: 1
                };
                firstSeekTime = now;
                return;
            }
            lastSeek.numberOfTimes++;
            if (lastSeek.numberOfTimes >= 10 && firstSeekTime && now - firstSeekTime <= 2000) {
                throw new Error(`Seeking infinite loop detected: Seeked to byte 0x${byte.toString(16)} ${lastSeek.numberOfTimes} times in a row in the last 2 seconds. Check your usage of .seek().`);
            }
            if (now - firstSeekTime > 2000) {
                lastSeek = {
                    byte,
                    numberOfTimes: 1
                };
                firstSeekTime = now;
            }
        },
        reset: ()=>{
            lastSeek = null;
            firstSeekTime = null;
        }
    };
};
exports.seekInfiniteLoopDetectionState = seekInfiniteLoopDetectionState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/timings.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.timingsState = void 0;
const timingsState = ()=>{
    return {
        timeIterating: 0,
        timeReadingData: 0,
        timeSeeking: 0,
        timeCheckingIfDone: 0,
        timeFreeingData: 0,
        timeInParseLoop: 0
    };
};
exports.timingsState = timingsState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/transport-stream/last-emitted-sample.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.lastEmittedSampleState = void 0;
const lastEmittedSampleState = ()=>{
    let lastEmittedSample = null;
    return {
        setLastEmittedSample: (sample)=>{
            lastEmittedSample = sample;
        },
        getLastEmittedSample: ()=>lastEmittedSample,
        resetLastEmittedSample: ()=>{
            lastEmittedSample = null;
        }
    };
};
exports.lastEmittedSampleState = lastEmittedSampleState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/transport-stream/next-pes-header-store.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makeNextPesHeaderStore = void 0;
const makeNextPesHeaderStore = ()=>{
    let nextPesHeader = null;
    return {
        setNextPesHeader: (pesHeader)=>{
            nextPesHeader = pesHeader;
        },
        getNextPesHeader: ()=>{
            if (!nextPesHeader) {
                throw new Error('No next PES header found');
            }
            return nextPesHeader;
        }
    };
};
exports.makeNextPesHeaderStore = makeNextPesHeaderStore;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/transport-stream/pts-start-offset.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.ptsStartOffsetStore = void 0;
const ptsStartOffsetStore = ()=>{
    const offsets = {};
    return {
        getOffset: (trackId)=>offsets[trackId] || 0,
        setOffset: ({ newOffset, trackId })=>{
            offsets[trackId] = newOffset;
        }
    };
};
exports.ptsStartOffsetStore = ptsStartOffsetStore;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/transport-stream/transport-stream.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.transportStreamState = void 0;
const last_emitted_sample_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/transport-stream/last-emitted-sample.js [app-route] (ecmascript)");
const next_pes_header_store_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/transport-stream/next-pes-header-store.js [app-route] (ecmascript)");
const observed_pes_header_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/transport-stream/observed-pes-header.js [app-route] (ecmascript)");
const pts_start_offset_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/transport-stream/pts-start-offset.js [app-route] (ecmascript)");
const transportStreamState = ()=>{
    const streamBuffers = new Map();
    const startOffset = (0, pts_start_offset_1.ptsStartOffsetStore)();
    const lastEmittedSample = (0, last_emitted_sample_1.lastEmittedSampleState)();
    const state = {
        nextPesHeaderStore: (0, next_pes_header_store_1.makeNextPesHeaderStore)(),
        observedPesHeaders: (0, observed_pes_header_1.makeObservedPesHeader)(),
        streamBuffers,
        startOffset,
        resetBeforeSeek: ()=>{
            state.streamBuffers.clear();
            state.nextPesHeaderStore = (0, next_pes_header_store_1.makeNextPesHeaderStore)();
        // start offset is useful, we can keep it
        },
        lastEmittedSample
    };
    return state;
};
exports.transportStreamState = transportStreamState;
}),
"[project]/node_modules/@remotion/media-parser/dist/state/parser-state.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.makeParserState = void 0;
const get_fields_from_callbacks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-fields-from-callbacks.js [app-route] (ecmascript)");
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const aac_state_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/aac-state.js [app-route] (ecmascript)");
const avc_state_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/avc/avc-state.js [app-route] (ecmascript)");
const current_reader_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/current-reader.js [app-route] (ecmascript)");
const emitted_fields_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/emitted-fields.js [app-route] (ecmascript)");
const flac_state_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/flac-state.js [app-route] (ecmascript)");
const images_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/images.js [app-route] (ecmascript)");
const iso_state_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/iso-base-media/iso-state.js [app-route] (ecmascript)");
const keyframes_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/keyframes.js [app-route] (ecmascript)");
const m3u_state_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/m3u-state.js [app-route] (ecmascript)");
const webm_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/matroska/webm.js [app-route] (ecmascript)");
const mp3_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/mp3.js [app-route] (ecmascript)");
const riff_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/riff.js [app-route] (ecmascript)");
const sample_callbacks_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/sample-callbacks.js [app-route] (ecmascript)");
const slow_duration_fps_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/samples-observed/slow-duration-fps.js [app-route] (ecmascript)");
const seek_infinite_loop_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/seek-infinite-loop.js [app-route] (ecmascript)");
const structure_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/structure.js [app-route] (ecmascript)");
const timings_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/timings.js [app-route] (ecmascript)");
const transport_stream_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/transport-stream/transport-stream.js [app-route] (ecmascript)");
const video_section_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/video-section.js [app-route] (ecmascript)");
const makeParserState = ({ hasAudioTrackHandlers, hasVideoTrackHandlers, controller, onAudioTrack, onVideoTrack, contentLength, logLevel, mode, src, readerInterface, onDiscardedData, selectM3uStreamFn, selectM3uAssociatedPlaylistsFn, m3uPlaylistContext, contentType, name, callbacks, fieldsInReturnValue, mimeType, initialReaderInstance, makeSamplesStartAtZero, prefetchCache })=>{
    let skippedBytes = 0;
    const returnValue = {};
    const iterator = (0, buffer_iterator_1.getArrayBufferIterator)({
        initialData: new Uint8Array([]),
        maxBytes: contentLength,
        logLevel
    });
    const increaseSkippedBytes = (bytes)=>{
        skippedBytes += bytes;
    };
    const structure = (0, structure_1.structureState)();
    const keyframes = (0, keyframes_1.keyframesState)();
    const emittedFields = (0, emitted_fields_1.emittedState)();
    const samplesObserved = (0, slow_duration_fps_1.samplesObservedState)();
    const mp3 = (0, mp3_1.makeMp3State)();
    const images = (0, images_1.imagesState)();
    const timings = (0, timings_1.timingsState)();
    const seekInfiniteLoop = (0, seek_infinite_loop_1.seekInfiniteLoopDetectionState)();
    const currentReaderState = (0, current_reader_1.currentReader)(initialReaderInstance);
    const avc = (0, avc_state_1.avcState)();
    const errored = null;
    const discardReadBytes = async (force)=>{
        const { bytesRemoved, removedData } = iterator.removeBytesRead(force, mode);
        if (bytesRemoved) {
            log_1.Log.verbose(logLevel, `Freed ${bytesRemoved} bytes`);
        }
        if (removedData && onDiscardedData) {
            await onDiscardedData(removedData);
        }
    };
    const fields = (0, get_fields_from_callbacks_1.getFieldsFromCallback)({
        fields: fieldsInReturnValue,
        callbacks
    });
    const mediaSection = (0, video_section_1.mediaSectionState)();
    return {
        riff: (0, riff_1.riffSpecificState)({
            controller,
            logLevel,
            readerInterface,
            src,
            prefetchCache,
            contentLength
        }),
        transportStream: (0, transport_stream_1.transportStreamState)(),
        webm: (0, webm_1.webmState)({
            controller,
            logLevel,
            readerInterface,
            src,
            prefetchCache
        }),
        iso: (0, iso_state_1.isoBaseMediaState)({
            contentLength,
            controller,
            readerInterface,
            src,
            logLevel,
            prefetchCache
        }),
        mp3,
        aac: (0, aac_state_1.aacState)(),
        flac: (0, flac_state_1.flacState)(),
        m3u: (0, m3u_state_1.m3uState)(logLevel),
        timings,
        callbacks: (0, sample_callbacks_1.callbacksState)({
            controller,
            hasAudioTrackHandlers,
            hasVideoTrackHandlers,
            fields,
            keyframes,
            emittedFields,
            samplesObserved,
            structure,
            src,
            seekSignal: controller._internals.seekSignal,
            logLevel
        }),
        getInternalStats: ()=>{
            var _a;
            return {
                skippedBytes,
                finalCursorOffset: (_a = iterator.counter.getOffset()) !== null && _a !== void 0 ? _a : 0
            };
        },
        getSkipBytes: ()=>skippedBytes,
        increaseSkippedBytes,
        keyframes,
        structure,
        onAudioTrack,
        onVideoTrack,
        emittedFields,
        fields,
        samplesObserved,
        contentLength,
        images,
        mediaSection,
        logLevel,
        iterator,
        controller,
        mode,
        src,
        readerInterface,
        discardReadBytes,
        selectM3uStreamFn,
        selectM3uAssociatedPlaylistsFn,
        m3uPlaylistContext,
        contentType,
        name,
        returnValue,
        callbackFunctions: callbacks,
        fieldsInReturnValue,
        mimeType,
        errored: errored,
        currentReader: currentReaderState,
        seekInfiniteLoop,
        makeSamplesStartAtZero,
        prefetchCache,
        avc
    };
};
exports.makeParserState = makeParserState;
}),
"[project]/node_modules/@remotion/media-parser/dist/throttled-progress.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.throttledStateUpdate = void 0;
const throttledStateUpdate = ({ updateFn, everyMilliseconds, controller })=>{
    let currentState = {
        bytes: 0,
        percentage: null,
        totalBytes: null
    };
    if (!updateFn) {
        return {
            get: ()=>currentState,
            update: null,
            stopAndGetLastProgress: ()=>{}
        };
    }
    let lastUpdated = null;
    const callUpdateIfChanged = ()=>{
        if (currentState === lastUpdated) {
            return;
        }
        updateFn(currentState);
        lastUpdated = currentState;
    };
    let cleanup = ()=>{};
    if (everyMilliseconds > 0) {
        const interval = setInterval(()=>{
            callUpdateIfChanged();
        }, everyMilliseconds);
        const onAbort = ()=>{
            clearInterval(interval);
        };
        controller._internals.signal.addEventListener('abort', onAbort, {
            once: true
        });
        cleanup = ()=>{
            clearInterval(interval);
            controller._internals.signal.removeEventListener('abort', onAbort);
        };
    }
    return {
        get: ()=>currentState,
        update: (fn)=>{
            currentState = fn(currentState);
            if (everyMilliseconds === 0) {
                callUpdateIfChanged();
            }
        },
        stopAndGetLastProgress: ()=>{
            cleanup();
            return currentState;
        }
    };
};
exports.throttledStateUpdate = throttledStateUpdate;
}),
"[project]/node_modules/@remotion/media-parser/dist/internal-parse-media.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.internalParseMedia = void 0;
const media_parser_controller_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/controller/media-parser-controller.js [app-route] (ecmascript)");
const emit_all_info_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/emit-all-info.js [app-route] (ecmascript)");
const get_seeking_hints_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/get-seeking-hints.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const parse_loop_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/parse-loop.js [app-route] (ecmascript)");
const print_timings_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/print-timings.js [app-route] (ecmascript)");
const remotion_license_acknowledge_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/remotion-license-acknowledge.js [app-route] (ecmascript)");
const set_seeking_hints_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/set-seeking-hints.js [app-route] (ecmascript)");
const parser_state_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/parser-state.js [app-route] (ecmascript)");
const throttled_progress_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/throttled-progress.js [app-route] (ecmascript)");
const work_on_seek_request_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/work-on-seek-request.js [app-route] (ecmascript)");
const internalParseMedia = async function({ src, fields: _fieldsInReturnValue, reader: readerInterface, onAudioTrack, onVideoTrack, controller = (0, media_parser_controller_1.mediaParserController)(), logLevel, onParseProgress: onParseProgressDoNotCallDirectly, progressIntervalInMs, mode, onDiscardedData, onError, acknowledgeRemotionLicense, apiName, selectM3uStream: selectM3uStreamFn, selectM3uAssociatedPlaylists: selectM3uAssociatedPlaylistsFn, m3uPlaylistContext, makeSamplesStartAtZero, seekingHints, ...more }) {
    var _a;
    if (!src) {
        throw new Error('No "src" provided');
    }
    controller._internals.markAsReadyToEmitEvents();
    (0, remotion_license_acknowledge_1.warnIfRemotionLicenseNotAcknowledged)({
        acknowledgeRemotionLicense,
        logLevel,
        apiName
    });
    log_1.Log.verbose(logLevel, `Reading ${typeof src === 'string' ? src : src instanceof URL ? src.toString() : src instanceof File ? src.name : src.toString()}`);
    const prefetchCache = new Map();
    const { reader: readerInstance, contentLength, name, contentType, supportsContentRange, needsContentRange } = await readerInterface.read({
        src,
        range: null,
        controller,
        logLevel,
        prefetchCache
    });
    if (contentLength === null) {
        throw new Error(`Cannot read media ${src} without a content length. This is currently not supported. Ensure the media has a "Content-Length" HTTP header.`);
    }
    if (!supportsContentRange && needsContentRange) {
        throw new Error('Cannot read media without it supporting the "Content-Range" header. This is currently not supported. Ensure the media supports the "Content-Range" HTTP header.');
    }
    const hasAudioTrackHandlers = Boolean(onAudioTrack);
    const hasVideoTrackHandlers = Boolean(onVideoTrack);
    const state = (0, parser_state_1.makeParserState)({
        hasAudioTrackHandlers,
        hasVideoTrackHandlers,
        controller,
        onAudioTrack: onAudioTrack !== null && onAudioTrack !== void 0 ? onAudioTrack : null,
        onVideoTrack: onVideoTrack !== null && onVideoTrack !== void 0 ? onVideoTrack : null,
        contentLength,
        logLevel,
        mode,
        readerInterface,
        src,
        onDiscardedData,
        selectM3uStreamFn,
        selectM3uAssociatedPlaylistsFn,
        m3uPlaylistContext,
        contentType,
        name,
        callbacks: more,
        fieldsInReturnValue: _fieldsInReturnValue !== null && _fieldsInReturnValue !== void 0 ? _fieldsInReturnValue : {},
        mimeType: contentType,
        initialReaderInstance: readerInstance,
        makeSamplesStartAtZero,
        prefetchCache
    });
    if (seekingHints) {
        (0, set_seeking_hints_1.setSeekingHints)({
            hints: seekingHints,
            state
        });
    }
    controller._internals.attachSeekingHintResolution(()=>Promise.resolve((0, get_seeking_hints_1.getSeekingHints)({
            tracksState: state.callbacks.tracks,
            keyframesState: state.keyframes,
            webmState: state.webm,
            structureState: state.structure,
            m3uPlaylistContext: state.m3uPlaylistContext,
            mediaSectionState: state.mediaSection,
            isoState: state.iso,
            transportStream: state.transportStream,
            flacState: state.flac,
            samplesObserved: state.samplesObserved,
            riffState: state.riff,
            mp3State: state.mp3,
            contentLength: state.contentLength,
            aacState: state.aac
        })));
    controller._internals.attachSimulateSeekResolution((seek)=>{
        const { aacState, avcState, flacState, isoState, iterator, keyframes, m3uState, mediaSection, mp3State, riffState, samplesObserved, structureState, tracksState, transportStream, webmState } = (0, work_on_seek_request_1.getWorkOnSeekRequestOptions)(state);
        return (0, work_on_seek_request_1.turnSeekIntoByte)({
            aacState,
            seek,
            avcState,
            contentLength,
            flacState,
            isoState,
            iterator,
            keyframes,
            logLevel,
            m3uPlaylistContext,
            m3uState,
            mediaSectionState: mediaSection,
            mp3State,
            riffState,
            samplesObserved,
            structureState,
            tracksState,
            transportStream,
            webmState
        });
    });
    if (!hasAudioTrackHandlers && !hasVideoTrackHandlers && Object.values(state.fields).every((v)=>!v) && mode === 'query') {
        log_1.Log.warn(logLevel, new Error('Warning - No `fields` and no `on*` callbacks were passed to `parseMedia()`. Specify the data you would like to retrieve.'));
    }
    const throttledState = (0, throttled_progress_1.throttledStateUpdate)({
        updateFn: onParseProgressDoNotCallDirectly !== null && onParseProgressDoNotCallDirectly !== void 0 ? onParseProgressDoNotCallDirectly : null,
        everyMilliseconds: progressIntervalInMs !== null && progressIntervalInMs !== void 0 ? progressIntervalInMs : 100,
        controller,
        totalBytes: contentLength
    });
    await (0, emit_all_info_1.triggerInfoEmit)(state);
    await (0, parse_loop_1.parseLoop)({
        state,
        throttledState,
        onError
    });
    log_1.Log.verbose(logLevel, 'Finished parsing file');
    await (0, emit_all_info_1.emitAllInfo)(state);
    (0, print_timings_1.printTimings)(state);
    state.currentReader.getCurrent().abort();
    (_a = state.iterator) === null || _a === void 0 ? void 0 : _a.destroy();
    state.callbacks.tracks.ensureHasTracksAtEnd(state.fields);
    state.m3u.abortM3UStreamRuns();
    prefetchCache.clear();
    if (state.errored) {
        throw state.errored;
    }
    if (state.controller._internals.seekSignal.getSeek() !== null) {
        throw new Error('Should not finish while a seek is pending');
    }
    return state.returnValue;
};
exports.internalParseMedia = internalParseMedia;
}),
"[project]/node_modules/@remotion/media-parser/dist/download-and-parse-media.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.downloadAndParseMedia = void 0;
const select_stream_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/select-stream.js [app-route] (ecmascript)");
const internal_parse_media_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/internal-parse-media.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const web_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/web.js [app-route] (ecmascript)");
const downloadAndParseMedia = async (options)=>{
    var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v, _w, _x, _y, _z, _0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16;
    if (!options) {
        return Promise.reject(new Error('No options provided. See https://www.remotion.dev/media-parser for how to get started.'));
    }
    const logLevel = (_a = options.logLevel) !== null && _a !== void 0 ? _a : 'info';
    const content = await options.writer.createContent({
        filename: 'hmm',
        mimeType: 'shouldnotmatter',
        logLevel
    });
    const returnValue = await (0, internal_parse_media_1.internalParseMedia)({
        fields: (_b = options.fields) !== null && _b !== void 0 ? _b : null,
        logLevel,
        mode: 'download',
        onAudioCodec: (_c = options.onAudioCodec) !== null && _c !== void 0 ? _c : null,
        onAudioTrack: (_d = options.onAudioTrack) !== null && _d !== void 0 ? _d : null,
        onContainer: (_e = options.onContainer) !== null && _e !== void 0 ? _e : null,
        onDimensions: (_f = options.onDimensions) !== null && _f !== void 0 ? _f : null,
        selectM3uStream: (_g = options.selectM3uStream) !== null && _g !== void 0 ? _g : select_stream_1.defaultSelectM3uStreamFn,
        selectM3uAssociatedPlaylists: (_h = options.selectM3uAssociatedPlaylists) !== null && _h !== void 0 ? _h : select_stream_1.defaultSelectM3uAssociatedPlaylists,
        m3uPlaylistContext: (_j = options.m3uPlaylistContext) !== null && _j !== void 0 ? _j : null,
        onDiscardedData: async (data)=>{
            await content.write(data);
        },
        onDurationInSeconds: (_k = options.onDurationInSeconds) !== null && _k !== void 0 ? _k : null,
        onFps: (_l = options.onFps) !== null && _l !== void 0 ? _l : null,
        onImages: (_m = options.onImages) !== null && _m !== void 0 ? _m : null,
        onInternalStats: (_o = options.onInternalStats) !== null && _o !== void 0 ? _o : null,
        onIsHdr: (_p = options.onIsHdr) !== null && _p !== void 0 ? _p : null,
        onKeyframes: (_q = options.onKeyframes) !== null && _q !== void 0 ? _q : null,
        onLocation: (_r = options.onLocation) !== null && _r !== void 0 ? _r : null,
        onMetadata: (_s = options.onMetadata) !== null && _s !== void 0 ? _s : null,
        onMimeType: (_t = options.onMimeType) !== null && _t !== void 0 ? _t : null,
        onName: (_u = options.onName) !== null && _u !== void 0 ? _u : null,
        onNumberOfAudioChannels: (_v = options.onNumberOfAudioChannels) !== null && _v !== void 0 ? _v : null,
        onParseProgress: (_w = options.onParseProgress) !== null && _w !== void 0 ? _w : null,
        onRotation: (_x = options.onRotation) !== null && _x !== void 0 ? _x : null,
        onSampleRate: (_y = options.onSampleRate) !== null && _y !== void 0 ? _y : null,
        onSize: (_z = options.onSize) !== null && _z !== void 0 ? _z : null,
        onSlowAudioBitrate: (_0 = options.onSlowAudioBitrate) !== null && _0 !== void 0 ? _0 : null,
        onSlowDurationInSeconds: (_1 = options.onSlowDurationInSeconds) !== null && _1 !== void 0 ? _1 : null,
        onSlowFps: (_2 = options.onSlowFps) !== null && _2 !== void 0 ? _2 : null,
        onSlowKeyframes: (_3 = options.onSlowKeyframes) !== null && _3 !== void 0 ? _3 : null,
        onSlowNumberOfFrames: (_4 = options.onSlowNumberOfFrames) !== null && _4 !== void 0 ? _4 : null,
        onSlowVideoBitrate: (_5 = options.onSlowVideoBitrate) !== null && _5 !== void 0 ? _5 : null,
        onSlowStructure: (_6 = options.onSlowStructure) !== null && _6 !== void 0 ? _6 : null,
        onM3uStreams: (_7 = options.onM3uStreams) !== null && _7 !== void 0 ? _7 : null,
        onTracks: (_8 = options.onTracks) !== null && _8 !== void 0 ? _8 : null,
        onUnrotatedDimensions: (_9 = options.onUnrotatedDimensions) !== null && _9 !== void 0 ? _9 : null,
        onVideoCodec: (_10 = options.onVideoCodec) !== null && _10 !== void 0 ? _10 : null,
        onVideoTrack: (_11 = options.onVideoTrack) !== null && _11 !== void 0 ? _11 : null,
        progressIntervalInMs: (_12 = options.progressIntervalInMs) !== null && _12 !== void 0 ? _12 : null,
        reader: (_13 = options.reader) !== null && _13 !== void 0 ? _13 : web_1.webReader,
        controller: (_14 = options.controller) !== null && _14 !== void 0 ? _14 : undefined,
        src: options.src,
        onError: async (err)=>{
            var _a, _b;
            const action = (_b = await ((_a = options.onError) === null || _a === void 0 ? void 0 : _a.call(options, err))) !== null && _b !== void 0 ? _b : {
                action: 'fail'
            };
            if (action.action === 'fail') {
                log_1.Log.verbose(logLevel, 'Removing content');
                await content.finish();
                await content.remove();
            }
            return action;
        },
        acknowledgeRemotionLicense: Boolean(options.acknowledgeRemotionLicense),
        apiName: 'parseAndDownloadMedia()',
        makeSamplesStartAtZero: (_15 = options.makeSamplesStartAtZero) !== null && _15 !== void 0 ? _15 : true,
        seekingHints: (_16 = options.seekingHints) !== null && _16 !== void 0 ? _16 : null
    });
    await content.finish();
    return returnValue;
};
exports.downloadAndParseMedia = downloadAndParseMedia;
}),
"[project]/node_modules/@remotion/media-parser/dist/version.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.VERSION = void 0;
// Automatically generated on publish
exports.VERSION = '4.0.394';
}),
"[project]/node_modules/@remotion/media-parser/dist/index.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.WEBCODECS_TIMESCALE = exports.VERSION = exports.mediaParserController = exports.defaultSelectM3uStreamFn = exports.defaultSelectM3uAssociatedPlaylists = exports.MediaParserInternals = exports.downloadAndParseMedia = exports.MediaParserAbortError = exports.IsAPdfError = exports.IsAnUnsupportedFileTypeError = exports.IsAnImageError = exports.hasBeenAborted = exports.parseMedia = void 0;
const aac_codecprivate_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/aac-codecprivate.js [app-route] (ecmascript)");
const ftyp_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/ftyp.js [app-route] (ecmascript)");
const mvhd_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/moov/mvhd.js [app-route] (ecmascript)");
const samples_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/samples.js [app-route] (ecmascript)");
const stsd_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/stsd/stsd.js [app-route] (ecmascript)");
const tkhd_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/iso-base-media/tkhd.js [app-route] (ecmascript)");
const parse_ebml_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/parse-ebml.js [app-route] (ecmascript)");
const all_segments_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/webm/segments/all-segments.js [app-route] (ecmascript)");
const internal_parse_media_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/internal-parse-media.js [app-route] (ecmascript)");
const buffer_iterator_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/iterator/buffer-iterator.js [app-route] (ecmascript)");
const log_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/log.js [app-route] (ecmascript)");
const need_samples_for_fields_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/need-samples-for-fields.js [app-route] (ecmascript)");
const parser_state_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/state/parser-state.js [app-route] (ecmascript)");
var parse_media_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/parse-media.js [app-route] (ecmascript)");
Object.defineProperty(exports, "parseMedia", {
    enumerable: true,
    get: function() {
        return parse_media_1.parseMedia;
    }
});
var errors_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/errors.js [app-route] (ecmascript)");
Object.defineProperty(exports, "hasBeenAborted", {
    enumerable: true,
    get: function() {
        return errors_1.hasBeenAborted;
    }
});
Object.defineProperty(exports, "IsAnImageError", {
    enumerable: true,
    get: function() {
        return errors_1.IsAnImageError;
    }
});
Object.defineProperty(exports, "IsAnUnsupportedFileTypeError", {
    enumerable: true,
    get: function() {
        return errors_1.IsAnUnsupportedFileTypeError;
    }
});
Object.defineProperty(exports, "IsAPdfError", {
    enumerable: true,
    get: function() {
        return errors_1.IsAPdfError;
    }
});
Object.defineProperty(exports, "MediaParserAbortError", {
    enumerable: true,
    get: function() {
        return errors_1.MediaParserAbortError;
    }
});
var download_and_parse_media_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/download-and-parse-media.js [app-route] (ecmascript)");
Object.defineProperty(exports, "downloadAndParseMedia", {
    enumerable: true,
    get: function() {
        return download_and_parse_media_1.downloadAndParseMedia;
    }
});
/**
 * @deprecated Dont use these yet.
 */ exports.MediaParserInternals = {
    Log: log_1.Log,
    createAacCodecPrivate: aac_codecprivate_1.createAacCodecPrivate,
    matroskaElements: all_segments_1.matroskaElements,
    ebmlMap: all_segments_1.ebmlMap,
    parseTkhd: tkhd_1.parseTkhd,
    getArrayBufferIterator: buffer_iterator_1.getArrayBufferIterator,
    parseStsd: stsd_1.parseStsd,
    makeParserState: parser_state_1.makeParserState,
    processSample: samples_1.processIsoFormatBox,
    parseFtyp: ftyp_1.parseFtyp,
    parseEbml: parse_ebml_1.parseEbml,
    parseMvhd: mvhd_1.parseMvhd,
    internalParseMedia: internal_parse_media_1.internalParseMedia,
    fieldsNeedSamplesMap: need_samples_for_fields_1.fieldsNeedSamplesMap
};
var select_stream_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/containers/m3u/select-stream.js [app-route] (ecmascript)");
Object.defineProperty(exports, "defaultSelectM3uAssociatedPlaylists", {
    enumerable: true,
    get: function() {
        return select_stream_1.defaultSelectM3uAssociatedPlaylists;
    }
});
Object.defineProperty(exports, "defaultSelectM3uStreamFn", {
    enumerable: true,
    get: function() {
        return select_stream_1.defaultSelectM3uStreamFn;
    }
});
var media_parser_controller_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/controller/media-parser-controller.js [app-route] (ecmascript)");
Object.defineProperty(exports, "mediaParserController", {
    enumerable: true,
    get: function() {
        return media_parser_controller_1.mediaParserController;
    }
});
var version_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/version.js [app-route] (ecmascript)");
Object.defineProperty(exports, "VERSION", {
    enumerable: true,
    get: function() {
        return version_1.VERSION;
    }
});
var webcodecs_timescale_1 = __turbopack_context__.r("[project]/node_modules/@remotion/media-parser/dist/webcodecs-timescale.js [app-route] (ecmascript)");
Object.defineProperty(exports, "WEBCODECS_TIMESCALE", {
    enumerable: true,
    get: function() {
        return webcodecs_timescale_1.WEBCODECS_TIMESCALE;
    }
});
}),
];

//# sourceMappingURL=node_modules_%40remotion_media-parser_dist_972b5ca2._.js.map