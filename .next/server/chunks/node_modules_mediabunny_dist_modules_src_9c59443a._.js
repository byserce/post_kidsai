module.exports = [
"[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "AsyncMutex",
    ()=>AsyncMutex,
    "Bitstream",
    ()=>Bitstream,
    "COLOR_PRIMARIES_MAP",
    ()=>COLOR_PRIMARIES_MAP,
    "COLOR_PRIMARIES_MAP_INVERSE",
    ()=>COLOR_PRIMARIES_MAP_INVERSE,
    "CallSerializer",
    ()=>CallSerializer,
    "MATRIX_COEFFICIENTS_MAP",
    ()=>MATRIX_COEFFICIENTS_MAP,
    "MATRIX_COEFFICIENTS_MAP_INVERSE",
    ()=>MATRIX_COEFFICIENTS_MAP_INVERSE,
    "SECOND_TO_MICROSECOND_FACTOR",
    ()=>SECOND_TO_MICROSECOND_FACTOR,
    "TRANSFER_CHARACTERISTICS_MAP",
    ()=>TRANSFER_CHARACTERISTICS_MAP,
    "TRANSFER_CHARACTERISTICS_MAP_INVERSE",
    ()=>TRANSFER_CHARACTERISTICS_MAP_INVERSE,
    "UNDETERMINED_LANGUAGE",
    ()=>UNDETERMINED_LANGUAGE,
    "assert",
    ()=>assert,
    "assertNever",
    ()=>assertNever,
    "base64ToBytes",
    ()=>base64ToBytes,
    "binarySearchExact",
    ()=>binarySearchExact,
    "binarySearchLessOrEqual",
    ()=>binarySearchLessOrEqual,
    "bytesToBase64",
    ()=>bytesToBase64,
    "bytesToHexString",
    ()=>bytesToHexString,
    "clamp",
    ()=>clamp,
    "closedIntervalsOverlap",
    ()=>closedIntervalsOverlap,
    "coalesceIndex",
    ()=>coalesceIndex,
    "colorSpaceIsComplete",
    ()=>colorSpaceIsComplete,
    "computeRationalApproximation",
    ()=>computeRationalApproximation,
    "findLast",
    ()=>findLast,
    "findLastIndex",
    ()=>findLastIndex,
    "getChromiumVersion",
    ()=>getChromiumVersion,
    "getInt24",
    ()=>getInt24,
    "getUint24",
    ()=>getUint24,
    "ilog",
    ()=>ilog,
    "imageMimeTypeToExtension",
    ()=>imageMimeTypeToExtension,
    "insertSorted",
    ()=>insertSorted,
    "isAllowSharedBufferSource",
    ()=>isAllowSharedBufferSource,
    "isChromium",
    ()=>isChromium,
    "isFirefox",
    ()=>isFirefox,
    "isIso639Dash2LanguageCode",
    ()=>isIso639Dash2LanguageCode,
    "isIso88591Compatible",
    ()=>isIso88591Compatible,
    "isNumber",
    ()=>isNumber,
    "isU32",
    ()=>isU32,
    "isWebKit",
    ()=>isWebKit,
    "keyValueIterator",
    ()=>keyValueIterator,
    "last",
    ()=>last,
    "mapAsyncGenerator",
    ()=>mapAsyncGenerator,
    "mergeRequestInit",
    ()=>mergeRequestInit,
    "normalizeRotation",
    ()=>normalizeRotation,
    "polyfillSymbolDispose",
    ()=>polyfillSymbolDispose,
    "promiseWithResolvers",
    ()=>promiseWithResolvers,
    "readExpGolomb",
    ()=>readExpGolomb,
    "readSignedExpGolomb",
    ()=>readSignedExpGolomb,
    "removeItem",
    ()=>removeItem,
    "retriedFetch",
    ()=>retriedFetch,
    "reverseBitsU32",
    ()=>reverseBitsU32,
    "roundIfAlmostInteger",
    ()=>roundIfAlmostInteger,
    "roundToMultiple",
    ()=>roundToMultiple,
    "setInt24",
    ()=>setInt24,
    "setInt64",
    ()=>setInt64,
    "setUint24",
    ()=>setUint24,
    "textDecoder",
    ()=>textDecoder,
    "textEncoder",
    ()=>textEncoder,
    "toAsyncIterator",
    ()=>toAsyncIterator,
    "toDataView",
    ()=>toDataView,
    "toUint8Array",
    ()=>toUint8Array,
    "uint8ArraysAreEqual",
    ()=>uint8ArraysAreEqual,
    "validateAnyIterable",
    ()=>validateAnyIterable,
    "writeBits",
    ()=>writeBits
]);
function assert(x) {
    if (!x) {
        throw new Error('Assertion failed.');
    }
}
const normalizeRotation = (rotation)=>{
    const mappedRotation = (rotation % 360 + 360) % 360;
    if (mappedRotation === 0 || mappedRotation === 90 || mappedRotation === 180 || mappedRotation === 270) {
        return mappedRotation;
    } else {
        throw new Error(`Invalid rotation ${rotation}.`);
    }
};
const last = (arr)=>{
    return arr && arr[arr.length - 1];
};
const isU32 = (value)=>{
    return value >= 0 && value < 2 ** 32;
};
class Bitstream {
    constructor(bytes){
        this.bytes = bytes;
        /** Current offset in bits. */ this.pos = 0;
    }
    seekToByte(byteOffset) {
        this.pos = 8 * byteOffset;
    }
    readBit() {
        const byteIndex = Math.floor(this.pos / 8);
        const byte = this.bytes[byteIndex] ?? 0;
        const bitIndex = 0b111 - (this.pos & 0b111);
        const bit = (byte & 1 << bitIndex) >> bitIndex;
        this.pos++;
        return bit;
    }
    readBits(n) {
        if (n === 1) {
            return this.readBit();
        }
        let result = 0;
        for(let i = 0; i < n; i++){
            result <<= 1;
            result |= this.readBit();
        }
        return result;
    }
    writeBits(n, value) {
        const end = this.pos + n;
        for(let i = this.pos; i < end; i++){
            const byteIndex = Math.floor(i / 8);
            let byte = this.bytes[byteIndex];
            const bitIndex = 0b111 - (i & 0b111);
            byte &= ~(1 << bitIndex);
            byte |= (value & 1 << end - i - 1) >> end - i - 1 << bitIndex;
            this.bytes[byteIndex] = byte;
        }
        this.pos = end;
    }
    readAlignedByte() {
        // Ensure we're byte-aligned
        if (this.pos % 8 !== 0) {
            throw new Error('Bitstream is not byte-aligned.');
        }
        const byteIndex = this.pos / 8;
        const byte = this.bytes[byteIndex] ?? 0;
        this.pos += 8;
        return byte;
    }
    skipBits(n) {
        this.pos += n;
    }
    getBitsLeft() {
        return this.bytes.length * 8 - this.pos;
    }
    clone() {
        const clone = new Bitstream(this.bytes);
        clone.pos = this.pos;
        return clone;
    }
}
const readExpGolomb = (bitstream)=>{
    let leadingZeroBits = 0;
    while(bitstream.readBits(1) === 0 && leadingZeroBits < 32){
        leadingZeroBits++;
    }
    if (leadingZeroBits >= 32) {
        throw new Error('Invalid exponential-Golomb code.');
    }
    const result = (1 << leadingZeroBits) - 1 + bitstream.readBits(leadingZeroBits);
    return result;
};
const readSignedExpGolomb = (bitstream)=>{
    const codeNum = readExpGolomb(bitstream);
    return (codeNum & 1) === 0 ? -(codeNum >> 1) : codeNum + 1 >> 1;
};
const writeBits = (bytes, start, end, value)=>{
    for(let i = start; i < end; i++){
        const byteIndex = Math.floor(i / 8);
        let byte = bytes[byteIndex];
        const bitIndex = 0b111 - (i & 0b111);
        byte &= ~(1 << bitIndex);
        byte |= (value & 1 << end - i - 1) >> end - i - 1 << bitIndex;
        bytes[byteIndex] = byte;
    }
};
const toUint8Array = (source)=>{
    if (source.constructor === Uint8Array) {
        return source;
    } else if (ArrayBuffer.isView(source)) {
        return new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else {
        return new Uint8Array(source);
    }
};
const toDataView = (source)=>{
    if (source.constructor === DataView) {
        return source;
    } else if (ArrayBuffer.isView(source)) {
        return new DataView(source.buffer, source.byteOffset, source.byteLength);
    } else {
        return new DataView(source);
    }
};
const textDecoder = /* #__PURE__ */ new TextDecoder();
const textEncoder = /* #__PURE__ */ new TextEncoder();
const isIso88591Compatible = (text)=>{
    for(let i = 0; i < text.length; i++){
        const code = text.charCodeAt(i);
        if (code > 255) {
            return false;
        }
    }
    return true;
};
const invertObject = (object)=>{
    return Object.fromEntries(Object.entries(object).map(([key, value])=>[
            value,
            key
        ]));
};
const COLOR_PRIMARIES_MAP = {
    bt709: 1,
    bt470bg: 5,
    smpte170m: 6,
    bt2020: 9,
    smpte432: 12
};
const COLOR_PRIMARIES_MAP_INVERSE = /* #__PURE__ */ invertObject(COLOR_PRIMARIES_MAP);
const TRANSFER_CHARACTERISTICS_MAP = {
    'bt709': 1,
    'smpte170m': 6,
    'linear': 8,
    'iec61966-2-1': 13,
    'pq': 16,
    'hlg': 18
};
const TRANSFER_CHARACTERISTICS_MAP_INVERSE = /* #__PURE__ */ invertObject(TRANSFER_CHARACTERISTICS_MAP);
const MATRIX_COEFFICIENTS_MAP = {
    'rgb': 0,
    'bt709': 1,
    'bt470bg': 5,
    'smpte170m': 6,
    'bt2020-ncl': 9
};
const MATRIX_COEFFICIENTS_MAP_INVERSE = /* #__PURE__ */ invertObject(MATRIX_COEFFICIENTS_MAP);
const colorSpaceIsComplete = (colorSpace)=>{
    return !!colorSpace && !!colorSpace.primaries && !!colorSpace.transfer && !!colorSpace.matrix && colorSpace.fullRange !== undefined;
};
const isAllowSharedBufferSource = (x)=>{
    return x instanceof ArrayBuffer || typeof SharedArrayBuffer !== 'undefined' && x instanceof SharedArrayBuffer || ArrayBuffer.isView(x);
};
class AsyncMutex {
    constructor(){
        this.currentPromise = Promise.resolve();
    }
    async acquire() {
        let resolver;
        const nextPromise = new Promise((resolve)=>{
            resolver = resolve;
        });
        const currentPromiseAlias = this.currentPromise;
        this.currentPromise = nextPromise;
        await currentPromiseAlias;
        return resolver;
    }
}
const bytesToHexString = (bytes)=>{
    return [
        ...bytes
    ].map((x)=>x.toString(16).padStart(2, '0')).join('');
};
const reverseBitsU32 = (x)=>{
    x = x >> 1 & 0x55555555 | (x & 0x55555555) << 1;
    x = x >> 2 & 0x33333333 | (x & 0x33333333) << 2;
    x = x >> 4 & 0x0f0f0f0f | (x & 0x0f0f0f0f) << 4;
    x = x >> 8 & 0x00ff00ff | (x & 0x00ff00ff) << 8;
    x = x >> 16 & 0x0000ffff | (x & 0x0000ffff) << 16;
    return x >>> 0; // Ensure it's treated as an unsigned 32-bit integer
};
const binarySearchExact = (arr, key, valueGetter)=>{
    let low = 0;
    let high = arr.length - 1;
    let ans = -1;
    while(low <= high){
        const mid = low + high >> 1;
        const midVal = valueGetter(arr[mid]);
        if (midVal === key) {
            ans = mid;
            high = mid - 1; // Continue searching left to find the lowest index
        } else if (midVal < key) {
            low = mid + 1;
        } else {
            high = mid - 1;
        }
    }
    return ans;
};
const binarySearchLessOrEqual = (arr, key, valueGetter)=>{
    let low = 0;
    let high = arr.length - 1;
    let ans = -1;
    while(low <= high){
        const mid = low + (high - low + 1) / 2 | 0;
        const midVal = valueGetter(arr[mid]);
        if (midVal <= key) {
            ans = mid;
            low = mid + 1;
        } else {
            high = mid - 1;
        }
    }
    return ans;
};
const insertSorted = (arr, item, valueGetter)=>{
    const insertionIndex = binarySearchLessOrEqual(arr, valueGetter(item), valueGetter);
    arr.splice(insertionIndex + 1, 0, item); // This even behaves correctly for the -1 case
};
const promiseWithResolvers = ()=>{
    let resolve;
    let reject;
    const promise = new Promise((res, rej)=>{
        resolve = res;
        reject = rej;
    });
    return {
        promise,
        resolve: resolve,
        reject: reject
    };
};
const removeItem = (arr, item)=>{
    const index = arr.indexOf(item);
    if (index !== -1) {
        arr.splice(index, 1);
    }
};
const findLast = (arr, predicate)=>{
    for(let i = arr.length - 1; i >= 0; i--){
        if (predicate(arr[i])) {
            return arr[i];
        }
    }
    return undefined;
};
const findLastIndex = (arr, predicate)=>{
    for(let i = arr.length - 1; i >= 0; i--){
        if (predicate(arr[i])) {
            return i;
        }
    }
    return -1;
};
const toAsyncIterator = async function*(source) {
    if (Symbol.iterator in source) {
        // @ts-expect-error Trust me
        yield* source[Symbol.iterator]();
    } else {
        // @ts-expect-error Trust me
        yield* source[Symbol.asyncIterator]();
    }
};
const validateAnyIterable = (iterable)=>{
    if (!(Symbol.iterator in iterable) && !(Symbol.asyncIterator in iterable)) {
        throw new TypeError('Argument must be an iterable or async iterable.');
    }
};
const assertNever = (x)=>{
    // eslint-disable-next-line @typescript-eslint/restrict-template-expressions
    throw new Error(`Unexpected value: ${x}`);
};
const getUint24 = (view, byteOffset, littleEndian)=>{
    const byte1 = view.getUint8(byteOffset);
    const byte2 = view.getUint8(byteOffset + 1);
    const byte3 = view.getUint8(byteOffset + 2);
    if (littleEndian) {
        return byte1 | byte2 << 8 | byte3 << 16;
    } else {
        return byte1 << 16 | byte2 << 8 | byte3;
    }
};
const getInt24 = (view, byteOffset, littleEndian)=>{
    // The left shift pushes the most significant bit into the sign bit region, and the subsequent right shift
    // then correctly interprets the sign bit.
    return getUint24(view, byteOffset, littleEndian) << 8 >> 8;
};
const setUint24 = (view, byteOffset, value, littleEndian)=>{
    // Ensure the value is within 24-bit unsigned range (0 to 16777215)
    value = value >>> 0; // Convert to unsigned 32-bit
    value = value & 0xFFFFFF; // Mask to 24 bits
    if (littleEndian) {
        view.setUint8(byteOffset, value & 0xFF);
        view.setUint8(byteOffset + 1, value >>> 8 & 0xFF);
        view.setUint8(byteOffset + 2, value >>> 16 & 0xFF);
    } else {
        view.setUint8(byteOffset, value >>> 16 & 0xFF);
        view.setUint8(byteOffset + 1, value >>> 8 & 0xFF);
        view.setUint8(byteOffset + 2, value & 0xFF);
    }
};
const setInt24 = (view, byteOffset, value, littleEndian)=>{
    // Ensure the value is within 24-bit signed range (-8388608 to 8388607)
    value = clamp(value, -8388608, 8388607);
    // Convert negative values to their 24-bit representation
    if (value < 0) {
        value = value + 0x1000000 & 0xFFFFFF;
    }
    setUint24(view, byteOffset, value, littleEndian);
};
const setInt64 = (view, byteOffset, value, littleEndian)=>{
    if (littleEndian) {
        view.setUint32(byteOffset + 0, value, true);
        view.setInt32(byteOffset + 4, Math.floor(value / 2 ** 32), true);
    } else {
        view.setInt32(byteOffset + 0, Math.floor(value / 2 ** 32), true);
        view.setUint32(byteOffset + 4, value, true);
    }
};
const mapAsyncGenerator = (generator, map)=>{
    return {
        async next () {
            const result = await generator.next();
            if (result.done) {
                return {
                    value: undefined,
                    done: true
                };
            } else {
                return {
                    value: map(result.value),
                    done: false
                };
            }
        },
        return () {
            return generator.return();
        },
        throw (error) {
            return generator.throw(error);
        },
        [Symbol.asyncIterator] () {
            return this;
        }
    };
};
const clamp = (value, min, max)=>{
    return Math.max(min, Math.min(max, value));
};
const UNDETERMINED_LANGUAGE = 'und';
const roundIfAlmostInteger = (value)=>{
    const rounded = Math.round(value);
    if (Math.abs(value / rounded - 1) < 10 * Number.EPSILON) {
        return rounded;
    } else {
        return value;
    }
};
const roundToMultiple = (value, multiple)=>{
    return Math.round(value / multiple) * multiple;
};
const ilog = (x)=>{
    let ret = 0;
    while(x){
        ret++;
        x >>= 1;
    }
    return ret;
};
const ISO_639_2_REGEX = /^[a-z]{3}$/;
const isIso639Dash2LanguageCode = (x)=>{
    return ISO_639_2_REGEX.test(x);
};
const SECOND_TO_MICROSECOND_FACTOR = 1e6 * (1 + Number.EPSILON);
const mergeRequestInit = (init1, init2)=>{
    const merged = {
        ...init1,
        ...init2
    };
    // Special handling for headers
    if (init1.headers || init2.headers) {
        const headers1 = init1.headers ? normalizeHeaders(init1.headers) : {};
        const headers2 = init2.headers ? normalizeHeaders(init2.headers) : {};
        const mergedHeaders = {
            ...headers1
        };
        // For each header in headers2, check if a case-insensitive match exists in mergedHeaders
        Object.entries(headers2).forEach(([key2, value2])=>{
            const existingKey = Object.keys(mergedHeaders).find((key1)=>key1.toLowerCase() === key2.toLowerCase());
            if (existingKey) {
                delete mergedHeaders[existingKey];
            }
            mergedHeaders[key2] = value2;
        });
        merged.headers = mergedHeaders;
    }
    return merged;
};
/** Normalizes HeadersInit to a Record<string, string> format. */ const normalizeHeaders = (headers)=>{
    if (headers instanceof Headers) {
        const result = {};
        headers.forEach((value, key)=>{
            result[key] = value;
        });
        return result;
    }
    if (Array.isArray(headers)) {
        const result = {};
        headers.forEach(([key, value])=>{
            result[key] = value;
        });
        return result;
    }
    return headers;
};
const retriedFetch = async (fetchFn, url, requestInit, getRetryDelay, shouldStop)=>{
    let attempts = 0;
    while(true){
        try {
            return await fetchFn(url, requestInit);
        } catch (error) {
            if (shouldStop()) {
                throw error;
            }
            attempts++;
            const retryDelayInSeconds = getRetryDelay(attempts, error, url);
            if (retryDelayInSeconds === null) {
                throw error;
            }
            console.error('Retrying failed fetch. Error:', error);
            if (!Number.isFinite(retryDelayInSeconds) || retryDelayInSeconds < 0) {
                throw new TypeError('Retry delay must be a non-negative finite number.');
            }
            if (retryDelayInSeconds > 0) {
                await new Promise((resolve)=>setTimeout(resolve, 1000 * retryDelayInSeconds));
            }
            if (shouldStop()) {
                throw error;
            }
        }
    }
};
const computeRationalApproximation = (x, maxDenominator)=>{
    // Handle negative numbers
    const sign = x < 0 ? -1 : 1;
    x = Math.abs(x);
    let prevNumerator = 0, prevDenominator = 1;
    let currNumerator = 1, currDenominator = 0;
    // Continued fraction algorithm
    let remainder = x;
    while(true){
        const integer = Math.floor(remainder);
        // Calculate next convergent
        const nextNumerator = integer * currNumerator + prevNumerator;
        const nextDenominator = integer * currDenominator + prevDenominator;
        if (nextDenominator > maxDenominator) {
            return {
                numerator: sign * currNumerator,
                denominator: currDenominator
            };
        }
        prevNumerator = currNumerator;
        prevDenominator = currDenominator;
        currNumerator = nextNumerator;
        currDenominator = nextDenominator;
        remainder = 1 / (remainder - integer);
        // Guard against precision issues
        if (!isFinite(remainder)) {
            break;
        }
    }
    return {
        numerator: sign * currNumerator,
        denominator: currDenominator
    };
};
class CallSerializer {
    constructor(){
        this.currentPromise = Promise.resolve();
    }
    call(fn) {
        return this.currentPromise = this.currentPromise.then(fn);
    }
}
let isWebKitCache = null;
const isWebKit = ()=>{
    if (isWebKitCache !== null) {
        return isWebKitCache;
    }
    // This even returns true for WebKit-wrapping browsers such as Chrome on iOS
    return isWebKitCache = !!(typeof navigator !== 'undefined' && (navigator.vendor?.match(/apple/i) || /AppleWebKit/.test(navigator.userAgent) && !/Chrome/.test(navigator.userAgent) || /\b(iPad|iPhone|iPod)\b/.test(navigator.userAgent)));
};
let isFirefoxCache = null;
const isFirefox = ()=>{
    if (isFirefoxCache !== null) {
        return isFirefoxCache;
    }
    return isFirefoxCache = typeof navigator !== 'undefined' && navigator.userAgent?.includes('Firefox');
};
let isChromiumCache = null;
const isChromium = ()=>{
    if (isChromiumCache !== null) {
        return isChromiumCache;
    }
    return isChromiumCache = !!(typeof navigator !== 'undefined' && (navigator.vendor?.includes('Google Inc') || /Chrome/.test(navigator.userAgent)));
};
let chromiumVersionCache = null;
const getChromiumVersion = ()=>{
    if (chromiumVersionCache !== null) {
        return chromiumVersionCache;
    }
    if (typeof navigator === 'undefined') {
        return null;
    }
    const match = /\bChrome\/(\d+)/.exec(navigator.userAgent);
    if (!match) {
        return null;
    }
    return chromiumVersionCache = Number(match[1]);
};
const coalesceIndex = (a, b)=>{
    return a !== -1 ? a : b;
};
const closedIntervalsOverlap = (startA, endA, startB, endB)=>{
    return startA <= endB && startB <= endA;
};
const keyValueIterator = function*(object) {
    for(const key in object){
        const value = object[key];
        if (value === undefined) {
            continue;
        }
        yield {
            key,
            value
        };
    }
};
const imageMimeTypeToExtension = (mimeType)=>{
    switch(mimeType.toLowerCase()){
        case 'image/jpeg':
        case 'image/jpg':
            return '.jpg';
        case 'image/png':
            return '.png';
        case 'image/gif':
            return '.gif';
        case 'image/webp':
            return '.webp';
        case 'image/bmp':
            return '.bmp';
        case 'image/svg+xml':
            return '.svg';
        case 'image/tiff':
            return '.tiff';
        case 'image/avif':
            return '.avif';
        case 'image/x-icon':
        case 'image/vnd.microsoft.icon':
            return '.ico';
        default:
            return null;
    }
};
const base64ToBytes = (base64)=>{
    const decoded = atob(base64);
    const bytes = new Uint8Array(decoded.length);
    for(let i = 0; i < decoded.length; i++){
        bytes[i] = decoded.charCodeAt(i);
    }
    return bytes;
};
const bytesToBase64 = (bytes)=>{
    let string = '';
    for(let i = 0; i < bytes.length; i++){
        string += String.fromCharCode(bytes[i]);
    }
    return btoa(string);
};
const uint8ArraysAreEqual = (a, b)=>{
    if (a.length !== b.length) {
        return false;
    }
    for(let i = 0; i < a.length; i++){
        if (a[i] !== b[i]) {
            return false;
        }
    }
    return true;
};
const polyfillSymbolDispose = ()=>{
    // https://www.typescriptlang.org/docs/handbook/release-notes/typescript-5-2.html
    // @ts-expect-error Readonly
    Symbol.dispose ??= Symbol('Symbol.dispose');
};
const isNumber = (x)=>{
    return typeof x === 'number' && !Number.isNaN(x);
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "AUDIO_CODECS",
    ()=>AUDIO_CODECS,
    "NON_PCM_AUDIO_CODECS",
    ()=>NON_PCM_AUDIO_CODECS,
    "OPUS_SAMPLE_RATE",
    ()=>OPUS_SAMPLE_RATE,
    "PCM_AUDIO_CODECS",
    ()=>PCM_AUDIO_CODECS,
    "SUBTITLE_CODECS",
    ()=>SUBTITLE_CODECS,
    "VIDEO_CODECS",
    ()=>VIDEO_CODECS,
    "VP9_LEVEL_TABLE",
    ()=>VP9_LEVEL_TABLE,
    "aacChannelMap",
    ()=>aacChannelMap,
    "aacFrequencyTable",
    ()=>aacFrequencyTable,
    "buildAacAudioSpecificConfig",
    ()=>buildAacAudioSpecificConfig,
    "buildAudioCodecString",
    ()=>buildAudioCodecString,
    "buildVideoCodecString",
    ()=>buildVideoCodecString,
    "extractAudioCodecString",
    ()=>extractAudioCodecString,
    "extractVideoCodecString",
    ()=>extractVideoCodecString,
    "generateAv1CodecConfigurationFromCodecString",
    ()=>generateAv1CodecConfigurationFromCodecString,
    "generateVp9CodecConfigurationFromCodecString",
    ()=>generateVp9CodecConfigurationFromCodecString,
    "getAudioEncoderConfigExtension",
    ()=>getAudioEncoderConfigExtension,
    "getVideoEncoderConfigExtension",
    ()=>getVideoEncoderConfigExtension,
    "inferCodecFromCodecString",
    ()=>inferCodecFromCodecString,
    "parseAacAudioSpecificConfig",
    ()=>parseAacAudioSpecificConfig,
    "parsePcmCodec",
    ()=>parsePcmCodec,
    "validateAudioChunkMetadata",
    ()=>validateAudioChunkMetadata,
    "validateSubtitleMetadata",
    ()=>validateSubtitleMetadata,
    "validateVideoChunkMetadata",
    ()=>validateVideoChunkMetadata
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
;
const VIDEO_CODECS = [
    'avc',
    'hevc',
    'vp9',
    'av1',
    'vp8'
];
const PCM_AUDIO_CODECS = [
    'pcm-s16',
    'pcm-s16be',
    'pcm-s24',
    'pcm-s24be',
    'pcm-s32',
    'pcm-s32be',
    'pcm-f32',
    'pcm-f32be',
    'pcm-f64',
    'pcm-f64be',
    'pcm-u8',
    'pcm-s8',
    'ulaw',
    'alaw'
];
const NON_PCM_AUDIO_CODECS = [
    'aac',
    'opus',
    'mp3',
    'vorbis',
    'flac'
];
const AUDIO_CODECS = [
    ...NON_PCM_AUDIO_CODECS,
    ...PCM_AUDIO_CODECS
];
const SUBTITLE_CODECS = [
    'webvtt'
]; // TODO add the rest
// https://en.wikipedia.org/wiki/Advanced_Video_Coding
const AVC_LEVEL_TABLE = [
    {
        maxMacroblocks: 99,
        maxBitrate: 64000,
        level: 0x0A
    },
    {
        maxMacroblocks: 396,
        maxBitrate: 192000,
        level: 0x0B
    },
    {
        maxMacroblocks: 396,
        maxBitrate: 384000,
        level: 0x0C
    },
    {
        maxMacroblocks: 396,
        maxBitrate: 768000,
        level: 0x0D
    },
    {
        maxMacroblocks: 396,
        maxBitrate: 2000000,
        level: 0x14
    },
    {
        maxMacroblocks: 792,
        maxBitrate: 4000000,
        level: 0x15
    },
    {
        maxMacroblocks: 1620,
        maxBitrate: 4000000,
        level: 0x16
    },
    {
        maxMacroblocks: 1620,
        maxBitrate: 10000000,
        level: 0x1E
    },
    {
        maxMacroblocks: 3600,
        maxBitrate: 14000000,
        level: 0x1F
    },
    {
        maxMacroblocks: 5120,
        maxBitrate: 20000000,
        level: 0x20
    },
    {
        maxMacroblocks: 8192,
        maxBitrate: 20000000,
        level: 0x28
    },
    {
        maxMacroblocks: 8192,
        maxBitrate: 50000000,
        level: 0x29
    },
    {
        maxMacroblocks: 8704,
        maxBitrate: 50000000,
        level: 0x2A
    },
    {
        maxMacroblocks: 22080,
        maxBitrate: 135000000,
        level: 0x32
    },
    {
        maxMacroblocks: 36864,
        maxBitrate: 240000000,
        level: 0x33
    },
    {
        maxMacroblocks: 36864,
        maxBitrate: 240000000,
        level: 0x34
    },
    {
        maxMacroblocks: 139264,
        maxBitrate: 240000000,
        level: 0x3C
    },
    {
        maxMacroblocks: 139264,
        maxBitrate: 480000000,
        level: 0x3D
    },
    {
        maxMacroblocks: 139264,
        maxBitrate: 800000000,
        level: 0x3E
    }
];
// https://en.wikipedia.org/wiki/High_Efficiency_Video_Coding
const HEVC_LEVEL_TABLE = [
    {
        maxPictureSize: 36864,
        maxBitrate: 128000,
        tier: 'L',
        level: 30
    },
    {
        maxPictureSize: 122880,
        maxBitrate: 1500000,
        tier: 'L',
        level: 60
    },
    {
        maxPictureSize: 245760,
        maxBitrate: 3000000,
        tier: 'L',
        level: 63
    },
    {
        maxPictureSize: 552960,
        maxBitrate: 6000000,
        tier: 'L',
        level: 90
    },
    {
        maxPictureSize: 983040,
        maxBitrate: 10000000,
        tier: 'L',
        level: 93
    },
    {
        maxPictureSize: 2228224,
        maxBitrate: 12000000,
        tier: 'L',
        level: 120
    },
    {
        maxPictureSize: 2228224,
        maxBitrate: 30000000,
        tier: 'H',
        level: 120
    },
    {
        maxPictureSize: 2228224,
        maxBitrate: 20000000,
        tier: 'L',
        level: 123
    },
    {
        maxPictureSize: 2228224,
        maxBitrate: 50000000,
        tier: 'H',
        level: 123
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 25000000,
        tier: 'L',
        level: 150
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 100000000,
        tier: 'H',
        level: 150
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 40000000,
        tier: 'L',
        level: 153
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 160000000,
        tier: 'H',
        level: 153
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 60000000,
        tier: 'L',
        level: 156
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 240000000,
        tier: 'H',
        level: 156
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 60000000,
        tier: 'L',
        level: 180
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 240000000,
        tier: 'H',
        level: 180
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 120000000,
        tier: 'L',
        level: 183
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 480000000,
        tier: 'H',
        level: 183
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 240000000,
        tier: 'L',
        level: 186
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 800000000,
        tier: 'H',
        level: 186
    }
];
const VP9_LEVEL_TABLE = [
    {
        maxPictureSize: 36864,
        maxBitrate: 200000,
        level: 10
    },
    {
        maxPictureSize: 73728,
        maxBitrate: 800000,
        level: 11
    },
    {
        maxPictureSize: 122880,
        maxBitrate: 1800000,
        level: 20
    },
    {
        maxPictureSize: 245760,
        maxBitrate: 3600000,
        level: 21
    },
    {
        maxPictureSize: 552960,
        maxBitrate: 7200000,
        level: 30
    },
    {
        maxPictureSize: 983040,
        maxBitrate: 12000000,
        level: 31
    },
    {
        maxPictureSize: 2228224,
        maxBitrate: 18000000,
        level: 40
    },
    {
        maxPictureSize: 2228224,
        maxBitrate: 30000000,
        level: 41
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 60000000,
        level: 50
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 120000000,
        level: 51
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 180000000,
        level: 52
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 180000000,
        level: 60
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 240000000,
        level: 61
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 480000000,
        level: 62
    }
];
// https://en.wikipedia.org/wiki/AV1
const AV1_LEVEL_TABLE = [
    {
        maxPictureSize: 147456,
        maxBitrate: 1500000,
        tier: 'M',
        level: 0
    },
    {
        maxPictureSize: 278784,
        maxBitrate: 3000000,
        tier: 'M',
        level: 1
    },
    {
        maxPictureSize: 665856,
        maxBitrate: 6000000,
        tier: 'M',
        level: 4
    },
    {
        maxPictureSize: 1065024,
        maxBitrate: 10000000,
        tier: 'M',
        level: 5
    },
    {
        maxPictureSize: 2359296,
        maxBitrate: 12000000,
        tier: 'M',
        level: 8
    },
    {
        maxPictureSize: 2359296,
        maxBitrate: 30000000,
        tier: 'H',
        level: 8
    },
    {
        maxPictureSize: 2359296,
        maxBitrate: 20000000,
        tier: 'M',
        level: 9
    },
    {
        maxPictureSize: 2359296,
        maxBitrate: 50000000,
        tier: 'H',
        level: 9
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 30000000,
        tier: 'M',
        level: 12
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 100000000,
        tier: 'H',
        level: 12
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 40000000,
        tier: 'M',
        level: 13
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 160000000,
        tier: 'H',
        level: 13
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 60000000,
        tier: 'M',
        level: 14
    },
    {
        maxPictureSize: 8912896,
        maxBitrate: 240000000,
        tier: 'H',
        level: 14
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 60000000,
        tier: 'M',
        level: 15
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 240000000,
        tier: 'H',
        level: 15
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 60000000,
        tier: 'M',
        level: 16
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 240000000,
        tier: 'H',
        level: 16
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 100000000,
        tier: 'M',
        level: 17
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 480000000,
        tier: 'H',
        level: 17
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 160000000,
        tier: 'M',
        level: 18
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 800000000,
        tier: 'H',
        level: 18
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 160000000,
        tier: 'M',
        level: 19
    },
    {
        maxPictureSize: 35651584,
        maxBitrate: 800000000,
        tier: 'H',
        level: 19
    }
];
const VP9_DEFAULT_SUFFIX = '.01.01.01.01.00';
const AV1_DEFAULT_SUFFIX = '.0.110.01.01.01.0';
const buildVideoCodecString = (codec, width, height, bitrate)=>{
    if (codec === 'avc') {
        const profileIndication = 0x64; // High Profile
        const totalMacroblocks = Math.ceil(width / 16) * Math.ceil(height / 16);
        // Determine the level based on the table
        const levelInfo = AVC_LEVEL_TABLE.find((level)=>totalMacroblocks <= level.maxMacroblocks && bitrate <= level.maxBitrate) ?? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["last"])(AVC_LEVEL_TABLE);
        const levelIndication = levelInfo ? levelInfo.level : 0;
        const hexProfileIndication = profileIndication.toString(16).padStart(2, '0');
        const hexProfileCompatibility = '00';
        const hexLevelIndication = levelIndication.toString(16).padStart(2, '0');
        return `avc1.${hexProfileIndication}${hexProfileCompatibility}${hexLevelIndication}`;
    } else if (codec === 'hevc') {
        const profilePrefix = ''; // Profile space 0
        const profileIdc = 1; // Main Profile
        const compatibilityFlags = '6'; // Taken from the example in ISO 14496-15
        const pictureSize = width * height;
        const levelInfo = HEVC_LEVEL_TABLE.find((level)=>pictureSize <= level.maxPictureSize && bitrate <= level.maxBitrate) ?? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["last"])(HEVC_LEVEL_TABLE);
        const constraintFlags = 'B0'; // Progressive source flag
        return 'hev1.' + `${profilePrefix}${profileIdc}.` + `${compatibilityFlags}.` + `${levelInfo.tier}${levelInfo.level}.` + `${constraintFlags}`;
    } else if (codec === 'vp8') {
        return 'vp8'; // Easy, this one
    } else if (codec === 'vp9') {
        const profile = '00'; // Profile 0
        const pictureSize = width * height;
        const levelInfo = VP9_LEVEL_TABLE.find((level)=>pictureSize <= level.maxPictureSize && bitrate <= level.maxBitrate) ?? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["last"])(VP9_LEVEL_TABLE);
        const bitDepth = '08'; // 8-bit
        return `vp09.${profile}.${levelInfo.level.toString().padStart(2, '0')}.${bitDepth}`;
    } else if (codec === 'av1') {
        const profile = 0; // Main Profile, single digit
        const pictureSize = width * height;
        const levelInfo = AV1_LEVEL_TABLE.find((level)=>pictureSize <= level.maxPictureSize && bitrate <= level.maxBitrate) ?? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["last"])(AV1_LEVEL_TABLE);
        const level = levelInfo.level.toString().padStart(2, '0');
        const bitDepth = '08'; // 8-bit
        return `av01.${profile}.${level}${levelInfo.tier}.${bitDepth}`;
    }
    // eslint-disable-next-line @typescript-eslint/restrict-template-expressions
    throw new TypeError(`Unhandled codec '${codec}'.`);
};
const generateVp9CodecConfigurationFromCodecString = (codecString)=>{
    // Reference: https://www.webmproject.org/docs/container/#vp9-codec-feature-metadata-codecprivate
    const parts = codecString.split('.'); // We can derive the required values from the codec string
    const profile = Number(parts[1]);
    const level = Number(parts[2]);
    const bitDepth = Number(parts[3]);
    const chromaSubsampling = parts[4] ? Number(parts[4]) : 1;
    return [
        1,
        1,
        profile,
        2,
        1,
        level,
        3,
        1,
        bitDepth,
        4,
        1,
        chromaSubsampling
    ];
};
const generateAv1CodecConfigurationFromCodecString = (codecString)=>{
    // Reference: https://aomediacodec.github.io/av1-isobmff/
    const parts = codecString.split('.'); // We can derive the required values from the codec string
    const marker = 1;
    const version = 1;
    const firstByte = (marker << 7) + version;
    const profile = Number(parts[1]);
    const levelAndTier = parts[2];
    const level = Number(levelAndTier.slice(0, -1));
    const secondByte = (profile << 5) + level;
    const tier = levelAndTier.slice(-1) === 'H' ? 1 : 0;
    const bitDepth = Number(parts[3]);
    const highBitDepth = bitDepth === 8 ? 0 : 1;
    const twelveBit = 0;
    const monochrome = parts[4] ? Number(parts[4]) : 0;
    const chromaSubsamplingX = parts[5] ? Number(parts[5][0]) : 1;
    const chromaSubsamplingY = parts[5] ? Number(parts[5][1]) : 1;
    const chromaSamplePosition = parts[5] ? Number(parts[5][2]) : 0; // CSP_UNKNOWN
    const thirdByte = (tier << 7) + (highBitDepth << 6) + (twelveBit << 5) + (monochrome << 4) + (chromaSubsamplingX << 3) + (chromaSubsamplingY << 2) + chromaSamplePosition;
    const initialPresentationDelayPresent = 0; // Should be fine
    const fourthByte = initialPresentationDelayPresent;
    return [
        firstByte,
        secondByte,
        thirdByte,
        fourthByte
    ];
};
const extractVideoCodecString = (trackInfo)=>{
    const { codec, codecDescription, colorSpace, avcCodecInfo, hevcCodecInfo, vp9CodecInfo, av1CodecInfo } = trackInfo;
    if (codec === 'avc') {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(trackInfo.avcType !== null);
        if (avcCodecInfo) {
            const bytes = new Uint8Array([
                avcCodecInfo.avcProfileIndication,
                avcCodecInfo.profileCompatibility,
                avcCodecInfo.avcLevelIndication
            ]);
            return `avc${trackInfo.avcType}.${(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["bytesToHexString"])(bytes)}`;
        }
        if (!codecDescription || codecDescription.byteLength < 4) {
            throw new TypeError('AVC decoder description is not provided or is not at least 4 bytes long.');
        }
        return `avc${trackInfo.avcType}.${(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["bytesToHexString"])(codecDescription.subarray(1, 4))}`;
    } else if (codec === 'hevc') {
        let generalProfileSpace;
        let generalProfileIdc;
        let compatibilityFlags;
        let generalTierFlag;
        let generalLevelIdc;
        let constraintFlags;
        if (hevcCodecInfo) {
            generalProfileSpace = hevcCodecInfo.generalProfileSpace;
            generalProfileIdc = hevcCodecInfo.generalProfileIdc;
            compatibilityFlags = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["reverseBitsU32"])(hevcCodecInfo.generalProfileCompatibilityFlags);
            generalTierFlag = hevcCodecInfo.generalTierFlag;
            generalLevelIdc = hevcCodecInfo.generalLevelIdc;
            constraintFlags = [
                ...hevcCodecInfo.generalConstraintIndicatorFlags
            ];
        } else {
            if (!codecDescription || codecDescription.byteLength < 23) {
                throw new TypeError('HEVC decoder description is not provided or is not at least 23 bytes long.');
            }
            const view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(codecDescription);
            const profileByte = view.getUint8(1);
            generalProfileSpace = profileByte >> 6 & 0x03;
            generalProfileIdc = profileByte & 0x1F;
            compatibilityFlags = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["reverseBitsU32"])(view.getUint32(2));
            generalTierFlag = profileByte >> 5 & 0x01;
            generalLevelIdc = view.getUint8(12);
            constraintFlags = [];
            for(let i = 0; i < 6; i++){
                constraintFlags.push(view.getUint8(6 + i));
            }
        }
        let codecString = 'hev1.';
        codecString += [
            '',
            'A',
            'B',
            'C'
        ][generalProfileSpace] + generalProfileIdc;
        codecString += '.';
        codecString += compatibilityFlags.toString(16).toUpperCase();
        codecString += '.';
        codecString += generalTierFlag === 0 ? 'L' : 'H';
        codecString += generalLevelIdc;
        while(constraintFlags.length > 0 && constraintFlags[constraintFlags.length - 1] === 0){
            constraintFlags.pop();
        }
        if (constraintFlags.length > 0) {
            codecString += '.';
            codecString += constraintFlags.map((x)=>x.toString(16).toUpperCase()).join('.');
        }
        return codecString;
    } else if (codec === 'vp8') {
        return 'vp8'; // Easy, this one
    } else if (codec === 'vp9') {
        if (!vp9CodecInfo) {
            // Calculate level based on dimensions
            const pictureSize = trackInfo.width * trackInfo.height;
            let level = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["last"])(VP9_LEVEL_TABLE).level; // Default to highest level
            for (const entry of VP9_LEVEL_TABLE){
                if (pictureSize <= entry.maxPictureSize) {
                    level = entry.level;
                    break;
                }
            }
            // We don't really know better, so let's return a general-purpose, common codec string and hope for the best
            return `vp09.00.${level.toString().padStart(2, '0')}.08`;
        }
        const profile = vp9CodecInfo.profile.toString().padStart(2, '0');
        const level = vp9CodecInfo.level.toString().padStart(2, '0');
        const bitDepth = vp9CodecInfo.bitDepth.toString().padStart(2, '0');
        const chromaSubsampling = vp9CodecInfo.chromaSubsampling.toString().padStart(2, '0');
        const colourPrimaries = vp9CodecInfo.colourPrimaries.toString().padStart(2, '0');
        const transferCharacteristics = vp9CodecInfo.transferCharacteristics.toString().padStart(2, '0');
        const matrixCoefficients = vp9CodecInfo.matrixCoefficients.toString().padStart(2, '0');
        const videoFullRangeFlag = vp9CodecInfo.videoFullRangeFlag.toString().padStart(2, '0');
        let string = `vp09.${profile}.${level}.${bitDepth}.${chromaSubsampling}`;
        string += `.${colourPrimaries}.${transferCharacteristics}.${matrixCoefficients}.${videoFullRangeFlag}`;
        if (string.endsWith(VP9_DEFAULT_SUFFIX)) {
            string = string.slice(0, -VP9_DEFAULT_SUFFIX.length);
        }
        return string;
    } else if (codec === 'av1') {
        if (!av1CodecInfo) {
            // Calculate level based on dimensions
            const pictureSize = trackInfo.width * trackInfo.height;
            let level = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["last"])(VP9_LEVEL_TABLE).level; // Default to highest level
            for (const entry of VP9_LEVEL_TABLE){
                if (pictureSize <= entry.maxPictureSize) {
                    level = entry.level;
                    break;
                }
            }
            // We don't really know better, so let's return a general-purpose, common codec string and hope for the best
            return `av01.0.${level.toString().padStart(2, '0')}M.08`;
        }
        // https://aomediacodec.github.io/av1-isobmff/#codecsparam
        const profile = av1CodecInfo.profile; // Single digit
        const level = av1CodecInfo.level.toString().padStart(2, '0');
        const tier = av1CodecInfo.tier ? 'H' : 'M';
        const bitDepth = av1CodecInfo.bitDepth.toString().padStart(2, '0');
        const monochrome = av1CodecInfo.monochrome ? '1' : '0';
        const chromaSubsampling = 100 * av1CodecInfo.chromaSubsamplingX + 10 * av1CodecInfo.chromaSubsamplingY + 1 * (av1CodecInfo.chromaSubsamplingX && av1CodecInfo.chromaSubsamplingY ? av1CodecInfo.chromaSamplePosition : 0);
        // The defaults are 1 (ITU-R BT.709)
        const colorPrimaries = colorSpace?.primaries ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["COLOR_PRIMARIES_MAP"][colorSpace.primaries] : 1;
        const transferCharacteristics = colorSpace?.transfer ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TRANSFER_CHARACTERISTICS_MAP"][colorSpace.transfer] : 1;
        const matrixCoefficients = colorSpace?.matrix ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MATRIX_COEFFICIENTS_MAP"][colorSpace.matrix] : 1;
        const videoFullRangeFlag = colorSpace?.fullRange ? 1 : 0;
        let string = `av01.${profile}.${level}${tier}.${bitDepth}`;
        string += `.${monochrome}.${chromaSubsampling.toString().padStart(3, '0')}`;
        string += `.${colorPrimaries.toString().padStart(2, '0')}`;
        string += `.${transferCharacteristics.toString().padStart(2, '0')}`;
        string += `.${matrixCoefficients.toString().padStart(2, '0')}`;
        string += `.${videoFullRangeFlag}`;
        if (string.endsWith(AV1_DEFAULT_SUFFIX)) {
            string = string.slice(0, -AV1_DEFAULT_SUFFIX.length);
        }
        return string;
    }
    throw new TypeError(`Unhandled codec '${codec}'.`);
};
const buildAudioCodecString = (codec, numberOfChannels, sampleRate)=>{
    if (codec === 'aac') {
        // If stereo or higher channels and lower sample rate, likely using HE-AAC v2 with PS
        if (numberOfChannels >= 2 && sampleRate <= 24000) {
            return 'mp4a.40.29'; // HE-AAC v2 (AAC LC + SBR + PS)
        }
        // If sample rate is low, likely using HE-AAC v1 with SBR
        if (sampleRate <= 24000) {
            return 'mp4a.40.5'; // HE-AAC v1 (AAC LC + SBR)
        }
        // Default to standard AAC-LC for higher sample rates
        return 'mp4a.40.2'; // AAC-LC
    } else if (codec === 'mp3') {
        return 'mp3';
    } else if (codec === 'opus') {
        return 'opus';
    } else if (codec === 'vorbis') {
        return 'vorbis';
    } else if (codec === 'flac') {
        return 'flac';
    } else if (PCM_AUDIO_CODECS.includes(codec)) {
        return codec;
    }
    throw new TypeError(`Unhandled codec '${codec}'.`);
};
const extractAudioCodecString = (trackInfo)=>{
    const { codec, codecDescription, aacCodecInfo } = trackInfo;
    if (codec === 'aac') {
        if (!aacCodecInfo) {
            throw new TypeError('AAC codec info must be provided.');
        }
        if (aacCodecInfo.isMpeg2) {
            return 'mp4a.67';
        } else {
            const audioSpecificConfig = parseAacAudioSpecificConfig(codecDescription);
            return `mp4a.40.${audioSpecificConfig.objectType}`;
        }
    } else if (codec === 'mp3') {
        return 'mp3';
    } else if (codec === 'opus') {
        return 'opus';
    } else if (codec === 'vorbis') {
        return 'vorbis';
    } else if (codec === 'flac') {
        return 'flac';
    } else if (codec && PCM_AUDIO_CODECS.includes(codec)) {
        return codec;
    }
    throw new TypeError(`Unhandled codec '${codec}'.`);
};
const aacFrequencyTable = [
    96000,
    88200,
    64000,
    48000,
    44100,
    32000,
    24000,
    22050,
    16000,
    12000,
    11025,
    8000,
    7350
];
const aacChannelMap = [
    -1,
    1,
    2,
    3,
    4,
    5,
    6,
    8
];
const parseAacAudioSpecificConfig = (bytes)=>{
    if (!bytes || bytes.byteLength < 2) {
        throw new TypeError('AAC description must be at least 2 bytes long.');
    }
    const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](bytes);
    let objectType = bitstream.readBits(5);
    if (objectType === 31) {
        objectType = 32 + bitstream.readBits(6);
    }
    const frequencyIndex = bitstream.readBits(4);
    let sampleRate = null;
    if (frequencyIndex === 15) {
        sampleRate = bitstream.readBits(24);
    } else {
        if (frequencyIndex < aacFrequencyTable.length) {
            sampleRate = aacFrequencyTable[frequencyIndex];
        }
    }
    const channelConfiguration = bitstream.readBits(4);
    let numberOfChannels = null;
    if (channelConfiguration >= 1 && channelConfiguration <= 7) {
        numberOfChannels = aacChannelMap[channelConfiguration];
    }
    return {
        objectType,
        frequencyIndex,
        sampleRate,
        channelConfiguration,
        numberOfChannels
    };
};
const buildAacAudioSpecificConfig = (config)=>{
    let frequencyIndex = aacFrequencyTable.indexOf(config.sampleRate);
    let customSampleRate = null;
    if (frequencyIndex === -1) {
        frequencyIndex = 15;
        customSampleRate = config.sampleRate;
    }
    const channelConfiguration = aacChannelMap.indexOf(config.numberOfChannels);
    if (channelConfiguration === -1) {
        throw new TypeError(`Unsupported number of channels: ${config.numberOfChannels}`);
    }
    let bitCount = 5 + 4 + 4;
    if (config.objectType >= 32) {
        bitCount += 6;
    }
    if (frequencyIndex === 15) {
        bitCount += 24;
    }
    const byteCount = Math.ceil(bitCount / 8);
    const bytes = new Uint8Array(byteCount);
    const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](bytes);
    if (config.objectType < 32) {
        bitstream.writeBits(5, config.objectType);
    } else {
        bitstream.writeBits(5, 31);
        bitstream.writeBits(6, config.objectType - 32);
    }
    bitstream.writeBits(4, frequencyIndex);
    if (frequencyIndex === 15) {
        bitstream.writeBits(24, customSampleRate);
    }
    bitstream.writeBits(4, channelConfiguration);
    return bytes;
};
const OPUS_SAMPLE_RATE = 48_000;
const PCM_CODEC_REGEX = /^pcm-([usf])(\d+)+(be)?$/;
const parsePcmCodec = (codec)=>{
    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(PCM_AUDIO_CODECS.includes(codec));
    if (codec === 'ulaw') {
        return {
            dataType: 'ulaw',
            sampleSize: 1,
            littleEndian: true,
            silentValue: 255
        };
    } else if (codec === 'alaw') {
        return {
            dataType: 'alaw',
            sampleSize: 1,
            littleEndian: true,
            silentValue: 213
        };
    }
    const match = PCM_CODEC_REGEX.exec(codec);
    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(match);
    let dataType;
    if (match[1] === 'u') {
        dataType = 'unsigned';
    } else if (match[1] === 's') {
        dataType = 'signed';
    } else {
        dataType = 'float';
    }
    const sampleSize = Number(match[2]) / 8;
    const littleEndian = match[3] !== 'be';
    const silentValue = codec === 'pcm-u8' ? 2 ** 7 : 0;
    return {
        dataType,
        sampleSize,
        littleEndian,
        silentValue
    };
};
const inferCodecFromCodecString = (codecString)=>{
    // Video codecs
    if (codecString.startsWith('avc1') || codecString.startsWith('avc3')) {
        return 'avc';
    } else if (codecString.startsWith('hev1') || codecString.startsWith('hvc1')) {
        return 'hevc';
    } else if (codecString === 'vp8') {
        return 'vp8';
    } else if (codecString.startsWith('vp09')) {
        return 'vp9';
    } else if (codecString.startsWith('av01')) {
        return 'av1';
    }
    // Audio codecs
    if (codecString.startsWith('mp4a.40') || codecString === 'mp4a.67') {
        return 'aac';
    } else if (codecString === 'mp3' || codecString === 'mp4a.69' || codecString === 'mp4a.6B' || codecString === 'mp4a.6b') {
        return 'mp3';
    } else if (codecString === 'opus') {
        return 'opus';
    } else if (codecString === 'vorbis') {
        return 'vorbis';
    } else if (codecString === 'flac') {
        return 'flac';
    } else if (codecString === 'ulaw') {
        return 'ulaw';
    } else if (codecString === 'alaw') {
        return 'alaw';
    } else if (PCM_CODEC_REGEX.test(codecString)) {
        return codecString;
    }
    // Subtitle codecs
    if (codecString === 'webvtt') {
        return 'webvtt';
    }
    return null;
};
const getVideoEncoderConfigExtension = (codec)=>{
    if (codec === 'avc') {
        return {
            avc: {
                format: 'avc'
            }
        };
    } else if (codec === 'hevc') {
        return {
            hevc: {
                format: 'hevc'
            }
        };
    }
    return {};
};
const getAudioEncoderConfigExtension = (codec)=>{
    if (codec === 'aac') {
        return {
            aac: {
                format: 'aac'
            }
        };
    } else if (codec === 'opus') {
        return {
            opus: {
                format: 'opus'
            }
        };
    }
    return {};
};
const VALID_VIDEO_CODEC_STRING_PREFIXES = [
    'avc1',
    'avc3',
    'hev1',
    'hvc1',
    'vp8',
    'vp09',
    'av01'
];
const AVC_CODEC_STRING_REGEX = /^(avc1|avc3)\.[0-9a-fA-F]{6}$/;
const HEVC_CODEC_STRING_REGEX = /^(hev1|hvc1)\.(?:[ABC]?\d+)\.[0-9a-fA-F]{1,8}\.[LH]\d+(?:\.[0-9a-fA-F]{1,2}){0,6}$/;
const VP9_CODEC_STRING_REGEX = /^vp09(?:\.\d{2}){3}(?:(?:\.\d{2}){5})?$/;
const AV1_CODEC_STRING_REGEX = /^av01\.\d\.\d{2}[MH]\.\d{2}(?:\.\d\.\d{3}\.\d{2}\.\d{2}\.\d{2}\.\d)?$/;
const validateVideoChunkMetadata = (metadata)=>{
    if (!metadata) {
        throw new TypeError('Video chunk metadata must be provided.');
    }
    if (typeof metadata !== 'object') {
        throw new TypeError('Video chunk metadata must be an object.');
    }
    if (!metadata.decoderConfig) {
        throw new TypeError('Video chunk metadata must include a decoder configuration.');
    }
    if (typeof metadata.decoderConfig !== 'object') {
        throw new TypeError('Video chunk metadata decoder configuration must be an object.');
    }
    if (typeof metadata.decoderConfig.codec !== 'string') {
        throw new TypeError('Video chunk metadata decoder configuration must specify a codec string.');
    }
    if (!VALID_VIDEO_CODEC_STRING_PREFIXES.some((prefix)=>metadata.decoderConfig.codec.startsWith(prefix))) {
        throw new TypeError('Video chunk metadata decoder configuration codec string must be a valid video codec string as specified in' + ' the WebCodecs Codec Registry.');
    }
    if (!Number.isInteger(metadata.decoderConfig.codedWidth) || metadata.decoderConfig.codedWidth <= 0) {
        throw new TypeError('Video chunk metadata decoder configuration must specify a valid codedWidth (positive integer).');
    }
    if (!Number.isInteger(metadata.decoderConfig.codedHeight) || metadata.decoderConfig.codedHeight <= 0) {
        throw new TypeError('Video chunk metadata decoder configuration must specify a valid codedHeight (positive integer).');
    }
    if (metadata.decoderConfig.description !== undefined) {
        if (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isAllowSharedBufferSource"])(metadata.decoderConfig.description)) {
            throw new TypeError('Video chunk metadata decoder configuration description, when defined, must be an ArrayBuffer or an' + ' ArrayBuffer view.');
        }
    }
    if (metadata.decoderConfig.colorSpace !== undefined) {
        const { colorSpace } = metadata.decoderConfig;
        if (typeof colorSpace !== 'object') {
            throw new TypeError('Video chunk metadata decoder configuration colorSpace, when provided, must be an object.');
        }
        const primariesValues = Object.keys(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["COLOR_PRIMARIES_MAP"]);
        if (colorSpace.primaries != null && !primariesValues.includes(colorSpace.primaries)) {
            throw new TypeError(`Video chunk metadata decoder configuration colorSpace primaries, when defined, must be one of` + ` ${primariesValues.join(', ')}.`);
        }
        const transferValues = Object.keys(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TRANSFER_CHARACTERISTICS_MAP"]);
        if (colorSpace.transfer != null && !transferValues.includes(colorSpace.transfer)) {
            throw new TypeError(`Video chunk metadata decoder configuration colorSpace transfer, when defined, must be one of` + ` ${transferValues.join(', ')}.`);
        }
        const matrixValues = Object.keys(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MATRIX_COEFFICIENTS_MAP"]);
        if (colorSpace.matrix != null && !matrixValues.includes(colorSpace.matrix)) {
            throw new TypeError(`Video chunk metadata decoder configuration colorSpace matrix, when defined, must be one of` + ` ${matrixValues.join(', ')}.`);
        }
        if (colorSpace.fullRange != null && typeof colorSpace.fullRange !== 'boolean') {
            throw new TypeError('Video chunk metadata decoder configuration colorSpace fullRange, when defined, must be a boolean.');
        }
    }
    if (metadata.decoderConfig.codec.startsWith('avc1') || metadata.decoderConfig.codec.startsWith('avc3')) {
        // AVC-specific validation
        if (!AVC_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
            throw new TypeError('Video chunk metadata decoder configuration codec string for AVC must be a valid AVC codec string as' + ' specified in Section 3.4 of RFC 6381.');
        }
    // `description` may or may not be set, depending on if the format is AVCC or Annex B, so don't perform any
    // validation for it.
    // https://www.w3.org/TR/webcodecs-avc-codec-registration
    } else if (metadata.decoderConfig.codec.startsWith('hev1') || metadata.decoderConfig.codec.startsWith('hvc1')) {
        // HEVC-specific validation
        if (!HEVC_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
            throw new TypeError('Video chunk metadata decoder configuration codec string for HEVC must be a valid HEVC codec string as' + ' specified in Section E.3 of ISO 14496-15.');
        }
    // `description` may or may not be set, depending on if the format is HEVC or Annex B, so don't perform any
    // validation for it.
    // https://www.w3.org/TR/webcodecs-hevc-codec-registration
    } else if (metadata.decoderConfig.codec.startsWith('vp8')) {
        // VP8-specific validation
        if (metadata.decoderConfig.codec !== 'vp8') {
            throw new TypeError('Video chunk metadata decoder configuration codec string for VP8 must be "vp8".');
        }
    } else if (metadata.decoderConfig.codec.startsWith('vp09')) {
        // VP9-specific validation
        if (!VP9_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
            throw new TypeError('Video chunk metadata decoder configuration codec string for VP9 must be a valid VP9 codec string as' + ' specified in Section "Codecs Parameter String" of https://www.webmproject.org/vp9/mp4/.');
        }
    } else if (metadata.decoderConfig.codec.startsWith('av01')) {
        // AV1-specific validation
        if (!AV1_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
            throw new TypeError('Video chunk metadata decoder configuration codec string for AV1 must be a valid AV1 codec string as' + ' specified in Section "Codecs Parameter String" of https://aomediacodec.github.io/av1-isobmff/.');
        }
    }
};
const VALID_AUDIO_CODEC_STRING_PREFIXES = [
    'mp4a',
    'mp3',
    'opus',
    'vorbis',
    'flac',
    'ulaw',
    'alaw',
    'pcm'
];
const validateAudioChunkMetadata = (metadata)=>{
    if (!metadata) {
        throw new TypeError('Audio chunk metadata must be provided.');
    }
    if (typeof metadata !== 'object') {
        throw new TypeError('Audio chunk metadata must be an object.');
    }
    if (!metadata.decoderConfig) {
        throw new TypeError('Audio chunk metadata must include a decoder configuration.');
    }
    if (typeof metadata.decoderConfig !== 'object') {
        throw new TypeError('Audio chunk metadata decoder configuration must be an object.');
    }
    if (typeof metadata.decoderConfig.codec !== 'string') {
        throw new TypeError('Audio chunk metadata decoder configuration must specify a codec string.');
    }
    if (!VALID_AUDIO_CODEC_STRING_PREFIXES.some((prefix)=>metadata.decoderConfig.codec.startsWith(prefix))) {
        throw new TypeError('Audio chunk metadata decoder configuration codec string must be a valid audio codec string as specified in' + ' the WebCodecs Codec Registry.');
    }
    if (!Number.isInteger(metadata.decoderConfig.sampleRate) || metadata.decoderConfig.sampleRate <= 0) {
        throw new TypeError('Audio chunk metadata decoder configuration must specify a valid sampleRate (positive integer).');
    }
    if (!Number.isInteger(metadata.decoderConfig.numberOfChannels) || metadata.decoderConfig.numberOfChannels <= 0) {
        throw new TypeError('Audio chunk metadata decoder configuration must specify a valid numberOfChannels (positive integer).');
    }
    if (metadata.decoderConfig.description !== undefined) {
        if (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isAllowSharedBufferSource"])(metadata.decoderConfig.description)) {
            throw new TypeError('Audio chunk metadata decoder configuration description, when defined, must be an ArrayBuffer or an' + ' ArrayBuffer view.');
        }
    }
    if (metadata.decoderConfig.codec.startsWith('mp4a') && metadata.decoderConfig.codec !== 'mp4a.69' && metadata.decoderConfig.codec !== 'mp4a.6B' && metadata.decoderConfig.codec !== 'mp4a.6b') {
        // AAC-specific validation
        const validStrings = [
            'mp4a.40.2',
            'mp4a.40.02',
            'mp4a.40.5',
            'mp4a.40.05',
            'mp4a.40.29',
            'mp4a.67'
        ];
        if (!validStrings.includes(metadata.decoderConfig.codec)) {
            throw new TypeError('Audio chunk metadata decoder configuration codec string for AAC must be a valid AAC codec string as' + ' specified in https://www.w3.org/TR/webcodecs-aac-codec-registration/.');
        }
        if (!metadata.decoderConfig.description) {
            throw new TypeError('Audio chunk metadata decoder configuration for AAC must include a description, which is expected to be' + ' an AudioSpecificConfig as specified in ISO 14496-3.');
        }
    } else if (metadata.decoderConfig.codec.startsWith('mp3') || metadata.decoderConfig.codec.startsWith('mp4a')) {
        // MP3-specific validation
        if (metadata.decoderConfig.codec !== 'mp3' && metadata.decoderConfig.codec !== 'mp4a.69' && metadata.decoderConfig.codec !== 'mp4a.6B' && metadata.decoderConfig.codec !== 'mp4a.6b') {
            throw new TypeError('Audio chunk metadata decoder configuration codec string for MP3 must be "mp3", "mp4a.69" or' + ' "mp4a.6B".');
        }
    } else if (metadata.decoderConfig.codec.startsWith('opus')) {
        // Opus-specific validation
        if (metadata.decoderConfig.codec !== 'opus') {
            throw new TypeError('Audio chunk metadata decoder configuration codec string for Opus must be "opus".');
        }
        if (metadata.decoderConfig.description && metadata.decoderConfig.description.byteLength < 18) {
            // Description is optional for Opus per-spec, so we shouldn't enforce it
            throw new TypeError('Audio chunk metadata decoder configuration description, when specified, is expected to be an' + ' Identification Header as specified in Section 5.1 of RFC 7845.');
        }
    } else if (metadata.decoderConfig.codec.startsWith('vorbis')) {
        // Vorbis-specific validation
        if (metadata.decoderConfig.codec !== 'vorbis') {
            throw new TypeError('Audio chunk metadata decoder configuration codec string for Vorbis must be "vorbis".');
        }
        if (!metadata.decoderConfig.description) {
            throw new TypeError('Audio chunk metadata decoder configuration for Vorbis must include a description, which is expected to' + ' adhere to the format described in https://www.w3.org/TR/webcodecs-vorbis-codec-registration/.');
        }
    } else if (metadata.decoderConfig.codec.startsWith('flac')) {
        // FLAC-specific validation
        if (metadata.decoderConfig.codec !== 'flac') {
            throw new TypeError('Audio chunk metadata decoder configuration codec string for FLAC must be "flac".');
        }
        const minDescriptionSize = 4 + 4 + 34; // 'fLaC' + metadata block header + STREAMINFO block
        if (!metadata.decoderConfig.description || metadata.decoderConfig.description.byteLength < minDescriptionSize) {
            throw new TypeError('Audio chunk metadata decoder configuration for FLAC must include a description, which is expected to' + ' adhere to the format described in https://www.w3.org/TR/webcodecs-flac-codec-registration/.');
        }
    } else if (metadata.decoderConfig.codec.startsWith('pcm') || metadata.decoderConfig.codec.startsWith('ulaw') || metadata.decoderConfig.codec.startsWith('alaw')) {
        // PCM-specific validation
        if (!PCM_AUDIO_CODECS.includes(metadata.decoderConfig.codec)) {
            throw new TypeError('Audio chunk metadata decoder configuration codec string for PCM must be one of the supported PCM' + ` codecs (${PCM_AUDIO_CODECS.join(', ')}).`);
        }
    }
};
const validateSubtitleMetadata = (metadata)=>{
    if (!metadata) {
        throw new TypeError('Subtitle metadata must be provided.');
    }
    if (typeof metadata !== 'object') {
        throw new TypeError('Subtitle metadata must be an object.');
    }
    if (!metadata.config) {
        throw new TypeError('Subtitle metadata must include a config object.');
    }
    if (typeof metadata.config !== 'object') {
        throw new TypeError('Subtitle metadata config must be an object.');
    }
    if (typeof metadata.config.description !== 'string') {
        throw new TypeError('Subtitle metadata config description must be a string.');
    }
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/subtitles.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "SubtitleParser",
    ()=>SubtitleParser,
    "formatSubtitleTimestamp",
    ()=>formatSubtitleTimestamp,
    "inlineTimestampRegex",
    ()=>inlineTimestampRegex,
    "parseSubtitleTimestamp",
    ()=>parseSubtitleTimestamp
]);
const cueBlockHeaderRegex = /(?:(.+?)\n)?((?:\d{2}:)?\d{2}:\d{2}.\d{3})\s+-->\s+((?:\d{2}:)?\d{2}:\d{2}.\d{3})/g;
const preambleStartRegex = /^WEBVTT(.|\n)*?\n{2}/;
const inlineTimestampRegex = /<(?:(\d{2}):)?(\d{2}):(\d{2}).(\d{3})>/g;
class SubtitleParser {
    constructor(options){
        this.preambleText = null;
        this.preambleEmitted = false;
        this.options = options;
    }
    parse(text) {
        text = text.replaceAll('\r\n', '\n').replaceAll('\r', '\n');
        cueBlockHeaderRegex.lastIndex = 0;
        let match;
        if (!this.preambleText) {
            if (!preambleStartRegex.test(text)) {
                throw new Error('WebVTT preamble incorrect.');
            }
            match = cueBlockHeaderRegex.exec(text);
            const preamble = text.slice(0, match?.index ?? text.length).trimEnd();
            if (!preamble) {
                throw new Error('No WebVTT preamble provided.');
            }
            this.preambleText = preamble;
            if (match) {
                text = text.slice(match.index);
                cueBlockHeaderRegex.lastIndex = 0;
            }
        }
        while(match = cueBlockHeaderRegex.exec(text)){
            const notes = text.slice(0, match.index);
            const cueIdentifier = match[1];
            const matchEnd = match.index + match[0].length;
            const bodyStart = text.indexOf('\n', matchEnd) + 1;
            const cueSettings = text.slice(matchEnd, bodyStart).trim();
            let bodyEnd = text.indexOf('\n\n', matchEnd);
            if (bodyEnd === -1) bodyEnd = text.length;
            const startTime = parseSubtitleTimestamp(match[2]);
            const endTime = parseSubtitleTimestamp(match[3]);
            const duration = endTime - startTime;
            const body = text.slice(bodyStart, bodyEnd).trim();
            text = text.slice(bodyEnd).trimStart();
            cueBlockHeaderRegex.lastIndex = 0;
            const cue = {
                timestamp: startTime / 1000,
                duration: duration / 1000,
                text: body,
                identifier: cueIdentifier,
                settings: cueSettings,
                notes
            };
            const meta = {};
            if (!this.preambleEmitted) {
                meta.config = {
                    description: this.preambleText
                };
                this.preambleEmitted = true;
            }
            this.options.output(cue, meta);
        }
    }
}
const timestampRegex = /(?:(\d{2}):)?(\d{2}):(\d{2}).(\d{3})/;
const parseSubtitleTimestamp = (string)=>{
    const match = timestampRegex.exec(string);
    if (!match) throw new Error('Expected match.');
    return 60 * 60 * 1000 * Number(match[1] || '0') + 60 * 1000 * Number(match[2]) + 1000 * Number(match[3]) + Number(match[4]);
};
const formatSubtitleTimestamp = (timestamp)=>{
    const hours = Math.floor(timestamp / (60 * 60 * 1000));
    const minutes = Math.floor(timestamp % (60 * 60 * 1000) / (60 * 1000));
    const seconds = Math.floor(timestamp % (60 * 1000) / 1000);
    const milliseconds = timestamp % 1000;
    return hours.toString().padStart(2, '0') + ':' + minutes.toString().padStart(2, '0') + ':' + seconds.toString().padStart(2, '0') + '.' + milliseconds.toString().padStart(3, '0');
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/pcm.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ // https://github.com/dystopiancode/pcm-g711/blob/master/pcm-g711/g711.c
__turbopack_context__.s([
    "fromAlaw",
    ()=>fromAlaw,
    "fromUlaw",
    ()=>fromUlaw,
    "toAlaw",
    ()=>toAlaw,
    "toUlaw",
    ()=>toUlaw
]);
const toUlaw = (s16)=>{
    const MULAW_MAX = 0x1FFF;
    const MULAW_BIAS = 33;
    let number = s16;
    let mask = 0x1000;
    let sign = 0;
    let position = 12;
    let lsb = 0;
    if (number < 0) {
        number = -number;
        sign = 0x80;
    }
    number += MULAW_BIAS;
    if (number > MULAW_MAX) {
        number = MULAW_MAX;
    }
    while((number & mask) !== mask && position >= 5){
        mask >>= 1;
        position--;
    }
    lsb = number >> position - 4 & 0x0f;
    return ~(sign | position - 5 << 4 | lsb) & 0xFF;
};
const fromUlaw = (u8)=>{
    const MULAW_BIAS = 33;
    let sign = 0;
    let position = 0;
    let number = ~u8;
    if (number & 0x80) {
        number &= ~(1 << 7);
        sign = -1;
    }
    position = ((number & 0xF0) >> 4) + 5;
    const decoded = (1 << position | (number & 0x0F) << position - 4 | 1 << position - 5) - MULAW_BIAS;
    return sign === 0 ? decoded : -decoded;
};
const toAlaw = (s16)=>{
    const ALAW_MAX = 0xFFF;
    let mask = 0x800;
    let sign = 0;
    let position = 11;
    let lsb = 0;
    let number = s16;
    if (number < 0) {
        number = -number;
        sign = 0x80;
    }
    if (number > ALAW_MAX) {
        number = ALAW_MAX;
    }
    while((number & mask) !== mask && position >= 5){
        mask >>= 1;
        position--;
    }
    lsb = number >> (position === 4 ? 1 : position - 4) & 0x0f;
    return (sign | position - 4 << 4 | lsb) ^ 0x55;
};
const fromAlaw = (u8)=>{
    let sign = 0x00;
    let position = 0;
    let number = u8 ^ 0x55;
    if (number & 0x80) {
        number &= ~(1 << 7);
        sign = -1;
    }
    position = ((number & 0xF0) >> 4) + 4;
    let decoded = 0;
    if (position !== 4) {
        decoded = 1 << position | (number & 0x0F) << position - 4 | 1 << position - 5;
    } else {
        decoded = number << 1 | 1;
    }
    return sign === 0 ? decoded : -decoded;
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/custom-coder.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ /**
 * Base class for custom video decoders. To add your own custom video decoder, extend this class, implement the
 * abstract methods and static `supports` method, and register the decoder using {@link registerDecoder}.
 * @group Custom coders
 * @public
 */ __turbopack_context__.s([
    "CustomAudioDecoder",
    ()=>CustomAudioDecoder,
    "CustomAudioEncoder",
    ()=>CustomAudioEncoder,
    "CustomVideoDecoder",
    ()=>CustomVideoDecoder,
    "CustomVideoEncoder",
    ()=>CustomVideoEncoder,
    "customAudioDecoders",
    ()=>customAudioDecoders,
    "customAudioEncoders",
    ()=>customAudioEncoders,
    "customVideoDecoders",
    ()=>customVideoDecoders,
    "customVideoEncoders",
    ()=>customVideoEncoders,
    "registerDecoder",
    ()=>registerDecoder,
    "registerEncoder",
    ()=>registerEncoder
]);
class CustomVideoDecoder {
    /** Returns true if and only if the decoder can decode the given codec configuration. */ // eslint-disable-next-line @typescript-eslint/no-unused-vars
    static supports(codec, config) {
        return false;
    }
}
class CustomAudioDecoder {
    /** Returns true if and only if the decoder can decode the given codec configuration. */ // eslint-disable-next-line @typescript-eslint/no-unused-vars
    static supports(codec, config) {
        return false;
    }
}
class CustomVideoEncoder {
    /** Returns true if and only if the encoder can encode the given codec configuration. */ // eslint-disable-next-line @typescript-eslint/no-unused-vars
    static supports(codec, config) {
        return false;
    }
}
class CustomAudioEncoder {
    /** Returns true if and only if the encoder can encode the given codec configuration. */ // eslint-disable-next-line @typescript-eslint/no-unused-vars
    static supports(codec, config) {
        return false;
    }
}
const customVideoDecoders = [];
const customAudioDecoders = [];
const customVideoEncoders = [];
const customAudioEncoders = [];
const registerDecoder = (decoder)=>{
    if (decoder.prototype instanceof CustomVideoDecoder) {
        const casted = decoder;
        if (customVideoDecoders.includes(casted)) {
            console.warn('Video decoder already registered.');
            return;
        }
        customVideoDecoders.push(casted);
    } else if (decoder.prototype instanceof CustomAudioDecoder) {
        const casted = decoder;
        if (customAudioDecoders.includes(casted)) {
            console.warn('Audio decoder already registered.');
            return;
        }
        customAudioDecoders.push(casted);
    } else {
        throw new TypeError('Decoder must be a CustomVideoDecoder or CustomAudioDecoder.');
    }
};
const registerEncoder = (encoder)=>{
    if (encoder.prototype instanceof CustomVideoEncoder) {
        const casted = encoder;
        if (customVideoEncoders.includes(casted)) {
            console.warn('Video encoder already registered.');
            return;
        }
        customVideoEncoders.push(casted);
    } else if (encoder.prototype instanceof CustomAudioEncoder) {
        const casted = encoder;
        if (customAudioEncoders.includes(casted)) {
            console.warn('Audio encoder already registered.');
            return;
        }
        customAudioEncoders.push(casted);
    } else {
        throw new TypeError('Encoder must be a CustomVideoEncoder or CustomAudioEncoder.');
    }
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/packet.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "EncodedPacket",
    ()=>EncodedPacket,
    "PLACEHOLDER_DATA",
    ()=>PLACEHOLDER_DATA
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
;
const PLACEHOLDER_DATA = /* #__PURE__ */ new Uint8Array(0);
class EncodedPacket {
    /** Creates a new {@link EncodedPacket} from raw bytes and timing information. */ constructor(/** The encoded data of this packet. */ data, /** The type of this packet. */ type, /**
     * The presentation timestamp of this packet in seconds. May be negative. Samples with negative end timestamps
     * should not be presented.
     */ timestamp, /** The duration of this packet in seconds. */ duration, /**
     * The sequence number indicates the decode order of the packets. Packet A  must be decoded before packet B if A
     * has a lower sequence number than B. If two packets have the same sequence number, they are the same packet.
     * Otherwise, sequence numbers are arbitrary and are not guaranteed to have any meaning besides their relative
     * ordering. Negative sequence numbers mean the sequence number is undefined.
     */ sequenceNumber = -1, byteLength, sideData){
        this.data = data;
        this.type = type;
        this.timestamp = timestamp;
        this.duration = duration;
        this.sequenceNumber = sequenceNumber;
        if (data === PLACEHOLDER_DATA && byteLength === undefined) {
            throw new Error('Internal error: byteLength must be explicitly provided when constructing metadata-only packets.');
        }
        if (byteLength === undefined) {
            byteLength = data.byteLength;
        }
        if (!(data instanceof Uint8Array)) {
            throw new TypeError('data must be a Uint8Array.');
        }
        if (type !== 'key' && type !== 'delta') {
            throw new TypeError('type must be either "key" or "delta".');
        }
        if (!Number.isFinite(timestamp)) {
            throw new TypeError('timestamp must be a number.');
        }
        if (!Number.isFinite(duration) || duration < 0) {
            throw new TypeError('duration must be a non-negative number.');
        }
        if (!Number.isFinite(sequenceNumber)) {
            throw new TypeError('sequenceNumber must be a number.');
        }
        if (!Number.isInteger(byteLength) || byteLength < 0) {
            throw new TypeError('byteLength must be a non-negative integer.');
        }
        if (sideData !== undefined && (typeof sideData !== 'object' || !sideData)) {
            throw new TypeError('sideData, when provided, must be an object.');
        }
        if (sideData?.alpha !== undefined && !(sideData.alpha instanceof Uint8Array)) {
            throw new TypeError('sideData.alpha, when provided, must be a Uint8Array.');
        }
        if (sideData?.alphaByteLength !== undefined && (!Number.isInteger(sideData.alphaByteLength) || sideData.alphaByteLength < 0)) {
            throw new TypeError('sideData.alphaByteLength, when provided, must be a non-negative integer.');
        }
        this.byteLength = byteLength;
        this.sideData = sideData ?? {};
        if (this.sideData.alpha && this.sideData.alphaByteLength === undefined) {
            this.sideData.alphaByteLength = this.sideData.alpha.byteLength;
        }
    }
    /**
     * If this packet is a metadata-only packet. Metadata-only packets don't contain their packet data. They are the
     * result of retrieving packets with {@link PacketRetrievalOptions.metadataOnly} set to `true`.
     */ get isMetadataOnly() {
        return this.data === PLACEHOLDER_DATA;
    }
    /** The timestamp of this packet in microseconds. */ get microsecondTimestamp() {
        return Math.trunc(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SECOND_TO_MICROSECOND_FACTOR"] * this.timestamp);
    }
    /** The duration of this packet in microseconds. */ get microsecondDuration() {
        return Math.trunc(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SECOND_TO_MICROSECOND_FACTOR"] * this.duration);
    }
    /** Converts this packet to an
     * [`EncodedVideoChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedVideoChunk) for use with the
     * WebCodecs API. */ toEncodedVideoChunk() {
        if (this.isMetadataOnly) {
            throw new TypeError('Metadata-only packets cannot be converted to a video chunk.');
        }
        if (typeof EncodedVideoChunk === 'undefined') {
            throw new Error('Your browser does not support EncodedVideoChunk.');
        }
        return new EncodedVideoChunk({
            data: this.data,
            type: this.type,
            timestamp: this.microsecondTimestamp,
            duration: this.microsecondDuration
        });
    }
    /**
     * Converts this packet to an
     * [`EncodedVideoChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedVideoChunk) for use with the
     * WebCodecs API, using the alpha side data instead of the color data. Throws if no alpha side data is defined.
     */ alphaToEncodedVideoChunk(type = this.type) {
        if (!this.sideData.alpha) {
            throw new TypeError('This packet does not contain alpha side data.');
        }
        if (this.isMetadataOnly) {
            throw new TypeError('Metadata-only packets cannot be converted to a video chunk.');
        }
        if (typeof EncodedVideoChunk === 'undefined') {
            throw new Error('Your browser does not support EncodedVideoChunk.');
        }
        return new EncodedVideoChunk({
            data: this.sideData.alpha,
            type,
            timestamp: this.microsecondTimestamp,
            duration: this.microsecondDuration
        });
    }
    /** Converts this packet to an
     * [`EncodedAudioChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedAudioChunk) for use with the
     * WebCodecs API. */ toEncodedAudioChunk() {
        if (this.isMetadataOnly) {
            throw new TypeError('Metadata-only packets cannot be converted to an audio chunk.');
        }
        if (typeof EncodedAudioChunk === 'undefined') {
            throw new Error('Your browser does not support EncodedAudioChunk.');
        }
        return new EncodedAudioChunk({
            data: this.data,
            type: this.type,
            timestamp: this.microsecondTimestamp,
            duration: this.microsecondDuration
        });
    }
    /**
     * Creates an {@link EncodedPacket} from an
     * [`EncodedVideoChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedVideoChunk) or
     * [`EncodedAudioChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedAudioChunk). This method is useful
     * for converting chunks from the WebCodecs API to `EncodedPacket` instances.
     */ static fromEncodedChunk(chunk, sideData) {
        if (!(chunk instanceof EncodedVideoChunk || chunk instanceof EncodedAudioChunk)) {
            throw new TypeError('chunk must be an EncodedVideoChunk or EncodedAudioChunk.');
        }
        const data = new Uint8Array(chunk.byteLength);
        chunk.copyTo(data);
        return new EncodedPacket(data, chunk.type, chunk.timestamp / 1e6, (chunk.duration ?? 0) / 1e6, undefined, undefined, sideData);
    }
    /** Clones this packet while optionally updating timing information. */ clone(options) {
        if (options !== undefined && (typeof options !== 'object' || options === null)) {
            throw new TypeError('options, when provided, must be an object.');
        }
        if (options?.timestamp !== undefined && !Number.isFinite(options.timestamp)) {
            throw new TypeError('options.timestamp, when provided, must be a number.');
        }
        if (options?.duration !== undefined && !Number.isFinite(options.duration)) {
            throw new TypeError('options.duration, when provided, must be a number.');
        }
        return new EncodedPacket(this.data, this.type, options?.timestamp ?? this.timestamp, options?.duration ?? this.duration, this.sequenceNumber, this.byteLength);
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/sample.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "AudioSample",
    ()=>AudioSample,
    "VIDEO_SAMPLE_PIXEL_FORMATS",
    ()=>VIDEO_SAMPLE_PIXEL_FORMATS,
    "VideoSample",
    ()=>VideoSample,
    "VideoSampleColorSpace",
    ()=>VideoSampleColorSpace,
    "clampCropRectangle",
    ()=>clampCropRectangle,
    "validateCropRectangle",
    ()=>validateCropRectangle
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
;
(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["polyfillSymbolDispose"])();
// Let's manually handle logging the garbage collection errors that are typically logged by the browser. This way, they
// also kick for audio samples (which is normally not the case), making sure any incorrect code is quickly caught.
let lastVideoGcErrorLog = -Infinity;
let lastAudioGcErrorLog = -Infinity;
let finalizationRegistry = null;
if (typeof FinalizationRegistry !== 'undefined') {
    finalizationRegistry = new FinalizationRegistry((value)=>{
        const now = Date.now();
        if (value.type === 'video') {
            if (now - lastVideoGcErrorLog >= 1000) {
                // This error is annoying but oh so important
                console.error(`A VideoSample was garbage collected without first being closed. For proper resource management,` + ` make sure to call close() on all your VideoSamples as soon as you're done using them.`);
                lastVideoGcErrorLog = now;
            }
            if (typeof VideoFrame !== 'undefined' && value.data instanceof VideoFrame) {
                value.data.close(); // Prevent the browser error since we're logging our own
            }
        } else {
            if (now - lastAudioGcErrorLog >= 1000) {
                console.error(`An AudioSample was garbage collected without first being closed. For proper resource management,` + ` make sure to call close() on all your AudioSamples as soon as you're done using them.`);
                lastAudioGcErrorLog = now;
            }
            if (typeof AudioData !== 'undefined' && value.data instanceof AudioData) {
                value.data.close();
            }
        }
    });
}
const VIDEO_SAMPLE_PIXEL_FORMATS = [
    // 4:2:0 Y, U, V
    'I420',
    'I420P10',
    'I420P12',
    // 4:2:0 Y, U, V, A
    'I420A',
    'I420AP10',
    'I420AP12',
    // 4:2:2 Y, U, V
    'I422',
    'I422P10',
    'I422P12',
    // 4:2:2 Y, U, V, A
    'I422A',
    'I422AP10',
    'I422AP12',
    // 4:4:4 Y, U, V
    'I444',
    'I444P10',
    'I444P12',
    // 4:4:4 Y, U, V, A
    'I444A',
    'I444AP10',
    'I444AP12',
    // 4:2:0 Y, UV
    'NV12',
    // 4:4:4 RGBA
    'RGBA',
    // 4:4:4 RGBX (opaque)
    'RGBX',
    // 4:4:4 BGRA
    'BGRA',
    // 4:4:4 BGRX (opaque)
    'BGRX'
];
const VIDEO_SAMPLE_PIXEL_FORMATS_SET = new Set(VIDEO_SAMPLE_PIXEL_FORMATS);
class VideoSample {
    /** The width of the frame in pixels after rotation. */ get displayWidth() {
        return this.rotation % 180 === 0 ? this.codedWidth : this.codedHeight;
    }
    /** The height of the frame in pixels after rotation. */ get displayHeight() {
        return this.rotation % 180 === 0 ? this.codedHeight : this.codedWidth;
    }
    /** The presentation timestamp of the frame in microseconds. */ get microsecondTimestamp() {
        return Math.trunc(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SECOND_TO_MICROSECOND_FACTOR"] * this.timestamp);
    }
    /** The duration of the frame in microseconds. */ get microsecondDuration() {
        return Math.trunc(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SECOND_TO_MICROSECOND_FACTOR"] * this.duration);
    }
    /**
     * Whether this sample uses a pixel format that can hold transparency data. Note that this doesn't necessarily mean
     * that the sample is transparent.
     */ get hasAlpha() {
        return this.format && this.format.includes('A');
    }
    constructor(data, init){
        /** @internal */ this._closed = false;
        if (data instanceof ArrayBuffer || typeof SharedArrayBuffer !== 'undefined' && data instanceof SharedArrayBuffer || ArrayBuffer.isView(data)) {
            if (!init || typeof init !== 'object') {
                throw new TypeError('init must be an object.');
            }
            if (init.format === undefined || !VIDEO_SAMPLE_PIXEL_FORMATS_SET.has(init.format)) {
                throw new TypeError('init.format must be one of: ' + VIDEO_SAMPLE_PIXEL_FORMATS.join(', '));
            }
            if (!Number.isInteger(init.codedWidth) || init.codedWidth <= 0) {
                throw new TypeError('init.codedWidth must be a positive integer.');
            }
            if (!Number.isInteger(init.codedHeight) || init.codedHeight <= 0) {
                throw new TypeError('init.codedHeight must be a positive integer.');
            }
            if (init.rotation !== undefined && ![
                0,
                90,
                180,
                270
            ].includes(init.rotation)) {
                throw new TypeError('init.rotation, when provided, must be 0, 90, 180, or 270.');
            }
            if (!Number.isFinite(init.timestamp)) {
                throw new TypeError('init.timestamp must be a number.');
            }
            if (init.duration !== undefined && (!Number.isFinite(init.duration) || init.duration < 0)) {
                throw new TypeError('init.duration, when provided, must be a non-negative number.');
            }
            this._data = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(data).slice(); // Copy it
            this._layout = init.layout ?? createDefaultPlaneLayout(init.format, init.codedWidth, init.codedHeight);
            this.format = init.format;
            this.codedWidth = init.codedWidth;
            this.codedHeight = init.codedHeight;
            this.rotation = init.rotation ?? 0;
            this.timestamp = init.timestamp;
            this.duration = init.duration ?? 0;
            this.colorSpace = new VideoSampleColorSpace(init.colorSpace);
        } else if (typeof VideoFrame !== 'undefined' && data instanceof VideoFrame) {
            if (init?.rotation !== undefined && ![
                0,
                90,
                180,
                270
            ].includes(init.rotation)) {
                throw new TypeError('init.rotation, when provided, must be 0, 90, 180, or 270.');
            }
            if (init?.timestamp !== undefined && !Number.isFinite(init?.timestamp)) {
                throw new TypeError('init.timestamp, when provided, must be a number.');
            }
            if (init?.duration !== undefined && (!Number.isFinite(init.duration) || init.duration < 0)) {
                throw new TypeError('init.duration, when provided, must be a non-negative number.');
            }
            this._data = data;
            this._layout = null;
            this.format = data.format;
            // Copying the display dimensions here, assuming no innate VideoFrame rotation
            this.codedWidth = data.displayWidth;
            this.codedHeight = data.displayHeight;
            // The VideoFrame's rotation is ignored here. It's still a new field, and I'm not sure of any application
            // where the browser makes use of it. If a case gets found, I'll add it.
            this.rotation = init?.rotation ?? 0;
            this.timestamp = init?.timestamp ?? data.timestamp / 1e6;
            this.duration = init?.duration ?? (data.duration ?? 0) / 1e6;
            this.colorSpace = new VideoSampleColorSpace(data.colorSpace);
        } else if (typeof HTMLImageElement !== 'undefined' && data instanceof HTMLImageElement || typeof SVGImageElement !== 'undefined' && data instanceof SVGImageElement || typeof ImageBitmap !== 'undefined' && data instanceof ImageBitmap || typeof HTMLVideoElement !== 'undefined' && data instanceof HTMLVideoElement || typeof HTMLCanvasElement !== 'undefined' && data instanceof HTMLCanvasElement || typeof OffscreenCanvas !== 'undefined' && data instanceof OffscreenCanvas) {
            if (!init || typeof init !== 'object') {
                throw new TypeError('init must be an object.');
            }
            if (init.rotation !== undefined && ![
                0,
                90,
                180,
                270
            ].includes(init.rotation)) {
                throw new TypeError('init.rotation, when provided, must be 0, 90, 180, or 270.');
            }
            if (!Number.isFinite(init.timestamp)) {
                throw new TypeError('init.timestamp must be a number.');
            }
            if (init.duration !== undefined && (!Number.isFinite(init.duration) || init.duration < 0)) {
                throw new TypeError('init.duration, when provided, must be a non-negative number.');
            }
            if (typeof VideoFrame !== 'undefined') {
                return new VideoSample(new VideoFrame(data, {
                    timestamp: Math.trunc(init.timestamp * __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SECOND_TO_MICROSECOND_FACTOR"]),
                    // Drag 0 to undefined
                    duration: Math.trunc((init.duration ?? 0) * __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SECOND_TO_MICROSECOND_FACTOR"]) || undefined
                }), init);
            }
            let width = 0;
            let height = 0;
            // Determine the dimensions of the thing
            if ('naturalWidth' in data) {
                width = data.naturalWidth;
                height = data.naturalHeight;
            } else if ('videoWidth' in data) {
                width = data.videoWidth;
                height = data.videoHeight;
            } else if ('width' in data) {
                width = Number(data.width);
                height = Number(data.height);
            }
            if (!width || !height) {
                throw new TypeError('Could not determine dimensions.');
            }
            const canvas = new OffscreenCanvas(width, height);
            const context = canvas.getContext('2d', {
                alpha: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isFirefox"])(),
                willReadFrequently: true
            });
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(context);
            // Draw it to a canvas
            context.drawImage(data, 0, 0);
            this._data = canvas;
            this._layout = null;
            this.format = 'RGBX';
            this.codedWidth = width;
            this.codedHeight = height;
            this.rotation = init.rotation ?? 0;
            this.timestamp = init.timestamp;
            this.duration = init.duration ?? 0;
            this.colorSpace = new VideoSampleColorSpace({
                matrix: 'rgb',
                primaries: 'bt709',
                transfer: 'iec61966-2-1',
                fullRange: true
            });
        } else {
            throw new TypeError('Invalid data type: Must be a BufferSource or CanvasImageSource.');
        }
        finalizationRegistry?.register(this, {
            type: 'video',
            data: this._data
        }, this);
    }
    /** Clones this video sample. */ clone() {
        if (this._closed) {
            throw new Error('VideoSample is closed.');
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._data !== null);
        if (isVideoFrame(this._data)) {
            return new VideoSample(this._data.clone(), {
                timestamp: this.timestamp,
                duration: this.duration,
                rotation: this.rotation
            });
        } else if (this._data instanceof Uint8Array) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._layout);
            return new VideoSample(this._data, {
                format: this.format,
                layout: this._layout,
                codedWidth: this.codedWidth,
                codedHeight: this.codedHeight,
                timestamp: this.timestamp,
                duration: this.duration,
                colorSpace: this.colorSpace,
                rotation: this.rotation
            });
        } else {
            return new VideoSample(this._data, {
                format: this.format,
                codedWidth: this.codedWidth,
                codedHeight: this.codedHeight,
                timestamp: this.timestamp,
                duration: this.duration,
                colorSpace: this.colorSpace,
                rotation: this.rotation
            });
        }
    }
    /**
     * Closes this video sample, releasing held resources. Video samples should be closed as soon as they are not
     * needed anymore.
     */ close() {
        if (this._closed) {
            return;
        }
        finalizationRegistry?.unregister(this);
        if (isVideoFrame(this._data)) {
            this._data.close();
        } else {
            this._data = null; // GC that shit
        }
        this._closed = true;
    }
    /**
     * Returns the number of bytes required to hold this video sample's pixel data. Throws if `format` is `null`;
     * specify an explicit RGB format in the options in this case.
     */ allocationSize(options = {}) {
        validateVideoFrameCopyToOptions(options);
        if (this._closed) {
            throw new Error('VideoSample is closed.');
        }
        if ((options.format ?? this.format) === null) {
            throw new Error('Cannot get allocation size when format is null. Please manually provide an RGB pixel format in the' + ' options instead.');
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._data !== null);
        if (!isVideoFrame(this._data)) {
            if (options.colorSpace || options.format && options.format !== this.format || options.layout || options.rect) {
                // Temporarily convert to VideoFrame to get it done
                const videoFrame = this.toVideoFrame();
                const size = videoFrame.allocationSize(options);
                videoFrame.close();
                return size;
            }
        }
        if (isVideoFrame(this._data)) {
            return this._data.allocationSize(options);
        } else if (this._data instanceof Uint8Array) {
            return this._data.byteLength;
        } else {
            return this.codedWidth * this.codedHeight * 4; // RGBX
        }
    }
    /**
     * Copies this video sample's pixel data to an ArrayBuffer or ArrayBufferView. Throws if `format` is `null`;
     * specify an explicit RGB format in the options in this case.
     * @returns The byte layout of the planes of the copied data.
     */ async copyTo(destination, options = {}) {
        if (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isAllowSharedBufferSource"])(destination)) {
            throw new TypeError('destination must be an ArrayBuffer or an ArrayBuffer view.');
        }
        validateVideoFrameCopyToOptions(options);
        if (this._closed) {
            throw new Error('VideoSample is closed.');
        }
        if ((options.format ?? this.format) === null) {
            throw new Error('Cannot copy video sample data when format is null. Please manually provide an RGB pixel format in the' + ' options instead.');
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._data !== null);
        if (!isVideoFrame(this._data)) {
            if (options.colorSpace || options.format && options.format !== this.format || options.layout || options.rect) {
                // Temporarily convert to VideoFrame to get it done
                const videoFrame = this.toVideoFrame();
                const layout = await videoFrame.copyTo(destination, options);
                videoFrame.close();
                return layout;
            }
        }
        if (isVideoFrame(this._data)) {
            return this._data.copyTo(destination, options);
        } else if (this._data instanceof Uint8Array) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._layout);
            const dest = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(destination);
            dest.set(this._data);
            return this._layout;
        } else {
            const canvas = this._data;
            const context = canvas.getContext('2d');
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(context);
            const imageData = context.getImageData(0, 0, this.codedWidth, this.codedHeight);
            const dest = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(destination);
            dest.set(imageData.data);
            return [
                {
                    offset: 0,
                    stride: 4 * this.codedWidth
                }
            ];
        }
    }
    /**
     * Converts this video sample to a VideoFrame for use with the WebCodecs API. The VideoFrame returned by this
     * method *must* be closed separately from this video sample.
     */ toVideoFrame() {
        if (this._closed) {
            throw new Error('VideoSample is closed.');
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._data !== null);
        if (isVideoFrame(this._data)) {
            return new VideoFrame(this._data, {
                timestamp: this.microsecondTimestamp,
                duration: this.microsecondDuration || undefined
            });
        } else if (this._data instanceof Uint8Array) {
            return new VideoFrame(this._data, {
                format: this.format,
                codedWidth: this.codedWidth,
                codedHeight: this.codedHeight,
                timestamp: this.microsecondTimestamp,
                duration: this.microsecondDuration || undefined,
                colorSpace: this.colorSpace
            });
        } else {
            return new VideoFrame(this._data, {
                timestamp: this.microsecondTimestamp,
                duration: this.microsecondDuration || undefined
            });
        }
    }
    draw(context, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8) {
        let sx = 0;
        let sy = 0;
        let sWidth = this.displayWidth;
        let sHeight = this.displayHeight;
        let dx = 0;
        let dy = 0;
        let dWidth = this.displayWidth;
        let dHeight = this.displayHeight;
        if (arg5 !== undefined) {
            sx = arg1;
            sy = arg2;
            sWidth = arg3;
            sHeight = arg4;
            dx = arg5;
            dy = arg6;
            if (arg7 !== undefined) {
                dWidth = arg7;
                dHeight = arg8;
            } else {
                dWidth = sWidth;
                dHeight = sHeight;
            }
        } else {
            dx = arg1;
            dy = arg2;
            if (arg3 !== undefined) {
                dWidth = arg3;
                dHeight = arg4;
            }
        }
        if (!(typeof CanvasRenderingContext2D !== 'undefined' && context instanceof CanvasRenderingContext2D || typeof OffscreenCanvasRenderingContext2D !== 'undefined' && context instanceof OffscreenCanvasRenderingContext2D)) {
            throw new TypeError('context must be a CanvasRenderingContext2D or OffscreenCanvasRenderingContext2D.');
        }
        if (!Number.isFinite(sx)) {
            throw new TypeError('sx must be a number.');
        }
        if (!Number.isFinite(sy)) {
            throw new TypeError('sy must be a number.');
        }
        if (!Number.isFinite(sWidth) || sWidth < 0) {
            throw new TypeError('sWidth must be a non-negative number.');
        }
        if (!Number.isFinite(sHeight) || sHeight < 0) {
            throw new TypeError('sHeight must be a non-negative number.');
        }
        if (!Number.isFinite(dx)) {
            throw new TypeError('dx must be a number.');
        }
        if (!Number.isFinite(dy)) {
            throw new TypeError('dy must be a number.');
        }
        if (!Number.isFinite(dWidth) || dWidth < 0) {
            throw new TypeError('dWidth must be a non-negative number.');
        }
        if (!Number.isFinite(dHeight) || dHeight < 0) {
            throw new TypeError('dHeight must be a non-negative number.');
        }
        if (this._closed) {
            throw new Error('VideoSample is closed.');
        }
        ({ sx, sy, sWidth, sHeight } = this._rotateSourceRegion(sx, sy, sWidth, sHeight, this.rotation));
        const source = this.toCanvasImageSource();
        context.save();
        const centerX = dx + dWidth / 2;
        const centerY = dy + dHeight / 2;
        context.translate(centerX, centerY);
        context.rotate(this.rotation * Math.PI / 180);
        const aspectRatioChange = this.rotation % 180 === 0 ? 1 : dWidth / dHeight;
        // Scale to compensate for aspect ratio changes when rotated
        context.scale(1 / aspectRatioChange, aspectRatioChange);
        context.drawImage(source, sx, sy, sWidth, sHeight, -dWidth / 2, -dHeight / 2, dWidth, dHeight);
        context.restore();
    }
    /**
     * Draws the sample in the middle of the canvas corresponding to the context with the specified fit behavior.
     */ drawWithFit(context, options) {
        if (!(typeof CanvasRenderingContext2D !== 'undefined' && context instanceof CanvasRenderingContext2D || typeof OffscreenCanvasRenderingContext2D !== 'undefined' && context instanceof OffscreenCanvasRenderingContext2D)) {
            throw new TypeError('context must be a CanvasRenderingContext2D or OffscreenCanvasRenderingContext2D.');
        }
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (![
            'fill',
            'contain',
            'cover'
        ].includes(options.fit)) {
            throw new TypeError('options.fit must be \'fill\', \'contain\', or \'cover\'.');
        }
        if (options.rotation !== undefined && ![
            0,
            90,
            180,
            270
        ].includes(options.rotation)) {
            throw new TypeError('options.rotation, when provided, must be 0, 90, 180, or 270.');
        }
        if (options.crop !== undefined) {
            validateCropRectangle(options.crop, 'options.');
        }
        const canvasWidth = context.canvas.width;
        const canvasHeight = context.canvas.height;
        const rotation = options.rotation ?? this.rotation;
        const [rotatedWidth, rotatedHeight] = rotation % 180 === 0 ? [
            this.codedWidth,
            this.codedHeight
        ] : [
            this.codedHeight,
            this.codedWidth
        ];
        if (options.crop) {
            clampCropRectangle(options.crop, rotatedWidth, rotatedHeight);
        }
        // These variables specify where the final sample will be drawn on the canvas
        let dx;
        let dy;
        let newWidth;
        let newHeight;
        const { sx, sy, sWidth, sHeight } = this._rotateSourceRegion(options.crop?.left ?? 0, options.crop?.top ?? 0, options.crop?.width ?? rotatedWidth, options.crop?.height ?? rotatedHeight, rotation);
        if (options.fit === 'fill') {
            dx = 0;
            dy = 0;
            newWidth = canvasWidth;
            newHeight = canvasHeight;
        } else {
            const [sampleWidth, sampleHeight] = options.crop ? [
                options.crop.width,
                options.crop.height
            ] : [
                rotatedWidth,
                rotatedHeight
            ];
            const scale = options.fit === 'contain' ? Math.min(canvasWidth / sampleWidth, canvasHeight / sampleHeight) : Math.max(canvasWidth / sampleWidth, canvasHeight / sampleHeight);
            newWidth = sampleWidth * scale;
            newHeight = sampleHeight * scale;
            dx = (canvasWidth - newWidth) / 2;
            dy = (canvasHeight - newHeight) / 2;
        }
        context.save();
        const aspectRatioChange = rotation % 180 === 0 ? 1 : newWidth / newHeight;
        context.translate(canvasWidth / 2, canvasHeight / 2);
        context.rotate(rotation * Math.PI / 180);
        // This aspect ratio compensation is done so that we can draw the sample with the intended dimensions and
        // don't need to think about how those dimensions change after the rotation
        context.scale(1 / aspectRatioChange, aspectRatioChange);
        context.translate(-canvasWidth / 2, -canvasHeight / 2);
        // Important that we don't use .draw() here since that would take rotation into account, but we wanna handle it
        // ourselves here
        context.drawImage(this.toCanvasImageSource(), sx, sy, sWidth, sHeight, dx, dy, newWidth, newHeight);
        context.restore();
    }
    /** @internal */ _rotateSourceRegion(sx, sy, sWidth, sHeight, rotation) {
        // The provided sx,sy,sWidth,sHeight refer to the final rotated image, but that's not actually how the image is
        // stored. Therefore, we must map these back onto the original, pre-rotation image.
        if (rotation === 90) {
            [sx, sy, sWidth, sHeight] = [
                sy,
                this.codedHeight - sx - sWidth,
                sHeight,
                sWidth
            ];
        } else if (rotation === 180) {
            [sx, sy] = [
                this.codedWidth - sx - sWidth,
                this.codedHeight - sy - sHeight
            ];
        } else if (rotation === 270) {
            [sx, sy, sWidth, sHeight] = [
                this.codedWidth - sy - sHeight,
                sx,
                sHeight,
                sWidth
            ];
        }
        return {
            sx,
            sy,
            sWidth,
            sHeight
        };
    }
    /**
     * Converts this video sample to a
     * [`CanvasImageSource`](https://udn.realityripple.com/docs/Web/API/CanvasImageSource) for drawing to a canvas.
     *
     * You must use the value returned by this method immediately, as any VideoFrame created internally will
     * automatically be closed in the next microtask.
     */ toCanvasImageSource() {
        if (this._closed) {
            throw new Error('VideoSample is closed.');
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._data !== null);
        if (this._data instanceof Uint8Array) {
            // Requires VideoFrame to be defined
            const videoFrame = this.toVideoFrame();
            queueMicrotask(()=>videoFrame.close()); // Let's automatically close the frame in the next microtask
            return videoFrame;
        } else {
            return this._data;
        }
    }
    /** Sets the rotation metadata of this video sample. */ setRotation(newRotation) {
        if (![
            0,
            90,
            180,
            270
        ].includes(newRotation)) {
            throw new TypeError('newRotation must be 0, 90, 180, or 270.');
        }
        // eslint-disable-next-line @typescript-eslint/no-unnecessary-type-assertion
        this.rotation = newRotation;
    }
    /** Sets the presentation timestamp of this video sample, in seconds. */ setTimestamp(newTimestamp) {
        if (!Number.isFinite(newTimestamp)) {
            throw new TypeError('newTimestamp must be a number.');
        }
        // eslint-disable-next-line @typescript-eslint/no-unnecessary-type-assertion
        this.timestamp = newTimestamp;
    }
    /** Sets the duration of this video sample, in seconds. */ setDuration(newDuration) {
        if (!Number.isFinite(newDuration) || newDuration < 0) {
            throw new TypeError('newDuration must be a non-negative number.');
        }
        // eslint-disable-next-line @typescript-eslint/no-unnecessary-type-assertion
        this.duration = newDuration;
    }
    /** Calls `.close()`. */ [Symbol.dispose]() {
        this.close();
    }
}
class VideoSampleColorSpace {
    /** Creates a new VideoSampleColorSpace. */ constructor(init){
        this.primaries = init?.primaries ?? null;
        this.transfer = init?.transfer ?? null;
        this.matrix = init?.matrix ?? null;
        this.fullRange = init?.fullRange ?? null;
    }
    /** Serializes the color space to a JSON object. */ toJSON() {
        return {
            primaries: this.primaries,
            transfer: this.transfer,
            matrix: this.matrix,
            fullRange: this.fullRange
        };
    }
}
const isVideoFrame = (x)=>{
    return typeof VideoFrame !== 'undefined' && x instanceof VideoFrame;
};
const clampCropRectangle = (crop, outerWidth, outerHeight)=>{
    crop.left = Math.min(crop.left, outerWidth);
    crop.top = Math.min(crop.top, outerHeight);
    crop.width = Math.min(crop.width, outerWidth - crop.left);
    crop.height = Math.min(crop.height, outerHeight - crop.top);
    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(crop.width >= 0);
    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(crop.height >= 0);
};
const validateCropRectangle = (crop, prefix)=>{
    if (!crop || typeof crop !== 'object') {
        throw new TypeError(prefix + 'crop, when provided, must be an object.');
    }
    if (!Number.isInteger(crop.left) || crop.left < 0) {
        throw new TypeError(prefix + 'crop.left must be a non-negative integer.');
    }
    if (!Number.isInteger(crop.top) || crop.top < 0) {
        throw new TypeError(prefix + 'crop.top must be a non-negative integer.');
    }
    if (!Number.isInteger(crop.width) || crop.width < 0) {
        throw new TypeError(prefix + 'crop.width must be a non-negative integer.');
    }
    if (!Number.isInteger(crop.height) || crop.height < 0) {
        throw new TypeError(prefix + 'crop.height must be a non-negative integer.');
    }
};
const validateVideoFrameCopyToOptions = (options)=>{
    if (!options || typeof options !== 'object') {
        throw new TypeError('options must be an object.');
    }
    if (options.colorSpace !== undefined && ![
        'display-p3',
        'srgb'
    ].includes(options.colorSpace)) {
        throw new TypeError('options.colorSpace, when provided, must be \'display-p3\' or \'srgb\'.');
    }
    if (options.format !== undefined && typeof options.format !== 'string') {
        throw new TypeError('options.format, when provided, must be a string.');
    }
    if (options.layout !== undefined) {
        if (!Array.isArray(options.layout)) {
            throw new TypeError('options.layout, when provided, must be an array.');
        }
        for (const plane of options.layout){
            if (!plane || typeof plane !== 'object') {
                throw new TypeError('Each entry in options.layout must be an object.');
            }
            if (!Number.isInteger(plane.offset) || plane.offset < 0) {
                throw new TypeError('plane.offset must be a non-negative integer.');
            }
            if (!Number.isInteger(plane.stride) || plane.stride < 0) {
                throw new TypeError('plane.stride must be a non-negative integer.');
            }
        }
    }
    if (options.rect !== undefined) {
        if (!options.rect || typeof options.rect !== 'object') {
            throw new TypeError('options.rect, when provided, must be an object.');
        }
        if (options.rect.x !== undefined && (!Number.isInteger(options.rect.x) || options.rect.x < 0)) {
            throw new TypeError('options.rect.x, when provided, must be a non-negative integer.');
        }
        if (options.rect.y !== undefined && (!Number.isInteger(options.rect.y) || options.rect.y < 0)) {
            throw new TypeError('options.rect.y, when provided, must be a non-negative integer.');
        }
        if (options.rect.width !== undefined && (!Number.isInteger(options.rect.width) || options.rect.width < 0)) {
            throw new TypeError('options.rect.width, when provided, must be a non-negative integer.');
        }
        if (options.rect.height !== undefined && (!Number.isInteger(options.rect.height) || options.rect.height < 0)) {
            throw new TypeError('options.rect.height, when provided, must be a non-negative integer.');
        }
    }
};
/** Implements logic from WebCodecs  9.4.6 "Compute Layout and Allocation Size" */ const createDefaultPlaneLayout = (format, codedWidth, codedHeight)=>{
    const planes = getPlaneConfigs(format);
    const layouts = [];
    let currentOffset = 0;
    for (const plane of planes){
        // Per  9.8, dimensions are usually "rounded up to the nearest integer".
        const planeWidth = Math.ceil(codedWidth / plane.widthDivisor);
        const planeHeight = Math.ceil(codedHeight / plane.heightDivisor);
        const stride = planeWidth * plane.sampleBytes;
        // Tight packing
        const planeSize = stride * planeHeight;
        layouts.push({
            offset: currentOffset,
            stride: stride
        });
        currentOffset += planeSize;
    }
    return layouts;
};
/** Helper to retrieve plane configurations based on WebCodecs  9.8 Pixel Format definitions. */ const getPlaneConfigs = (format)=>{
    // Helper for standard YUV planes
    const yuv = (yBytes, uvBytes, subX, subY, hasAlpha)=>{
        const configs = [
            {
                sampleBytes: yBytes,
                widthDivisor: 1,
                heightDivisor: 1
            },
            {
                sampleBytes: uvBytes,
                widthDivisor: subX,
                heightDivisor: subY
            },
            {
                sampleBytes: uvBytes,
                widthDivisor: subX,
                heightDivisor: subY
            }
        ];
        if (hasAlpha) {
            // Match luma dimensions
            configs.push({
                sampleBytes: yBytes,
                widthDivisor: 1,
                heightDivisor: 1
            });
        }
        return configs;
    };
    switch(format){
        case 'I420':
            return yuv(1, 1, 2, 2, false);
        case 'I420P10':
        case 'I420P12':
            return yuv(2, 2, 2, 2, false);
        case 'I420A':
            return yuv(1, 1, 2, 2, true);
        case 'I420AP10':
        case 'I420AP12':
            return yuv(2, 2, 2, 2, true);
        case 'I422':
            return yuv(1, 1, 2, 1, false);
        case 'I422P10':
        case 'I422P12':
            return yuv(2, 2, 2, 1, false);
        case 'I422A':
            return yuv(1, 1, 2, 1, true);
        case 'I422AP10':
        case 'I422AP12':
            return yuv(2, 2, 2, 1, true);
        case 'I444':
            return yuv(1, 1, 1, 1, false);
        case 'I444P10':
        case 'I444P12':
            return yuv(2, 2, 1, 1, false);
        case 'I444A':
            return yuv(1, 1, 1, 1, true);
        case 'I444AP10':
        case 'I444AP12':
            return yuv(2, 2, 1, 1, true);
        case 'NV12':
            return [
                {
                    sampleBytes: 1,
                    widthDivisor: 1,
                    heightDivisor: 1
                },
                {
                    sampleBytes: 2,
                    widthDivisor: 2,
                    heightDivisor: 2
                }
            ];
        case 'RGBA':
        case 'RGBX':
        case 'BGRA':
        case 'BGRX':
            return [
                {
                    sampleBytes: 4,
                    widthDivisor: 1,
                    heightDivisor: 1
                }
            ];
        default:
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(format);
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
    }
};
const AUDIO_SAMPLE_FORMATS = new Set([
    'f32',
    'f32-planar',
    's16',
    's16-planar',
    's32',
    's32-planar',
    'u8',
    'u8-planar'
]);
class AudioSample {
    /** The presentation timestamp of the sample in microseconds. */ get microsecondTimestamp() {
        return Math.trunc(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SECOND_TO_MICROSECOND_FACTOR"] * this.timestamp);
    }
    /** The duration of the sample in microseconds. */ get microsecondDuration() {
        return Math.trunc(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SECOND_TO_MICROSECOND_FACTOR"] * this.duration);
    }
    /**
     * Creates a new {@link AudioSample}, either from an existing
     * [`AudioData`](https://developer.mozilla.org/en-US/docs/Web/API/AudioData) or from raw bytes specified in
     * {@link AudioSampleInit}.
     */ constructor(init){
        /** @internal */ this._closed = false;
        if (isAudioData(init)) {
            if (init.format === null) {
                throw new TypeError('AudioData with null format is not supported.');
            }
            this._data = init;
            this.format = init.format;
            this.sampleRate = init.sampleRate;
            this.numberOfFrames = init.numberOfFrames;
            this.numberOfChannels = init.numberOfChannels;
            this.timestamp = init.timestamp / 1e6;
            this.duration = init.numberOfFrames / init.sampleRate;
        } else {
            if (!init || typeof init !== 'object') {
                throw new TypeError('Invalid AudioDataInit: must be an object.');
            }
            if (!AUDIO_SAMPLE_FORMATS.has(init.format)) {
                throw new TypeError('Invalid AudioDataInit: invalid format.');
            }
            if (!Number.isFinite(init.sampleRate) || init.sampleRate <= 0) {
                throw new TypeError('Invalid AudioDataInit: sampleRate must be > 0.');
            }
            if (!Number.isInteger(init.numberOfChannels) || init.numberOfChannels === 0) {
                throw new TypeError('Invalid AudioDataInit: numberOfChannels must be an integer > 0.');
            }
            if (!Number.isFinite(init?.timestamp)) {
                throw new TypeError('init.timestamp must be a number.');
            }
            const numberOfFrames = init.data.byteLength / (getBytesPerSample(init.format) * init.numberOfChannels);
            if (!Number.isInteger(numberOfFrames)) {
                throw new TypeError('Invalid AudioDataInit: data size is not a multiple of frame size.');
            }
            this.format = init.format;
            this.sampleRate = init.sampleRate;
            this.numberOfFrames = numberOfFrames;
            this.numberOfChannels = init.numberOfChannels;
            this.timestamp = init.timestamp;
            this.duration = numberOfFrames / init.sampleRate;
            let dataBuffer;
            if (init.data instanceof ArrayBuffer) {
                dataBuffer = new Uint8Array(init.data);
            } else if (ArrayBuffer.isView(init.data)) {
                dataBuffer = new Uint8Array(init.data.buffer, init.data.byteOffset, init.data.byteLength);
            } else {
                throw new TypeError('Invalid AudioDataInit: data is not a BufferSource.');
            }
            const expectedSize = this.numberOfFrames * this.numberOfChannels * getBytesPerSample(this.format);
            if (dataBuffer.byteLength < expectedSize) {
                throw new TypeError('Invalid AudioDataInit: insufficient data size.');
            }
            this._data = dataBuffer;
        }
        finalizationRegistry?.register(this, {
            type: 'audio',
            data: this._data
        }, this);
    }
    /** Returns the number of bytes required to hold the audio sample's data as specified by the given options. */ allocationSize(options) {
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (!Number.isInteger(options.planeIndex) || options.planeIndex < 0) {
            throw new TypeError('planeIndex must be a non-negative integer.');
        }
        if (options.format !== undefined && !AUDIO_SAMPLE_FORMATS.has(options.format)) {
            throw new TypeError('Invalid format.');
        }
        if (options.frameOffset !== undefined && (!Number.isInteger(options.frameOffset) || options.frameOffset < 0)) {
            throw new TypeError('frameOffset must be a non-negative integer.');
        }
        if (options.frameCount !== undefined && (!Number.isInteger(options.frameCount) || options.frameCount < 0)) {
            throw new TypeError('frameCount must be a non-negative integer.');
        }
        if (this._closed) {
            throw new Error('AudioSample is closed.');
        }
        const destFormat = options.format ?? this.format;
        const frameOffset = options.frameOffset ?? 0;
        if (frameOffset >= this.numberOfFrames) {
            throw new RangeError('frameOffset out of range');
        }
        const copyFrameCount = options.frameCount !== undefined ? options.frameCount : this.numberOfFrames - frameOffset;
        if (copyFrameCount > this.numberOfFrames - frameOffset) {
            throw new RangeError('frameCount out of range');
        }
        const bytesPerSample = getBytesPerSample(destFormat);
        const isPlanar = formatIsPlanar(destFormat);
        if (isPlanar && options.planeIndex >= this.numberOfChannels) {
            throw new RangeError('planeIndex out of range');
        }
        if (!isPlanar && options.planeIndex !== 0) {
            throw new RangeError('planeIndex out of range');
        }
        const elementCount = isPlanar ? copyFrameCount : copyFrameCount * this.numberOfChannels;
        return elementCount * bytesPerSample;
    }
    /** Copies the audio sample's data to an ArrayBuffer or ArrayBufferView as specified by the given options. */ copyTo(destination, options) {
        if (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isAllowSharedBufferSource"])(destination)) {
            throw new TypeError('destination must be an ArrayBuffer or an ArrayBuffer view.');
        }
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (!Number.isInteger(options.planeIndex) || options.planeIndex < 0) {
            throw new TypeError('planeIndex must be a non-negative integer.');
        }
        if (options.format !== undefined && !AUDIO_SAMPLE_FORMATS.has(options.format)) {
            throw new TypeError('Invalid format.');
        }
        if (options.frameOffset !== undefined && (!Number.isInteger(options.frameOffset) || options.frameOffset < 0)) {
            throw new TypeError('frameOffset must be a non-negative integer.');
        }
        if (options.frameCount !== undefined && (!Number.isInteger(options.frameCount) || options.frameCount < 0)) {
            throw new TypeError('frameCount must be a non-negative integer.');
        }
        if (this._closed) {
            throw new Error('AudioSample is closed.');
        }
        const { planeIndex, format, frameCount: optFrameCount, frameOffset: optFrameOffset } = options;
        const destFormat = format ?? this.format;
        if (!destFormat) throw new Error('Destination format not determined');
        const numFrames = this.numberOfFrames;
        const numChannels = this.numberOfChannels;
        const frameOffset = optFrameOffset ?? 0;
        if (frameOffset >= numFrames) {
            throw new RangeError('frameOffset out of range');
        }
        const copyFrameCount = optFrameCount !== undefined ? optFrameCount : numFrames - frameOffset;
        if (copyFrameCount > numFrames - frameOffset) {
            throw new RangeError('frameCount out of range');
        }
        const destBytesPerSample = getBytesPerSample(destFormat);
        const destIsPlanar = formatIsPlanar(destFormat);
        if (destIsPlanar && planeIndex >= numChannels) {
            throw new RangeError('planeIndex out of range');
        }
        if (!destIsPlanar && planeIndex !== 0) {
            throw new RangeError('planeIndex out of range');
        }
        const destElementCount = destIsPlanar ? copyFrameCount : copyFrameCount * numChannels;
        const requiredSize = destElementCount * destBytesPerSample;
        if (destination.byteLength < requiredSize) {
            throw new RangeError('Destination buffer is too small');
        }
        const destView = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(destination);
        const writeFn = getWriteFunction(destFormat);
        if (isAudioData(this._data)) {
            if (destIsPlanar) {
                if (destFormat === 'f32-planar') {
                    // Simple, since the browser must support f32-planar, we can just delegate here
                    this._data.copyTo(destination, {
                        planeIndex,
                        frameOffset,
                        frameCount: copyFrameCount,
                        format: 'f32-planar'
                    });
                } else {
                    // Allocate temporary buffer for f32-planar data
                    const tempBuffer = new ArrayBuffer(copyFrameCount * 4);
                    const tempArray = new Float32Array(tempBuffer);
                    this._data.copyTo(tempArray, {
                        planeIndex,
                        frameOffset,
                        frameCount: copyFrameCount,
                        format: 'f32-planar'
                    });
                    // Convert each f32 sample to destination format
                    const tempView = new DataView(tempBuffer);
                    for(let i = 0; i < copyFrameCount; i++){
                        const destOffset = i * destBytesPerSample;
                        const sample = tempView.getFloat32(i * 4, true);
                        writeFn(destView, destOffset, sample);
                    }
                }
            } else {
                // Destination is interleaved.
                // Allocate a temporary Float32Array to hold one channel's worth of data.
                const numCh = numChannels;
                const temp = new Float32Array(copyFrameCount);
                for(let ch = 0; ch < numCh; ch++){
                    this._data.copyTo(temp, {
                        planeIndex: ch,
                        frameOffset,
                        frameCount: copyFrameCount,
                        format: 'f32-planar'
                    });
                    for(let i = 0; i < copyFrameCount; i++){
                        const destIndex = i * numCh + ch;
                        const destOffset = destIndex * destBytesPerSample;
                        writeFn(destView, destOffset, temp[i]);
                    }
                }
            }
        } else {
            const uint8Data = this._data;
            const srcView = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(uint8Data);
            const srcFormat = this.format;
            const readFn = getReadFunction(srcFormat);
            const srcBytesPerSample = getBytesPerSample(srcFormat);
            const srcIsPlanar = formatIsPlanar(srcFormat);
            for(let i = 0; i < copyFrameCount; i++){
                if (destIsPlanar) {
                    const destOffset = i * destBytesPerSample;
                    let srcOffset;
                    if (srcIsPlanar) {
                        srcOffset = (planeIndex * numFrames + (i + frameOffset)) * srcBytesPerSample;
                    } else {
                        srcOffset = ((i + frameOffset) * numChannels + planeIndex) * srcBytesPerSample;
                    }
                    const normalized = readFn(srcView, srcOffset);
                    writeFn(destView, destOffset, normalized);
                } else {
                    for(let ch = 0; ch < numChannels; ch++){
                        const destIndex = i * numChannels + ch;
                        const destOffset = destIndex * destBytesPerSample;
                        let srcOffset;
                        if (srcIsPlanar) {
                            srcOffset = (ch * numFrames + (i + frameOffset)) * srcBytesPerSample;
                        } else {
                            srcOffset = ((i + frameOffset) * numChannels + ch) * srcBytesPerSample;
                        }
                        const normalized = readFn(srcView, srcOffset);
                        writeFn(destView, destOffset, normalized);
                    }
                }
            }
        }
    }
    /** Clones this audio sample. */ clone() {
        if (this._closed) {
            throw new Error('AudioSample is closed.');
        }
        if (isAudioData(this._data)) {
            const sample = new AudioSample(this._data.clone());
            sample.setTimestamp(this.timestamp); // Make sure the timestamp is precise (beyond microsecond accuracy)
            return sample;
        } else {
            return new AudioSample({
                format: this.format,
                sampleRate: this.sampleRate,
                numberOfFrames: this.numberOfFrames,
                numberOfChannels: this.numberOfChannels,
                timestamp: this.timestamp,
                data: this._data
            });
        }
    }
    /**
     * Closes this audio sample, releasing held resources. Audio samples should be closed as soon as they are not
     * needed anymore.
     */ close() {
        if (this._closed) {
            return;
        }
        finalizationRegistry?.unregister(this);
        if (isAudioData(this._data)) {
            this._data.close();
        } else {
            this._data = new Uint8Array(0);
        }
        this._closed = true;
    }
    /**
     * Converts this audio sample to an AudioData for use with the WebCodecs API. The AudioData returned by this
     * method *must* be closed separately from this audio sample.
     */ toAudioData() {
        if (this._closed) {
            throw new Error('AudioSample is closed.');
        }
        if (isAudioData(this._data)) {
            if (this._data.timestamp === this.microsecondTimestamp) {
                // Timestamp matches, let's just return the data (but cloned)
                return this._data.clone();
            } else {
                // It's impossible to simply change an AudioData's timestamp, so we'll need to create a new one
                if (formatIsPlanar(this.format)) {
                    const size = this.allocationSize({
                        planeIndex: 0,
                        format: this.format
                    });
                    const data = new ArrayBuffer(size * this.numberOfChannels);
                    // We gotta read out each plane individually
                    for(let i = 0; i < this.numberOfChannels; i++){
                        this.copyTo(new Uint8Array(data, i * size, size), {
                            planeIndex: i,
                            format: this.format
                        });
                    }
                    return new AudioData({
                        format: this.format,
                        sampleRate: this.sampleRate,
                        numberOfFrames: this.numberOfFrames,
                        numberOfChannels: this.numberOfChannels,
                        timestamp: this.microsecondTimestamp,
                        data
                    });
                } else {
                    const data = new ArrayBuffer(this.allocationSize({
                        planeIndex: 0,
                        format: this.format
                    }));
                    this.copyTo(data, {
                        planeIndex: 0,
                        format: this.format
                    });
                    return new AudioData({
                        format: this.format,
                        sampleRate: this.sampleRate,
                        numberOfFrames: this.numberOfFrames,
                        numberOfChannels: this.numberOfChannels,
                        timestamp: this.microsecondTimestamp,
                        data
                    });
                }
            }
        } else {
            return new AudioData({
                format: this.format,
                sampleRate: this.sampleRate,
                numberOfFrames: this.numberOfFrames,
                numberOfChannels: this.numberOfChannels,
                timestamp: this.microsecondTimestamp,
                data: this._data.buffer instanceof ArrayBuffer ? this._data.buffer : this._data.slice()
            });
        }
    }
    /** Convert this audio sample to an AudioBuffer for use with the Web Audio API. */ toAudioBuffer() {
        if (this._closed) {
            throw new Error('AudioSample is closed.');
        }
        const audioBuffer = new AudioBuffer({
            numberOfChannels: this.numberOfChannels,
            length: this.numberOfFrames,
            sampleRate: this.sampleRate
        });
        const dataBytes = new Float32Array(this.allocationSize({
            planeIndex: 0,
            format: 'f32-planar'
        }) / 4);
        for(let i = 0; i < this.numberOfChannels; i++){
            this.copyTo(dataBytes, {
                planeIndex: i,
                format: 'f32-planar'
            });
            audioBuffer.copyToChannel(dataBytes, i);
        }
        return audioBuffer;
    }
    /** Sets the presentation timestamp of this audio sample, in seconds. */ setTimestamp(newTimestamp) {
        if (!Number.isFinite(newTimestamp)) {
            throw new TypeError('newTimestamp must be a number.');
        }
        // eslint-disable-next-line @typescript-eslint/no-unnecessary-type-assertion
        this.timestamp = newTimestamp;
    }
    /** Calls `.close()`. */ [Symbol.dispose]() {
        this.close();
    }
    /** @internal */ static *_fromAudioBuffer(audioBuffer, timestamp) {
        if (!(audioBuffer instanceof AudioBuffer)) {
            throw new TypeError('audioBuffer must be an AudioBuffer.');
        }
        const MAX_FLOAT_COUNT = 48000 * 5; // 5 seconds of mono 48 kHz audio per sample
        const numberOfChannels = audioBuffer.numberOfChannels;
        const sampleRate = audioBuffer.sampleRate;
        const totalFrames = audioBuffer.length;
        const maxFramesPerChunk = Math.floor(MAX_FLOAT_COUNT / numberOfChannels);
        let currentRelativeFrame = 0;
        let remainingFrames = totalFrames;
        // Create AudioSamples in a chunked fashion so we don't create huge Float32Arrays
        while(remainingFrames > 0){
            const framesToCopy = Math.min(maxFramesPerChunk, remainingFrames);
            const chunkData = new Float32Array(numberOfChannels * framesToCopy);
            for(let channel = 0; channel < numberOfChannels; channel++){
                audioBuffer.copyFromChannel(chunkData.subarray(channel * framesToCopy, (channel + 1) * framesToCopy), channel, currentRelativeFrame);
            }
            yield new AudioSample({
                format: 'f32-planar',
                sampleRate,
                numberOfFrames: framesToCopy,
                numberOfChannels,
                timestamp: timestamp + currentRelativeFrame / sampleRate,
                data: chunkData
            });
            currentRelativeFrame += framesToCopy;
            remainingFrames -= framesToCopy;
        }
    }
    /**
     * Creates AudioSamples from an AudioBuffer, starting at the given timestamp in seconds. Typically creates exactly
     * one sample, but may create multiple if the AudioBuffer is exceedingly large.
     */ static fromAudioBuffer(audioBuffer, timestamp) {
        if (!(audioBuffer instanceof AudioBuffer)) {
            throw new TypeError('audioBuffer must be an AudioBuffer.');
        }
        const MAX_FLOAT_COUNT = 48000 * 5; // 5 seconds of mono 48 kHz audio per sample
        const numberOfChannels = audioBuffer.numberOfChannels;
        const sampleRate = audioBuffer.sampleRate;
        const totalFrames = audioBuffer.length;
        const maxFramesPerChunk = Math.floor(MAX_FLOAT_COUNT / numberOfChannels);
        let currentRelativeFrame = 0;
        let remainingFrames = totalFrames;
        const result = [];
        // Create AudioSamples in a chunked fashion so we don't create huge Float32Arrays
        while(remainingFrames > 0){
            const framesToCopy = Math.min(maxFramesPerChunk, remainingFrames);
            const chunkData = new Float32Array(numberOfChannels * framesToCopy);
            for(let channel = 0; channel < numberOfChannels; channel++){
                audioBuffer.copyFromChannel(chunkData.subarray(channel * framesToCopy, (channel + 1) * framesToCopy), channel, currentRelativeFrame);
            }
            const audioSample = new AudioSample({
                format: 'f32-planar',
                sampleRate,
                numberOfFrames: framesToCopy,
                numberOfChannels,
                timestamp: timestamp + currentRelativeFrame / sampleRate,
                data: chunkData
            });
            result.push(audioSample);
            currentRelativeFrame += framesToCopy;
            remainingFrames -= framesToCopy;
        }
        return result;
    }
}
const getBytesPerSample = (format)=>{
    switch(format){
        case 'u8':
        case 'u8-planar':
            return 1;
        case 's16':
        case 's16-planar':
            return 2;
        case 's32':
        case 's32-planar':
            return 4;
        case 'f32':
        case 'f32-planar':
            return 4;
        default:
            throw new Error('Unknown AudioSampleFormat');
    }
};
const formatIsPlanar = (format)=>{
    switch(format){
        case 'u8-planar':
        case 's16-planar':
        case 's32-planar':
        case 'f32-planar':
            return true;
        default:
            return false;
    }
};
const getReadFunction = (format)=>{
    switch(format){
        case 'u8':
        case 'u8-planar':
            return (view, offset)=>(view.getUint8(offset) - 128) / 128;
        case 's16':
        case 's16-planar':
            return (view, offset)=>view.getInt16(offset, true) / 32768;
        case 's32':
        case 's32-planar':
            return (view, offset)=>view.getInt32(offset, true) / 2147483648;
        case 'f32':
        case 'f32-planar':
            return (view, offset)=>view.getFloat32(offset, true);
    }
};
const getWriteFunction = (format)=>{
    switch(format){
        case 'u8':
        case 'u8-planar':
            return (view, offset, value)=>view.setUint8(offset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])((value + 1) * 127.5, 0, 255));
        case 's16':
        case 's16-planar':
            return (view, offset, value)=>view.setInt16(offset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])(Math.round(value * 32767), -32768, 32767), true);
        case 's32':
        case 's32-planar':
            return (view, offset, value)=>view.setInt32(offset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])(Math.round(value * 2147483647), -2147483648, 2147483647), true);
        case 'f32':
        case 'f32-planar':
            return (view, offset, value)=>view.setFloat32(offset, value, true);
    }
};
const isAudioData = (x)=>{
    return typeof AudioData !== 'undefined' && x instanceof AudioData;
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/encode.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "QUALITY_HIGH",
    ()=>QUALITY_HIGH,
    "QUALITY_LOW",
    ()=>QUALITY_LOW,
    "QUALITY_MEDIUM",
    ()=>QUALITY_MEDIUM,
    "QUALITY_VERY_HIGH",
    ()=>QUALITY_VERY_HIGH,
    "QUALITY_VERY_LOW",
    ()=>QUALITY_VERY_LOW,
    "Quality",
    ()=>Quality,
    "buildAudioEncoderConfig",
    ()=>buildAudioEncoderConfig,
    "buildVideoEncoderConfig",
    ()=>buildVideoEncoderConfig,
    "canEncode",
    ()=>canEncode,
    "canEncodeAudio",
    ()=>canEncodeAudio,
    "canEncodeSubtitles",
    ()=>canEncodeSubtitles,
    "canEncodeVideo",
    ()=>canEncodeVideo,
    "getEncodableAudioCodecs",
    ()=>getEncodableAudioCodecs,
    "getEncodableCodecs",
    ()=>getEncodableCodecs,
    "getEncodableSubtitleCodecs",
    ()=>getEncodableSubtitleCodecs,
    "getEncodableVideoCodecs",
    ()=>getEncodableVideoCodecs,
    "getFirstEncodableAudioCodec",
    ()=>getFirstEncodableAudioCodec,
    "getFirstEncodableSubtitleCodec",
    ()=>getFirstEncodableSubtitleCodec,
    "getFirstEncodableVideoCodec",
    ()=>getFirstEncodableVideoCodec,
    "validateAudioEncodingAdditionalOptions",
    ()=>validateAudioEncodingAdditionalOptions,
    "validateAudioEncodingConfig",
    ()=>validateAudioEncodingConfig,
    "validateVideoEncodingAdditionalOptions",
    ()=>validateVideoEncodingAdditionalOptions,
    "validateVideoEncodingConfig",
    ()=>validateVideoEncodingConfig
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/custom-coder.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
;
;
;
const validateVideoEncodingConfig = (config)=>{
    if (!config || typeof config !== 'object') {
        throw new TypeError('Encoding config must be an object.');
    }
    if (!__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"].includes(config.codec)) {
        throw new TypeError(`Invalid video codec '${config.codec}'. Must be one of: ${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"].join(', ')}.`);
    }
    if (!(config.bitrate instanceof Quality) && (!Number.isInteger(config.bitrate) || config.bitrate <= 0)) {
        throw new TypeError('config.bitrate must be a positive integer or a quality.');
    }
    if (config.keyFrameInterval !== undefined && (!Number.isFinite(config.keyFrameInterval) || config.keyFrameInterval < 0)) {
        throw new TypeError('config.keyFrameInterval, when provided, must be a non-negative number.');
    }
    if (config.sizeChangeBehavior !== undefined && ![
        'deny',
        'passThrough',
        'fill',
        'contain',
        'cover'
    ].includes(config.sizeChangeBehavior)) {
        throw new TypeError('config.sizeChangeBehavior, when provided, must be \'deny\', \'passThrough\', \'fill\', \'contain\'' + ' or \'cover\'.');
    }
    if (config.onEncodedPacket !== undefined && typeof config.onEncodedPacket !== 'function') {
        throw new TypeError('config.onEncodedChunk, when provided, must be a function.');
    }
    if (config.onEncoderConfig !== undefined && typeof config.onEncoderConfig !== 'function') {
        throw new TypeError('config.onEncoderConfig, when provided, must be a function.');
    }
    validateVideoEncodingAdditionalOptions(config.codec, config);
};
const validateVideoEncodingAdditionalOptions = (codec, options)=>{
    if (!options || typeof options !== 'object') {
        throw new TypeError('Encoding options must be an object.');
    }
    if (options.alpha !== undefined && ![
        'discard',
        'keep'
    ].includes(options.alpha)) {
        throw new TypeError('options.alpha, when provided, must be \'discard\' or \'keep\'.');
    }
    if (options.bitrateMode !== undefined && ![
        'constant',
        'variable'
    ].includes(options.bitrateMode)) {
        throw new TypeError('bitrateMode, when provided, must be \'constant\' or \'variable\'.');
    }
    if (options.latencyMode !== undefined && ![
        'quality',
        'realtime'
    ].includes(options.latencyMode)) {
        throw new TypeError('latencyMode, when provided, must be \'quality\' or \'realtime\'.');
    }
    if (options.fullCodecString !== undefined && typeof options.fullCodecString !== 'string') {
        throw new TypeError('fullCodecString, when provided, must be a string.');
    }
    if (options.fullCodecString !== undefined && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["inferCodecFromCodecString"])(options.fullCodecString) !== codec) {
        throw new TypeError(`fullCodecString, when provided, must be a string that matches the specified codec (${codec}).`);
    }
    if (options.hardwareAcceleration !== undefined && ![
        'no-preference',
        'prefer-hardware',
        'prefer-software'
    ].includes(options.hardwareAcceleration)) {
        throw new TypeError('hardwareAcceleration, when provided, must be \'no-preference\', \'prefer-hardware\' or' + ' \'prefer-software\'.');
    }
    if (options.scalabilityMode !== undefined && typeof options.scalabilityMode !== 'string') {
        throw new TypeError('scalabilityMode, when provided, must be a string.');
    }
    if (options.contentHint !== undefined && typeof options.contentHint !== 'string') {
        throw new TypeError('contentHint, when provided, must be a string.');
    }
};
const buildVideoEncoderConfig = (options)=>{
    const resolvedBitrate = options.bitrate instanceof Quality ? options.bitrate._toVideoBitrate(options.codec, options.width, options.height) : options.bitrate;
    return {
        codec: options.fullCodecString ?? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["buildVideoCodecString"])(options.codec, options.width, options.height, resolvedBitrate),
        width: options.width,
        height: options.height,
        bitrate: resolvedBitrate,
        bitrateMode: options.bitrateMode,
        alpha: options.alpha ?? 'discard',
        framerate: options.framerate,
        latencyMode: options.latencyMode,
        hardwareAcceleration: options.hardwareAcceleration,
        scalabilityMode: options.scalabilityMode,
        contentHint: options.contentHint,
        ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getVideoEncoderConfigExtension"])(options.codec)
    };
};
const validateAudioEncodingConfig = (config)=>{
    if (!config || typeof config !== 'object') {
        throw new TypeError('Encoding config must be an object.');
    }
    if (!__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AUDIO_CODECS"].includes(config.codec)) {
        throw new TypeError(`Invalid audio codec '${config.codec}'. Must be one of: ${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AUDIO_CODECS"].join(', ')}.`);
    }
    if (config.bitrate === undefined && (!__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PCM_AUDIO_CODECS"].includes(config.codec) || config.codec === 'flac')) {
        throw new TypeError('config.bitrate must be provided for compressed audio codecs.');
    }
    if (config.bitrate !== undefined && !(config.bitrate instanceof Quality) && (!Number.isInteger(config.bitrate) || config.bitrate <= 0)) {
        throw new TypeError('config.bitrate, when provided, must be a positive integer or a quality.');
    }
    if (config.onEncodedPacket !== undefined && typeof config.onEncodedPacket !== 'function') {
        throw new TypeError('config.onEncodedChunk, when provided, must be a function.');
    }
    if (config.onEncoderConfig !== undefined && typeof config.onEncoderConfig !== 'function') {
        throw new TypeError('config.onEncoderConfig, when provided, must be a function.');
    }
    validateAudioEncodingAdditionalOptions(config.codec, config);
};
const validateAudioEncodingAdditionalOptions = (codec, options)=>{
    if (!options || typeof options !== 'object') {
        throw new TypeError('Encoding options must be an object.');
    }
    if (options.bitrateMode !== undefined && ![
        'constant',
        'variable'
    ].includes(options.bitrateMode)) {
        throw new TypeError('bitrateMode, when provided, must be \'constant\' or \'variable\'.');
    }
    if (options.fullCodecString !== undefined && typeof options.fullCodecString !== 'string') {
        throw new TypeError('fullCodecString, when provided, must be a string.');
    }
    if (options.fullCodecString !== undefined && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["inferCodecFromCodecString"])(options.fullCodecString) !== codec) {
        throw new TypeError(`fullCodecString, when provided, must be a string that matches the specified codec (${codec}).`);
    }
};
const buildAudioEncoderConfig = (options)=>{
    const resolvedBitrate = options.bitrate instanceof Quality ? options.bitrate._toAudioBitrate(options.codec) : options.bitrate;
    return {
        codec: options.fullCodecString ?? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["buildAudioCodecString"])(options.codec, options.numberOfChannels, options.sampleRate),
        numberOfChannels: options.numberOfChannels,
        sampleRate: options.sampleRate,
        bitrate: resolvedBitrate,
        bitrateMode: options.bitrateMode,
        ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getAudioEncoderConfigExtension"])(options.codec)
    };
};
class Quality {
    /** @internal */ constructor(factor){
        this._factor = factor;
    }
    /** @internal */ _toVideoBitrate(codec, width, height) {
        const pixels = width * height;
        const codecEfficiencyFactors = {
            avc: 1.0,
            hevc: 0.6,
            vp9: 0.6,
            av1: 0.4,
            vp8: 1.2
        };
        const referencePixels = 1920 * 1080;
        const referenceBitrate = 3000000;
        const scaleFactor = Math.pow(pixels / referencePixels, 0.95); // Slight non-linear scaling
        const baseBitrate = referenceBitrate * scaleFactor;
        const codecAdjustedBitrate = baseBitrate * codecEfficiencyFactors[codec];
        const finalBitrate = codecAdjustedBitrate * this._factor;
        return Math.ceil(finalBitrate / 1000) * 1000;
    }
    /** @internal */ _toAudioBitrate(codec) {
        if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PCM_AUDIO_CODECS"].includes(codec) || codec === 'flac') {
            return undefined;
        }
        const baseRates = {
            aac: 128000,
            opus: 64000,
            mp3: 160000,
            vorbis: 64000
        };
        const baseBitrate = baseRates[codec];
        if (!baseBitrate) {
            throw new Error(`Unhandled codec: ${codec}`);
        }
        let finalBitrate = baseBitrate * this._factor;
        if (codec === 'aac') {
            // AAC only works with specific bitrates, let's find the closest
            const validRates = [
                96000,
                128000,
                160000,
                192000
            ];
            finalBitrate = validRates.reduce((prev, curr)=>Math.abs(curr - finalBitrate) < Math.abs(prev - finalBitrate) ? curr : prev);
        } else if (codec === 'opus' || codec === 'vorbis') {
            finalBitrate = Math.max(6000, finalBitrate);
        } else if (codec === 'mp3') {
            const validRates = [
                8000,
                16000,
                24000,
                32000,
                40000,
                48000,
                64000,
                80000,
                96000,
                112000,
                128000,
                160000,
                192000,
                224000,
                256000,
                320000
            ];
            finalBitrate = validRates.reduce((prev, curr)=>Math.abs(curr - finalBitrate) < Math.abs(prev - finalBitrate) ? curr : prev);
        }
        return Math.round(finalBitrate / 1000) * 1000;
    }
}
const QUALITY_VERY_LOW = /* #__PURE__ */ new Quality(0.3);
const QUALITY_LOW = /* #__PURE__ */ new Quality(0.6);
const QUALITY_MEDIUM = /* #__PURE__ */ new Quality(1);
const QUALITY_HIGH = /* #__PURE__ */ new Quality(2);
const QUALITY_VERY_HIGH = /* #__PURE__ */ new Quality(4);
const canEncode = (codec)=>{
    if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"].includes(codec)) {
        return canEncodeVideo(codec);
    } else if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AUDIO_CODECS"].includes(codec)) {
        return canEncodeAudio(codec);
    } else if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SUBTITLE_CODECS"].includes(codec)) {
        return canEncodeSubtitles(codec);
    }
    throw new TypeError(`Unknown codec '${codec}'.`);
};
const canEncodeVideo = async (codec, options = {})=>{
    const { width = 1280, height = 720, bitrate = 1e6, ...restOptions } = options;
    if (!__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"].includes(codec)) {
        return false;
    }
    if (!Number.isInteger(width) || width <= 0) {
        throw new TypeError('width must be a positive integer.');
    }
    if (!Number.isInteger(height) || height <= 0) {
        throw new TypeError('height must be a positive integer.');
    }
    if (!(bitrate instanceof Quality) && (!Number.isInteger(bitrate) || bitrate <= 0)) {
        throw new TypeError('bitrate must be a positive integer or a quality.');
    }
    validateVideoEncodingAdditionalOptions(codec, restOptions);
    let encoderConfig = null;
    if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["customVideoEncoders"].length > 0) {
        encoderConfig ??= buildVideoEncoderConfig({
            codec,
            width,
            height,
            bitrate,
            framerate: undefined,
            ...restOptions
        });
        if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["customVideoEncoders"].some((x)=>x.supports(codec, encoderConfig))) {
            // There's a custom encoder
            return true;
        }
    }
    if (typeof VideoEncoder === 'undefined') {
        return false;
    }
    const hasOddDimension = width % 2 === 1 || height % 2 === 1;
    if (hasOddDimension && (codec === 'avc' || codec === 'hevc')) {
        // Disallow odd dimensions for certain codecs
        return false;
    }
    encoderConfig ??= buildVideoEncoderConfig({
        codec,
        width,
        height,
        bitrate,
        framerate: undefined,
        ...restOptions,
        alpha: 'discard'
    });
    const support = await VideoEncoder.isConfigSupported(encoderConfig);
    if (!support.supported) {
        return false;
    }
    if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isFirefox"])()) {
        // isConfigSupported on Firefox appears to unreliably indicate if encoding will actually succeed. Therefore, we
        // just try encoding a frame to see if it actually works.
        // https://github.com/Vanilagy/mediabunny/issues/222
        // eslint-disable-next-line @typescript-eslint/no-misused-promises, no-async-promise-executor
        return new Promise(async (resolve)=>{
            try {
                const encoder = new VideoEncoder({
                    output: ()=>{},
                    error: ()=>resolve(false)
                });
                encoder.configure(encoderConfig);
                const frameData = new Uint8Array(width * height * 4);
                const frame = new VideoFrame(frameData, {
                    format: 'RGBA',
                    codedWidth: width,
                    codedHeight: height,
                    timestamp: 0
                });
                encoder.encode(frame);
                frame.close();
                await encoder.flush();
                resolve(true);
            } catch  {
                resolve(false);
            }
        });
    } else {
        return true;
    }
};
const canEncodeAudio = async (codec, options = {})=>{
    const { numberOfChannels = 2, sampleRate = 48000, bitrate = 128e3, ...restOptions } = options;
    if (!__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AUDIO_CODECS"].includes(codec)) {
        return false;
    }
    if (!Number.isInteger(numberOfChannels) || numberOfChannels <= 0) {
        throw new TypeError('numberOfChannels must be a positive integer.');
    }
    if (!Number.isInteger(sampleRate) || sampleRate <= 0) {
        throw new TypeError('sampleRate must be a positive integer.');
    }
    if (!(bitrate instanceof Quality) && (!Number.isInteger(bitrate) || bitrate <= 0)) {
        throw new TypeError('bitrate must be a positive integer.');
    }
    validateAudioEncodingAdditionalOptions(codec, restOptions);
    let encoderConfig = null;
    if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["customAudioEncoders"].length > 0) {
        encoderConfig ??= buildAudioEncoderConfig({
            codec,
            numberOfChannels,
            sampleRate,
            bitrate,
            ...restOptions
        });
        if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["customAudioEncoders"].some((x)=>x.supports(codec, encoderConfig))) {
            // There's a custom encoder
            return true;
        }
    }
    if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PCM_AUDIO_CODECS"].includes(codec)) {
        return true; // Because we encode these ourselves
    }
    if (typeof AudioEncoder === 'undefined') {
        return false;
    }
    encoderConfig ??= buildAudioEncoderConfig({
        codec,
        numberOfChannels,
        sampleRate,
        bitrate,
        ...restOptions
    });
    const support = await AudioEncoder.isConfigSupported(encoderConfig);
    return support.supported === true;
};
const canEncodeSubtitles = async (codec)=>{
    if (!__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SUBTITLE_CODECS"].includes(codec)) {
        return false;
    }
    return true;
};
const getEncodableCodecs = async ()=>{
    const [videoCodecs, audioCodecs, subtitleCodecs] = await Promise.all([
        getEncodableVideoCodecs(),
        getEncodableAudioCodecs(),
        getEncodableSubtitleCodecs()
    ]);
    return [
        ...videoCodecs,
        ...audioCodecs,
        ...subtitleCodecs
    ];
};
const getEncodableVideoCodecs = async (checkedCodecs = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"], options)=>{
    const bools = await Promise.all(checkedCodecs.map((codec)=>canEncodeVideo(codec, options)));
    return checkedCodecs.filter((_, i)=>bools[i]);
};
const getEncodableAudioCodecs = async (checkedCodecs = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AUDIO_CODECS"], options)=>{
    const bools = await Promise.all(checkedCodecs.map((codec)=>canEncodeAudio(codec, options)));
    return checkedCodecs.filter((_, i)=>bools[i]);
};
const getEncodableSubtitleCodecs = async (checkedCodecs = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SUBTITLE_CODECS"])=>{
    const bools = await Promise.all(checkedCodecs.map(canEncodeSubtitles));
    return checkedCodecs.filter((_, i)=>bools[i]);
};
const getFirstEncodableVideoCodec = async (checkedCodecs, options)=>{
    for (const codec of checkedCodecs){
        if (await canEncodeVideo(codec, options)) {
            return codec;
        }
    }
    return null;
};
const getFirstEncodableAudioCodec = async (checkedCodecs, options)=>{
    for (const codec of checkedCodecs){
        if (await canEncodeAudio(codec, options)) {
            return codec;
        }
    }
    return null;
};
const getFirstEncodableSubtitleCodec = async (checkedCodecs)=>{
    for (const codec of checkedCodecs){
        if (await canEncodeSubtitles(codec)) {
            return codec;
        }
    }
    return null;
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/media-source.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "AudioBufferSource",
    ()=>AudioBufferSource,
    "AudioSampleSource",
    ()=>AudioSampleSource,
    "AudioSource",
    ()=>AudioSource,
    "CanvasSource",
    ()=>CanvasSource,
    "EncodedAudioPacketSource",
    ()=>EncodedAudioPacketSource,
    "EncodedVideoPacketSource",
    ()=>EncodedVideoPacketSource,
    "MediaSource",
    ()=>MediaSource,
    "MediaStreamAudioTrackSource",
    ()=>MediaStreamAudioTrackSource,
    "MediaStreamVideoTrackSource",
    ()=>MediaStreamVideoTrackSource,
    "SubtitleSource",
    ()=>SubtitleSource,
    "TextSubtitleSource",
    ()=>TextSubtitleSource,
    "VideoSampleSource",
    ()=>VideoSampleSource,
    "VideoSource",
    ()=>VideoSource
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$subtitles$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/subtitles.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$pcm$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/pcm.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/custom-coder.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/packet.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/sample.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$encode$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/encode.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
class MediaSource {
    constructor(){
        /** @internal */ this._connectedTrack = null;
        /** @internal */ this._closingPromise = null;
        /** @internal */ this._closed = false;
        /**
         * @internal
         * A time offset in seconds that is added to all timestamps generated by this source.
         */ this._timestampOffset = 0;
    }
    /** @internal */ _ensureValidAdd() {
        if (!this._connectedTrack) {
            throw new Error('Source is not connected to an output track.');
        }
        if (this._connectedTrack.output.state === 'canceled') {
            throw new Error('Output has been canceled.');
        }
        if (this._connectedTrack.output.state === 'finalizing' || this._connectedTrack.output.state === 'finalized') {
            throw new Error('Output has been finalized.');
        }
        if (this._connectedTrack.output.state === 'pending') {
            throw new Error('Output has not started.');
        }
        if (this._closed) {
            throw new Error('Source is closed.');
        }
    }
    /** @internal */ async _start() {}
    /** @internal */ // eslint-disable-next-line @typescript-eslint/no-unused-vars
    async _flushAndClose(forceClose) {}
    /**
     * Closes this source. This prevents future samples from being added and signals to the output file that no further
     * samples will come in for this track. Calling `.close()` is optional but recommended after adding the
     * last sample - for improved performance and reduced memory usage.
     */ close() {
        if (this._closingPromise) {
            return;
        }
        const connectedTrack = this._connectedTrack;
        if (!connectedTrack) {
            throw new Error('Cannot call close without connecting the source to an output track.');
        }
        if (connectedTrack.output.state === 'pending') {
            throw new Error('Cannot call close before output has been started.');
        }
        this._closingPromise = (async ()=>{
            await this._flushAndClose(false);
            this._closed = true;
            if (connectedTrack.output.state === 'finalizing' || connectedTrack.output.state === 'finalized') {
                return;
            }
            connectedTrack.output._muxer.onTrackClose(connectedTrack);
        })();
    }
    /** @internal */ async _flushOrWaitForOngoingClose(forceClose) {
        if (this._closingPromise) {
            // Since closing also flushes, we don't want to do it twice
            return this._closingPromise;
        } else {
            return this._flushAndClose(forceClose);
        }
    }
}
class VideoSource extends MediaSource {
    /** Internal constructor. */ constructor(codec){
        super();
        /** @internal */ this._connectedTrack = null;
        if (!__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"].includes(codec)) {
            throw new TypeError(`Invalid video codec '${codec}'. Must be one of: ${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"].join(', ')}.`);
        }
        this._codec = codec;
    }
}
class EncodedVideoPacketSource extends VideoSource {
    /** Creates a new {@link EncodedVideoPacketSource} whose packets are encoded using `codec`. */ constructor(codec){
        super(codec);
    }
    /**
     * Adds an encoded packet to the output video track. Packets must be added in *decode order*, while a packet's
     * timestamp must be its *presentation timestamp*. B-frames are handled automatically.
     *
     * @param meta - Additional metadata from the encoder. You should pass this for the first call, including a valid
     * decoder config.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */ add(packet, meta) {
        if (!(packet instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"])) {
            throw new TypeError('packet must be an EncodedPacket.');
        }
        if (packet.isMetadataOnly) {
            throw new TypeError('Metadata-only packets cannot be added.');
        }
        if (meta !== undefined && (!meta || typeof meta !== 'object')) {
            throw new TypeError('meta, when provided, must be an object.');
        }
        this._ensureValidAdd();
        return this._connectedTrack.output._muxer.addEncodedVideoPacket(this._connectedTrack, packet, meta);
    }
}
class VideoEncoderWrapper {
    constructor(source, encodingConfig){
        this.source = source;
        this.encodingConfig = encodingConfig;
        this.ensureEncoderPromise = null;
        this.encoderInitialized = false;
        this.encoder = null;
        this.muxer = null;
        this.lastMultipleOfKeyFrameInterval = -1;
        this.codedWidth = null;
        this.codedHeight = null;
        this.resizeCanvas = null;
        this.customEncoder = null;
        this.customEncoderCallSerializer = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["CallSerializer"]();
        this.customEncoderQueueSize = 0;
        // Alpha stuff
        this.alphaEncoder = null;
        this.splitter = null;
        this.splitterCreationFailed = false;
        this.alphaFrameQueue = [];
        /**
         * Encoders typically throw their errors "out of band", meaning asynchronously in some other execution context.
         * However, we want to surface these errors to the user within the normal control flow, so they don't go uncaught.
         * So, we keep track of the encoder error and throw it as soon as we get the chance.
         */ this.error = null;
        this.errorNeedsNewStack = true;
    }
    async add(videoSample, shouldClose, encodeOptions) {
        try {
            this.checkForEncoderError();
            this.source._ensureValidAdd();
            // Ensure video sample size remains constant
            if (this.codedWidth !== null && this.codedHeight !== null) {
                if (videoSample.codedWidth !== this.codedWidth || videoSample.codedHeight !== this.codedHeight) {
                    const sizeChangeBehavior = this.encodingConfig.sizeChangeBehavior ?? 'deny';
                    if (sizeChangeBehavior === 'passThrough') {
                    // Do nada
                    } else if (sizeChangeBehavior === 'deny') {
                        throw new Error(`Video sample size must remain constant. Expected ${this.codedWidth}x${this.codedHeight},` + ` got ${videoSample.codedWidth}x${videoSample.codedHeight}. To allow the sample size to` + ` change over time, set \`sizeChangeBehavior\` to a value other than 'strict' in the` + ` encoding options.`);
                    } else {
                        let canvasIsNew = false;
                        if (!this.resizeCanvas) {
                            if (typeof document !== 'undefined') {
                                // Prefer an HTMLCanvasElement
                                this.resizeCanvas = document.createElement('canvas');
                                this.resizeCanvas.width = this.codedWidth;
                                this.resizeCanvas.height = this.codedHeight;
                            } else {
                                this.resizeCanvas = new OffscreenCanvas(this.codedWidth, this.codedHeight);
                            }
                            canvasIsNew = true;
                        }
                        const context = this.resizeCanvas.getContext('2d', {
                            alpha: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isFirefox"])()
                        });
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(context);
                        if (!canvasIsNew) {
                            if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isFirefox"])()) {
                                context.fillStyle = 'black';
                                context.fillRect(0, 0, this.codedWidth, this.codedHeight);
                            } else {
                                context.clearRect(0, 0, this.codedWidth, this.codedHeight);
                            }
                        }
                        videoSample.drawWithFit(context, {
                            fit: sizeChangeBehavior
                        });
                        if (shouldClose) {
                            videoSample.close();
                        }
                        videoSample = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VideoSample"](this.resizeCanvas, {
                            timestamp: videoSample.timestamp,
                            duration: videoSample.duration,
                            rotation: videoSample.rotation
                        });
                        shouldClose = true;
                    }
                }
            } else {
                this.codedWidth = videoSample.codedWidth;
                this.codedHeight = videoSample.codedHeight;
            }
            if (!this.encoderInitialized) {
                if (!this.ensureEncoderPromise) {
                    this.ensureEncoder(videoSample);
                }
                // No, this "if" statement is not useless. Sometimes, the above call to `ensureEncoder` might have
                // synchronously completed and the encoder is already initialized. In this case, we don't need to await
                // the promise anymore. This also fixes nasty async race condition bugs when multiple code paths are
                // calling this method: It's important that the call that initialized the encoder go through this
                // code first.
                if (!this.encoderInitialized) {
                    await this.ensureEncoderPromise;
                }
            }
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.encoderInitialized);
            const keyFrameInterval = this.encodingConfig.keyFrameInterval ?? 5;
            const multipleOfKeyFrameInterval = Math.floor(videoSample.timestamp / keyFrameInterval);
            // Ensure a key frame every keyFrameInterval seconds. It is important that all video tracks follow the same
            // "key frame" rhythm, because aligned key frames are required to start new fragments in ISOBMFF or clusters
            // in Matroska (or at least desirable).
            const finalEncodeOptions = {
                ...encodeOptions,
                keyFrame: encodeOptions?.keyFrame || keyFrameInterval === 0 || multipleOfKeyFrameInterval !== this.lastMultipleOfKeyFrameInterval
            };
            this.lastMultipleOfKeyFrameInterval = multipleOfKeyFrameInterval;
            if (this.customEncoder) {
                this.customEncoderQueueSize++;
                // We clone the sample so it cannot be closed on us from the outside before it reaches the encoder
                const clonedSample = videoSample.clone();
                const promise = this.customEncoderCallSerializer.call(()=>this.customEncoder.encode(clonedSample, finalEncodeOptions)).then(()=>this.customEncoderQueueSize--).catch((error)=>this.error ??= error).finally(()=>{
                    clonedSample.close();
                // `videoSample` gets closed in the finally block at the end of the method
                });
                if (this.customEncoderQueueSize >= 4) {
                    await promise;
                }
            } else {
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.encoder);
                const videoFrame = videoSample.toVideoFrame();
                if (!this.alphaEncoder) {
                    // No alpha encoder, simple case
                    this.encoder.encode(videoFrame, finalEncodeOptions);
                    videoFrame.close();
                } else {
                    // We're expected to encode alpha as well
                    const frameDefinitelyHasNoAlpha = !!videoFrame.format && !videoFrame.format.includes('A');
                    if (frameDefinitelyHasNoAlpha || this.splitterCreationFailed) {
                        this.alphaFrameQueue.push(null);
                        this.encoder.encode(videoFrame, finalEncodeOptions);
                        videoFrame.close();
                    } else {
                        const width = videoFrame.displayWidth;
                        const height = videoFrame.displayHeight;
                        if (!this.splitter) {
                            try {
                                this.splitter = new ColorAlphaSplitter(width, height);
                            } catch (error) {
                                console.error('Due to an error, only color data will be encoded.', error);
                                this.splitterCreationFailed = true;
                                this.alphaFrameQueue.push(null);
                                this.encoder.encode(videoFrame, finalEncodeOptions);
                                videoFrame.close();
                            }
                        }
                        if (this.splitter) {
                            const colorFrame = this.splitter.extractColor(videoFrame);
                            const alphaFrame = this.splitter.extractAlpha(videoFrame);
                            this.alphaFrameQueue.push(alphaFrame);
                            this.encoder.encode(colorFrame, finalEncodeOptions);
                            colorFrame.close();
                            videoFrame.close();
                        }
                    }
                }
                if (shouldClose) {
                    videoSample.close();
                }
                // We need to do this after sending the frame to the encoder as the frame otherwise might be closed
                if (this.encoder.encodeQueueSize >= 4) {
                    await new Promise((resolve)=>this.encoder.addEventListener('dequeue', resolve, {
                            once: true
                        }));
                }
            }
            await this.muxer.mutex.currentPromise; // Allow the writer to apply backpressure
        } finally{
            if (shouldClose) {
                // Make sure it's always closed, even if there was an error
                videoSample.close();
            }
        }
    }
    ensureEncoder(videoSample) {
        const encoderError = new Error();
        this.ensureEncoderPromise = (async ()=>{
            const encoderConfig = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$encode$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["buildVideoEncoderConfig"])({
                width: videoSample.codedWidth,
                height: videoSample.codedHeight,
                ...this.encodingConfig,
                framerate: this.source._connectedTrack?.metadata.frameRate
            });
            this.encodingConfig.onEncoderConfig?.(encoderConfig);
            const MatchingCustomEncoder = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["customVideoEncoders"].find((x)=>x.supports(this.encodingConfig.codec, encoderConfig));
            if (MatchingCustomEncoder) {
                // @ts-expect-error "Can't create instance of abstract class "
                this.customEncoder = new MatchingCustomEncoder();
                // @ts-expect-error It's technically readonly
                this.customEncoder.codec = this.encodingConfig.codec;
                // @ts-expect-error It's technically readonly
                this.customEncoder.config = encoderConfig;
                // @ts-expect-error It's technically readonly
                this.customEncoder.onPacket = (packet, meta)=>{
                    if (!(packet instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"])) {
                        throw new TypeError('The first argument passed to onPacket must be an EncodedPacket.');
                    }
                    if (meta !== undefined && (!meta || typeof meta !== 'object')) {
                        throw new TypeError('The second argument passed to onPacket must be an object or undefined.');
                    }
                    this.encodingConfig.onEncodedPacket?.(packet, meta);
                    void this.muxer.addEncodedVideoPacket(this.source._connectedTrack, packet, meta).catch((error)=>{
                        this.error ??= error;
                        this.errorNeedsNewStack = false;
                    });
                };
                await this.customEncoder.init();
            } else {
                if (typeof VideoEncoder === 'undefined') {
                    throw new Error('VideoEncoder is not supported by this browser.');
                }
                encoderConfig.alpha = 'discard'; // Since we handle alpha ourselves
                if (this.encodingConfig.alpha === 'keep') {
                    // Encoding alpha requires using two parallel encoders, so we need to make sure they stay in sync
                    // and that neither of them drops frames. Setting latencyMode to 'quality' achieves this, because
                    // "User Agents MUST not drop frames to achieve the target bitrate and/or framerate."
                    encoderConfig.latencyMode = 'quality';
                }
                const hasOddDimension = encoderConfig.width % 2 === 1 || encoderConfig.height % 2 === 1;
                if (hasOddDimension && (this.encodingConfig.codec === 'avc' || this.encodingConfig.codec === 'hevc')) {
                    // Throw a special error for this case as it gets hit often
                    throw new Error(`The dimensions ${encoderConfig.width}x${encoderConfig.height} are not supported for codec` + ` '${this.encodingConfig.codec}'; both width and height must be even numbers. Make sure to` + ` round your dimensions to the nearest even number.`);
                }
                const support = await VideoEncoder.isConfigSupported(encoderConfig);
                if (!support.supported) {
                    throw new Error(`This specific encoder configuration (${encoderConfig.codec}, ${encoderConfig.bitrate} bps,` + ` ${encoderConfig.width}x${encoderConfig.height}, hardware acceleration:` + ` ${encoderConfig.hardwareAcceleration ?? 'no-preference'}) is not supported by this browser.` + ` Consider using another codec or changing your video parameters.`);
                }
                /** Queue of color chunks waiting for their alpha counterpart. */ const colorChunkQueue = [];
                /** Each value is the number of encoded alpha chunks at which a null alpha chunk should be added. */ const nullAlphaChunkQueue = [];
                let encodedAlphaChunkCount = 0;
                let alphaEncoderQueue = 0;
                const addPacket = (colorChunk, alphaChunk, meta)=>{
                    const sideData = {};
                    if (alphaChunk) {
                        const alphaData = new Uint8Array(alphaChunk.byteLength);
                        alphaChunk.copyTo(alphaData);
                        sideData.alpha = alphaData;
                    }
                    const packet = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"].fromEncodedChunk(colorChunk, sideData);
                    this.encodingConfig.onEncodedPacket?.(packet, meta);
                    void this.muxer.addEncodedVideoPacket(this.source._connectedTrack, packet, meta).catch((error)=>{
                        this.error ??= error;
                        this.errorNeedsNewStack = false;
                    });
                };
                this.encoder = new VideoEncoder({
                    output: (chunk, meta)=>{
                        if (!this.alphaEncoder) {
                            // We're done
                            addPacket(chunk, null, meta);
                            return;
                        }
                        const alphaFrame = this.alphaFrameQueue.shift();
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(alphaFrame !== undefined);
                        if (alphaFrame) {
                            this.alphaEncoder.encode(alphaFrame, {
                                // Crucial: The alpha frame is forced to be a key frame whenever the color frame
                                // also is. Without this, playback can glitch and even crash in some browsers.
                                // This is the reason why the two encoders are wired in series and not in parallel.
                                keyFrame: chunk.type === 'key'
                            });
                            alphaEncoderQueue++;
                            alphaFrame.close();
                            colorChunkQueue.push({
                                chunk,
                                meta
                            });
                        } else {
                            // There was no alpha component for this frame
                            if (alphaEncoderQueue === 0) {
                                // No pending alpha encodes either, so we're done
                                addPacket(chunk, null, meta);
                            } else {
                                // There are still alpha encodes pending, so we can't add the packet immediately since
                                // we'd end up with out-of-order packets. Instead, let's queue a null alpha chunk to be
                                // added in the future, after the current encoder workload has completed:
                                nullAlphaChunkQueue.push(encodedAlphaChunkCount + alphaEncoderQueue);
                                colorChunkQueue.push({
                                    chunk,
                                    meta
                                });
                            }
                        }
                    },
                    error: (error)=>{
                        error.stack = encoderError.stack; // Provide a more useful stack trace
                        this.error ??= error;
                    }
                });
                this.encoder.configure(encoderConfig);
                if (this.encodingConfig.alpha === 'keep') {
                    // We need to encode alpha as well, which we do with a separate encoder
                    this.alphaEncoder = new VideoEncoder({
                        // We ignore the alpha chunk's metadata
                        // eslint-disable-next-line @typescript-eslint/no-unused-vars
                        output: (chunk, meta)=>{
                            alphaEncoderQueue--;
                            // There has to be a color chunk because the encoders are wired in series
                            const colorChunk = colorChunkQueue.shift();
                            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(colorChunk !== undefined);
                            addPacket(colorChunk.chunk, chunk, colorChunk.meta);
                            // See if there are any null alpha chunks queued up
                            encodedAlphaChunkCount++;
                            while(nullAlphaChunkQueue.length > 0 && nullAlphaChunkQueue[0] === encodedAlphaChunkCount){
                                nullAlphaChunkQueue.shift();
                                const colorChunk = colorChunkQueue.shift();
                                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(colorChunk !== undefined);
                                addPacket(colorChunk.chunk, null, colorChunk.meta);
                            }
                        },
                        error: (error)=>{
                            error.stack = encoderError.stack; // Provide a more useful stack trace
                            this.error ??= error;
                        }
                    });
                    this.alphaEncoder.configure(encoderConfig);
                }
            }
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.source._connectedTrack);
            this.muxer = this.source._connectedTrack.output._muxer;
            this.encoderInitialized = true;
        })();
    }
    async flushAndClose(forceClose) {
        if (!forceClose) this.checkForEncoderError();
        if (this.customEncoder) {
            if (!forceClose) {
                void this.customEncoderCallSerializer.call(()=>this.customEncoder.flush());
            }
            await this.customEncoderCallSerializer.call(()=>this.customEncoder.close());
        } else if (this.encoder) {
            if (!forceClose) {
                // These are wired in series, therefore they must also be flushed in series
                await this.encoder.flush();
                await this.alphaEncoder?.flush();
            }
            if (this.encoder.state !== 'closed') {
                this.encoder.close();
            }
            if (this.alphaEncoder && this.alphaEncoder.state !== 'closed') {
                this.alphaEncoder.close();
            }
            this.alphaFrameQueue.forEach((x)=>x?.close());
            this.splitter?.close();
        }
        if (!forceClose) this.checkForEncoderError();
    }
    getQueueSize() {
        if (this.customEncoder) {
            return this.customEncoderQueueSize;
        } else {
            // Because the color and alpha encoders are wired in series, there's no need to also include the alpha
            // encoder's queue size here
            return this.encoder?.encodeQueueSize ?? 0;
        }
    }
    checkForEncoderError() {
        if (this.error) {
            if (this.errorNeedsNewStack) {
                this.error.stack = new Error().stack; // Provide an even more useful stack trace
            }
            throw this.error;
        }
    }
}
/** Utility class for splitting a composite frame into separate color and alpha components. */ class ColorAlphaSplitter {
    constructor(initialWidth, initialHeight){
        this.lastFrame = null;
        if (typeof OffscreenCanvas !== 'undefined') {
            this.canvas = new OffscreenCanvas(initialWidth, initialHeight);
        } else {
            this.canvas = document.createElement('canvas');
            this.canvas.width = initialWidth;
            this.canvas.height = initialHeight;
        }
        const gl = this.canvas.getContext('webgl2', {
            alpha: true
        }); // Casting because of some TypeScript weirdness
        if (!gl) {
            throw new Error('Couldn\'t acquire WebGL 2 context.');
        }
        this.gl = gl;
        this.colorProgram = this.createColorProgram();
        this.alphaProgram = this.createAlphaProgram();
        this.vao = this.createVAO();
        this.sourceTexture = this.createTexture();
        this.alphaResolutionLocation = this.gl.getUniformLocation(this.alphaProgram, 'u_resolution');
        this.gl.useProgram(this.colorProgram);
        this.gl.uniform1i(this.gl.getUniformLocation(this.colorProgram, 'u_sourceTexture'), 0);
        this.gl.useProgram(this.alphaProgram);
        this.gl.uniform1i(this.gl.getUniformLocation(this.alphaProgram, 'u_sourceTexture'), 0);
    }
    createVertexShader() {
        return this.createShader(this.gl.VERTEX_SHADER, `#version 300 es
			in vec2 a_position;
			in vec2 a_texCoord;
			out vec2 v_texCoord;
			
			void main() {
				gl_Position = vec4(a_position, 0.0, 1.0);
				v_texCoord = a_texCoord;
			}
		`);
    }
    createColorProgram() {
        const vertexShader = this.createVertexShader();
        // This shader is simple, simply copy the color information while setting alpha to 1
        const fragmentShader = this.createShader(this.gl.FRAGMENT_SHADER, `#version 300 es
			precision highp float;
			
			uniform sampler2D u_sourceTexture;
			in vec2 v_texCoord;
			out vec4 fragColor;
			
			void main() {
				vec4 source = texture(u_sourceTexture, v_texCoord);
				fragColor = vec4(source.rgb, 1.0);
			}
		`);
        const program = this.gl.createProgram();
        this.gl.attachShader(program, vertexShader);
        this.gl.attachShader(program, fragmentShader);
        this.gl.linkProgram(program);
        return program;
    }
    createAlphaProgram() {
        const vertexShader = this.createVertexShader();
        // This shader's more complex. The main reason is that this shader writes data in I420 (yuv420) pixel format
        // instead of regular RGBA. In other words, we use the shader to write out I420 data into an RGBA canvas, which
        // we then later read out with JavaScript. The reason being that browsers weirdly encode canvases and mess up
        // the color spaces, and the only way to have full control over the color space is by outputting YUV data
        // directly (avoiding the RGB conversion). Doing this conversion in JS is painfully slow, so let's utlize the
        // GPU since we're already calling it anyway.
        const fragmentShader = this.createShader(this.gl.FRAGMENT_SHADER, `#version 300 es
			precision highp float;
			
			uniform sampler2D u_sourceTexture;
			uniform vec2 u_resolution; // The width and height of the canvas
			in vec2 v_texCoord;
			out vec4 fragColor;

			// This function determines the value for a single byte in the YUV stream
			float getByteValue(float byteOffset) {
				float width = u_resolution.x;
				float height = u_resolution.y;

				float yPlaneSize = width * height;

				if (byteOffset < yPlaneSize) {
					// This byte is in the luma plane. Find the corresponding pixel coordinates to sample from
					float y = floor(byteOffset / width);
					float x = mod(byteOffset, width);
					
					// Add 0.5 to sample the center of the texel
					vec2 sampleCoord = (vec2(x, y) + 0.5) / u_resolution;
					
					// The luma value is the alpha from the source texture
					return texture(u_sourceTexture, sampleCoord).a;
				} else {
					// Write a fixed value for chroma and beyond
					return 128.0 / 255.0;
				}
			}
			
			void main() {
				// Each fragment writes 4 bytes (R, G, B, A)
				float pixelIndex = floor(gl_FragCoord.y) * u_resolution.x + floor(gl_FragCoord.x);
				float baseByteOffset = pixelIndex * 4.0;

				vec4 result;
				for (int i = 0; i < 4; i++) {
					float currentByteOffset = baseByteOffset + float(i);
					result[i] = getByteValue(currentByteOffset);
				}
				
				fragColor = result;
			}
		`);
        const program = this.gl.createProgram();
        this.gl.attachShader(program, vertexShader);
        this.gl.attachShader(program, fragmentShader);
        this.gl.linkProgram(program);
        return program;
    }
    createShader(type, source) {
        const shader = this.gl.createShader(type);
        this.gl.shaderSource(shader, source);
        this.gl.compileShader(shader);
        if (!this.gl.getShaderParameter(shader, this.gl.COMPILE_STATUS)) {
            console.error('Shader compile error:', this.gl.getShaderInfoLog(shader));
        }
        return shader;
    }
    createVAO() {
        const vao = this.gl.createVertexArray();
        this.gl.bindVertexArray(vao);
        const vertices = new Float32Array([
            -1,
            -1,
            0,
            1,
            1,
            -1,
            1,
            1,
            -1,
            1,
            0,
            0,
            1,
            1,
            1,
            0
        ]);
        const buffer = this.gl.createBuffer();
        this.gl.bindBuffer(this.gl.ARRAY_BUFFER, buffer);
        this.gl.bufferData(this.gl.ARRAY_BUFFER, vertices, this.gl.STATIC_DRAW);
        const positionLocation = this.gl.getAttribLocation(this.colorProgram, 'a_position');
        const texCoordLocation = this.gl.getAttribLocation(this.colorProgram, 'a_texCoord');
        this.gl.enableVertexAttribArray(positionLocation);
        this.gl.vertexAttribPointer(positionLocation, 2, this.gl.FLOAT, false, 16, 0);
        this.gl.enableVertexAttribArray(texCoordLocation);
        this.gl.vertexAttribPointer(texCoordLocation, 2, this.gl.FLOAT, false, 16, 8);
        return vao;
    }
    createTexture() {
        const texture = this.gl.createTexture();
        this.gl.bindTexture(this.gl.TEXTURE_2D, texture);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR);
        return texture;
    }
    updateTexture(sourceFrame) {
        if (this.lastFrame === sourceFrame) {
            return;
        }
        if (sourceFrame.displayWidth !== this.canvas.width || sourceFrame.displayHeight !== this.canvas.height) {
            this.canvas.width = sourceFrame.displayWidth;
            this.canvas.height = sourceFrame.displayHeight;
        }
        this.gl.activeTexture(this.gl.TEXTURE0);
        this.gl.bindTexture(this.gl.TEXTURE_2D, this.sourceTexture);
        this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, sourceFrame);
        this.lastFrame = sourceFrame;
    }
    extractColor(sourceFrame) {
        this.updateTexture(sourceFrame);
        this.gl.useProgram(this.colorProgram);
        this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);
        this.gl.clear(this.gl.COLOR_BUFFER_BIT);
        this.gl.bindVertexArray(this.vao);
        this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);
        return new VideoFrame(this.canvas, {
            timestamp: sourceFrame.timestamp,
            duration: sourceFrame.duration ?? undefined,
            alpha: 'discard'
        });
    }
    extractAlpha(sourceFrame) {
        this.updateTexture(sourceFrame);
        this.gl.useProgram(this.alphaProgram);
        this.gl.uniform2f(this.alphaResolutionLocation, this.canvas.width, this.canvas.height);
        this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);
        this.gl.clear(this.gl.COLOR_BUFFER_BIT);
        this.gl.bindVertexArray(this.vao);
        this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);
        const { width, height } = this.canvas;
        const chromaSamples = Math.ceil(width / 2) * Math.ceil(height / 2);
        const yuvSize = width * height + chromaSamples * 2;
        const requiredHeight = Math.ceil(yuvSize / (width * 4));
        let yuv = new Uint8Array(4 * width * requiredHeight);
        this.gl.readPixels(0, 0, width, requiredHeight, this.gl.RGBA, this.gl.UNSIGNED_BYTE, yuv);
        yuv = yuv.subarray(0, yuvSize);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(yuv[width * height] === 128); // Where chroma data starts
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(yuv[yuv.length - 1] === 128); // Assert the YUV data has been fully written
        // Defining this separately because TypeScript doesn't know `transfer` and I can't be bothered to do declaration
        // merging right now
        const init = {
            format: 'I420',
            codedWidth: width,
            codedHeight: height,
            timestamp: sourceFrame.timestamp,
            duration: sourceFrame.duration ?? undefined,
            transfer: [
                yuv.buffer
            ]
        };
        return new VideoFrame(yuv, init);
    }
    close() {
        this.gl.getExtension('WEBGL_lose_context')?.loseContext();
        this.gl = null;
    }
}
class VideoSampleSource extends VideoSource {
    /**
     * Creates a new {@link VideoSampleSource} whose samples are encoded according to the specified
     * {@link VideoEncodingConfig}.
     */ constructor(encodingConfig){
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$encode$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateVideoEncodingConfig"])(encodingConfig);
        super(encodingConfig.codec);
        this._encoder = new VideoEncoderWrapper(this, encodingConfig);
    }
    /**
     * Encodes a video sample (frame) and then adds it to the output.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */ add(videoSample, encodeOptions) {
        if (!(videoSample instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VideoSample"])) {
            throw new TypeError('videoSample must be a VideoSample.');
        }
        return this._encoder.add(videoSample, false, encodeOptions);
    }
    /** @internal */ _flushAndClose(forceClose) {
        return this._encoder.flushAndClose(forceClose);
    }
}
class CanvasSource extends VideoSource {
    /**
     * Creates a new {@link CanvasSource} from a canvas element or `OffscreenCanvas` whose samples are encoded
     * according to the specified {@link VideoEncodingConfig}.
     */ constructor(canvas, encodingConfig){
        if (!(typeof HTMLCanvasElement !== 'undefined' && canvas instanceof HTMLCanvasElement) && !(typeof OffscreenCanvas !== 'undefined' && canvas instanceof OffscreenCanvas)) {
            throw new TypeError('canvas must be an HTMLCanvasElement or OffscreenCanvas.');
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$encode$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateVideoEncodingConfig"])(encodingConfig);
        super(encodingConfig.codec);
        this._encoder = new VideoEncoderWrapper(this, encodingConfig);
        this._canvas = canvas;
    }
    /**
     * Captures the current canvas state as a video sample (frame), encodes it and adds it to the output.
     *
     * @param timestamp - The timestamp of the sample, in seconds.
     * @param duration - The duration of the sample, in seconds.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */ add(timestamp, duration = 0, encodeOptions) {
        if (!Number.isFinite(timestamp) || timestamp < 0) {
            throw new TypeError('timestamp must be a non-negative number.');
        }
        if (!Number.isFinite(duration) || duration < 0) {
            throw new TypeError('duration must be a non-negative number.');
        }
        const sample = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VideoSample"](this._canvas, {
            timestamp,
            duration
        });
        return this._encoder.add(sample, true, encodeOptions);
    }
    /** @internal */ _flushAndClose(forceClose) {
        return this._encoder.flushAndClose(forceClose);
    }
}
class MediaStreamVideoTrackSource extends VideoSource {
    /** A promise that rejects upon any error within this source. This promise never resolves. */ get errorPromise() {
        this._errorPromiseAccessed = true;
        return this._promiseWithResolvers.promise;
    }
    /** Whether this source is currently paused as a result of calling `.pause()`. */ get paused() {
        return this._paused;
    }
    /**
     * Creates a new {@link MediaStreamVideoTrackSource} from a
     * [`MediaStreamVideoTrack`](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack), which will pull
     * video samples from the stream in real time and encode them according to {@link VideoEncodingConfig}.
     */ constructor(track, encodingConfig){
        if (!(track instanceof MediaStreamTrack) || track.kind !== 'video') {
            throw new TypeError('track must be a video MediaStreamTrack.');
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$encode$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateVideoEncodingConfig"])(encodingConfig);
        encodingConfig = {
            ...encodingConfig,
            latencyMode: 'realtime'
        };
        super(encodingConfig.codec);
        /** @internal */ this._abortController = null;
        /** @internal */ this._workerTrackId = null;
        /** @internal */ this._workerListener = null;
        /** @internal */ this._promiseWithResolvers = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])();
        /** @internal */ this._errorPromiseAccessed = false;
        /** @internal */ this._paused = false;
        /** @internal */ this._lastSampleTimestamp = null;
        /** @internal */ this._pauseOffset = 0;
        this._encoder = new VideoEncoderWrapper(this, encodingConfig);
        this._track = track;
    }
    /** @internal */ async _start() {
        if (!this._errorPromiseAccessed) {
            console.warn('Make sure not to ignore the `errorPromise` field on MediaStreamVideoTrackSource, so that any internal' + ' errors get bubbled up properly.');
        }
        this._abortController = new AbortController();
        let firstVideoFrameTimestamp = null;
        let errored = false;
        const onVideoFrame = (videoFrame)=>{
            if (errored) {
                videoFrame.close();
                return;
            }
            const currentTimestamp = videoFrame.timestamp / 1e6;
            if (this._paused) {
                const frameSeen = firstVideoFrameTimestamp !== null;
                if (frameSeen) {
                    if (this._lastSampleTimestamp !== null) {
                        // In addition to dropping this frame, let's also keep track of the time we have lost due to the
                        // pause. Doing it like this instead of simply keeping track of the paused time is better since
                        // it retains the frame rate of the underlying source.
                        const timeDelta = currentTimestamp - this._lastSampleTimestamp;
                        // We modify this field instead of _timestampOffset since we still might have data in flight
                        // in the encoder, with which we don't want to mess.
                        this._pauseOffset -= timeDelta;
                    }
                    this._lastSampleTimestamp = currentTimestamp;
                }
                videoFrame.close();
                return;
            }
            if (firstVideoFrameTimestamp === null) {
                firstVideoFrameTimestamp = currentTimestamp;
                const muxer = this._connectedTrack.output._muxer;
                if (muxer.firstMediaStreamTimestamp === null) {
                    muxer.firstMediaStreamTimestamp = performance.now() / 1000;
                    this._timestampOffset = -firstVideoFrameTimestamp;
                } else {
                    this._timestampOffset = performance.now() / 1000 - muxer.firstMediaStreamTimestamp - firstVideoFrameTimestamp;
                }
            }
            this._lastSampleTimestamp = currentTimestamp;
            if (this._encoder.getQueueSize() >= 4) {
                // Drop frames if the encoder is overloaded
                videoFrame.close();
                return;
            }
            const sample = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VideoSample"](videoFrame, {
                timestamp: currentTimestamp + this._pauseOffset
            });
            void this._encoder.add(sample, true).catch((error)=>{
                errored = true;
                this._abortController?.abort();
                this._promiseWithResolvers.reject(error);
                if (this._workerTrackId !== null) {
                    // Tell the worker to stop the track
                    sendMessageToMediaStreamTrackProcessorWorker({
                        type: 'stopTrack',
                        trackId: this._workerTrackId
                    });
                }
            });
        };
        if (typeof MediaStreamTrackProcessor !== 'undefined') {
            // We can do it here directly, perfect
            const processor = new MediaStreamTrackProcessor({
                track: this._track
            });
            const consumer = new WritableStream({
                write: onVideoFrame
            });
            processor.readable.pipeTo(consumer, {
                signal: this._abortController.signal
            }).catch((error)=>{
                // Handle AbortError silently
                if (error instanceof DOMException && error.name === 'AbortError') return;
                this._promiseWithResolvers.reject(error);
            });
        } else {
            // It might still be supported in a worker, so let's check that
            const supportedInWorker = await mediaStreamTrackProcessorIsSupportedInWorker();
            if (supportedInWorker) {
                this._workerTrackId = nextMediaStreamTrackProcessorWorkerId++;
                sendMessageToMediaStreamTrackProcessorWorker({
                    type: 'videoTrack',
                    trackId: this._workerTrackId,
                    track: this._track
                });
                this._workerListener = (event)=>{
                    const message = event.data;
                    if (message.type === 'videoFrame' && message.trackId === this._workerTrackId) {
                        onVideoFrame(message.videoFrame);
                    } else if (message.type === 'error' && message.trackId === this._workerTrackId) {
                        this._promiseWithResolvers.reject(message.error);
                    }
                };
                mediaStreamTrackProcessorWorker.addEventListener('message', this._workerListener);
            } else {
                throw new Error('MediaStreamTrackProcessor is required but not supported by this browser.');
            }
        }
    }
    /**
     * Pauses the capture of video frames - any video frames emitted by the underlying media stream will be ignored
     * while paused. This does *not* close the underlying `MediaStreamVideoTrack`, it just ignores its output.
     */ pause() {
        this._paused = true;
    }
    /** Resumes the capture of video frames after being paused. */ resume() {
        this._paused = false;
    }
    /** @internal */ async _flushAndClose(forceClose) {
        if (this._abortController) {
            this._abortController.abort();
            this._abortController = null;
        }
        if (this._workerTrackId !== null) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._workerListener);
            sendMessageToMediaStreamTrackProcessorWorker({
                type: 'stopTrack',
                trackId: this._workerTrackId
            });
            // Wait for the worker to stop the track
            await new Promise((resolve)=>{
                const listener = (event)=>{
                    const message = event.data;
                    if (message.type === 'trackStopped' && message.trackId === this._workerTrackId) {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._workerListener);
                        mediaStreamTrackProcessorWorker.removeEventListener('message', this._workerListener);
                        mediaStreamTrackProcessorWorker.removeEventListener('message', listener);
                        resolve();
                    }
                };
                mediaStreamTrackProcessorWorker.addEventListener('message', listener);
            });
        }
        await this._encoder.flushAndClose(forceClose);
    }
}
class AudioSource extends MediaSource {
    /** Internal constructor. */ constructor(codec){
        super();
        /** @internal */ this._connectedTrack = null;
        if (!__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AUDIO_CODECS"].includes(codec)) {
            throw new TypeError(`Invalid audio codec '${codec}'. Must be one of: ${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AUDIO_CODECS"].join(', ')}.`);
        }
        this._codec = codec;
    }
}
class EncodedAudioPacketSource extends AudioSource {
    /** Creates a new {@link EncodedAudioPacketSource} whose packets are encoded using `codec`. */ constructor(codec){
        super(codec);
    }
    /**
     * Adds an encoded packet to the output audio track. Packets must be added in *decode order*.
     *
     * @param meta - Additional metadata from the encoder. You should pass this for the first call, including a valid
     * decoder config.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */ add(packet, meta) {
        if (!(packet instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"])) {
            throw new TypeError('packet must be an EncodedPacket.');
        }
        if (packet.isMetadataOnly) {
            throw new TypeError('Metadata-only packets cannot be added.');
        }
        if (meta !== undefined && (!meta || typeof meta !== 'object')) {
            throw new TypeError('meta, when provided, must be an object.');
        }
        this._ensureValidAdd();
        return this._connectedTrack.output._muxer.addEncodedAudioPacket(this._connectedTrack, packet, meta);
    }
}
class AudioEncoderWrapper {
    constructor(source, encodingConfig){
        this.source = source;
        this.encodingConfig = encodingConfig;
        this.ensureEncoderPromise = null;
        this.encoderInitialized = false;
        this.encoder = null;
        this.muxer = null;
        this.lastNumberOfChannels = null;
        this.lastSampleRate = null;
        this.isPcmEncoder = false;
        this.outputSampleSize = null;
        this.writeOutputValue = null;
        this.customEncoder = null;
        this.customEncoderCallSerializer = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["CallSerializer"]();
        this.customEncoderQueueSize = 0;
        this.lastEndSampleIndex = null;
        /**
         * Encoders typically throw their errors "out of band", meaning asynchronously in some other execution context.
         * However, we want to surface these errors to the user within the normal control flow, so they don't go uncaught.
         * So, we keep track of the encoder error and throw it as soon as we get the chance.
         */ this.error = null;
        this.errorNeedsNewStack = true;
    }
    async add(audioSample, shouldClose) {
        try {
            this.checkForEncoderError();
            this.source._ensureValidAdd();
            // Ensure audio parameters remain constant
            if (this.lastNumberOfChannels !== null && this.lastSampleRate !== null) {
                if (audioSample.numberOfChannels !== this.lastNumberOfChannels || audioSample.sampleRate !== this.lastSampleRate) {
                    throw new Error(`Audio parameters must remain constant. Expected ${this.lastNumberOfChannels} channels at` + ` ${this.lastSampleRate} Hz, got ${audioSample.numberOfChannels} channels at` + ` ${audioSample.sampleRate} Hz.`);
                }
            } else {
                this.lastNumberOfChannels = audioSample.numberOfChannels;
                this.lastSampleRate = audioSample.sampleRate;
            }
            if (!this.encoderInitialized) {
                if (!this.ensureEncoderPromise) {
                    this.ensureEncoder(audioSample);
                }
                // No, this "if" statement is not useless. Sometimes, the above call to `ensureEncoder` might have
                // synchronously completed and the encoder is already initialized. In this case, we don't need to await
                // the promise anymore. This also fixes nasty async race condition bugs when multiple code paths are
                // calling this method: It's important that the call that initialized the encoder go through this
                // code first.
                if (!this.encoderInitialized) {
                    await this.ensureEncoderPromise;
                }
            }
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.encoderInitialized);
            // Handle padding of gaps with silence to avoid audio drift over time, like in
            // https://github.com/Vanilagy/mediabunny/issues/176
            // TODO An open question is how encoders deal with the first AudioData having a non-zero timestamp, and with
            // AudioDatas that have an overlapping timestamp range.
            {
                const startSampleIndex = Math.round(audioSample.timestamp * audioSample.sampleRate);
                const endSampleIndex = Math.round((audioSample.timestamp + audioSample.duration) * audioSample.sampleRate);
                if (this.lastEndSampleIndex === null) {
                    this.lastEndSampleIndex = endSampleIndex;
                } else {
                    const sampleDiff = startSampleIndex - this.lastEndSampleIndex;
                    if (sampleDiff >= 64) {
                        // The gap is big enough, let's add a correction sample
                        const fillSample = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AudioSample"]({
                            data: new Float32Array(sampleDiff * audioSample.numberOfChannels),
                            format: 'f32-planar',
                            sampleRate: audioSample.sampleRate,
                            numberOfChannels: audioSample.numberOfChannels,
                            numberOfFrames: sampleDiff,
                            timestamp: this.lastEndSampleIndex / audioSample.sampleRate
                        });
                        await this.add(fillSample, true); // Recursive call
                    }
                    this.lastEndSampleIndex += audioSample.numberOfFrames;
                }
            }
            if (this.customEncoder) {
                this.customEncoderQueueSize++;
                // We clone the sample so it cannot be closed on us from the outside before it reaches the encoder
                const clonedSample = audioSample.clone();
                const promise = this.customEncoderCallSerializer.call(()=>this.customEncoder.encode(clonedSample)).then(()=>this.customEncoderQueueSize--).catch((error)=>this.error ??= error).finally(()=>{
                    clonedSample.close();
                // `audioSample` gets closed in the finally block at the end of the method
                });
                if (this.customEncoderQueueSize >= 4) {
                    await promise;
                }
                await this.muxer.mutex.currentPromise; // Allow the writer to apply backpressure
            } else if (this.isPcmEncoder) {
                await this.doPcmEncoding(audioSample, shouldClose);
            } else {
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.encoder);
                const audioData = audioSample.toAudioData();
                this.encoder.encode(audioData);
                audioData.close();
                if (shouldClose) {
                    audioSample.close();
                }
                if (this.encoder.encodeQueueSize >= 4) {
                    await new Promise((resolve)=>this.encoder.addEventListener('dequeue', resolve, {
                            once: true
                        }));
                }
                await this.muxer.mutex.currentPromise; // Allow the writer to apply backpressure
            }
        } finally{
            if (shouldClose) {
                // Make sure it's always closed, even if there was an error
                audioSample.close();
            }
        }
    }
    async doPcmEncoding(audioSample, shouldClose) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.outputSampleSize);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.writeOutputValue);
        // Need to extract data from the audio data before we close it
        const { numberOfChannels, numberOfFrames, sampleRate, timestamp } = audioSample;
        const CHUNK_SIZE = 2048;
        const outputs = [];
        // Prepare all of the output buffers, each being bounded by CHUNK_SIZE so we don't generate huge packets
        for(let frame = 0; frame < numberOfFrames; frame += CHUNK_SIZE){
            const frameCount = Math.min(CHUNK_SIZE, audioSample.numberOfFrames - frame);
            const outputSize = frameCount * numberOfChannels * this.outputSampleSize;
            const outputBuffer = new ArrayBuffer(outputSize);
            const outputView = new DataView(outputBuffer);
            outputs.push({
                frameCount,
                view: outputView
            });
        }
        const allocationSize = audioSample.allocationSize({
            planeIndex: 0,
            format: 'f32-planar'
        });
        const floats = new Float32Array(allocationSize / Float32Array.BYTES_PER_ELEMENT);
        for(let i = 0; i < numberOfChannels; i++){
            audioSample.copyTo(floats, {
                planeIndex: i,
                format: 'f32-planar'
            });
            for(let j = 0; j < outputs.length; j++){
                const { frameCount, view } = outputs[j];
                for(let k = 0; k < frameCount; k++){
                    this.writeOutputValue(view, (k * numberOfChannels + i) * this.outputSampleSize, floats[j * CHUNK_SIZE + k]);
                }
            }
        }
        if (shouldClose) {
            audioSample.close();
        }
        const meta = {
            decoderConfig: {
                codec: this.encodingConfig.codec,
                numberOfChannels,
                sampleRate
            }
        };
        for(let i = 0; i < outputs.length; i++){
            const { frameCount, view } = outputs[i];
            const outputBuffer = view.buffer;
            const startFrame = i * CHUNK_SIZE;
            const packet = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"](new Uint8Array(outputBuffer), 'key', timestamp + startFrame / sampleRate, frameCount / sampleRate);
            this.encodingConfig.onEncodedPacket?.(packet, meta);
            await this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta); // With backpressure
        }
    }
    ensureEncoder(audioSample) {
        const encoderError = new Error();
        this.ensureEncoderPromise = (async ()=>{
            const { numberOfChannels, sampleRate } = audioSample;
            const encoderConfig = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$encode$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["buildAudioEncoderConfig"])({
                numberOfChannels,
                sampleRate,
                ...this.encodingConfig
            });
            this.encodingConfig.onEncoderConfig?.(encoderConfig);
            const MatchingCustomEncoder = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["customAudioEncoders"].find((x)=>x.supports(this.encodingConfig.codec, encoderConfig));
            if (MatchingCustomEncoder) {
                // @ts-expect-error "Can't create instance of abstract class "
                this.customEncoder = new MatchingCustomEncoder();
                // @ts-expect-error It's technically readonly
                this.customEncoder.codec = this.encodingConfig.codec;
                // @ts-expect-error It's technically readonly
                this.customEncoder.config = encoderConfig;
                // @ts-expect-error It's technically readonly
                this.customEncoder.onPacket = (packet, meta)=>{
                    if (!(packet instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"])) {
                        throw new TypeError('The first argument passed to onPacket must be an EncodedPacket.');
                    }
                    if (meta !== undefined && (!meta || typeof meta !== 'object')) {
                        throw new TypeError('The second argument passed to onPacket must be an object or undefined.');
                    }
                    this.encodingConfig.onEncodedPacket?.(packet, meta);
                    void this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta).catch((error)=>{
                        this.error ??= error;
                        this.errorNeedsNewStack = false;
                    });
                };
                await this.customEncoder.init();
            } else if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PCM_AUDIO_CODECS"].includes(this.encodingConfig.codec)) {
                this.initPcmEncoder();
            } else {
                if (typeof AudioEncoder === 'undefined') {
                    throw new Error('AudioEncoder is not supported by this browser.');
                }
                const support = await AudioEncoder.isConfigSupported(encoderConfig);
                if (!support.supported) {
                    throw new Error(`This specific encoder configuration (${encoderConfig.codec}, ${encoderConfig.bitrate} bps,` + ` ${encoderConfig.numberOfChannels} channels, ${encoderConfig.sampleRate} Hz) is not` + ` supported by this browser. Consider using another codec or changing your audio parameters.`);
                }
                this.encoder = new AudioEncoder({
                    output: (chunk, meta)=>{
                        // WebKit emits an invalid description for AAC (https://bugs.webkit.org/show_bug.cgi?id=302253),
                        // which we try to detect here. If detected, we'll provide our own description instead, derived
                        // from the codec string and audio parameters.
                        if (this.encodingConfig.codec === 'aac' && meta?.decoderConfig) {
                            let needsDescriptionOverwrite = false;
                            if (!meta.decoderConfig.description || meta.decoderConfig.description.byteLength < 2) {
                                needsDescriptionOverwrite = true;
                            } else {
                                const audioSpecificConfig = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseAacAudioSpecificConfig"])((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(meta.decoderConfig.description));
                                needsDescriptionOverwrite = audioSpecificConfig.objectType === 0;
                            }
                            if (needsDescriptionOverwrite) {
                                const objectType = Number((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["last"])(encoderConfig.codec.split('.')));
                                meta.decoderConfig.description = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["buildAacAudioSpecificConfig"])({
                                    objectType,
                                    numberOfChannels: meta.decoderConfig.numberOfChannels,
                                    sampleRate: meta.decoderConfig.sampleRate
                                });
                            }
                        }
                        const packet = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"].fromEncodedChunk(chunk);
                        this.encodingConfig.onEncodedPacket?.(packet, meta);
                        void this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta).catch((error)=>{
                            this.error ??= error;
                            this.errorNeedsNewStack = false;
                        });
                    },
                    error: (error)=>{
                        error.stack = encoderError.stack; // Provide a more useful stack trace
                        this.error ??= error;
                    }
                });
                this.encoder.configure(encoderConfig);
            }
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.source._connectedTrack);
            this.muxer = this.source._connectedTrack.output._muxer;
            this.encoderInitialized = true;
        })();
    }
    initPcmEncoder() {
        this.isPcmEncoder = true;
        const codec = this.encodingConfig.codec;
        const { dataType, sampleSize, littleEndian } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parsePcmCodec"])(codec);
        this.outputSampleSize = sampleSize;
        // All these functions receive a float sample as input and map it into the desired format
        switch(sampleSize){
            case 1:
                {
                    if (dataType === 'unsigned') {
                        this.writeOutputValue = (view, byteOffset, value)=>view.setUint8(byteOffset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])((value + 1) * 127.5, 0, 255));
                    } else if (dataType === 'signed') {
                        this.writeOutputValue = (view, byteOffset, value)=>{
                            view.setInt8(byteOffset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])(Math.round(value * 128), -128, 127));
                        };
                    } else if (dataType === 'ulaw') {
                        this.writeOutputValue = (view, byteOffset, value)=>{
                            const int16 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])(Math.floor(value * 32767), -32768, 32767);
                            view.setUint8(byteOffset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$pcm$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUlaw"])(int16));
                        };
                    } else if (dataType === 'alaw') {
                        this.writeOutputValue = (view, byteOffset, value)=>{
                            const int16 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])(Math.floor(value * 32767), -32768, 32767);
                            view.setUint8(byteOffset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$pcm$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toAlaw"])(int16));
                        };
                    } else {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                    }
                }
                ;
                break;
            case 2:
                {
                    if (dataType === 'unsigned') {
                        this.writeOutputValue = (view, byteOffset, value)=>view.setUint16(byteOffset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])((value + 1) * 32767.5, 0, 65535), littleEndian);
                    } else if (dataType === 'signed') {
                        this.writeOutputValue = (view, byteOffset, value)=>view.setInt16(byteOffset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])(Math.round(value * 32767), -32768, 32767), littleEndian);
                    } else {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                    }
                }
                ;
                break;
            case 3:
                {
                    if (dataType === 'unsigned') {
                        this.writeOutputValue = (view, byteOffset, value)=>(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["setUint24"])(view, byteOffset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])((value + 1) * 8388607.5, 0, 16777215), littleEndian);
                    } else if (dataType === 'signed') {
                        this.writeOutputValue = (view, byteOffset, value)=>(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["setInt24"])(view, byteOffset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])(Math.round(value * 8388607), -8388608, 8388607), littleEndian);
                    } else {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                    }
                }
                ;
                break;
            case 4:
                {
                    if (dataType === 'unsigned') {
                        this.writeOutputValue = (view, byteOffset, value)=>view.setUint32(byteOffset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])((value + 1) * 2147483647.5, 0, 4294967295), littleEndian);
                    } else if (dataType === 'signed') {
                        this.writeOutputValue = (view, byteOffset, value)=>view.setInt32(byteOffset, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])(Math.round(value * 2147483647), -2147483648, 2147483647), littleEndian);
                    } else if (dataType === 'float') {
                        this.writeOutputValue = (view, byteOffset, value)=>view.setFloat32(byteOffset, value, littleEndian);
                    } else {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                    }
                }
                ;
                break;
            case 8:
                {
                    if (dataType === 'float') {
                        this.writeOutputValue = (view, byteOffset, value)=>view.setFloat64(byteOffset, value, littleEndian);
                    } else {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                    }
                }
                ;
                break;
            default:
                {
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(sampleSize);
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                }
                ;
        }
    }
    async flushAndClose(forceClose) {
        if (!forceClose) this.checkForEncoderError();
        if (this.customEncoder) {
            if (!forceClose) {
                void this.customEncoderCallSerializer.call(()=>this.customEncoder.flush());
            }
            await this.customEncoderCallSerializer.call(()=>this.customEncoder.close());
        } else if (this.encoder) {
            if (!forceClose) {
                await this.encoder.flush();
            }
            if (this.encoder.state !== 'closed') {
                this.encoder.close();
            }
        }
        if (!forceClose) this.checkForEncoderError();
    }
    getQueueSize() {
        if (this.customEncoder) {
            return this.customEncoderQueueSize;
        } else if (this.isPcmEncoder) {
            return 0;
        } else {
            return this.encoder?.encodeQueueSize ?? 0;
        }
    }
    checkForEncoderError() {
        if (this.error) {
            if (this.errorNeedsNewStack) {
                this.error.stack = new Error().stack; // Provide an even more useful stack trace
            }
            throw this.error;
        }
    }
}
class AudioSampleSource extends AudioSource {
    /**
     * Creates a new {@link AudioSampleSource} whose samples are encoded according to the specified
     * {@link AudioEncodingConfig}.
     */ constructor(encodingConfig){
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$encode$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateAudioEncodingConfig"])(encodingConfig);
        super(encodingConfig.codec);
        this._encoder = new AudioEncoderWrapper(this, encodingConfig);
    }
    /**
     * Encodes an audio sample and then adds it to the output.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */ add(audioSample) {
        if (!(audioSample instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AudioSample"])) {
            throw new TypeError('audioSample must be an AudioSample.');
        }
        return this._encoder.add(audioSample, false);
    }
    /** @internal */ _flushAndClose(forceClose) {
        return this._encoder.flushAndClose(forceClose);
    }
}
class AudioBufferSource extends AudioSource {
    /**
     * Creates a new {@link AudioBufferSource} whose `AudioBuffer` instances are encoded according to the specified
     * {@link AudioEncodingConfig}.
     */ constructor(encodingConfig){
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$encode$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateAudioEncodingConfig"])(encodingConfig);
        super(encodingConfig.codec);
        /** @internal */ this._accumulatedTime = 0;
        this._encoder = new AudioEncoderWrapper(this, encodingConfig);
    }
    /**
     * Converts an AudioBuffer to audio samples, encodes them and adds them to the output. The first AudioBuffer will
     * be played at timestamp 0, and any subsequent AudioBuffer will have a timestamp equal to the total duration of
     * all previous AudioBuffers.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */ async add(audioBuffer) {
        if (!(audioBuffer instanceof AudioBuffer)) {
            throw new TypeError('audioBuffer must be an AudioBuffer.');
        }
        const iterator = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AudioSample"]._fromAudioBuffer(audioBuffer, this._accumulatedTime);
        this._accumulatedTime += audioBuffer.duration;
        for (const audioSample of iterator){
            await this._encoder.add(audioSample, true);
        }
    }
    /** @internal */ _flushAndClose(forceClose) {
        return this._encoder.flushAndClose(forceClose);
    }
}
class MediaStreamAudioTrackSource extends AudioSource {
    /** A promise that rejects upon any error within this source. This promise never resolves. */ get errorPromise() {
        this._errorPromiseAccessed = true;
        return this._promiseWithResolvers.promise;
    }
    /** Whether this source is currently paused as a result of calling `.pause()`. */ get paused() {
        return this._paused;
    }
    /**
     * Creates a new {@link MediaStreamAudioTrackSource} from a `MediaStreamAudioTrack`, which will pull audio samples
     * from the stream in real time and encode them according to {@link AudioEncodingConfig}.
     */ constructor(track, encodingConfig){
        if (!(track instanceof MediaStreamTrack) || track.kind !== 'audio') {
            throw new TypeError('track must be an audio MediaStreamTrack.');
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$encode$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateAudioEncodingConfig"])(encodingConfig);
        super(encodingConfig.codec);
        /** @internal */ this._abortController = null;
        /** @internal */ this._audioContext = null;
        /** @internal */ this._scriptProcessorNode = null; // Deprecated but goated
        /** @internal */ this._promiseWithResolvers = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])();
        /** @internal */ this._errorPromiseAccessed = false;
        /** @internal */ this._paused = false;
        /** @internal */ this._lastSampleTimestamp = null;
        /** @internal */ this._pauseOffset = 0;
        this._encoder = new AudioEncoderWrapper(this, encodingConfig);
        this._track = track;
    }
    /** @internal */ async _start() {
        if (!this._errorPromiseAccessed) {
            console.warn('Make sure not to ignore the `errorPromise` field on MediaStreamVideoTrackSource, so that any internal' + ' errors get bubbled up properly.');
        }
        this._abortController = new AbortController();
        let firstAudioDataTimestamp = null;
        let errored = false;
        const onAudioSample = (audioSample)=>{
            if (errored) {
                audioSample.close();
                return;
            }
            const currentTimestamp = audioSample.timestamp;
            if (this._paused) {
                const dataSeen = firstAudioDataTimestamp !== null;
                if (dataSeen) {
                    if (this._lastSampleTimestamp !== null) {
                        // In addition to dropping this sample, let's also keep track of the time we have lost due to
                        // the pause. Doing it like this instead of simply keeping track of the paused time is better
                        // since it retains the sample rate of the underlying source.
                        const timeDelta = currentTimestamp - this._lastSampleTimestamp;
                        // We modify this field instead of _timestampOffset since we still might have data in flight
                        // in the encoder, with which we don't want to mess.
                        this._pauseOffset -= timeDelta;
                    }
                    this._lastSampleTimestamp = currentTimestamp;
                }
                audioSample.close();
                return;
            }
            if (firstAudioDataTimestamp === null) {
                firstAudioDataTimestamp = audioSample.timestamp;
                const muxer = this._connectedTrack.output._muxer;
                if (muxer.firstMediaStreamTimestamp === null) {
                    muxer.firstMediaStreamTimestamp = performance.now() / 1000;
                    this._timestampOffset = -firstAudioDataTimestamp;
                } else {
                    this._timestampOffset = performance.now() / 1000 - muxer.firstMediaStreamTimestamp - firstAudioDataTimestamp;
                }
            }
            this._lastSampleTimestamp = currentTimestamp;
            if (this._encoder.getQueueSize() >= 4) {
                // Drop data if the encoder is overloaded
                audioSample.close();
                return;
            }
            audioSample.setTimestamp(currentTimestamp + this._pauseOffset);
            void this._encoder.add(audioSample, true).catch((error)=>{
                errored = true;
                this._abortController?.abort();
                this._promiseWithResolvers.reject(error);
                void this._audioContext?.suspend();
            });
        };
        if (typeof MediaStreamTrackProcessor !== 'undefined') {
            // Great, MediaStreamTrackProcessor is supported, this is the preferred way of doing things
            const processor = new MediaStreamTrackProcessor({
                track: this._track
            });
            const consumer = new WritableStream({
                write: (audioData)=>onAudioSample(new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AudioSample"](audioData))
            });
            processor.readable.pipeTo(consumer, {
                signal: this._abortController.signal
            }).catch((error)=>{
                // Handle AbortError silently
                if (error instanceof DOMException && error.name === 'AbortError') return;
                this._promiseWithResolvers.reject(error);
            });
        } else {
            // Let's fall back to an AudioContext approach
            // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/no-unsafe-member-access
            const AudioContext = window.AudioContext || window.webkitAudioContext;
            this._audioContext = new AudioContext({
                sampleRate: this._track.getSettings().sampleRate
            });
            const sourceNode = this._audioContext.createMediaStreamSource(new MediaStream([
                this._track
            ]));
            this._scriptProcessorNode = this._audioContext.createScriptProcessor(4096);
            if (this._audioContext.state === 'suspended') {
                await this._audioContext.resume();
            }
            sourceNode.connect(this._scriptProcessorNode);
            this._scriptProcessorNode.connect(this._audioContext.destination);
            let totalDuration = 0;
            this._scriptProcessorNode.onaudioprocess = (event)=>{
                const iterator = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AudioSample"]._fromAudioBuffer(event.inputBuffer, totalDuration);
                totalDuration += event.inputBuffer.duration;
                for (const audioSample of iterator){
                    onAudioSample(audioSample);
                }
            };
        }
    }
    /**
     * Pauses the capture of audio data - any audio data emitted by the underlying media stream will be ignored
     * while paused. This does *not* close the underlying `MediaStreamAudioTrack`, it just ignores its output.
     */ pause() {
        this._paused = true;
    }
    /** Resumes the capture of audio data after being paused. */ resume() {
        this._paused = false;
    }
    /** @internal */ async _flushAndClose(forceClose) {
        if (this._abortController) {
            this._abortController.abort();
            this._abortController = null;
        }
        if (this._audioContext) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._scriptProcessorNode);
            this._scriptProcessorNode.disconnect();
            await this._audioContext.suspend();
        }
        await this._encoder.flushAndClose(forceClose);
    }
}
const mediaStreamTrackProcessorWorkerCode = ()=>{
    const sendMessage = (message, transfer)=>{
        if (transfer) {
            self.postMessage(message, {
                transfer
            });
        } else {
            self.postMessage(message);
        }
    };
    // Immediately send a message to the main thread, letting them know of the support
    sendMessage({
        type: 'support',
        supported: typeof MediaStreamTrackProcessor !== 'undefined'
    });
    const abortControllers = new Map();
    const activeTracks = new Map();
    self.addEventListener('message', (event)=>{
        const message = event.data;
        switch(message.type){
            case 'videoTrack':
                {
                    activeTracks.set(message.trackId, message.track);
                    const processor = new MediaStreamTrackProcessor({
                        track: message.track
                    });
                    const consumer = new WritableStream({
                        write: (videoFrame)=>{
                            if (!activeTracks.has(message.trackId)) {
                                videoFrame.close();
                                return;
                            }
                            // Send it to the main thread
                            sendMessage({
                                type: 'videoFrame',
                                trackId: message.trackId,
                                videoFrame
                            }, [
                                videoFrame
                            ]);
                        }
                    });
                    const abortController = new AbortController();
                    abortControllers.set(message.trackId, abortController);
                    processor.readable.pipeTo(consumer, {
                        signal: abortController.signal
                    }).catch((error)=>{
                        // Handle AbortError silently
                        if (error instanceof DOMException && error.name === 'AbortError') return;
                        sendMessage({
                            type: 'error',
                            trackId: message.trackId,
                            error
                        });
                    });
                }
                ;
                break;
            case 'stopTrack':
                {
                    const abortController = abortControllers.get(message.trackId);
                    if (abortController) {
                        abortController.abort();
                        abortControllers.delete(message.trackId);
                    }
                    const track = activeTracks.get(message.trackId);
                    track?.stop();
                    activeTracks.delete(message.trackId);
                    sendMessage({
                        type: 'trackStopped',
                        trackId: message.trackId
                    });
                }
                ;
                break;
            default:
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(message);
        }
    });
};
let nextMediaStreamTrackProcessorWorkerId = 0;
let mediaStreamTrackProcessorWorker = null;
const initMediaStreamTrackProcessorWorker = ()=>{
    const blob = new Blob([
        `(${mediaStreamTrackProcessorWorkerCode.toString()})()`
    ], {
        type: 'application/javascript'
    });
    const url = URL.createObjectURL(blob);
    mediaStreamTrackProcessorWorker = new Worker(url);
};
let mediaStreamTrackProcessorIsSupportedInWorkerCache = null;
const mediaStreamTrackProcessorIsSupportedInWorker = async ()=>{
    if (mediaStreamTrackProcessorIsSupportedInWorkerCache !== null) {
        return mediaStreamTrackProcessorIsSupportedInWorkerCache;
    }
    if (!mediaStreamTrackProcessorWorker) {
        initMediaStreamTrackProcessorWorker();
    }
    return new Promise((resolve)=>{
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(mediaStreamTrackProcessorWorker);
        const listener = (event)=>{
            const message = event.data;
            if (message.type === 'support') {
                mediaStreamTrackProcessorIsSupportedInWorkerCache = message.supported;
                mediaStreamTrackProcessorWorker.removeEventListener('message', listener);
                resolve(message.supported);
            }
        };
        mediaStreamTrackProcessorWorker.addEventListener('message', listener);
    });
};
const sendMessageToMediaStreamTrackProcessorWorker = (message, transfer)=>{
    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(mediaStreamTrackProcessorWorker);
    if (transfer) {
        mediaStreamTrackProcessorWorker.postMessage(message, transfer);
    } else {
        mediaStreamTrackProcessorWorker.postMessage(message);
    }
};
class SubtitleSource extends MediaSource {
    /** Internal constructor. */ constructor(codec){
        super();
        /** @internal */ this._connectedTrack = null;
        if (!__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SUBTITLE_CODECS"].includes(codec)) {
            throw new TypeError(`Invalid subtitle codec '${codec}'. Must be one of: ${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SUBTITLE_CODECS"].join(', ')}.`);
        }
        this._codec = codec;
    }
}
class TextSubtitleSource extends SubtitleSource {
    /** Creates a new {@link TextSubtitleSource} where added text chunks are in the specified `codec`. */ constructor(codec){
        super(codec);
        /** @internal */ this._error = null;
        this._parser = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$subtitles$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SubtitleParser"]({
            codec,
            output: (cue, metadata)=>{
                void this._connectedTrack?.output._muxer.addSubtitleCue(this._connectedTrack, cue, metadata).catch((error)=>{
                    this._error ??= error;
                });
            }
        });
    }
    /**
     * Parses the subtitle text according to the specified codec and adds it to the output track. You don't have to
     * add the entire subtitle file at once here; you can provide it in chunks.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */ add(text) {
        if (typeof text !== 'string') {
            throw new TypeError('text must be a string.');
        }
        this._checkForError();
        this._ensureValidAdd();
        this._parser.parse(text);
        return this._connectedTrack.output._muxer.mutex.currentPromise;
    }
    /** @internal */ _checkForError() {
        if (this._error) {
            throw this._error;
        }
    }
    /** @internal */ async _flushAndClose(forceClose) {
        if (!forceClose) {
            this._checkForError();
        }
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/writer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "BufferTargetWriter",
    ()=>BufferTargetWriter,
    "NullTargetWriter",
    ()=>NullTargetWriter,
    "StreamTargetWriter",
    ()=>StreamTargetWriter,
    "Writer",
    ()=>Writer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
;
class Writer {
    constructor(){
        /** Setting this to true will cause the writer to ensure data is written in a strictly monotonic, streamable way. */ this.ensureMonotonicity = false;
        this.trackedWrites = null;
        this.trackedStart = -1;
        this.trackedEnd = -1;
    }
    start() {}
    maybeTrackWrites(data) {
        if (!this.trackedWrites) {
            return;
        }
        // Handle negative relative write positions
        let pos = this.getPos();
        if (pos < this.trackedStart) {
            if (pos + data.byteLength <= this.trackedStart) {
                return;
            }
            data = data.subarray(this.trackedStart - pos);
            pos = 0;
        }
        const neededSize = pos + data.byteLength - this.trackedStart;
        let newLength = this.trackedWrites.byteLength;
        while(newLength < neededSize){
            newLength *= 2;
        }
        // Check if we need to resize the buffer
        if (newLength !== this.trackedWrites.byteLength) {
            const copy = new Uint8Array(newLength);
            copy.set(this.trackedWrites, 0);
            this.trackedWrites = copy;
        }
        this.trackedWrites.set(data, pos - this.trackedStart);
        this.trackedEnd = Math.max(this.trackedEnd, pos + data.byteLength);
    }
    startTrackingWrites() {
        this.trackedWrites = new Uint8Array(2 ** 10);
        this.trackedStart = this.getPos();
        this.trackedEnd = this.trackedStart;
    }
    stopTrackingWrites() {
        if (!this.trackedWrites) {
            throw new Error('Internal error: Can\'t get tracked writes since nothing was tracked.');
        }
        const slice = this.trackedWrites.subarray(0, this.trackedEnd - this.trackedStart);
        const result = {
            data: slice,
            start: this.trackedStart,
            end: this.trackedEnd
        };
        this.trackedWrites = null;
        return result;
    }
}
const ARRAY_BUFFER_INITIAL_SIZE = 2 ** 16;
const ARRAY_BUFFER_MAX_SIZE = 2 ** 32;
class BufferTargetWriter extends Writer {
    constructor(target){
        super();
        this.pos = 0;
        this.maxPos = 0;
        this.target = target;
        this.supportsResize = 'resize' in new ArrayBuffer(0);
        if (this.supportsResize) {
            try {
                // @ts-expect-error Don't want to bump "lib" in tsconfig
                this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE, {
                    maxByteLength: ARRAY_BUFFER_MAX_SIZE
                });
            } catch  {
                this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE);
                this.supportsResize = false;
            }
        } else {
            this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE);
        }
        this.bytes = new Uint8Array(this.buffer);
    }
    ensureSize(size) {
        let newLength = this.buffer.byteLength;
        while(newLength < size)newLength *= 2;
        if (newLength === this.buffer.byteLength) return;
        if (newLength > ARRAY_BUFFER_MAX_SIZE) {
            throw new Error(`ArrayBuffer exceeded maximum size of ${ARRAY_BUFFER_MAX_SIZE} bytes. Please consider using another` + ` target.`);
        }
        if (this.supportsResize) {
            // Use resize if it exists
            // @ts-expect-error Don't want to bump "lib" in tsconfig
            // eslint-disable-next-line @typescript-eslint/no-unsafe-call
            this.buffer.resize(newLength);
        // The Uint8Array scales automatically
        } else {
            const newBuffer = new ArrayBuffer(newLength);
            const newBytes = new Uint8Array(newBuffer);
            newBytes.set(this.bytes, 0);
            this.buffer = newBuffer;
            this.bytes = newBytes;
        }
    }
    write(data) {
        this.maybeTrackWrites(data);
        this.ensureSize(this.pos + data.byteLength);
        this.bytes.set(data, this.pos);
        this.target.onwrite?.(this.pos, this.pos + data.byteLength);
        this.pos += data.byteLength;
        this.maxPos = Math.max(this.maxPos, this.pos);
    }
    seek(newPos) {
        this.pos = newPos;
    }
    getPos() {
        return this.pos;
    }
    async flush() {}
    async finalize() {
        this.ensureSize(this.pos);
        this.target.buffer = this.buffer.slice(0, Math.max(this.maxPos, this.pos));
    }
    async close() {}
    getSlice(start, end) {
        return this.bytes.slice(start, end);
    }
}
const DEFAULT_CHUNK_SIZE = 2 ** 24;
const MAX_CHUNKS_AT_ONCE = 2;
class StreamTargetWriter extends Writer {
    constructor(target){
        super();
        this.pos = 0;
        this.sections = [];
        this.lastWriteEnd = 0;
        this.lastFlushEnd = 0;
        this.writer = null;
        /**
         * The data is divided up into fixed-size chunks, whose contents are first filled in RAM and then flushed out.
         * A chunk is flushed if all of its contents have been written.
         */ this.chunks = [];
        this.target = target;
        this.chunked = target._options.chunked ?? false;
        this.chunkSize = target._options.chunkSize ?? DEFAULT_CHUNK_SIZE;
    }
    start() {
        this.writer = this.target._writable.getWriter();
    }
    write(data) {
        if (this.pos > this.lastWriteEnd) {
            const paddingBytesNeeded = this.pos - this.lastWriteEnd;
            this.pos = this.lastWriteEnd;
            this.write(new Uint8Array(paddingBytesNeeded));
        }
        this.maybeTrackWrites(data);
        this.sections.push({
            data: data.slice(),
            start: this.pos
        });
        this.target.onwrite?.(this.pos, this.pos + data.byteLength);
        this.pos += data.byteLength;
        this.lastWriteEnd = Math.max(this.lastWriteEnd, this.pos);
    }
    seek(newPos) {
        this.pos = newPos;
    }
    getPos() {
        return this.pos;
    }
    async flush() {
        if (this.pos > this.lastWriteEnd) {
            // There's a "void" between the last written byte and the next byte we're about to write. Let's pad that
            // void with zeroes explicitly.
            const paddingBytesNeeded = this.pos - this.lastWriteEnd;
            this.pos = this.lastWriteEnd;
            this.write(new Uint8Array(paddingBytesNeeded));
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.writer);
        if (this.sections.length === 0) return;
        const chunks = [];
        const sorted = [
            ...this.sections
        ].sort((a, b)=>a.start - b.start);
        chunks.push({
            start: sorted[0].start,
            size: sorted[0].data.byteLength
        });
        // Figure out how many contiguous chunks we have
        for(let i = 1; i < sorted.length; i++){
            const lastChunk = chunks[chunks.length - 1];
            const section = sorted[i];
            if (section.start <= lastChunk.start + lastChunk.size) {
                lastChunk.size = Math.max(lastChunk.size, section.start + section.data.byteLength - lastChunk.start);
            } else {
                chunks.push({
                    start: section.start,
                    size: section.data.byteLength
                });
            }
        }
        for (const chunk of chunks){
            chunk.data = new Uint8Array(chunk.size);
            // Make sure to write the data in the correct order for correct overwriting
            for (const section of this.sections){
                // Check if the section is in the chunk
                if (chunk.start <= section.start && section.start < chunk.start + chunk.size) {
                    chunk.data.set(section.data, section.start - chunk.start);
                }
            }
            if (this.writer.desiredSize !== null && this.writer.desiredSize <= 0) {
                await this.writer.ready; // Allow the writer to apply backpressure
            }
            if (this.chunked) {
                // Let's first gather the data into bigger chunks before writing it
                this.writeDataIntoChunks(chunk.data, chunk.start);
                this.tryToFlushChunks();
            } else {
                if (this.ensureMonotonicity && chunk.start !== this.lastFlushEnd) {
                    throw new Error('Internal error: Monotonicity violation.');
                }
                // Write out the data immediately
                void this.writer.write({
                    type: 'write',
                    data: chunk.data,
                    position: chunk.start
                });
                this.lastFlushEnd = chunk.start + chunk.data.byteLength;
            }
        }
        this.sections.length = 0;
    }
    writeDataIntoChunks(data, position) {
        // First, find the chunk to write the data into, or create one if none exists
        let chunkIndex = this.chunks.findIndex((x)=>x.start <= position && position < x.start + this.chunkSize);
        if (chunkIndex === -1) chunkIndex = this.createChunk(position);
        const chunk = this.chunks[chunkIndex];
        // Figure out how much to write to the chunk, and then write to the chunk
        const relativePosition = position - chunk.start;
        const toWrite = data.subarray(0, Math.min(this.chunkSize - relativePosition, data.byteLength));
        chunk.data.set(toWrite, relativePosition);
        // Create a section describing the region of data that was just written to
        const section = {
            start: relativePosition,
            end: relativePosition + toWrite.byteLength
        };
        this.insertSectionIntoChunk(chunk, section);
        // Queue chunk for flushing to target if it has been fully written to
        if (chunk.written[0].start === 0 && chunk.written[0].end === this.chunkSize) {
            chunk.shouldFlush = true;
        }
        // Make sure we don't hold too many chunks in memory at once to keep memory usage down
        if (this.chunks.length > MAX_CHUNKS_AT_ONCE) {
            // Flush all but the last chunk
            for(let i = 0; i < this.chunks.length - 1; i++){
                this.chunks[i].shouldFlush = true;
            }
            this.tryToFlushChunks();
        }
        // If the data didn't fit in one chunk, recurse with the remaining data
        if (toWrite.byteLength < data.byteLength) {
            this.writeDataIntoChunks(data.subarray(toWrite.byteLength), position + toWrite.byteLength);
        }
    }
    insertSectionIntoChunk(chunk, section) {
        let low = 0;
        let high = chunk.written.length - 1;
        let index = -1;
        // Do a binary search to find the last section with a start not larger than `section`'s start
        while(low <= high){
            const mid = Math.floor(low + (high - low + 1) / 2);
            if (chunk.written[mid].start <= section.start) {
                low = mid + 1;
                index = mid;
            } else {
                high = mid - 1;
            }
        }
        // Insert the new section
        chunk.written.splice(index + 1, 0, section);
        if (index === -1 || chunk.written[index].end < section.start) index++;
        // Merge overlapping sections
        while(index < chunk.written.length - 1 && chunk.written[index].end >= chunk.written[index + 1].start){
            chunk.written[index].end = Math.max(chunk.written[index].end, chunk.written[index + 1].end);
            chunk.written.splice(index + 1, 1);
        }
    }
    createChunk(includesPosition) {
        const start = Math.floor(includesPosition / this.chunkSize) * this.chunkSize;
        const chunk = {
            start,
            data: new Uint8Array(this.chunkSize),
            written: [],
            shouldFlush: false
        };
        this.chunks.push(chunk);
        this.chunks.sort((a, b)=>a.start - b.start);
        return this.chunks.indexOf(chunk);
    }
    tryToFlushChunks(force = false) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.writer);
        for(let i = 0; i < this.chunks.length; i++){
            const chunk = this.chunks[i];
            if (!chunk.shouldFlush && !force) continue;
            for (const section of chunk.written){
                const position = chunk.start + section.start;
                if (this.ensureMonotonicity && position !== this.lastFlushEnd) {
                    throw new Error('Internal error: Monotonicity violation.');
                }
                void this.writer.write({
                    type: 'write',
                    data: chunk.data.subarray(section.start, section.end),
                    position
                });
                this.lastFlushEnd = chunk.start + section.end;
            }
            this.chunks.splice(i--, 1);
        }
    }
    finalize() {
        if (this.chunked) {
            this.tryToFlushChunks(true);
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.writer);
        return this.writer.close();
    }
    async close() {
        return this.writer?.close();
    }
}
class NullTargetWriter extends Writer {
    constructor(target){
        super();
        this.target = target;
        this.pos = 0;
    }
    write(data) {
        this.maybeTrackWrites(data);
        this.target.onwrite?.(this.pos, this.pos + data.byteLength);
        this.pos += data.byteLength;
    }
    getPos() {
        return this.pos;
    }
    seek(newPos) {
        this.pos = newPos;
    }
    async flush() {}
    async finalize() {}
    async close() {}
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/node.js [app-route] (ecmascript) <locals>", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ // This file contains Node.js-specific code that does not run in a browser.
__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$externals$5d2f$node$3a$fs$2f$promises__$5b$external$5d$__$28$node$3a$fs$2f$promises$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/node:fs/promises [external] (node:fs/promises, cjs)");
;
}),
"[project]/node_modules/mediabunny/dist/modules/src/node.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "fs",
    ()=>__TURBOPACK__imported__module__$5b$externals$5d2f$node$3a$fs$2f$promises__$5b$external$5d$__$28$node$3a$fs$2f$promises$2c$__cjs$29$__
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$node$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/node.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$externals$5d2f$node$3a$fs$2f$promises__$5b$external$5d$__$28$node$3a$fs$2f$promises$2c$__cjs$29$__ = __turbopack_context__.i("[externals]/node:fs/promises [external] (node:fs/promises, cjs)");
}),
"[project]/node_modules/mediabunny/dist/modules/src/target.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "BufferTarget",
    ()=>BufferTarget,
    "FilePathTarget",
    ()=>FilePathTarget,
    "NullTarget",
    ()=>NullTarget,
    "StreamTarget",
    ()=>StreamTarget,
    "Target",
    ()=>Target
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$writer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/writer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$node$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/node.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
;
;
;
const node = typeof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$node$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ !== 'undefined' ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$node$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ // Aliasing it prevents some bundler warnings
 : undefined;
class Target {
    constructor(){
        /** @internal */ this._output = null;
        /**
         * Called each time data is written to the target. Will be called with the byte range into which data was written.
         *
         * Use this callback to track the size of the output file as it grows. But be warned, this function is chatty and
         * gets called *extremely* often.
         */ this.onwrite = null;
    }
}
class BufferTarget extends Target {
    constructor(){
        super(...arguments);
        /** Stores the final output buffer. Until the output is finalized, this will be `null`. */ this.buffer = null;
    }
    /** @internal */ _createWriter() {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$writer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BufferTargetWriter"](this);
    }
}
class StreamTarget extends Target {
    /** Creates a new {@link StreamTarget} which writes to the specified `writable`. */ constructor(writable, options = {}){
        super();
        if (!(writable instanceof WritableStream)) {
            throw new TypeError('StreamTarget requires a WritableStream instance.');
        }
        if (options != null && typeof options !== 'object') {
            throw new TypeError('StreamTarget options, when provided, must be an object.');
        }
        if (options.chunked !== undefined && typeof options.chunked !== 'boolean') {
            throw new TypeError('options.chunked, when provided, must be a boolean.');
        }
        if (options.chunkSize !== undefined && (!Number.isInteger(options.chunkSize) || options.chunkSize < 1024)) {
            throw new TypeError('options.chunkSize, when provided, must be an integer and not smaller than 1024.');
        }
        this._writable = writable;
        this._options = options;
    }
    /** @internal */ _createWriter() {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$writer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["StreamTargetWriter"](this);
    }
}
class FilePathTarget extends Target {
    /** Creates a new {@link FilePathTarget} that writes to the file at the specified file path. */ constructor(filePath, options = {}){
        if (typeof filePath !== 'string') {
            throw new TypeError('filePath must be a string.');
        }
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        super();
        /** @internal */ this._fileHandle = null;
        // Let's back this target with a StreamTarget, makes the implementation very simple
        const writable = new WritableStream({
            start: async ()=>{
                this._fileHandle = await node.fs.open(filePath, 'w');
            },
            write: async (chunk)=>{
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._fileHandle);
                await this._fileHandle.write(chunk.data, 0, chunk.data.byteLength, chunk.position);
            },
            close: async ()=>{
                if (this._fileHandle) {
                    await this._fileHandle.close();
                    this._fileHandle = null;
                }
            }
        });
        this._streamTarget = new StreamTarget(writable, {
            chunked: true,
            ...options
        });
        this._streamTarget._output = this._output;
    }
    /** @internal */ _createWriter() {
        return this._streamTarget._createWriter();
    }
}
class NullTarget extends Target {
    /** @internal */ _createWriter() {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$writer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NullTargetWriter"](this);
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/metadata.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ /**
 * Image data with additional metadata.
 *
 * @group Metadata tags
 * @public
 */ __turbopack_context__.s([
    "AttachedFile",
    ()=>AttachedFile,
    "DEFAULT_TRACK_DISPOSITION",
    ()=>DEFAULT_TRACK_DISPOSITION,
    "RichImageData",
    ()=>RichImageData,
    "metadataTagsAreEmpty",
    ()=>metadataTagsAreEmpty,
    "validateMetadataTags",
    ()=>validateMetadataTags,
    "validateTrackDisposition",
    ()=>validateTrackDisposition
]);
class RichImageData {
    /** Creates a new {@link RichImageData}. */ constructor(/** The raw image data. */ data, /** An RFC 6838 MIME type (e.g. image/jpeg, image/png, etc.) */ mimeType){
        this.data = data;
        this.mimeType = mimeType;
        if (!(data instanceof Uint8Array)) {
            throw new TypeError('data must be a Uint8Array.');
        }
        if (typeof mimeType !== 'string') {
            throw new TypeError('mimeType must be a string.');
        }
    }
}
class AttachedFile {
    /** Creates a new {@link AttachedFile}. */ constructor(/** The raw file data. */ data, /** An RFC 6838 MIME type (e.g. image/jpeg, image/png, font/ttf, etc.) */ mimeType, /** The name of the file. */ name, /** A description of the file. */ description){
        this.data = data;
        this.mimeType = mimeType;
        this.name = name;
        this.description = description;
        if (!(data instanceof Uint8Array)) {
            throw new TypeError('data must be a Uint8Array.');
        }
        if (mimeType !== undefined && typeof mimeType !== 'string') {
            throw new TypeError('mimeType, when provided, must be a string.');
        }
        if (name !== undefined && typeof name !== 'string') {
            throw new TypeError('name, when provided, must be a string.');
        }
        if (description !== undefined && typeof description !== 'string') {
            throw new TypeError('description, when provided, must be a string.');
        }
    }
}
;
const validateMetadataTags = (tags)=>{
    if (!tags || typeof tags !== 'object') {
        throw new TypeError('tags must be an object.');
    }
    if (tags.title !== undefined && typeof tags.title !== 'string') {
        throw new TypeError('tags.title, when provided, must be a string.');
    }
    if (tags.description !== undefined && typeof tags.description !== 'string') {
        throw new TypeError('tags.description, when provided, must be a string.');
    }
    if (tags.artist !== undefined && typeof tags.artist !== 'string') {
        throw new TypeError('tags.artist, when provided, must be a string.');
    }
    if (tags.album !== undefined && typeof tags.album !== 'string') {
        throw new TypeError('tags.album, when provided, must be a string.');
    }
    if (tags.albumArtist !== undefined && typeof tags.albumArtist !== 'string') {
        throw new TypeError('tags.albumArtist, when provided, must be a string.');
    }
    if (tags.trackNumber !== undefined && (!Number.isInteger(tags.trackNumber) || tags.trackNumber <= 0)) {
        throw new TypeError('tags.trackNumber, when provided, must be a positive integer.');
    }
    if (tags.tracksTotal !== undefined && (!Number.isInteger(tags.tracksTotal) || tags.tracksTotal <= 0)) {
        throw new TypeError('tags.tracksTotal, when provided, must be a positive integer.');
    }
    if (tags.discNumber !== undefined && (!Number.isInteger(tags.discNumber) || tags.discNumber <= 0)) {
        throw new TypeError('tags.discNumber, when provided, must be a positive integer.');
    }
    if (tags.discsTotal !== undefined && (!Number.isInteger(tags.discsTotal) || tags.discsTotal <= 0)) {
        throw new TypeError('tags.discsTotal, when provided, must be a positive integer.');
    }
    if (tags.genre !== undefined && typeof tags.genre !== 'string') {
        throw new TypeError('tags.genre, when provided, must be a string.');
    }
    if (tags.date !== undefined && (!(tags.date instanceof Date) || Number.isNaN(tags.date.getTime()))) {
        throw new TypeError('tags.date, when provided, must be a valid Date.');
    }
    if (tags.lyrics !== undefined && typeof tags.lyrics !== 'string') {
        throw new TypeError('tags.lyrics, when provided, must be a string.');
    }
    if (tags.images !== undefined) {
        if (!Array.isArray(tags.images)) {
            throw new TypeError('tags.images, when provided, must be an array.');
        }
        for (const image of tags.images){
            if (!image || typeof image !== 'object') {
                throw new TypeError('Each image in tags.images must be an object.');
            }
            if (!(image.data instanceof Uint8Array)) {
                throw new TypeError('Each image.data must be a Uint8Array.');
            }
            if (typeof image.mimeType !== 'string') {
                throw new TypeError('Each image.mimeType must be a string.');
            }
            if (![
                'coverFront',
                'coverBack',
                'unknown'
            ].includes(image.kind)) {
                throw new TypeError('Each image.kind must be \'coverFront\', \'coverBack\', or \'unknown\'.');
            }
        }
    }
    if (tags.comment !== undefined && typeof tags.comment !== 'string') {
        throw new TypeError('tags.comment, when provided, must be a string.');
    }
    if (tags.raw !== undefined) {
        if (!tags.raw || typeof tags.raw !== 'object') {
            throw new TypeError('tags.raw, when provided, must be an object.');
        }
        for (const value of Object.values(tags.raw)){
            if (value !== null && typeof value !== 'string' && !(value instanceof Uint8Array) && !(value instanceof RichImageData) && !(value instanceof AttachedFile)) {
                throw new TypeError('Each value in tags.raw must be a string, Uint8Array, RichImageData, AttachedFile, or null.');
            }
        }
    }
};
const metadataTagsAreEmpty = (tags)=>{
    return tags.title === undefined && tags.description === undefined && tags.artist === undefined && tags.album === undefined && tags.albumArtist === undefined && tags.trackNumber === undefined && tags.tracksTotal === undefined && tags.discNumber === undefined && tags.discsTotal === undefined && tags.genre === undefined && tags.date === undefined && tags.lyrics === undefined && (!tags.images || tags.images.length === 0) && tags.comment === undefined && (tags.raw === undefined || Object.keys(tags.raw).length === 0);
};
const DEFAULT_TRACK_DISPOSITION = {
    default: true,
    forced: false,
    original: false,
    commentary: false,
    hearingImpaired: false,
    visuallyImpaired: false
};
const validateTrackDisposition = (disposition)=>{
    if (!disposition || typeof disposition !== 'object') {
        throw new TypeError('disposition must be an object.');
    }
    if (disposition.default !== undefined && typeof disposition.default !== 'boolean') {
        throw new TypeError('disposition.default must be a boolean.');
    }
    if (disposition.forced !== undefined && typeof disposition.forced !== 'boolean') {
        throw new TypeError('disposition.forced must be a boolean.');
    }
    if (disposition.original !== undefined && typeof disposition.original !== 'boolean') {
        throw new TypeError('disposition.original must be a boolean.');
    }
    if (disposition.commentary !== undefined && typeof disposition.commentary !== 'boolean') {
        throw new TypeError('disposition.commentary must be a boolean.');
    }
    if (disposition.hearingImpaired !== undefined && typeof disposition.hearingImpaired !== 'boolean') {
        throw new TypeError('disposition.hearingImpaired must be a boolean.');
    }
    if (disposition.visuallyImpaired !== undefined && typeof disposition.visuallyImpaired !== 'boolean') {
        throw new TypeError('disposition.visuallyImpaired must be a boolean.');
    }
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/muxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "Muxer",
    ()=>Muxer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
;
class Muxer {
    constructor(output){
        this.mutex = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AsyncMutex"]();
        /**
         * This field is used to synchronize multiple MediaStreamTracks. They use the same time coordinate system across
         * tracks, and to ensure correct audio-video sync, we must use the same offset for all of them. The reason an offset
         * is needed at all is because the timestamps typically don't start at zero.
         */ this.firstMediaStreamTimestamp = null;
        this.trackTimestampInfo = new WeakMap();
        this.output = output;
    }
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    onTrackClose(track) {}
    validateAndNormalizeTimestamp(track, timestampInSeconds, isKeyPacket) {
        timestampInSeconds += track.source._timestampOffset;
        let timestampInfo = this.trackTimestampInfo.get(track);
        if (!timestampInfo) {
            if (!isKeyPacket) {
                throw new Error('First packet must be a key packet.');
            }
            timestampInfo = {
                maxTimestamp: timestampInSeconds,
                maxTimestampBeforeLastKeyPacket: timestampInSeconds
            };
            this.trackTimestampInfo.set(track, timestampInfo);
        }
        if (timestampInSeconds < 0) {
            throw new Error(`Timestamps must be non-negative (got ${timestampInSeconds}s).`);
        }
        if (isKeyPacket) {
            timestampInfo.maxTimestampBeforeLastKeyPacket = timestampInfo.maxTimestamp;
        }
        if (timestampInSeconds < timestampInfo.maxTimestampBeforeLastKeyPacket) {
            throw new Error(`Timestamps cannot be smaller than the largest timestamp of the previous GOP (a GOP begins with a key` + ` packet and ends right before the next key packet). Got ${timestampInSeconds}s, but largest` + ` timestamp is ${timestampInfo.maxTimestampBeforeLastKeyPacket}s.`);
        }
        timestampInfo.maxTimestamp = Math.max(timestampInfo.maxTimestamp, timestampInSeconds);
        return timestampInSeconds;
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/adts/adts-muxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "AdtsMuxer",
    ()=>AdtsMuxer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/muxer.js [app-route] (ecmascript)");
;
;
;
class AdtsMuxer extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Muxer"] {
    constructor(output, format){
        super(output);
        this.header = new Uint8Array(7);
        this.headerBitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](this.header);
        this.audioSpecificConfig = null;
        this.format = format;
        this.writer = output._writer;
    }
    async start() {
    // Nothing needed here
    }
    async getMimeType() {
        return 'audio/aac';
    }
    async addEncodedVideoPacket() {
        throw new Error('ADTS does not support video.');
    }
    async addEncodedAudioPacket(track, packet, meta) {
        // https://wiki.multimedia.cx/index.php/ADTS (last visited: 2025/08/17)
        const release = await this.mutex.acquire();
        try {
            this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === 'key');
            if (!this.audioSpecificConfig) {
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateAudioChunkMetadata"])(meta);
                const description = meta?.decoderConfig?.description;
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(description);
                this.audioSpecificConfig = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseAacAudioSpecificConfig"])((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(description));
                const { objectType, frequencyIndex, channelConfiguration } = this.audioSpecificConfig;
                const profile = objectType - 1;
                this.headerBitstream.writeBits(12, 0b1111_11111111); // Syncword
                this.headerBitstream.writeBits(1, 0); // MPEG Version
                this.headerBitstream.writeBits(2, 0); // Layer
                this.headerBitstream.writeBits(1, 1); // Protection absence
                this.headerBitstream.writeBits(2, profile); // Profile
                this.headerBitstream.writeBits(4, frequencyIndex); // MPEG-4 Sampling Frequency Index
                this.headerBitstream.writeBits(1, 0); // Private bit
                this.headerBitstream.writeBits(3, channelConfiguration); // MPEG-4 Channel Configuration
                this.headerBitstream.writeBits(1, 0); // Originality
                this.headerBitstream.writeBits(1, 0); // Home
                this.headerBitstream.writeBits(1, 0); // Copyright ID bit
                this.headerBitstream.writeBits(1, 0); // Copyright ID start
                this.headerBitstream.skipBits(13); // Frame length
                this.headerBitstream.writeBits(11, 0x7ff); // Buffer fullness
                this.headerBitstream.writeBits(2, 0); // Number of AAC frames minus 1
            // Omit CRC check
            }
            const frameLength = packet.data.byteLength + this.header.byteLength;
            this.headerBitstream.pos = 30;
            this.headerBitstream.writeBits(13, frameLength);
            const startPos = this.writer.getPos();
            this.writer.write(this.header);
            this.writer.write(packet.data);
            if (this.format._options.onFrame) {
                const frameBytes = new Uint8Array(frameLength);
                frameBytes.set(this.header, 0);
                frameBytes.set(packet.data, this.header.byteLength);
                this.format._options.onFrame(frameBytes, startPos);
            }
            await this.writer.flush();
        } finally{
            release();
        }
    }
    async addSubtitleCue() {
        throw new Error('ADTS does not support subtitles.');
    }
    async finalize() {}
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/adts/adts-reader.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "MAX_FRAME_HEADER_SIZE",
    ()=>MAX_FRAME_HEADER_SIZE,
    "MIN_FRAME_HEADER_SIZE",
    ()=>MIN_FRAME_HEADER_SIZE,
    "readFrameHeader",
    ()=>readFrameHeader
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
;
;
const MIN_FRAME_HEADER_SIZE = 7;
const MAX_FRAME_HEADER_SIZE = 9;
const readFrameHeader = (slice)=>{
    // https://wiki.multimedia.cx/index.php/ADTS (last visited: 2025/08/17)
    const startPos = slice.filePos;
    const bytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, 9); // 9 with CRC, 7 without CRC
    const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](bytes);
    const syncword = bitstream.readBits(12);
    if (syncword !== 0b1111_11111111) {
        return null;
    }
    bitstream.skipBits(1); // MPEG version
    const layer = bitstream.readBits(2);
    if (layer !== 0) {
        return null;
    }
    const protectionAbsence = bitstream.readBits(1);
    const objectType = bitstream.readBits(2) + 1;
    const samplingFrequencyIndex = bitstream.readBits(4);
    if (samplingFrequencyIndex === 15) {
        return null;
    }
    bitstream.skipBits(1); // Private bit
    const channelConfiguration = bitstream.readBits(3);
    if (channelConfiguration === 0) {
        throw new Error('ADTS frames with channel configuration 0 are not supported.');
    }
    bitstream.skipBits(1); // Originality
    bitstream.skipBits(1); // Home
    bitstream.skipBits(1); // Copyright ID bit
    bitstream.skipBits(1); // Copyright ID start
    const frameLength = bitstream.readBits(13);
    bitstream.skipBits(11); // Buffer fullness
    const numberOfAacFrames = bitstream.readBits(2) + 1;
    if (numberOfAacFrames !== 1) {
        throw new Error('ADTS frames with more than one AAC frame are not supported.');
    }
    let crcCheck = null;
    if (protectionAbsence === 1) {
        slice.filePos -= 2;
    } else {
        crcCheck = bitstream.readBits(16);
    }
    return {
        objectType,
        samplingFrequencyIndex,
        channelConfiguration,
        frameLength,
        numberOfAacFrames,
        crcCheck,
        startPos
    };
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/adts/adts-demuxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "AdtsDemuxer",
    ()=>AdtsDemuxer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/input-track.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/packet.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/metadata.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/adts/adts-reader.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
const SAMPLES_PER_AAC_FRAME = 1024;
class AdtsDemuxer extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Demuxer"] {
    constructor(input){
        super(input);
        this.metadataPromise = null;
        this.firstFrameHeader = null;
        this.loadedSamples = [];
        this.tracks = [];
        this.readingMutex = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AsyncMutex"]();
        this.lastSampleLoaded = false;
        this.lastLoadedPos = 0;
        this.nextTimestampInSamples = 0;
        this.reader = input._reader;
    }
    async readMetadata() {
        return this.metadataPromise ??= (async ()=>{
            // Keep loading until we find the first frame header
            while(!this.firstFrameHeader && !this.lastSampleLoaded){
                await this.advanceReader();
            }
            // There has to be a frame if this demuxer got selected
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.firstFrameHeader);
            // Create the single audio track
            this.tracks = [
                new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputAudioTrack"](this.input, new AdtsAudioTrackBacking(this))
            ];
        })();
    }
    async advanceReader() {
        let slice = this.reader.requestSliceRange(this.lastLoadedPos, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_FRAME_HEADER_SIZE"], __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_FRAME_HEADER_SIZE"]);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) {
            this.lastSampleLoaded = true;
            return;
        }
        const header = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readFrameHeader"])(slice);
        if (!header) {
            this.lastSampleLoaded = true;
            return;
        }
        if (this.reader.fileSize !== null && header.startPos + header.frameLength > this.reader.fileSize) {
            // Frame doesn't fit in the rest of the file
            this.lastSampleLoaded = true;
            return;
        }
        if (!this.firstFrameHeader) {
            this.firstFrameHeader = header;
        }
        const sampleRate = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["aacFrequencyTable"][header.samplingFrequencyIndex];
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(sampleRate !== undefined);
        const sampleDuration = SAMPLES_PER_AAC_FRAME / sampleRate;
        const headerSize = header.crcCheck ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_FRAME_HEADER_SIZE"] : __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_FRAME_HEADER_SIZE"];
        const sample = {
            timestamp: this.nextTimestampInSamples / sampleRate,
            duration: sampleDuration,
            dataStart: header.startPos + headerSize,
            dataSize: header.frameLength - headerSize
        };
        this.loadedSamples.push(sample);
        this.nextTimestampInSamples += SAMPLES_PER_AAC_FRAME;
        this.lastLoadedPos = header.startPos + header.frameLength;
    }
    async getMimeType() {
        return 'audio/aac';
    }
    async getTracks() {
        await this.readMetadata();
        return this.tracks;
    }
    async computeDuration() {
        await this.readMetadata();
        const track = this.tracks[0];
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(track);
        return track.computeDuration();
    }
    async getMetadataTags() {
        return {}; // No tags in this one
    }
}
class AdtsAudioTrackBacking {
    constructor(demuxer){
        this.demuxer = demuxer;
    }
    getId() {
        return 1;
    }
    async getFirstTimestamp() {
        return 0;
    }
    getTimeResolution() {
        const sampleRate = this.getSampleRate();
        return sampleRate / SAMPLES_PER_AAC_FRAME;
    }
    async computeDuration() {
        const lastPacket = await this.getPacket(Infinity, {
            metadataOnly: true
        });
        return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);
    }
    getName() {
        return null;
    }
    getLanguageCode() {
        return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["UNDETERMINED_LANGUAGE"];
    }
    getCodec() {
        return 'aac';
    }
    getInternalCodecId() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.firstFrameHeader);
        return this.demuxer.firstFrameHeader.objectType;
    }
    getNumberOfChannels() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.firstFrameHeader);
        const numberOfChannels = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["aacChannelMap"][this.demuxer.firstFrameHeader.channelConfiguration];
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(numberOfChannels !== undefined);
        return numberOfChannels;
    }
    getSampleRate() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.firstFrameHeader);
        const sampleRate = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["aacFrequencyTable"][this.demuxer.firstFrameHeader.samplingFrequencyIndex];
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(sampleRate !== undefined);
        return sampleRate;
    }
    getDisposition() {
        return {
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["DEFAULT_TRACK_DISPOSITION"]
        };
    }
    async getDecoderConfig() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.firstFrameHeader);
        const bytes = new Uint8Array(3); // 19 bits max
        const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](bytes);
        const { objectType, samplingFrequencyIndex, channelConfiguration } = this.demuxer.firstFrameHeader;
        if (objectType > 31) {
            bitstream.writeBits(5, 31);
            bitstream.writeBits(6, objectType - 32);
        } else {
            bitstream.writeBits(5, objectType);
        }
        bitstream.writeBits(4, samplingFrequencyIndex); // samplingFrequencyIndex === 15 is forbidden
        bitstream.writeBits(4, channelConfiguration);
        return {
            codec: `mp4a.40.${this.demuxer.firstFrameHeader.objectType}`,
            numberOfChannels: this.getNumberOfChannels(),
            sampleRate: this.getSampleRate(),
            description: bytes.subarray(0, Math.ceil((bitstream.pos - 1) / 8))
        };
    }
    async getPacketAtIndex(sampleIndex, options) {
        if (sampleIndex === -1) {
            return null;
        }
        const rawSample = this.demuxer.loadedSamples[sampleIndex];
        if (!rawSample) {
            return null;
        }
        let data;
        if (options.metadataOnly) {
            data = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PLACEHOLDER_DATA"];
        } else {
            let slice = this.demuxer.reader.requestSlice(rawSample.dataStart, rawSample.dataSize);
            if (slice instanceof Promise) slice = await slice;
            if (!slice) {
                return null; // Data didn't fit into the rest of the file
            }
            data = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, rawSample.dataSize);
        }
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"](data, 'key', rawSample.timestamp, rawSample.duration, sampleIndex, rawSample.dataSize);
    }
    getFirstPacket(options) {
        return this.getPacketAtIndex(0, options);
    }
    async getNextPacket(packet, options) {
        const release = await this.demuxer.readingMutex.acquire();
        try {
            const sampleIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["binarySearchExact"])(this.demuxer.loadedSamples, packet.timestamp, (x)=>x.timestamp);
            if (sampleIndex === -1) {
                throw new Error('Packet was not created from this track.');
            }
            const nextIndex = sampleIndex + 1;
            // Ensure the next sample exists
            while(nextIndex >= this.demuxer.loadedSamples.length && !this.demuxer.lastSampleLoaded){
                await this.demuxer.advanceReader();
            }
            return this.getPacketAtIndex(nextIndex, options);
        } finally{
            release();
        }
    }
    async getPacket(timestamp, options) {
        const release = await this.demuxer.readingMutex.acquire();
        try {
            while(true){
                const index = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["binarySearchLessOrEqual"])(this.demuxer.loadedSamples, timestamp, (x)=>x.timestamp);
                if (index === -1 && this.demuxer.loadedSamples.length > 0) {
                    // We're before the first sample
                    return null;
                }
                if (this.demuxer.lastSampleLoaded) {
                    // All data is loaded, return what we found
                    return this.getPacketAtIndex(index, options);
                }
                if (index >= 0 && index + 1 < this.demuxer.loadedSamples.length) {
                    // The next packet also exists, we're done
                    return this.getPacketAtIndex(index, options);
                }
                // Otherwise, keep loading data
                await this.demuxer.advanceReader();
            }
        } finally{
            release();
        }
    }
    getKeyPacket(timestamp, options) {
        return this.getPacket(timestamp, options);
    }
    getNextKeyPacket(packet, options) {
        return this.getNextPacket(packet, options);
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/codec-data.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "AvcNalUnitType",
    ()=>AvcNalUnitType,
    "FlacBlockType",
    ()=>FlacBlockType,
    "HevcNalUnitType",
    ()=>HevcNalUnitType,
    "createVorbisComments",
    ()=>createVorbisComments,
    "deserializeAvcDecoderConfigurationRecord",
    ()=>deserializeAvcDecoderConfigurationRecord,
    "determineVideoPacketType",
    ()=>determineVideoPacketType,
    "extractAv1CodecInfoFromPacket",
    ()=>extractAv1CodecInfoFromPacket,
    "extractAvcDecoderConfigurationRecord",
    ()=>extractAvcDecoderConfigurationRecord,
    "extractAvcNalUnits",
    ()=>extractAvcNalUnits,
    "extractHevcDecoderConfigurationRecord",
    ()=>extractHevcDecoderConfigurationRecord,
    "extractHevcNalUnits",
    ()=>extractHevcNalUnits,
    "extractNalUnitTypeForHevc",
    ()=>extractNalUnitTypeForHevc,
    "extractVp9CodecInfoFromPacket",
    ()=>extractVp9CodecInfoFromPacket,
    "findNalUnitsInAnnexB",
    ()=>findNalUnitsInAnnexB,
    "iterateAv1PacketObus",
    ()=>iterateAv1PacketObus,
    "parseAvcSps",
    ()=>parseAvcSps,
    "parseModesFromVorbisSetupPacket",
    ()=>parseModesFromVorbisSetupPacket,
    "parseOpusIdentificationHeader",
    ()=>parseOpusIdentificationHeader,
    "parseOpusTocByte",
    ()=>parseOpusTocByte,
    "readVorbisComments",
    ()=>readVorbisComments,
    "serializeAvcDecoderConfigurationRecord",
    ()=>serializeAvcDecoderConfigurationRecord,
    "serializeHevcDecoderConfigurationRecord",
    ()=>serializeHevcDecoderConfigurationRecord,
    "transformAnnexBToLengthPrefixed",
    ()=>transformAnnexBToLengthPrefixed
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
;
;
var AvcNalUnitType;
(function(AvcNalUnitType) {
    AvcNalUnitType[AvcNalUnitType["IDR"] = 5] = "IDR";
    AvcNalUnitType[AvcNalUnitType["SEI"] = 6] = "SEI";
    AvcNalUnitType[AvcNalUnitType["SPS"] = 7] = "SPS";
    AvcNalUnitType[AvcNalUnitType["PPS"] = 8] = "PPS";
    AvcNalUnitType[AvcNalUnitType["SPS_EXT"] = 13] = "SPS_EXT";
})(AvcNalUnitType || (AvcNalUnitType = {}));
var HevcNalUnitType;
(function(HevcNalUnitType) {
    HevcNalUnitType[HevcNalUnitType["RASL_N"] = 8] = "RASL_N";
    HevcNalUnitType[HevcNalUnitType["RASL_R"] = 9] = "RASL_R";
    HevcNalUnitType[HevcNalUnitType["BLA_W_LP"] = 16] = "BLA_W_LP";
    HevcNalUnitType[HevcNalUnitType["RSV_IRAP_VCL23"] = 23] = "RSV_IRAP_VCL23";
    HevcNalUnitType[HevcNalUnitType["VPS_NUT"] = 32] = "VPS_NUT";
    HevcNalUnitType[HevcNalUnitType["SPS_NUT"] = 33] = "SPS_NUT";
    HevcNalUnitType[HevcNalUnitType["PPS_NUT"] = 34] = "PPS_NUT";
    HevcNalUnitType[HevcNalUnitType["PREFIX_SEI_NUT"] = 39] = "PREFIX_SEI_NUT";
    HevcNalUnitType[HevcNalUnitType["SUFFIX_SEI_NUT"] = 40] = "SUFFIX_SEI_NUT";
})(HevcNalUnitType || (HevcNalUnitType = {}));
const findNalUnitsInAnnexB = (packetData)=>{
    const nalUnits = [];
    let i = 0;
    while(i < packetData.length){
        let startCodePos = -1;
        let startCodeLength = 0;
        for(let j = i; j < packetData.length - 3; j++){
            // Check for 3-byte start code (0x000001)
            if (packetData[j] === 0 && packetData[j + 1] === 0 && packetData[j + 2] === 1) {
                startCodePos = j;
                startCodeLength = 3;
                break;
            }
            // Check for 4-byte start code (0x00000001)
            if (j < packetData.length - 4 && packetData[j] === 0 && packetData[j + 1] === 0 && packetData[j + 2] === 0 && packetData[j + 3] === 1) {
                startCodePos = j;
                startCodeLength = 4;
                break;
            }
        }
        if (startCodePos === -1) {
            break; // No more start codes found
        }
        // If this isn't the first start code, extract the previous NAL unit
        if (i > 0 && startCodePos > i) {
            const nalData = packetData.subarray(i, startCodePos);
            if (nalData.length > 0) {
                nalUnits.push(nalData);
            }
        }
        i = startCodePos + startCodeLength;
    }
    // Extract the last NAL unit if there is one
    if (i < packetData.length) {
        const nalData = packetData.subarray(i);
        if (nalData.length > 0) {
            nalUnits.push(nalData);
        }
    }
    return nalUnits;
};
/** Finds all NAL units in an AVC packet in length-prefixed format. */ const findNalUnitsInLengthPrefixed = (packetData, lengthSize)=>{
    const nalUnits = [];
    let offset = 0;
    const dataView = new DataView(packetData.buffer, packetData.byteOffset, packetData.byteLength);
    while(offset + lengthSize <= packetData.length){
        let nalUnitLength;
        if (lengthSize === 1) {
            nalUnitLength = dataView.getUint8(offset);
        } else if (lengthSize === 2) {
            nalUnitLength = dataView.getUint16(offset, false);
        } else if (lengthSize === 3) {
            nalUnitLength = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getUint24"])(dataView, offset, false);
        } else if (lengthSize === 4) {
            nalUnitLength = dataView.getUint32(offset, false);
        } else {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(lengthSize);
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
        }
        offset += lengthSize;
        const nalUnit = packetData.subarray(offset, offset + nalUnitLength);
        nalUnits.push(nalUnit);
        offset += nalUnitLength;
    }
    return nalUnits;
};
const removeEmulationPreventionBytes = (data)=>{
    const result = [];
    const len = data.length;
    for(let i = 0; i < len; i++){
        // Look for the 0x000003 pattern
        if (i + 2 < len && data[i] === 0x00 && data[i + 1] === 0x00 && data[i + 2] === 0x03) {
            result.push(0x00, 0x00); // Push the first two bytes
            i += 2; // Skip the 0x03 byte
        } else {
            result.push(data[i]);
        }
    }
    return new Uint8Array(result);
};
const transformAnnexBToLengthPrefixed = (packetData)=>{
    const NAL_UNIT_LENGTH_SIZE = 4;
    const nalUnits = findNalUnitsInAnnexB(packetData);
    if (nalUnits.length === 0) {
        // If no NAL units were found, it's not valid Annex B data
        return null;
    }
    let totalSize = 0;
    for (const nalUnit of nalUnits){
        totalSize += NAL_UNIT_LENGTH_SIZE + nalUnit.byteLength;
    }
    const avccData = new Uint8Array(totalSize);
    const dataView = new DataView(avccData.buffer);
    let offset = 0;
    // Write each NAL unit with its length prefix
    for (const nalUnit of nalUnits){
        const length = nalUnit.byteLength;
        dataView.setUint32(offset, length, false);
        offset += 4;
        avccData.set(nalUnit, offset);
        offset += nalUnit.byteLength;
    }
    return avccData;
};
const extractAvcNalUnits = (packetData, decoderConfig)=>{
    if (decoderConfig.description) {
        // Stream is length-prefixed. Let's extract the size of the length prefix from the decoder config
        const bytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(decoderConfig.description);
        const lengthSizeMinusOne = bytes[4] & 0b11;
        const lengthSize = lengthSizeMinusOne + 1;
        return findNalUnitsInLengthPrefixed(packetData, lengthSize);
    } else {
        // Stream is in Annex B format
        return findNalUnitsInAnnexB(packetData);
    }
};
const extractNalUnitTypeForAvc = (data)=>{
    return data[0] & 0x1F;
};
const extractAvcDecoderConfigurationRecord = (packetData)=>{
    try {
        const nalUnits = findNalUnitsInAnnexB(packetData);
        const spsUnits = nalUnits.filter((unit)=>extractNalUnitTypeForAvc(unit) === AvcNalUnitType.SPS);
        const ppsUnits = nalUnits.filter((unit)=>extractNalUnitTypeForAvc(unit) === AvcNalUnitType.PPS);
        const spsExtUnits = nalUnits.filter((unit)=>extractNalUnitTypeForAvc(unit) === AvcNalUnitType.SPS_EXT);
        if (spsUnits.length === 0) {
            return null;
        }
        if (ppsUnits.length === 0) {
            return null;
        }
        // Let's get the first SPS for profile and level information
        const spsData = spsUnits[0];
        const spsInfo = parseAvcSps(spsData);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(spsInfo !== null);
        const hasExtendedData = spsInfo.profileIdc === 100 || spsInfo.profileIdc === 110 || spsInfo.profileIdc === 122 || spsInfo.profileIdc === 144;
        return {
            configurationVersion: 1,
            avcProfileIndication: spsInfo.profileIdc,
            profileCompatibility: spsInfo.constraintFlags,
            avcLevelIndication: spsInfo.levelIdc,
            lengthSizeMinusOne: 3,
            sequenceParameterSets: spsUnits,
            pictureParameterSets: ppsUnits,
            chromaFormat: hasExtendedData ? spsInfo.chromaFormatIdc : null,
            bitDepthLumaMinus8: hasExtendedData ? spsInfo.bitDepthLumaMinus8 : null,
            bitDepthChromaMinus8: hasExtendedData ? spsInfo.bitDepthChromaMinus8 : null,
            sequenceParameterSetExt: hasExtendedData ? spsExtUnits : null
        };
    } catch (error) {
        console.error('Error building AVC Decoder Configuration Record:', error);
        return null;
    }
};
const serializeAvcDecoderConfigurationRecord = (record)=>{
    const bytes = [];
    // Write header
    bytes.push(record.configurationVersion);
    bytes.push(record.avcProfileIndication);
    bytes.push(record.profileCompatibility);
    bytes.push(record.avcLevelIndication);
    bytes.push(0xFC | record.lengthSizeMinusOne & 0x03); // Reserved bits (6) + lengthSizeMinusOne (2)
    // Reserved bits (3) + numOfSequenceParameterSets (5)
    bytes.push(0xE0 | record.sequenceParameterSets.length & 0x1F);
    // Write SPS
    for (const sps of record.sequenceParameterSets){
        const length = sps.byteLength;
        bytes.push(length >> 8); // High byte
        bytes.push(length & 0xFF); // Low byte
        for(let i = 0; i < length; i++){
            bytes.push(sps[i]);
        }
    }
    bytes.push(record.pictureParameterSets.length);
    // Write PPS
    for (const pps of record.pictureParameterSets){
        const length = pps.byteLength;
        bytes.push(length >> 8); // High byte
        bytes.push(length & 0xFF); // Low byte
        for(let i = 0; i < length; i++){
            bytes.push(pps[i]);
        }
    }
    if (record.avcProfileIndication === 100 || record.avcProfileIndication === 110 || record.avcProfileIndication === 122 || record.avcProfileIndication === 144) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(record.chromaFormat !== null);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(record.bitDepthLumaMinus8 !== null);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(record.bitDepthChromaMinus8 !== null);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(record.sequenceParameterSetExt !== null);
        bytes.push(0xFC | record.chromaFormat & 0x03); // Reserved bits + chroma_format
        bytes.push(0xF8 | record.bitDepthLumaMinus8 & 0x07); // Reserved bits + bit_depth_luma_minus8
        bytes.push(0xF8 | record.bitDepthChromaMinus8 & 0x07); // Reserved bits + bit_depth_chroma_minus8
        bytes.push(record.sequenceParameterSetExt.length);
        // Write SPS Ext
        for (const spsExt of record.sequenceParameterSetExt){
            const length = spsExt.byteLength;
            bytes.push(length >> 8); // High byte
            bytes.push(length & 0xFF); // Low byte
            for(let i = 0; i < length; i++){
                bytes.push(spsExt[i]);
            }
        }
    }
    return new Uint8Array(bytes);
};
const deserializeAvcDecoderConfigurationRecord = (data)=>{
    try {
        const view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(data);
        let offset = 0;
        // Read header
        const configurationVersion = view.getUint8(offset++);
        const avcProfileIndication = view.getUint8(offset++);
        const profileCompatibility = view.getUint8(offset++);
        const avcLevelIndication = view.getUint8(offset++);
        const lengthSizeMinusOne = view.getUint8(offset++) & 0x03;
        const numOfSequenceParameterSets = view.getUint8(offset++) & 0x1F;
        // Read SPS
        const sequenceParameterSets = [];
        for(let i = 0; i < numOfSequenceParameterSets; i++){
            const length = view.getUint16(offset, false);
            offset += 2;
            sequenceParameterSets.push(data.subarray(offset, offset + length));
            offset += length;
        }
        const numOfPictureParameterSets = view.getUint8(offset++);
        // Read PPS
        const pictureParameterSets = [];
        for(let i = 0; i < numOfPictureParameterSets; i++){
            const length = view.getUint16(offset, false);
            offset += 2;
            pictureParameterSets.push(data.subarray(offset, offset + length));
            offset += length;
        }
        const record = {
            configurationVersion,
            avcProfileIndication,
            profileCompatibility,
            avcLevelIndication,
            lengthSizeMinusOne,
            sequenceParameterSets,
            pictureParameterSets,
            chromaFormat: null,
            bitDepthLumaMinus8: null,
            bitDepthChromaMinus8: null,
            sequenceParameterSetExt: null
        };
        // Check if there are extended profile fields
        if ((avcProfileIndication === 100 || avcProfileIndication === 110 || avcProfileIndication === 122 || avcProfileIndication === 144) && offset + 4 <= data.length) {
            const chromaFormat = view.getUint8(offset++) & 0x03;
            const bitDepthLumaMinus8 = view.getUint8(offset++) & 0x07;
            const bitDepthChromaMinus8 = view.getUint8(offset++) & 0x07;
            const numOfSequenceParameterSetExt = view.getUint8(offset++);
            record.chromaFormat = chromaFormat;
            record.bitDepthLumaMinus8 = bitDepthLumaMinus8;
            record.bitDepthChromaMinus8 = bitDepthChromaMinus8;
            // Read SPS Ext
            const sequenceParameterSetExt = [];
            for(let i = 0; i < numOfSequenceParameterSetExt; i++){
                const length = view.getUint16(offset, false);
                offset += 2;
                sequenceParameterSetExt.push(data.subarray(offset, offset + length));
                offset += length;
            }
            record.sequenceParameterSetExt = sequenceParameterSetExt;
        }
        return record;
    } catch (error) {
        console.error('Error deserializing AVC Decoder Configuration Record:', error);
        return null;
    }
};
const parseAvcSps = (sps)=>{
    try {
        const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](removeEmulationPreventionBytes(sps));
        bitstream.skipBits(1); // forbidden_zero_bit
        bitstream.skipBits(2); // nal_ref_idc
        const nalUnitType = bitstream.readBits(5);
        if (nalUnitType !== 7) {
            return null;
        }
        const profileIdc = bitstream.readAlignedByte();
        const constraintFlags = bitstream.readAlignedByte();
        const levelIdc = bitstream.readAlignedByte();
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // seq_parameter_set_id
        let chromaFormatIdc = null;
        let bitDepthLumaMinus8 = null;
        let bitDepthChromaMinus8 = null;
        // Handle high profile chroma_format_idc
        if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128) {
            chromaFormatIdc = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
            if (chromaFormatIdc === 3) {
                bitstream.skipBits(1); // separate_colour_plane_flag
            }
            bitDepthLumaMinus8 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
            bitDepthChromaMinus8 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
            bitstream.skipBits(1); // qpprime_y_zero_transform_bypass_flag
            const seqScalingMatrixPresentFlag = bitstream.readBits(1);
            if (seqScalingMatrixPresentFlag) {
                for(let i = 0; i < (chromaFormatIdc !== 3 ? 8 : 12); i++){
                    const seqScalingListPresentFlag = bitstream.readBits(1);
                    if (seqScalingListPresentFlag) {
                        const sizeOfScalingList = i < 6 ? 16 : 64;
                        let lastScale = 8;
                        let nextScale = 8;
                        for(let j = 0; j < sizeOfScalingList; j++){
                            if (nextScale !== 0) {
                                const deltaScale = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readSignedExpGolomb"])(bitstream);
                                nextScale = (lastScale + deltaScale + 256) % 256;
                            }
                            lastScale = nextScale === 0 ? lastScale : nextScale;
                        }
                    }
                }
            }
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // log2_max_frame_num_minus4
        const picOrderCntType = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
        if (picOrderCntType === 0) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // log2_max_pic_order_cnt_lsb_minus4
        } else if (picOrderCntType === 1) {
            bitstream.skipBits(1); // delta_pic_order_always_zero_flag
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readSignedExpGolomb"])(bitstream); // offset_for_non_ref_pic
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readSignedExpGolomb"])(bitstream); // offset_for_top_to_bottom_field
            const numRefFramesInPicOrderCntCycle = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
            for(let i = 0; i < numRefFramesInPicOrderCntCycle; i++){
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readSignedExpGolomb"])(bitstream); // offset_for_ref_frame[i]
            }
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // max_num_ref_frames
        bitstream.skipBits(1); // gaps_in_frame_num_value_allowed_flag
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // pic_width_in_mbs_minus1
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // pic_height_in_map_units_minus1
        const frameMbsOnlyFlag = bitstream.readBits(1);
        return {
            profileIdc,
            constraintFlags,
            levelIdc,
            frameMbsOnlyFlag,
            chromaFormatIdc,
            bitDepthLumaMinus8,
            bitDepthChromaMinus8
        };
    } catch (error) {
        console.error('Error parsing AVC SPS:', error);
        return null;
    }
};
const extractHevcNalUnits = (packetData, decoderConfig)=>{
    if (decoderConfig.description) {
        // Stream is length-prefixed. Let's extract the size of the length prefix from the decoder config
        const bytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(decoderConfig.description);
        const lengthSizeMinusOne = bytes[21] & 0b11;
        const lengthSize = lengthSizeMinusOne + 1;
        return findNalUnitsInLengthPrefixed(packetData, lengthSize);
    } else {
        // Stream is in Annex B format
        return findNalUnitsInAnnexB(packetData);
    }
};
const extractNalUnitTypeForHevc = (data)=>{
    return data[0] >> 1 & 0x3F;
};
const extractHevcDecoderConfigurationRecord = (packetData)=>{
    try {
        const nalUnits = findNalUnitsInAnnexB(packetData);
        const vpsUnits = nalUnits.filter((unit)=>extractNalUnitTypeForHevc(unit) === HevcNalUnitType.VPS_NUT);
        const spsUnits = nalUnits.filter((unit)=>extractNalUnitTypeForHevc(unit) === HevcNalUnitType.SPS_NUT);
        const ppsUnits = nalUnits.filter((unit)=>extractNalUnitTypeForHevc(unit) === HevcNalUnitType.PPS_NUT);
        const seiUnits = nalUnits.filter((unit)=>extractNalUnitTypeForHevc(unit) === HevcNalUnitType.PREFIX_SEI_NUT || extractNalUnitTypeForHevc(unit) === HevcNalUnitType.SUFFIX_SEI_NUT);
        if (spsUnits.length === 0 || ppsUnits.length === 0) return null;
        const sps = spsUnits[0];
        const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](removeEmulationPreventionBytes(sps));
        bitstream.skipBits(16); // NAL header
        bitstream.readBits(4); // sps_video_parameter_set_id
        const sps_max_sub_layers_minus1 = bitstream.readBits(3);
        const sps_temporal_id_nesting_flag = bitstream.readBits(1);
        const { general_profile_space, general_tier_flag, general_profile_idc, general_profile_compatibility_flags, general_constraint_indicator_flags, general_level_idc } = parseProfileTierLevel(bitstream, sps_max_sub_layers_minus1);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // sps_seq_parameter_set_id
        const chroma_format_idc = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
        if (chroma_format_idc === 3) bitstream.skipBits(1); // separate_colour_plane_flag
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // pic_width_in_luma_samples
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // pic_height_in_luma_samples
        if (bitstream.readBits(1)) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // conf_win_left_offset
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // conf_win_right_offset
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // conf_win_top_offset
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // conf_win_bottom_offset
        }
        const bit_depth_luma_minus8 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
        const bit_depth_chroma_minus8 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // log2_max_pic_order_cnt_lsb_minus4
        const sps_sub_layer_ordering_info_present_flag = bitstream.readBits(1);
        const maxNum = sps_sub_layer_ordering_info_present_flag ? 0 : sps_max_sub_layers_minus1;
        for(let i = maxNum; i <= sps_max_sub_layers_minus1; i++){
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // sps_max_dec_pic_buffering_minus1[i]
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // sps_max_num_reorder_pics[i]
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // sps_max_latency_increase_plus1[i]
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // log2_min_luma_coding_block_size_minus3
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // log2_diff_max_min_luma_coding_block_size
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // log2_min_luma_transform_block_size_minus2
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // log2_diff_max_min_luma_transform_block_size
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // max_transform_hierarchy_depth_inter
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // max_transform_hierarchy_depth_intra
        if (bitstream.readBits(1)) {
            if (bitstream.readBits(1)) {
                skipScalingListData(bitstream);
            }
        }
        bitstream.skipBits(1); // amp_enabled_flag
        bitstream.skipBits(1); // sample_adaptive_offset_enabled_flag
        if (bitstream.readBits(1)) {
            bitstream.skipBits(4); // pcm_sample_bit_depth_luma_minus1
            bitstream.skipBits(4); // pcm_sample_bit_depth_chroma_minus1
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // log2_min_pcm_luma_coding_block_size_minus3
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // log2_diff_max_min_pcm_luma_coding_block_size
            bitstream.skipBits(1); // pcm_loop_filter_disabled_flag
        }
        const num_short_term_ref_pic_sets = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
        skipAllStRefPicSets(bitstream, num_short_term_ref_pic_sets);
        if (bitstream.readBits(1)) {
            const num_long_term_ref_pics_sps = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
            for(let i = 0; i < num_long_term_ref_pics_sps; i++){
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // lt_ref_pic_poc_lsb_sps[i]
                bitstream.skipBits(1); // used_by_curr_pic_lt_sps_flag[i]
            }
        }
        bitstream.skipBits(1); // sps_temporal_mvp_enabled_flag
        bitstream.skipBits(1); // strong_intra_smoothing_enabled_flag
        let min_spatial_segmentation_idc = 0;
        if (bitstream.readBits(1)) {
            min_spatial_segmentation_idc = parseVuiForMinSpatialSegmentationIdc(bitstream, sps_max_sub_layers_minus1);
        }
        // Parse PPS for parallelismType
        let parallelismType = 0;
        if (ppsUnits.length > 0) {
            const pps = ppsUnits[0];
            const ppsBitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](removeEmulationPreventionBytes(pps));
            ppsBitstream.skipBits(16); // NAL header
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(ppsBitstream); // pps_pic_parameter_set_id
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(ppsBitstream); // pps_seq_parameter_set_id
            ppsBitstream.skipBits(1); // dependent_slice_segments_enabled_flag
            ppsBitstream.skipBits(1); // output_flag_present_flag
            ppsBitstream.skipBits(3); // num_extra_slice_header_bits
            ppsBitstream.skipBits(1); // sign_data_hiding_enabled_flag
            ppsBitstream.skipBits(1); // cabac_init_present_flag
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(ppsBitstream); // num_ref_idx_l0_default_active_minus1
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(ppsBitstream); // num_ref_idx_l1_default_active_minus1
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readSignedExpGolomb"])(ppsBitstream); // init_qp_minus26
            ppsBitstream.skipBits(1); // constrained_intra_pred_flag
            ppsBitstream.skipBits(1); // transform_skip_enabled_flag
            if (ppsBitstream.readBits(1)) {
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(ppsBitstream); // diff_cu_qp_delta_depth
            }
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readSignedExpGolomb"])(ppsBitstream); // pps_cb_qp_offset
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readSignedExpGolomb"])(ppsBitstream); // pps_cr_qp_offset
            ppsBitstream.skipBits(1); // pps_slice_chroma_qp_offsets_present_flag
            ppsBitstream.skipBits(1); // weighted_pred_flag
            ppsBitstream.skipBits(1); // weighted_bipred_flag
            ppsBitstream.skipBits(1); // transquant_bypass_enabled_flag
            const tiles_enabled_flag = ppsBitstream.readBits(1);
            const entropy_coding_sync_enabled_flag = ppsBitstream.readBits(1);
            if (!tiles_enabled_flag && !entropy_coding_sync_enabled_flag) parallelismType = 0;
            else if (tiles_enabled_flag && !entropy_coding_sync_enabled_flag) parallelismType = 2;
            else if (!tiles_enabled_flag && entropy_coding_sync_enabled_flag) parallelismType = 3;
            else parallelismType = 0;
        }
        const arrays = [
            ...vpsUnits.length ? [
                {
                    arrayCompleteness: 1,
                    nalUnitType: HevcNalUnitType.VPS_NUT,
                    nalUnits: vpsUnits
                }
            ] : [],
            ...spsUnits.length ? [
                {
                    arrayCompleteness: 1,
                    nalUnitType: HevcNalUnitType.SPS_NUT,
                    nalUnits: spsUnits
                }
            ] : [],
            ...ppsUnits.length ? [
                {
                    arrayCompleteness: 1,
                    nalUnitType: HevcNalUnitType.PPS_NUT,
                    nalUnits: ppsUnits
                }
            ] : [],
            ...seiUnits.length ? [
                {
                    arrayCompleteness: 1,
                    nalUnitType: extractNalUnitTypeForHevc(seiUnits[0]),
                    nalUnits: seiUnits
                }
            ] : []
        ];
        const record = {
            configurationVersion: 1,
            generalProfileSpace: general_profile_space,
            generalTierFlag: general_tier_flag,
            generalProfileIdc: general_profile_idc,
            generalProfileCompatibilityFlags: general_profile_compatibility_flags,
            generalConstraintIndicatorFlags: general_constraint_indicator_flags,
            generalLevelIdc: general_level_idc,
            minSpatialSegmentationIdc: min_spatial_segmentation_idc,
            parallelismType,
            chromaFormatIdc: chroma_format_idc,
            bitDepthLumaMinus8: bit_depth_luma_minus8,
            bitDepthChromaMinus8: bit_depth_chroma_minus8,
            avgFrameRate: 0,
            constantFrameRate: 0,
            numTemporalLayers: sps_max_sub_layers_minus1 + 1,
            temporalIdNested: sps_temporal_id_nesting_flag,
            lengthSizeMinusOne: 3,
            arrays
        };
        return record;
    } catch (error) {
        console.error('Error building HEVC Decoder Configuration Record:', error);
        return null;
    }
};
const parseProfileTierLevel = (bitstream, maxNumSubLayersMinus1)=>{
    const general_profile_space = bitstream.readBits(2);
    const general_tier_flag = bitstream.readBits(1);
    const general_profile_idc = bitstream.readBits(5);
    let general_profile_compatibility_flags = 0;
    for(let i = 0; i < 32; i++){
        general_profile_compatibility_flags = general_profile_compatibility_flags << 1 | bitstream.readBits(1);
    }
    const general_constraint_indicator_flags = new Uint8Array(6);
    for(let i = 0; i < 6; i++){
        general_constraint_indicator_flags[i] = bitstream.readBits(8);
    }
    const general_level_idc = bitstream.readBits(8);
    const sub_layer_profile_present_flag = [];
    const sub_layer_level_present_flag = [];
    for(let i = 0; i < maxNumSubLayersMinus1; i++){
        sub_layer_profile_present_flag.push(bitstream.readBits(1));
        sub_layer_level_present_flag.push(bitstream.readBits(1));
    }
    if (maxNumSubLayersMinus1 > 0) {
        for(let i = maxNumSubLayersMinus1; i < 8; i++){
            bitstream.skipBits(2); // reserved_zero_2bits
        }
    }
    for(let i = 0; i < maxNumSubLayersMinus1; i++){
        if (sub_layer_profile_present_flag[i]) bitstream.skipBits(88);
        if (sub_layer_level_present_flag[i]) bitstream.skipBits(8);
    }
    return {
        general_profile_space,
        general_tier_flag,
        general_profile_idc,
        general_profile_compatibility_flags,
        general_constraint_indicator_flags,
        general_level_idc
    };
};
const skipScalingListData = (bitstream)=>{
    for(let sizeId = 0; sizeId < 4; sizeId++){
        for(let matrixId = 0; matrixId < (sizeId === 3 ? 2 : 6); matrixId++){
            const scaling_list_pred_mode_flag = bitstream.readBits(1);
            if (!scaling_list_pred_mode_flag) {
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // scaling_list_pred_matrix_id_delta
            } else {
                const coefNum = Math.min(64, 1 << 4 + (sizeId << 1));
                if (sizeId > 1) {
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readSignedExpGolomb"])(bitstream); // scaling_list_dc_coef_minus8
                }
                for(let i = 0; i < coefNum; i++){
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readSignedExpGolomb"])(bitstream); // scaling_list_delta_coef
                }
            }
        }
    }
};
const skipAllStRefPicSets = (bitstream, num_short_term_ref_pic_sets)=>{
    const NumDeltaPocs = [];
    for(let stRpsIdx = 0; stRpsIdx < num_short_term_ref_pic_sets; stRpsIdx++){
        NumDeltaPocs[stRpsIdx] = skipStRefPicSet(bitstream, stRpsIdx, num_short_term_ref_pic_sets, NumDeltaPocs);
    }
};
const skipStRefPicSet = (bitstream, stRpsIdx, num_short_term_ref_pic_sets, NumDeltaPocs)=>{
    let NumDeltaPocsThis = 0;
    let inter_ref_pic_set_prediction_flag = 0;
    let RefRpsIdx = 0;
    if (stRpsIdx !== 0) {
        inter_ref_pic_set_prediction_flag = bitstream.readBits(1);
    }
    if (inter_ref_pic_set_prediction_flag) {
        if (stRpsIdx === num_short_term_ref_pic_sets) {
            const delta_idx_minus1 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
            RefRpsIdx = stRpsIdx - (delta_idx_minus1 + 1);
        } else {
            RefRpsIdx = stRpsIdx - 1;
        }
        bitstream.readBits(1); // delta_rps_sign
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // abs_delta_rps_minus1
        // The number of iterations is NumDeltaPocs[RefRpsIdx] + 1
        const numDelta = NumDeltaPocs[RefRpsIdx] ?? 0;
        for(let j = 0; j <= numDelta; j++){
            const used_by_curr_pic_flag = bitstream.readBits(1);
            if (!used_by_curr_pic_flag) {
                bitstream.readBits(1); // use_delta_flag
            }
        }
        NumDeltaPocsThis = NumDeltaPocs[RefRpsIdx];
    } else {
        const num_negative_pics = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
        const num_positive_pics = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
        for(let i = 0; i < num_negative_pics; i++){
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // delta_poc_s0_minus1[i]
            bitstream.readBits(1); // used_by_curr_pic_s0_flag[i]
        }
        for(let i = 0; i < num_positive_pics; i++){
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // delta_poc_s1_minus1[i]
            bitstream.readBits(1); // used_by_curr_pic_s1_flag[i]
        }
        NumDeltaPocsThis = num_negative_pics + num_positive_pics;
    }
    return NumDeltaPocsThis;
};
const parseVuiForMinSpatialSegmentationIdc = (bitstream, sps_max_sub_layers_minus1)=>{
    if (bitstream.readBits(1)) {
        const aspect_ratio_idc = bitstream.readBits(8);
        if (aspect_ratio_idc === 255) {
            bitstream.readBits(16); // sar_width
            bitstream.readBits(16); // sar_height
        }
    }
    if (bitstream.readBits(1)) {
        bitstream.readBits(1); // overscan_appropriate_flag
    }
    if (bitstream.readBits(1)) {
        bitstream.readBits(3); // video_format
        bitstream.readBits(1); // video_full_range_flag
        if (bitstream.readBits(1)) {
            bitstream.readBits(8); // colour_primaries
            bitstream.readBits(8); // transfer_characteristics
            bitstream.readBits(8); // matrix_coeffs
        }
    }
    if (bitstream.readBits(1)) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // chroma_sample_loc_type_top_field
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // chroma_sample_loc_type_bottom_field
    }
    bitstream.readBits(1); // neutral_chroma_indication_flag
    bitstream.readBits(1); // field_seq_flag
    bitstream.readBits(1); // frame_field_info_present_flag
    if (bitstream.readBits(1)) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // def_disp_win_left_offset
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // def_disp_win_right_offset
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // def_disp_win_top_offset
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // def_disp_win_bottom_offset
    }
    if (bitstream.readBits(1)) {
        bitstream.readBits(32); // vui_num_units_in_tick
        bitstream.readBits(32); // vui_time_scale
        if (bitstream.readBits(1)) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // vui_num_ticks_poc_diff_one_minus1
        }
        if (bitstream.readBits(1)) {
            skipHrdParameters(bitstream, true, sps_max_sub_layers_minus1);
        }
    }
    if (bitstream.readBits(1)) {
        bitstream.readBits(1); // tiles_fixed_structure_flag
        bitstream.readBits(1); // motion_vectors_over_pic_boundaries_flag
        bitstream.readBits(1); // restricted_ref_pic_lists_flag
        const min_spatial_segmentation_idc = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
        // skip the rest
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // max_bytes_per_pic_denom
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // max_bits_per_min_cu_denom
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // log2_max_mv_length_horizontal
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // log2_max_mv_length_vertical
        return min_spatial_segmentation_idc;
    }
    return 0;
};
const skipHrdParameters = (bitstream, commonInfPresentFlag, maxNumSubLayersMinus1)=>{
    let nal_hrd_parameters_present_flag = false;
    let vcl_hrd_parameters_present_flag = false;
    let sub_pic_hrd_params_present_flag = false;
    if (commonInfPresentFlag) {
        nal_hrd_parameters_present_flag = bitstream.readBits(1) === 1;
        vcl_hrd_parameters_present_flag = bitstream.readBits(1) === 1;
        if (nal_hrd_parameters_present_flag || vcl_hrd_parameters_present_flag) {
            sub_pic_hrd_params_present_flag = bitstream.readBits(1) === 1;
            if (sub_pic_hrd_params_present_flag) {
                bitstream.readBits(8); // tick_divisor_minus2
                bitstream.readBits(5); // du_cpb_removal_delay_increment_length_minus1
                bitstream.readBits(1); // sub_pic_cpb_params_in_pic_timing_sei_flag
                bitstream.readBits(5); // dpb_output_delay_du_length_minus1
            }
            bitstream.readBits(4); // bit_rate_scale
            bitstream.readBits(4); // cpb_size_scale
            if (sub_pic_hrd_params_present_flag) {
                bitstream.readBits(4); // cpb_size_du_scale
            }
            bitstream.readBits(5); // initial_cpb_removal_delay_length_minus1
            bitstream.readBits(5); // au_cpb_removal_delay_length_minus1
            bitstream.readBits(5); // dpb_output_delay_length_minus1
        }
    }
    for(let i = 0; i <= maxNumSubLayersMinus1; i++){
        const fixed_pic_rate_general_flag = bitstream.readBits(1) === 1;
        let fixed_pic_rate_within_cvs_flag = true; // Default assumption if general is true
        if (!fixed_pic_rate_general_flag) {
            fixed_pic_rate_within_cvs_flag = bitstream.readBits(1) === 1;
        }
        let low_delay_hrd_flag = false; // Default assumption
        if (fixed_pic_rate_within_cvs_flag) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // elemental_duration_in_tc_minus1[i]
        } else {
            low_delay_hrd_flag = bitstream.readBits(1) === 1;
        }
        let CpbCnt = 1; // Default if low_delay is true
        if (!low_delay_hrd_flag) {
            const cpb_cnt_minus1 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // cpb_cnt_minus1[i]
            CpbCnt = cpb_cnt_minus1 + 1;
        }
        if (nal_hrd_parameters_present_flag) {
            skipSubLayerHrdParameters(bitstream, CpbCnt, sub_pic_hrd_params_present_flag);
        }
        if (vcl_hrd_parameters_present_flag) {
            skipSubLayerHrdParameters(bitstream, CpbCnt, sub_pic_hrd_params_present_flag);
        }
    }
};
const skipSubLayerHrdParameters = (bitstream, CpbCnt, sub_pic_hrd_params_present_flag)=>{
    for(let i = 0; i < CpbCnt; i++){
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // bit_rate_value_minus1[i]
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // cpb_size_value_minus1[i]
        if (sub_pic_hrd_params_present_flag) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // cpb_size_du_value_minus1[i]
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream); // bit_rate_du_value_minus1[i]
        }
        bitstream.readBits(1); // cbr_flag[i]
    }
};
const serializeHevcDecoderConfigurationRecord = (record)=>{
    const bytes = [];
    bytes.push(record.configurationVersion);
    bytes.push((record.generalProfileSpace & 0x3) << 6 | (record.generalTierFlag & 0x1) << 5 | record.generalProfileIdc & 0x1F);
    bytes.push(record.generalProfileCompatibilityFlags >>> 24 & 0xFF);
    bytes.push(record.generalProfileCompatibilityFlags >>> 16 & 0xFF);
    bytes.push(record.generalProfileCompatibilityFlags >>> 8 & 0xFF);
    bytes.push(record.generalProfileCompatibilityFlags & 0xFF);
    bytes.push(...record.generalConstraintIndicatorFlags);
    bytes.push(record.generalLevelIdc & 0xFF);
    bytes.push(0xF0 | record.minSpatialSegmentationIdc >> 8 & 0x0F); // Reserved + high nibble
    bytes.push(record.minSpatialSegmentationIdc & 0xFF); // Low byte
    bytes.push(0xFC | record.parallelismType & 0x03);
    bytes.push(0xFC | record.chromaFormatIdc & 0x03);
    bytes.push(0xF8 | record.bitDepthLumaMinus8 & 0x07);
    bytes.push(0xF8 | record.bitDepthChromaMinus8 & 0x07);
    bytes.push(record.avgFrameRate >> 8 & 0xFF); // High byte
    bytes.push(record.avgFrameRate & 0xFF); // Low byte
    bytes.push((record.constantFrameRate & 0x03) << 6 | (record.numTemporalLayers & 0x07) << 3 | (record.temporalIdNested & 0x01) << 2 | record.lengthSizeMinusOne & 0x03);
    bytes.push(record.arrays.length & 0xFF);
    for (const arr of record.arrays){
        bytes.push((arr.arrayCompleteness & 0x01) << 7 | 0 << 6 | arr.nalUnitType & 0x3F);
        bytes.push(arr.nalUnits.length >> 8 & 0xFF); // High byte
        bytes.push(arr.nalUnits.length & 0xFF); // Low byte
        for (const nal of arr.nalUnits){
            bytes.push(nal.length >> 8 & 0xFF); // High byte
            bytes.push(nal.length & 0xFF); // Low byte
            for(let i = 0; i < nal.length; i++){
                bytes.push(nal[i]);
            }
        }
    }
    return new Uint8Array(bytes);
};
const extractVp9CodecInfoFromPacket = (packet)=>{
    // eslint-disable-next-line @stylistic/max-len
    // https://storage.googleapis.com/downloads.webmproject.org/docs/vp9/vp9-bitstream-specification-v0.7-20170222-draft.pdf
    // http://downloads.webmproject.org/docs/vp9/vp9-bitstream_superframe-and-uncompressed-header_v1.0.pdf
    const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](packet);
    // Frame marker (0b10)
    const frameMarker = bitstream.readBits(2);
    if (frameMarker !== 2) {
        return null;
    }
    // Profile
    const profileLowBit = bitstream.readBits(1);
    const profileHighBit = bitstream.readBits(1);
    const profile = (profileHighBit << 1) + profileLowBit;
    // Skip reserved bit for profile 3
    if (profile === 3) {
        bitstream.skipBits(1);
    }
    // show_existing_frame
    const showExistingFrame = bitstream.readBits(1);
    if (showExistingFrame === 1) {
        return null;
    }
    // frame_type (0 = key frame)
    const frameType = bitstream.readBits(1);
    if (frameType !== 0) {
        return null;
    }
    // Skip show_frame and error_resilient_mode
    bitstream.skipBits(2);
    // Sync code (0x498342)
    const syncCode = bitstream.readBits(24);
    if (syncCode !== 0x498342) {
        return null;
    }
    // Color config
    let bitDepth = 8;
    if (profile >= 2) {
        const tenOrTwelveBit = bitstream.readBits(1);
        bitDepth = tenOrTwelveBit ? 12 : 10;
    }
    // Color space
    const colorSpace = bitstream.readBits(3);
    let chromaSubsampling = 0;
    let videoFullRangeFlag = 0;
    if (colorSpace !== 7) {
        const colorRange = bitstream.readBits(1);
        videoFullRangeFlag = colorRange;
        if (profile === 1 || profile === 3) {
            const subsamplingX = bitstream.readBits(1);
            const subsamplingY = bitstream.readBits(1);
            // 0 = 4:2:0 vertical
            // 1 = 4:2:0 colocated
            // 2 = 4:2:2
            // 3 = 4:4:4
            chromaSubsampling = !subsamplingX && !subsamplingY ? 3 // 0,0 = 4:4:4
             : subsamplingX && !subsamplingY ? 2 // 1,0 = 4:2:2
             : 1; // 1,1 = 4:2:0 colocated (default)
            // Skip reserved bit
            bitstream.skipBits(1);
        } else {
            // For profile 0 and 2, always 4:2:0
            chromaSubsampling = 1; // Using colocated as default
        }
    } else {
        // RGB is always 4:4:4
        chromaSubsampling = 3;
        videoFullRangeFlag = 1;
    }
    // Parse frame size
    const widthMinusOne = bitstream.readBits(16);
    const heightMinusOne = bitstream.readBits(16);
    const width = widthMinusOne + 1;
    const height = heightMinusOne + 1;
    // Calculate level based on dimensions
    const pictureSize = width * height;
    let level = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["last"])(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VP9_LEVEL_TABLE"]).level; // Default to highest level
    for (const entry of __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VP9_LEVEL_TABLE"]){
        if (pictureSize <= entry.maxPictureSize) {
            level = entry.level;
            break;
        }
    }
    // Map color_space to standard values
    const matrixCoefficients = colorSpace === 7 ? 0 : colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;
    const colourPrimaries = colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;
    const transferCharacteristics = colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;
    return {
        profile,
        level,
        bitDepth,
        chromaSubsampling,
        videoFullRangeFlag,
        colourPrimaries,
        transferCharacteristics,
        matrixCoefficients
    };
};
const iterateAv1PacketObus = function*(packet) {
    // https://aomediacodec.github.io/av1-spec/av1-spec.pdf
    const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](packet);
    const readLeb128 = ()=>{
        let value = 0;
        for(let i = 0; i < 8; i++){
            const byte = bitstream.readAlignedByte();
            value |= (byte & 0x7f) << i * 7;
            if (!(byte & 0x80)) {
                break;
            }
            // Spec requirement
            if (i === 7 && byte & 0x80) {
                return null;
            }
        }
        // Spec requirement
        if (value >= 2 ** 32 - 1) {
            return null;
        }
        return value;
    };
    while(bitstream.getBitsLeft() >= 8){
        // Parse OBU header
        bitstream.skipBits(1);
        const obuType = bitstream.readBits(4);
        const obuExtension = bitstream.readBits(1);
        const obuHasSizeField = bitstream.readBits(1);
        bitstream.skipBits(1);
        // Skip extension header if present
        if (obuExtension) {
            bitstream.skipBits(8);
        }
        // Read OBU size if present
        let obuSize;
        if (obuHasSizeField) {
            const obuSizeValue = readLeb128();
            if (obuSizeValue === null) return; // It was invalid
            obuSize = obuSizeValue;
        } else {
            // Calculate remaining bits and convert to bytes, rounding down
            obuSize = Math.floor(bitstream.getBitsLeft() / 8);
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(bitstream.pos % 8 === 0);
        yield {
            type: obuType,
            data: packet.subarray(bitstream.pos / 8, bitstream.pos / 8 + obuSize)
        };
        // Move to next OBU
        bitstream.skipBits(obuSize * 8);
    }
};
const extractAv1CodecInfoFromPacket = (packet)=>{
    // https://aomediacodec.github.io/av1-spec/av1-spec.pdf
    for (const { type, data } of iterateAv1PacketObus(packet)){
        if (type !== 1) {
            continue; // 1 == OBU_SEQUENCE_HEADER
        }
        const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](data);
        // Read sequence header fields
        const seqProfile = bitstream.readBits(3);
        // eslint-disable-next-line @typescript-eslint/no-unused-vars
        const stillPicture = bitstream.readBits(1);
        const reducedStillPictureHeader = bitstream.readBits(1);
        let seqLevel = 0;
        let seqTier = 0;
        let bufferDelayLengthMinus1 = 0;
        if (reducedStillPictureHeader) {
            seqLevel = bitstream.readBits(5);
        } else {
            // Parse timing_info_present_flag
            const timingInfoPresentFlag = bitstream.readBits(1);
            if (timingInfoPresentFlag) {
                // Skip timing info (num_units_in_display_tick, time_scale, equal_picture_interval)
                bitstream.skipBits(32); // num_units_in_display_tick
                bitstream.skipBits(32); // time_scale
                const equalPictureInterval = bitstream.readBits(1);
                if (equalPictureInterval) {
                    // Skip num_ticks_per_picture_minus_1 (uvlc)
                    // Since this is variable length, we'd need to implement uvlc reading
                    // For now, we'll return null as this is rare
                    return null;
                }
            }
            // Parse decoder_model_info_present_flag
            const decoderModelInfoPresentFlag = bitstream.readBits(1);
            if (decoderModelInfoPresentFlag) {
                // Store buffer_delay_length_minus_1 instead of just skipping
                bufferDelayLengthMinus1 = bitstream.readBits(5);
                bitstream.skipBits(32); // num_units_in_decoding_tick
                bitstream.skipBits(5); // buffer_removal_time_length_minus_1
                bitstream.skipBits(5); // frame_presentation_time_length_minus_1
            }
            // Parse operating_points_cnt_minus_1
            const operatingPointsCntMinus1 = bitstream.readBits(5);
            // For each operating point
            for(let i = 0; i <= operatingPointsCntMinus1; i++){
                // operating_point_idc[i]
                bitstream.skipBits(12);
                // seq_level_idx[i]
                const seqLevelIdx = bitstream.readBits(5);
                if (i === 0) {
                    seqLevel = seqLevelIdx;
                }
                if (seqLevelIdx > 7) {
                    // seq_tier[i]
                    const seqTierTemp = bitstream.readBits(1);
                    if (i === 0) {
                        seqTier = seqTierTemp;
                    }
                }
                if (decoderModelInfoPresentFlag) {
                    // decoder_model_present_for_this_op[i]
                    const decoderModelPresentForThisOp = bitstream.readBits(1);
                    if (decoderModelPresentForThisOp) {
                        const n = bufferDelayLengthMinus1 + 1;
                        bitstream.skipBits(n); // decoder_buffer_delay[op]
                        bitstream.skipBits(n); // encoder_buffer_delay[op]
                        bitstream.skipBits(1); // low_delay_mode_flag[op]
                    }
                }
                // initial_display_delay_present_flag
                const initialDisplayDelayPresentFlag = bitstream.readBits(1);
                if (initialDisplayDelayPresentFlag) {
                    // initial_display_delay_minus_1[i]
                    bitstream.skipBits(4);
                }
            }
        }
        // Frame size
        const frameWidthBitsMinus1 = bitstream.readBits(4);
        const frameHeightBitsMinus1 = bitstream.readBits(4);
        const n1 = frameWidthBitsMinus1 + 1;
        bitstream.skipBits(n1); // max_frame_width_minus_1
        const n2 = frameHeightBitsMinus1 + 1;
        bitstream.skipBits(n2); // max_frame_height_minus_1
        // Frame IDs
        let frameIdNumbersPresentFlag = 0;
        if (reducedStillPictureHeader) {
            frameIdNumbersPresentFlag = 0;
        } else {
            frameIdNumbersPresentFlag = bitstream.readBits(1);
        }
        if (frameIdNumbersPresentFlag) {
            bitstream.skipBits(4); // delta_frame_id_length_minus_2
            bitstream.skipBits(3); // additional_frame_id_length_minus_1
        }
        bitstream.skipBits(1); // use_128x128_superblock
        bitstream.skipBits(1); // enable_filter_intra
        bitstream.skipBits(1); // enable_intra_edge_filter
        if (!reducedStillPictureHeader) {
            bitstream.skipBits(1); // enable_interintra_compound
            bitstream.skipBits(1); // enable_masked_compound
            bitstream.skipBits(1); // enable_warped_motion
            bitstream.skipBits(1); // enable_dual_filter
            const enableOrderHint = bitstream.readBits(1);
            if (enableOrderHint) {
                bitstream.skipBits(1); // enable_jnt_comp
                bitstream.skipBits(1); // enable_ref_frame_mvs
            }
            const seqChooseScreenContentTools = bitstream.readBits(1);
            let seqForceScreenContentTools = 0;
            if (seqChooseScreenContentTools) {
                seqForceScreenContentTools = 2; // SELECT_SCREEN_CONTENT_TOOLS
            } else {
                seqForceScreenContentTools = bitstream.readBits(1);
            }
            if (seqForceScreenContentTools > 0) {
                const seqChooseIntegerMv = bitstream.readBits(1);
                if (!seqChooseIntegerMv) {
                    bitstream.skipBits(1); // seq_force_integer_mv
                }
            }
            if (enableOrderHint) {
                bitstream.skipBits(3); // order_hint_bits_minus_1
            }
        }
        bitstream.skipBits(1); // enable_superres
        bitstream.skipBits(1); // enable_cdef
        bitstream.skipBits(1); // enable_restoration
        // color_config()
        const highBitdepth = bitstream.readBits(1);
        let bitDepth = 8;
        if (seqProfile === 2 && highBitdepth) {
            const twelveBit = bitstream.readBits(1);
            bitDepth = twelveBit ? 12 : 10;
        } else if (seqProfile <= 2) {
            bitDepth = highBitdepth ? 10 : 8;
        }
        let monochrome = 0;
        if (seqProfile !== 1) {
            monochrome = bitstream.readBits(1);
        }
        let chromaSubsamplingX = 1;
        let chromaSubsamplingY = 1;
        let chromaSamplePosition = 0;
        if (!monochrome) {
            if (seqProfile === 0) {
                chromaSubsamplingX = 1;
                chromaSubsamplingY = 1;
            } else if (seqProfile === 1) {
                chromaSubsamplingX = 0;
                chromaSubsamplingY = 0;
            } else {
                if (bitDepth === 12) {
                    chromaSubsamplingX = bitstream.readBits(1);
                    if (chromaSubsamplingX) {
                        chromaSubsamplingY = bitstream.readBits(1);
                    }
                }
            }
            if (chromaSubsamplingX && chromaSubsamplingY) {
                chromaSamplePosition = bitstream.readBits(2);
            }
        }
        return {
            profile: seqProfile,
            level: seqLevel,
            tier: seqTier,
            bitDepth,
            monochrome,
            chromaSubsamplingX,
            chromaSubsamplingY,
            chromaSamplePosition
        };
    }
    return null;
};
const parseOpusIdentificationHeader = (bytes)=>{
    const view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(bytes);
    const outputChannelCount = view.getUint8(9);
    const preSkip = view.getUint16(10, true);
    const inputSampleRate = view.getUint32(12, true);
    const outputGain = view.getInt16(16, true);
    const channelMappingFamily = view.getUint8(18);
    let channelMappingTable = null;
    if (channelMappingFamily) {
        channelMappingTable = bytes.subarray(19, 19 + 2 + outputChannelCount);
    }
    return {
        outputChannelCount,
        preSkip,
        inputSampleRate,
        outputGain,
        channelMappingFamily,
        channelMappingTable
    };
};
// From https://datatracker.ietf.org/doc/html/rfc6716, in 48 kHz samples
const OPUS_FRAME_DURATION_TABLE = [
    480,
    960,
    1920,
    2880,
    480,
    960,
    1920,
    2880,
    480,
    960,
    1920,
    2880,
    480,
    960,
    480,
    960,
    120,
    240,
    480,
    960,
    120,
    240,
    480,
    960,
    120,
    240,
    480,
    960,
    120,
    240,
    480,
    960
];
const parseOpusTocByte = (packet)=>{
    const config = packet[0] >> 3;
    return {
        durationInSamples: OPUS_FRAME_DURATION_TABLE[config]
    };
};
const parseModesFromVorbisSetupPacket = (setupHeader)=>{
    // Verify that this is a Setup header.
    if (setupHeader.length < 7) {
        throw new Error('Setup header is too short.');
    }
    if (setupHeader[0] !== 5) {
        throw new Error('Wrong packet type in Setup header.');
    }
    const signature = String.fromCharCode(...setupHeader.slice(1, 7));
    if (signature !== 'vorbis') {
        throw new Error('Invalid packet signature in Setup header.');
    }
    // Reverse the entire buffer.
    const bufSize = setupHeader.length;
    const revBuffer = new Uint8Array(bufSize);
    for(let i = 0; i < bufSize; i++){
        revBuffer[i] = setupHeader[bufSize - 1 - i];
    }
    // Initialize a Bitstream on the reversed buffer.
    const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](revBuffer);
    // --- Find the framing bit.
    // In FFmpeg code, we scan until get_bits1() returns 1.
    let gotFramingBit = 0;
    while(bitstream.getBitsLeft() > 97){
        if (bitstream.readBits(1) === 1) {
            gotFramingBit = bitstream.pos;
            break;
        }
    }
    if (gotFramingBit === 0) {
        throw new Error('Invalid Setup header: framing bit not found.');
    }
    // --- Search backwards for a valid mode header.
    // We try to guess the number of modes by reading a fixed pattern.
    let modeCount = 0;
    let gotModeHeader = false;
    let lastModeCount = 0;
    while(bitstream.getBitsLeft() >= 97){
        const tempPos = bitstream.pos;
        const a = bitstream.readBits(8);
        const b = bitstream.readBits(16);
        const c = bitstream.readBits(16);
        // If a > 63 or b or c nonzero, assume weve gone too far.
        if (a > 63 || b !== 0 || c !== 0) {
            bitstream.pos = tempPos;
            break;
        }
        bitstream.skipBits(1);
        modeCount++;
        if (modeCount > 64) {
            break;
        }
        const bsClone = bitstream.clone();
        const candidate = bsClone.readBits(6) + 1;
        if (candidate === modeCount) {
            gotModeHeader = true;
            lastModeCount = modeCount;
        }
    }
    if (!gotModeHeader) {
        throw new Error('Invalid Setup header: mode header not found.');
    }
    if (lastModeCount > 63) {
        throw new Error(`Unsupported mode count: ${lastModeCount}.`);
    }
    const finalModeCount = lastModeCount;
    // --- Reinitialize the bitstream.
    bitstream.pos = 0;
    // Skip the bits up to the found framing bit.
    bitstream.skipBits(gotFramingBit);
    // --- Now read, for each mode (in reverse order), 40 bits then one bit.
    // That one bit is the mode blockflag.
    const modeBlockflags = Array(finalModeCount).fill(0);
    for(let i = finalModeCount - 1; i >= 0; i--){
        bitstream.skipBits(40);
        modeBlockflags[i] = bitstream.readBits(1);
    }
    return {
        modeBlockflags
    };
};
const determineVideoPacketType = (codec, decoderConfig, packetData)=>{
    switch(codec){
        case 'avc':
            {
                const nalUnits = extractAvcNalUnits(packetData, decoderConfig);
                let isKeyframe = nalUnits.some((x)=>extractNalUnitTypeForAvc(x) === AvcNalUnitType.IDR);
                if (!isKeyframe && (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isChromium"])() || (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getChromiumVersion"])() >= 144)) {
                    // In addition to IDR, Recovery Point SEI also counts as a valid H.264 keyframe by current consensus.
                    // See https://github.com/w3c/webcodecs/issues/650 for the relevant discussion. WebKit and Firefox have
                    // always supported them, but Chromium hasn't, therefore the (admittedly dirty) version check.
                    for (const nalUnit of nalUnits){
                        const type = extractNalUnitTypeForAvc(nalUnit);
                        if (type !== AvcNalUnitType.SEI) {
                            continue;
                        }
                        const bytes = removeEmulationPreventionBytes(nalUnit);
                        let pos = 1; // Skip NALU header
                        // sei_rbsp()
                        do {
                            // sei_message()
                            let payloadType = 0;
                            while(true){
                                const nextByte = bytes[pos++];
                                if (nextByte === undefined) break;
                                payloadType += nextByte;
                                if (nextByte < 255) {
                                    break;
                                }
                            }
                            let payloadSize = 0;
                            while(true){
                                const nextByte = bytes[pos++];
                                if (nextByte === undefined) break;
                                payloadSize += nextByte;
                                if (nextByte < 255) {
                                    break;
                                }
                            }
                            // sei_payload()
                            const PAYLOAD_TYPE_RECOVERY_POINT = 6;
                            if (payloadType === PAYLOAD_TYPE_RECOVERY_POINT) {
                                const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](bytes);
                                bitstream.pos = 8 * pos;
                                const recoveryFrameCount = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readExpGolomb"])(bitstream);
                                const exactMatchFlag = bitstream.readBits(1);
                                if (recoveryFrameCount === 0 && exactMatchFlag === 1) {
                                    // https://github.com/w3c/webcodecs/pull/910
                                    // "recovery_frame_cnt == 0 and exact_match_flag=1 in the SEI recovery payload"
                                    isKeyframe = true;
                                    break;
                                }
                            }
                            pos += payloadSize;
                        }while (pos < bytes.length - 1)
                    }
                }
                return isKeyframe ? 'key' : 'delta';
            }
            //TURBOPACK unreachable
            ;
        case 'hevc':
            {
                const nalUnits = extractHevcNalUnits(packetData, decoderConfig);
                const isKeyframe = nalUnits.some((x)=>{
                    const type = extractNalUnitTypeForHevc(x);
                    return HevcNalUnitType.BLA_W_LP <= type && type <= HevcNalUnitType.RSV_IRAP_VCL23;
                });
                return isKeyframe ? 'key' : 'delta';
            }
            //TURBOPACK unreachable
            ;
        case 'vp8':
            {
                // VP8, once again, by far the easiest to deal with.
                const frameType = packetData[0] & 0b1;
                return frameType === 0 ? 'key' : 'delta';
            }
            //TURBOPACK unreachable
            ;
        case 'vp9':
            {
                const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](packetData);
                if (bitstream.readBits(2) !== 2) {
                    return null;
                }
                ;
                const profileLowBit = bitstream.readBits(1);
                const profileHighBit = bitstream.readBits(1);
                const profile = (profileHighBit << 1) + profileLowBit;
                // Skip reserved bit for profile 3
                if (profile === 3) {
                    bitstream.skipBits(1);
                }
                const showExistingFrame = bitstream.readBits(1);
                if (showExistingFrame) {
                    return null;
                }
                const frameType = bitstream.readBits(1);
                return frameType === 0 ? 'key' : 'delta';
            }
            //TURBOPACK unreachable
            ;
        case 'av1':
            {
                let reducedStillPictureHeader = false;
                for (const { type, data } of iterateAv1PacketObus(packetData)){
                    if (type === 1) {
                        const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](data);
                        bitstream.skipBits(4);
                        reducedStillPictureHeader = !!bitstream.readBits(1);
                    } else if (type === 3 // OBU_FRAME_HEADER
                     || type === 6 // OBU_FRAME
                     || type === 7 // OBU_REDUNDANT_FRAME_HEADER
                    ) {
                        if (reducedStillPictureHeader) {
                            return 'key';
                        }
                        const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](data);
                        const showExistingFrame = bitstream.readBits(1);
                        if (showExistingFrame) {
                            return null;
                        }
                        const frameType = bitstream.readBits(2);
                        return frameType === 0 ? 'key' : 'delta';
                    }
                }
                return null;
            }
            //TURBOPACK unreachable
            ;
        default:
            {
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(codec);
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
            }
            ;
    }
};
var FlacBlockType;
(function(FlacBlockType) {
    FlacBlockType[FlacBlockType["STREAMINFO"] = 0] = "STREAMINFO";
    FlacBlockType[FlacBlockType["VORBIS_COMMENT"] = 4] = "VORBIS_COMMENT";
    FlacBlockType[FlacBlockType["PICTURE"] = 6] = "PICTURE";
})(FlacBlockType || (FlacBlockType = {}));
const readVorbisComments = (bytes, metadataTags)=>{
    // https://datatracker.ietf.org/doc/html/rfc7845#section-5.2
    const commentView = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(bytes);
    let commentPos = 0;
    const vendorStringLength = commentView.getUint32(commentPos, true);
    commentPos += 4;
    const vendorString = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textDecoder"].decode(bytes.subarray(commentPos, commentPos + vendorStringLength));
    commentPos += vendorStringLength;
    if (vendorStringLength > 0) {
        // Expose the vendor string in the raw metadata
        metadataTags.raw ??= {};
        metadataTags.raw['vendor'] ??= vendorString;
    }
    const listLength = commentView.getUint32(commentPos, true);
    commentPos += 4;
    // Loop over all metadata tags
    for(let i = 0; i < listLength; i++){
        const stringLength = commentView.getUint32(commentPos, true);
        commentPos += 4;
        const string = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textDecoder"].decode(bytes.subarray(commentPos, commentPos + stringLength));
        commentPos += stringLength;
        const separatorIndex = string.indexOf('=');
        if (separatorIndex === -1) {
            continue;
        }
        const key = string.slice(0, separatorIndex).toUpperCase();
        const value = string.slice(separatorIndex + 1);
        metadataTags.raw ??= {};
        metadataTags.raw[key] ??= value;
        switch(key){
            case 'TITLE':
                {
                    metadataTags.title ??= value;
                }
                ;
                break;
            case 'DESCRIPTION':
                {
                    metadataTags.description ??= value;
                }
                ;
                break;
            case 'ARTIST':
                {
                    metadataTags.artist ??= value;
                }
                ;
                break;
            case 'ALBUM':
                {
                    metadataTags.album ??= value;
                }
                ;
                break;
            case 'ALBUMARTIST':
                {
                    metadataTags.albumArtist ??= value;
                }
                ;
                break;
            case 'COMMENT':
                {
                    metadataTags.comment ??= value;
                }
                ;
                break;
            case 'LYRICS':
                {
                    metadataTags.lyrics ??= value;
                }
                ;
                break;
            case 'TRACKNUMBER':
                {
                    const parts = value.split('/');
                    const trackNum = Number.parseInt(parts[0], 10);
                    const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);
                    if (Number.isInteger(trackNum) && trackNum > 0) {
                        metadataTags.trackNumber ??= trackNum;
                    }
                    if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {
                        metadataTags.tracksTotal ??= tracksTotal;
                    }
                }
                ;
                break;
            case 'TRACKTOTAL':
                {
                    const tracksTotal = Number.parseInt(value, 10);
                    if (Number.isInteger(tracksTotal) && tracksTotal > 0) {
                        metadataTags.tracksTotal ??= tracksTotal;
                    }
                }
                ;
                break;
            case 'DISCNUMBER':
                {
                    const parts = value.split('/');
                    const discNum = Number.parseInt(parts[0], 10);
                    const discsTotal = parts[1] && Number.parseInt(parts[1], 10);
                    if (Number.isInteger(discNum) && discNum > 0) {
                        metadataTags.discNumber ??= discNum;
                    }
                    if (discsTotal && Number.isInteger(discsTotal) && discsTotal > 0) {
                        metadataTags.discsTotal ??= discsTotal;
                    }
                }
                ;
                break;
            case 'DISCTOTAL':
                {
                    const discsTotal = Number.parseInt(value, 10);
                    if (Number.isInteger(discsTotal) && discsTotal > 0) {
                        metadataTags.discsTotal ??= discsTotal;
                    }
                }
                ;
                break;
            case 'DATE':
                {
                    const date = new Date(value);
                    if (!Number.isNaN(date.getTime())) {
                        metadataTags.date ??= date;
                    }
                }
                ;
                break;
            case 'GENRE':
                {
                    metadataTags.genre ??= value;
                }
                ;
                break;
            case 'METADATA_BLOCK_PICTURE':
                {
                    // https://datatracker.ietf.org/doc/rfc9639/ Section 8.8
                    const decoded = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64ToBytes"])(value);
                    const view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(decoded);
                    const pictureType = view.getUint32(0, false);
                    const mediaTypeLength = view.getUint32(4, false);
                    const mediaType = String.fromCharCode(...decoded.subarray(8, 8 + mediaTypeLength)); // ASCII
                    const descriptionLength = view.getUint32(8 + mediaTypeLength, false);
                    const description = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textDecoder"].decode(decoded.subarray(12 + mediaTypeLength, 12 + mediaTypeLength + descriptionLength));
                    const dataLength = view.getUint32(mediaTypeLength + descriptionLength + 28);
                    const data = decoded.subarray(mediaTypeLength + descriptionLength + 32, mediaTypeLength + descriptionLength + 32 + dataLength);
                    metadataTags.images ??= [];
                    metadataTags.images.push({
                        data,
                        mimeType: mediaType,
                        kind: pictureType === 3 ? 'coverFront' : pictureType === 4 ? 'coverBack' : 'unknown',
                        name: undefined,
                        description: description || undefined
                    });
                }
                ;
                break;
        }
    }
};
const createVorbisComments = (headerBytes, tags, writeImages)=>{
    // https://datatracker.ietf.org/doc/html/rfc7845#section-5.2
    const commentHeaderParts = [
        headerBytes
    ];
    const vendorString = 'Mediabunny';
    const encodedVendorString = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textEncoder"].encode(vendorString);
    let currentBuffer = new Uint8Array(4 + encodedVendorString.length);
    let currentView = new DataView(currentBuffer.buffer);
    currentView.setUint32(0, encodedVendorString.length, true);
    currentBuffer.set(encodedVendorString, 4);
    commentHeaderParts.push(currentBuffer);
    const writtenTags = new Set();
    const addCommentTag = (key, value)=>{
        const joined = `${key}=${value}`;
        const encoded = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textEncoder"].encode(joined);
        currentBuffer = new Uint8Array(4 + encoded.length);
        currentView = new DataView(currentBuffer.buffer);
        currentView.setUint32(0, encoded.length, true);
        currentBuffer.set(encoded, 4);
        commentHeaderParts.push(currentBuffer);
        writtenTags.add(key);
    };
    for (const { key, value } of (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["keyValueIterator"])(tags)){
        switch(key){
            case 'title':
                {
                    addCommentTag('TITLE', value);
                }
                ;
                break;
            case 'description':
                {
                    addCommentTag('DESCRIPTION', value);
                }
                ;
                break;
            case 'artist':
                {
                    addCommentTag('ARTIST', value);
                }
                ;
                break;
            case 'album':
                {
                    addCommentTag('ALBUM', value);
                }
                ;
                break;
            case 'albumArtist':
                {
                    addCommentTag('ALBUMARTIST', value);
                }
                ;
                break;
            case 'genre':
                {
                    addCommentTag('GENRE', value);
                }
                ;
                break;
            case 'date':
                {
                    const rawVersion = tags.raw?.['DATE'] ?? tags.raw?.['date'];
                    if (rawVersion && typeof rawVersion === 'string') {
                        addCommentTag('DATE', rawVersion);
                    } else {
                        addCommentTag('DATE', value.toISOString().slice(0, 10));
                    }
                }
                ;
                break;
            case 'comment':
                {
                    addCommentTag('COMMENT', value);
                }
                ;
                break;
            case 'lyrics':
                {
                    addCommentTag('LYRICS', value);
                }
                ;
                break;
            case 'trackNumber':
                {
                    addCommentTag('TRACKNUMBER', value.toString());
                }
                ;
                break;
            case 'tracksTotal':
                {
                    addCommentTag('TRACKTOTAL', value.toString());
                }
                ;
                break;
            case 'discNumber':
                {
                    addCommentTag('DISCNUMBER', value.toString());
                }
                ;
                break;
            case 'discsTotal':
                {
                    addCommentTag('DISCTOTAL', value.toString());
                }
                ;
                break;
            case 'images':
                {
                    // For example, in .flac, we put the pictures in a different section,
                    // not in the Vorbis comment header.
                    if (!writeImages) {
                        break;
                    }
                    for (const image of value){
                        // https://datatracker.ietf.org/doc/rfc9639/ Section 8.8
                        const pictureType = image.kind === 'coverFront' ? 3 : image.kind === 'coverBack' ? 4 : 0;
                        const encodedMediaType = new Uint8Array(image.mimeType.length);
                        for(let i = 0; i < image.mimeType.length; i++){
                            encodedMediaType[i] = image.mimeType.charCodeAt(i);
                        }
                        const encodedDescription = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textEncoder"].encode(image.description ?? '');
                        const buffer = new Uint8Array(4 // Picture type
                         + 4 // MIME type length
                         + encodedMediaType.length // MIME type
                         + 4 // Description length
                         + encodedDescription.length // Description
                         + 16 // Width, height, color depth, number of colors
                         + 4 // Picture data length
                         + image.data.length);
                        const view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(buffer);
                        view.setUint32(0, pictureType, false);
                        view.setUint32(4, encodedMediaType.length, false);
                        buffer.set(encodedMediaType, 8);
                        view.setUint32(8 + encodedMediaType.length, encodedDescription.length, false);
                        buffer.set(encodedDescription, 12 + encodedMediaType.length);
                        // Skip a bunch of fields (width, height, color depth, number of colors)
                        view.setUint32(28 + encodedMediaType.length + encodedDescription.length, image.data.length, false);
                        buffer.set(image.data, 32 + encodedMediaType.length + encodedDescription.length);
                        const encoded = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["bytesToBase64"])(buffer);
                        addCommentTag('METADATA_BLOCK_PICTURE', encoded);
                    }
                }
                ;
                break;
            case 'raw':
                {
                // Handled later
                }
                ;
                break;
            default:
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(key);
        }
    }
    if (tags.raw) {
        for(const key in tags.raw){
            const value = tags.raw[key] ?? tags.raw[key.toLowerCase()];
            if (key === 'vendor' || value == null || writtenTags.has(key)) {
                continue;
            }
            if (typeof value === 'string') {
                addCommentTag(key, value);
            }
        }
    }
    const listLengthBuffer = new Uint8Array(4);
    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(listLengthBuffer).setUint32(0, writtenTags.size, true);
    commentHeaderParts.splice(2, 0, listLengthBuffer); // Insert after the header and vendor section
    // Merge all comment header parts into a single buffer
    const commentHeaderLength = commentHeaderParts.reduce((a, b)=>a + b.length, 0);
    const commentHeader = new Uint8Array(commentHeaderLength);
    let pos = 0;
    for (const part of commentHeaderParts){
        commentHeader.set(part, pos);
        pos += part.length;
    }
    return commentHeader;
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/demuxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "Demuxer",
    ()=>Demuxer
]);
class Demuxer {
    constructor(input){
        this.input = input;
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/media-sink.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "AudioBufferSink",
    ()=>AudioBufferSink,
    "AudioSampleSink",
    ()=>AudioSampleSink,
    "BaseMediaSampleSink",
    ()=>BaseMediaSampleSink,
    "CanvasSink",
    ()=>CanvasSink,
    "EncodedPacketSink",
    ()=>EncodedPacketSink,
    "VideoSampleSink",
    ()=>VideoSampleSink
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec-data.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/custom-coder.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/input.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/input-track.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/packet.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$pcm$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/pcm.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/sample.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
;
const validatePacketRetrievalOptions = (options)=>{
    if (!options || typeof options !== 'object') {
        throw new TypeError('options must be an object.');
    }
    if (options.metadataOnly !== undefined && typeof options.metadataOnly !== 'boolean') {
        throw new TypeError('options.metadataOnly, when defined, must be a boolean.');
    }
    if (options.verifyKeyPackets !== undefined && typeof options.verifyKeyPackets !== 'boolean') {
        throw new TypeError('options.verifyKeyPackets, when defined, must be a boolean.');
    }
    if (options.verifyKeyPackets && options.metadataOnly) {
        throw new TypeError('options.verifyKeyPackets and options.metadataOnly cannot be enabled together.');
    }
};
const validateTimestamp = (timestamp)=>{
    if (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isNumber"])(timestamp)) {
        throw new TypeError('timestamp must be a number.'); // It can be non-finite, that's fine
    }
};
const maybeFixPacketType = (track, promise, options)=>{
    if (options.verifyKeyPackets) {
        return promise.then(async (packet)=>{
            if (!packet || packet.type === 'delta') {
                return packet;
            }
            const determinedType = await track.determinePacketType(packet);
            if (determinedType) {
                // @ts-expect-error Technically readonly
                packet.type = determinedType;
            }
            return packet;
        });
    } else {
        return promise;
    }
};
class EncodedPacketSink {
    /** Creates a new {@link EncodedPacketSink} for the given {@link InputTrack}. */ constructor(track){
        if (!(track instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputTrack"])) {
            throw new TypeError('track must be an InputTrack.');
        }
        this._track = track;
    }
    /**
     * Retrieves the track's first packet (in decode order), or null if it has no packets. The first packet is very
     * likely to be a key packet.
     */ getFirstPacket(options = {}) {
        validatePacketRetrievalOptions(options);
        if (this._track.input._disposed) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
        }
        return maybeFixPacketType(this._track, this._track._backing.getFirstPacket(options), options);
    }
    /**
     * Retrieves the packet corresponding to the given timestamp, in seconds. More specifically, returns the last packet
     * (in presentation order) with a start timestamp less than or equal to the given timestamp. This method can be
     * used to retrieve a track's last packet using `getPacket(Infinity)`. The method returns null if the timestamp
     * is before the first packet in the track.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */ getPacket(timestamp, options = {}) {
        validateTimestamp(timestamp);
        validatePacketRetrievalOptions(options);
        if (this._track.input._disposed) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
        }
        return maybeFixPacketType(this._track, this._track._backing.getPacket(timestamp, options), options);
    }
    /**
     * Retrieves the packet following the given packet (in decode order), or null if the given packet is the
     * last packet.
     */ getNextPacket(packet, options = {}) {
        if (!(packet instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"])) {
            throw new TypeError('packet must be an EncodedPacket.');
        }
        validatePacketRetrievalOptions(options);
        if (this._track.input._disposed) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
        }
        return maybeFixPacketType(this._track, this._track._backing.getNextPacket(packet, options), options);
    }
    /**
     * Retrieves the key packet corresponding to the given timestamp, in seconds. More specifically, returns the last
     * key packet (in presentation order) with a start timestamp less than or equal to the given timestamp. A key packet
     * is a packet that doesn't require previous packets to be decoded. This method can be used to retrieve a track's
     * last key packet using `getKeyPacket(Infinity)`. The method returns null if the timestamp is before the first
     * key packet in the track.
     *
     * To ensure that the returned packet is guaranteed to be a real key frame, enable `options.verifyKeyPackets`.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */ async getKeyPacket(timestamp, options = {}) {
        validateTimestamp(timestamp);
        validatePacketRetrievalOptions(options);
        if (this._track.input._disposed) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
        }
        if (!options.verifyKeyPackets) {
            return this._track._backing.getKeyPacket(timestamp, options);
        }
        const packet = await this._track._backing.getKeyPacket(timestamp, options);
        if (!packet) {
            return packet;
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(packet.type === 'key');
        const determinedType = await this._track.determinePacketType(packet);
        if (determinedType === 'delta') {
            // Try returning the previous key packet (in hopes that it's actually a key packet)
            return this.getKeyPacket(packet.timestamp - 1 / this._track.timeResolution, options);
        }
        return packet;
    }
    /**
     * Retrieves the key packet following the given packet (in decode order), or null if the given packet is the last
     * key packet.
     *
     * To ensure that the returned packet is guaranteed to be a real key frame, enable `options.verifyKeyPackets`.
     */ async getNextKeyPacket(packet, options = {}) {
        if (!(packet instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"])) {
            throw new TypeError('packet must be an EncodedPacket.');
        }
        validatePacketRetrievalOptions(options);
        if (this._track.input._disposed) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
        }
        if (!options.verifyKeyPackets) {
            return this._track._backing.getNextKeyPacket(packet, options);
        }
        const nextPacket = await this._track._backing.getNextKeyPacket(packet, options);
        if (!nextPacket) {
            return nextPacket;
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(nextPacket.type === 'key');
        const determinedType = await this._track.determinePacketType(nextPacket);
        if (determinedType === 'delta') {
            // Try returning the next key packet (in hopes that it's actually a key packet)
            return this.getNextKeyPacket(nextPacket, options);
        }
        return nextPacket;
    }
    /**
     * Creates an async iterator that yields the packets in this track in decode order. To enable fast iteration, this
     * method will intelligently preload packets based on the speed of the consumer.
     *
     * @param startPacket - (optional) The packet from which iteration should begin. This packet will also be yielded.
     * @param endTimestamp - (optional) The timestamp at which iteration should end. This packet will _not_ be yielded.
     */ packets(startPacket, endPacket, options = {}) {
        if (startPacket !== undefined && !(startPacket instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"])) {
            throw new TypeError('startPacket must be an EncodedPacket.');
        }
        if (startPacket !== undefined && startPacket.isMetadataOnly && !options?.metadataOnly) {
            throw new TypeError('startPacket can only be metadata-only if options.metadataOnly is enabled.');
        }
        if (endPacket !== undefined && !(endPacket instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"])) {
            throw new TypeError('endPacket must be an EncodedPacket.');
        }
        validatePacketRetrievalOptions(options);
        if (this._track.input._disposed) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
        }
        const packetQueue = [];
        let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])();
        let { promise: queueDequeue, resolve: onQueueDequeue } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])();
        let ended = false;
        let terminated = false;
        // This stores errors that are "out of band" in the sense that they didn't occur in the normal flow of this
        // method but instead in a different context. This error should not go unnoticed and must be bubbled up to
        // the consumer.
        let outOfBandError = null;
        const timestamps = [];
        // The queue should always be big enough to hold 1 second worth of packets
        const maxQueueSize = ()=>Math.max(2, timestamps.length);
        // The following is the "pump" process that keeps pumping packets into the queue
        (async ()=>{
            let packet = startPacket ?? await this.getFirstPacket(options);
            while(packet && !terminated && !this._track.input._disposed){
                if (endPacket && packet.sequenceNumber >= endPacket?.sequenceNumber) {
                    break;
                }
                if (packetQueue.length > maxQueueSize()) {
                    ({ promise: queueDequeue, resolve: onQueueDequeue } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])());
                    await queueDequeue;
                    continue;
                }
                packetQueue.push(packet);
                onQueueNotEmpty();
                ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])());
                packet = await this.getNextPacket(packet, options);
            }
            ended = true;
            onQueueNotEmpty();
        })().catch((error)=>{
            if (!outOfBandError) {
                outOfBandError = error;
                onQueueNotEmpty();
            }
        });
        const track = this._track;
        return {
            async next () {
                while(true){
                    if (track.input._disposed) {
                        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
                    } else if (terminated) {
                        return {
                            value: undefined,
                            done: true
                        };
                    } else if (outOfBandError) {
                        throw outOfBandError;
                    } else if (packetQueue.length > 0) {
                        const value = packetQueue.shift();
                        const now = performance.now();
                        timestamps.push(now);
                        while(timestamps.length > 0 && now - timestamps[0] >= 1000){
                            timestamps.shift();
                        }
                        onQueueDequeue();
                        return {
                            value,
                            done: false
                        };
                    } else if (ended) {
                        return {
                            value: undefined,
                            done: true
                        };
                    } else {
                        await queueNotEmpty;
                    }
                }
            },
            async return () {
                terminated = true;
                onQueueDequeue();
                onQueueNotEmpty();
                return {
                    value: undefined,
                    done: true
                };
            },
            async throw (error) {
                throw error;
            },
            [Symbol.asyncIterator] () {
                return this;
            }
        };
    }
}
class DecoderWrapper {
    constructor(onSample, onError){
        this.onSample = onSample;
        this.onError = onError;
    }
}
class BaseMediaSampleSink {
    /** @internal */ mediaSamplesInRange(startTimestamp = 0, endTimestamp = Infinity) {
        validateTimestamp(startTimestamp);
        validateTimestamp(endTimestamp);
        const sampleQueue = [];
        let firstSampleQueued = false;
        let lastSample = null;
        let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])();
        let { promise: queueDequeue, resolve: onQueueDequeue } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])();
        let decoderIsFlushed = false;
        let ended = false;
        let terminated = false;
        // This stores errors that are "out of band" in the sense that they didn't occur in the normal flow of this
        // method but instead in a different context. This error should not go unnoticed and must be bubbled up to
        // the consumer.
        let outOfBandError = null;
        // The following is the "pump" process that keeps pumping packets into the decoder
        (async ()=>{
            const decoder = await this._createDecoder((sample)=>{
                onQueueDequeue();
                if (sample.timestamp >= endTimestamp) {
                    ended = true;
                }
                if (ended) {
                    sample.close();
                    return;
                }
                if (lastSample) {
                    if (sample.timestamp > startTimestamp) {
                        // We don't know ahead of time what the first first is. This is because the first first is the
                        // last first whose timestamp is less than or equal to the start timestamp. Therefore we need to
                        // wait for the first first after the start timestamp, and then we'll know that the previous
                        // first was the first first.
                        sampleQueue.push(lastSample);
                        firstSampleQueued = true;
                    } else {
                        lastSample.close();
                    }
                }
                if (sample.timestamp >= startTimestamp) {
                    sampleQueue.push(sample);
                    firstSampleQueued = true;
                }
                lastSample = firstSampleQueued ? null : sample;
                if (sampleQueue.length > 0) {
                    onQueueNotEmpty();
                    ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])());
                }
            }, (error)=>{
                if (!outOfBandError) {
                    outOfBandError = error;
                    onQueueNotEmpty();
                }
            });
            const packetSink = this._createPacketSink();
            const keyPacket = await packetSink.getKeyPacket(startTimestamp, {
                verifyKeyPackets: true
            }) ?? await packetSink.getFirstPacket();
            let currentPacket = keyPacket;
            let endPacket = undefined;
            if (endTimestamp < Infinity) {
                // When an end timestamp is set, we cannot simply use that for the packet iterator due to out-of-order
                // frames (B-frames). Instead, we'll need to keep decoding packets until we get a frame that exceeds
                // this end time. However, we can still put a bound on it: Since key frames are by definition never
                // out of order, we can stop at the first key frame after the end timestamp.
                const packet = await packetSink.getPacket(endTimestamp);
                const keyPacket = !packet ? null : packet.type === 'key' && packet.timestamp === endTimestamp ? packet : await packetSink.getNextKeyPacket(packet, {
                    verifyKeyPackets: true
                });
                if (keyPacket) {
                    endPacket = keyPacket;
                }
            }
            const packets = packetSink.packets(keyPacket ?? undefined, endPacket);
            await packets.next(); // Skip the start packet as we already have it
            while(currentPacket && !ended && !this._track.input._disposed){
                const maxQueueSize = computeMaxQueueSize(sampleQueue.length);
                if (sampleQueue.length + decoder.getDecodeQueueSize() > maxQueueSize) {
                    ({ promise: queueDequeue, resolve: onQueueDequeue } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])());
                    await queueDequeue;
                    continue;
                }
                decoder.decode(currentPacket);
                const packetResult = await packets.next();
                if (packetResult.done) {
                    break;
                }
                currentPacket = packetResult.value;
            }
            await packets.return();
            if (!terminated && !this._track.input._disposed) {
                await decoder.flush();
            }
            decoder.close();
            if (!firstSampleQueued && lastSample) {
                sampleQueue.push(lastSample);
            }
            decoderIsFlushed = true;
            onQueueNotEmpty(); // To unstuck the generator
        })().catch((error)=>{
            if (!outOfBandError) {
                outOfBandError = error;
                onQueueNotEmpty();
            }
        });
        const track = this._track;
        const closeSamples = ()=>{
            lastSample?.close();
            for (const sample of sampleQueue){
                sample.close();
            }
        };
        return {
            async next () {
                while(true){
                    if (track.input._disposed) {
                        closeSamples();
                        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
                    } else if (terminated) {
                        return {
                            value: undefined,
                            done: true
                        };
                    } else if (outOfBandError) {
                        closeSamples();
                        throw outOfBandError;
                    } else if (sampleQueue.length > 0) {
                        const value = sampleQueue.shift();
                        onQueueDequeue();
                        return {
                            value,
                            done: false
                        };
                    } else if (!decoderIsFlushed) {
                        await queueNotEmpty;
                    } else {
                        return {
                            value: undefined,
                            done: true
                        };
                    }
                }
            },
            async return () {
                terminated = true;
                ended = true;
                onQueueDequeue();
                onQueueNotEmpty();
                closeSamples();
                return {
                    value: undefined,
                    done: true
                };
            },
            async throw (error) {
                throw error;
            },
            [Symbol.asyncIterator] () {
                return this;
            }
        };
    }
    /** @internal */ mediaSamplesAtTimestamps(timestamps) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateAnyIterable"])(timestamps);
        const timestampIterator = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toAsyncIterator"])(timestamps);
        const timestampsOfInterest = [];
        const sampleQueue = [];
        let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])();
        let { promise: queueDequeue, resolve: onQueueDequeue } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])();
        let decoderIsFlushed = false;
        let terminated = false;
        // This stores errors that are "out of band" in the sense that they didn't occur in the normal flow of this
        // method but instead in a different context. This error should not go unnoticed and must be bubbled up to
        // the consumer.
        let outOfBandError = null;
        const pushToQueue = (sample)=>{
            sampleQueue.push(sample);
            onQueueNotEmpty();
            ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])());
        };
        // The following is the "pump" process that keeps pumping packets into the decoder
        (async ()=>{
            const decoder = await this._createDecoder((sample)=>{
                onQueueDequeue();
                if (terminated) {
                    sample.close();
                    return;
                }
                let sampleUses = 0;
                while(timestampsOfInterest.length > 0 && sample.timestamp - timestampsOfInterest[0] > -1e-10 // Give it a little epsilon
                ){
                    sampleUses++;
                    timestampsOfInterest.shift();
                }
                if (sampleUses > 0) {
                    for(let i = 0; i < sampleUses; i++){
                        // Clone the sample if we need to emit it multiple times
                        pushToQueue(i < sampleUses - 1 ? sample.clone() : sample);
                    }
                } else {
                    sample.close();
                }
            }, (error)=>{
                if (!outOfBandError) {
                    outOfBandError = error;
                    onQueueNotEmpty();
                }
            });
            const packetSink = this._createPacketSink();
            let lastPacket = null;
            let lastKeyPacket = null;
            // The end sequence number (inclusive) in the next batch of packets that will be decoded. The batch starts
            // at the last key frame and goes until this sequence number.
            let maxSequenceNumber = -1;
            const decodePackets = async ()=>{
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(lastKeyPacket);
                // Start at the current key packet
                let currentPacket = lastKeyPacket;
                decoder.decode(currentPacket);
                while(currentPacket.sequenceNumber < maxSequenceNumber){
                    const maxQueueSize = computeMaxQueueSize(sampleQueue.length);
                    while(sampleQueue.length + decoder.getDecodeQueueSize() > maxQueueSize && !terminated){
                        ({ promise: queueDequeue, resolve: onQueueDequeue } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])());
                        await queueDequeue;
                    }
                    if (terminated) {
                        break;
                    }
                    const nextPacket = await packetSink.getNextPacket(currentPacket);
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(nextPacket);
                    decoder.decode(nextPacket);
                    currentPacket = nextPacket;
                }
                maxSequenceNumber = -1;
            };
            const flushDecoder = async ()=>{
                await decoder.flush();
                // We don't expect this list to have any elements in it anymore, but in case it does, let's emit
                // nulls for every remaining element, then clear it.
                for(let i = 0; i < timestampsOfInterest.length; i++){
                    pushToQueue(null);
                }
                timestampsOfInterest.length = 0;
            };
            for await (const timestamp of timestampIterator){
                validateTimestamp(timestamp);
                if (terminated || this._track.input._disposed) {
                    break;
                }
                const targetPacket = await packetSink.getPacket(timestamp);
                const keyPacket = targetPacket && await packetSink.getKeyPacket(timestamp, {
                    verifyKeyPackets: true
                });
                if (!keyPacket) {
                    if (maxSequenceNumber !== -1) {
                        await decodePackets();
                        await flushDecoder();
                    }
                    pushToQueue(null);
                    lastPacket = null;
                    continue;
                }
                // Check if the key packet has changed or if we're going back in time
                if (lastPacket && (keyPacket.sequenceNumber !== lastKeyPacket.sequenceNumber || targetPacket.timestamp < lastPacket.timestamp)) {
                    await decodePackets();
                    await flushDecoder(); // Always flush here, improves decoder compatibility
                }
                timestampsOfInterest.push(targetPacket.timestamp);
                maxSequenceNumber = Math.max(targetPacket.sequenceNumber, maxSequenceNumber);
                lastPacket = targetPacket;
                lastKeyPacket = keyPacket;
            }
            if (!terminated && !this._track.input._disposed) {
                if (maxSequenceNumber !== -1) {
                    // We still need to decode packets
                    await decodePackets();
                }
                await flushDecoder();
            }
            decoder.close();
            decoderIsFlushed = true;
            onQueueNotEmpty(); // To unstuck the generator
        })().catch((error)=>{
            if (!outOfBandError) {
                outOfBandError = error;
                onQueueNotEmpty();
            }
        });
        const track = this._track;
        const closeSamples = ()=>{
            for (const sample of sampleQueue){
                sample?.close();
            }
        };
        return {
            async next () {
                while(true){
                    if (track.input._disposed) {
                        closeSamples();
                        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
                    } else if (terminated) {
                        return {
                            value: undefined,
                            done: true
                        };
                    } else if (outOfBandError) {
                        closeSamples();
                        throw outOfBandError;
                    } else if (sampleQueue.length > 0) {
                        const value = sampleQueue.shift();
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(value !== undefined);
                        onQueueDequeue();
                        return {
                            value,
                            done: false
                        };
                    } else if (!decoderIsFlushed) {
                        await queueNotEmpty;
                    } else {
                        return {
                            value: undefined,
                            done: true
                        };
                    }
                }
            },
            async return () {
                terminated = true;
                onQueueDequeue();
                onQueueNotEmpty();
                closeSamples();
                return {
                    value: undefined,
                    done: true
                };
            },
            async throw (error) {
                throw error;
            },
            [Symbol.asyncIterator] () {
                return this;
            }
        };
    }
}
const computeMaxQueueSize = (decodedSampleQueueSize)=>{
    // If we have decoded samples lying around, limit the total queue size to a small value (decoded samples can use up
    // a lot of memory). If not, we're fine with a much bigger queue of encoded packets waiting to be decoded. In fact,
    // some decoders only start flushing out decoded chunks when the packet queue is large enough.
    return decodedSampleQueueSize === 0 ? 40 : 8;
};
class VideoDecoderWrapper extends DecoderWrapper {
    constructor(onSample, onError, codec, decoderConfig, rotation, timeResolution){
        super(onSample, onError);
        this.codec = codec;
        this.decoderConfig = decoderConfig;
        this.rotation = rotation;
        this.timeResolution = timeResolution;
        this.decoder = null;
        this.customDecoder = null;
        this.customDecoderCallSerializer = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["CallSerializer"]();
        this.customDecoderQueueSize = 0;
        this.inputTimestamps = []; // Timestamps input into the decoder, sorted.
        this.sampleQueue = []; // Safari-specific thing, check usage.
        this.currentPacketIndex = 0;
        this.raslSkipped = false; // For HEVC stuff
        // Alpha stuff
        this.alphaDecoder = null;
        this.alphaHadKeyframe = false;
        this.colorQueue = [];
        this.alphaQueue = [];
        this.merger = null;
        this.mergerCreationFailed = false;
        this.decodedAlphaChunkCount = 0;
        this.alphaDecoderQueueSize = 0;
        /** Each value is the number of decoded alpha chunks at which a null alpha frame should be added. */ this.nullAlphaFrameQueue = [];
        this.currentAlphaPacketIndex = 0;
        this.alphaRaslSkipped = false; // For HEVC stuff
        const MatchingCustomDecoder = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["customVideoDecoders"].find((x)=>x.supports(codec, decoderConfig));
        if (MatchingCustomDecoder) {
            // @ts-expect-error "Can't create instance of abstract class "
            this.customDecoder = new MatchingCustomDecoder();
            // @ts-expect-error It's technically readonly
            this.customDecoder.codec = codec;
            // @ts-expect-error It's technically readonly
            this.customDecoder.config = decoderConfig;
            // @ts-expect-error It's technically readonly
            this.customDecoder.onSample = (sample)=>{
                if (!(sample instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VideoSample"])) {
                    throw new TypeError('The argument passed to onSample must be a VideoSample.');
                }
                this.finalizeAndEmitSample(sample);
            };
            void this.customDecoderCallSerializer.call(()=>this.customDecoder.init());
        } else {
            const colorHandler = (frame)=>{
                if (this.alphaQueue.length > 0) {
                    // Even when no alpha data is present (most of the time), there will be nulls in this queue
                    const alphaFrame = this.alphaQueue.shift();
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(alphaFrame !== undefined);
                    this.mergeAlpha(frame, alphaFrame);
                } else {
                    this.colorQueue.push(frame);
                }
            };
            if (codec === 'avc' && this.decoderConfig.description && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isChromium"])()) {
                // Chromium has/had a bug with playing interlaced AVC (https://issues.chromium.org/issues/456919096)
                // which can be worked around by requesting that software decoding be used. So, here we peek into the
                // AVC description, if present, and switch to software decoding if we find interlaced content.
                const record = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["deserializeAvcDecoderConfigurationRecord"])((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(this.decoderConfig.description));
                if (record && record.sequenceParameterSets.length > 0) {
                    const sps = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseAvcSps"])(record.sequenceParameterSets[0]);
                    if (sps && sps.frameMbsOnlyFlag === 0) {
                        this.decoderConfig = {
                            ...this.decoderConfig,
                            hardwareAcceleration: 'prefer-software'
                        };
                    }
                }
            }
            const stack = new Error('Decoding error').stack;
            this.decoder = new VideoDecoder({
                output: (frame)=>{
                    try {
                        colorHandler(frame);
                    } catch (error) {
                        this.onError(error);
                    }
                },
                error: (error)=>{
                    error.stack = stack; // Provide a more useful stack trace, the default one sucks
                    this.onError(error);
                }
            });
            this.decoder.configure(this.decoderConfig);
        }
    }
    getDecodeQueueSize() {
        if (this.customDecoder) {
            return this.customDecoderQueueSize;
        } else {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.decoder);
            return Math.max(this.decoder.decodeQueueSize, this.alphaDecoder?.decodeQueueSize ?? 0);
        }
    }
    decode(packet) {
        if (this.codec === 'hevc' && this.currentPacketIndex > 0 && !this.raslSkipped) {
            if (this.hasHevcRaslPicture(packet.data)) {
                return; // Drop
            }
            this.raslSkipped = true;
        }
        this.currentPacketIndex++;
        if (this.customDecoder) {
            this.customDecoderQueueSize++;
            void this.customDecoderCallSerializer.call(()=>this.customDecoder.decode(packet)).then(()=>this.customDecoderQueueSize--);
        } else {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.decoder);
            if (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isWebKit"])()) {
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["insertSorted"])(this.inputTimestamps, packet.timestamp, (x)=>x);
            }
            this.decoder.decode(packet.toEncodedVideoChunk());
            this.decodeAlphaData(packet);
        }
    }
    decodeAlphaData(packet) {
        if (!packet.sideData.alpha || this.mergerCreationFailed) {
            // No alpha side data in the packet, most common case
            this.pushNullAlphaFrame();
            return;
        }
        if (!this.merger) {
            try {
                this.merger = new ColorAlphaMerger();
            } catch (error) {
                console.error('Due to an error, only color data will be decoded.', error);
                this.mergerCreationFailed = true;
                this.decodeAlphaData(packet); // Go again
                return;
            }
        }
        // Check if we need to set up the alpha decoder
        if (!this.alphaDecoder) {
            const alphaHandler = (frame)=>{
                this.alphaDecoderQueueSize--;
                if (this.colorQueue.length > 0) {
                    const colorFrame = this.colorQueue.shift();
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(colorFrame !== undefined);
                    this.mergeAlpha(colorFrame, frame);
                } else {
                    this.alphaQueue.push(frame);
                }
                // Check if any null frames have been queued for this point
                this.decodedAlphaChunkCount++;
                while(this.nullAlphaFrameQueue.length > 0 && this.nullAlphaFrameQueue[0] === this.decodedAlphaChunkCount){
                    this.nullAlphaFrameQueue.shift();
                    if (this.colorQueue.length > 0) {
                        const colorFrame = this.colorQueue.shift();
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(colorFrame !== undefined);
                        this.mergeAlpha(colorFrame, null);
                    } else {
                        this.alphaQueue.push(null);
                    }
                }
            };
            const stack = new Error('Decoding error').stack;
            this.alphaDecoder = new VideoDecoder({
                output: (frame)=>{
                    try {
                        alphaHandler(frame);
                    } catch (error) {
                        this.onError(error);
                    }
                },
                error: (error)=>{
                    error.stack = stack; // Provide a more useful stack trace, the default one sucks
                    this.onError(error);
                }
            });
            this.alphaDecoder.configure(this.decoderConfig);
        }
        const type = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["determineVideoPacketType"])(this.codec, this.decoderConfig, packet.sideData.alpha);
        // Alpha packets might follow a different key frame rhythm than the main packets. Therefore, before we start
        // decoding, we must first find a packet that's actually a key frame. Until then, we treat the image as opaque.
        if (!this.alphaHadKeyframe) {
            this.alphaHadKeyframe = type === 'key';
        }
        if (this.alphaHadKeyframe) {
            // Same RASL skipping logic as for color, unlikely to be hit (since who uses HEVC with separate alpha??) but
            // here for symmetry.
            if (this.codec === 'hevc' && this.currentAlphaPacketIndex > 0 && !this.alphaRaslSkipped) {
                if (this.hasHevcRaslPicture(packet.sideData.alpha)) {
                    this.pushNullAlphaFrame();
                    return;
                }
                this.alphaRaslSkipped = true;
            }
            this.currentAlphaPacketIndex++;
            this.alphaDecoder.decode(packet.alphaToEncodedVideoChunk(type ?? packet.type));
            this.alphaDecoderQueueSize++;
        } else {
            this.pushNullAlphaFrame();
        }
    }
    pushNullAlphaFrame() {
        if (this.alphaDecoderQueueSize === 0) {
            // Easy
            this.alphaQueue.push(null);
        } else {
            // There are still alpha chunks being decoded, so pushing `null` immediately would result in out-of-order
            // data and be incorrect. Instead, we need to enqueue a "null frame" for when the current decoder workload
            // has finished.
            this.nullAlphaFrameQueue.push(this.decodedAlphaChunkCount + this.alphaDecoderQueueSize);
        }
    }
    /**
     * If we're using HEVC, we need to make sure to skip any RASL slices that follow a non-IDR key frame such as
     * CRA_NUT. This is because RASL slices cannot be decoded without data before the CRA_NUT. Browsers behave
     * differently here: Chromium drops the packets, Safari throws a decoder error. Either way, it's not good
     * and causes bugs upstream. So, let's take the dropping into our own hands.
     */ hasHevcRaslPicture(packetData) {
        const nalUnits = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["extractHevcNalUnits"])(packetData, this.decoderConfig);
        return nalUnits.some((x)=>{
            const type = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["extractNalUnitTypeForHevc"])(x);
            return type === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HevcNalUnitType"].RASL_N || type === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HevcNalUnitType"].RASL_R;
        });
    }
    /** Handler for the WebCodecs VideoDecoder for ironing out browser differences. */ sampleHandler(sample) {
        if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isWebKit"])()) {
            // For correct B-frame handling, we don't just hand over the frames directly but instead add them to
            // a queue, because we want to ensure frames are emitted in presentation order. We flush the queue
            // each time we receive a frame with a timestamp larger than the highest we've seen so far, as we
            // can sure that is not a B-frame. Typically, WebCodecs automatically guarantees that frames are
            // emitted in presentation order, but Safari doesn't always follow this rule.
            if (this.sampleQueue.length > 0 && sample.timestamp >= (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["last"])(this.sampleQueue).timestamp) {
                for (const sample of this.sampleQueue){
                    this.finalizeAndEmitSample(sample);
                }
                this.sampleQueue.length = 0;
            }
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["insertSorted"])(this.sampleQueue, sample, (x)=>x.timestamp);
        } else {
            // Assign it the next earliest timestamp from the input. We do this because browsers, by spec, are
            // required to emit decoded frames in presentation order *while* retaining the timestamp of their
            // originating EncodedVideoChunk. For files with B-frames but no out-of-order timestamps (like a
            // missing ctts box, for example), this causes a mismatch. We therefore fix the timestamps and
            // ensure they are sorted by doing this.
            const timestamp = this.inputTimestamps.shift();
            // There's no way we'd have more decoded frames than encoded packets we passed in. Actually, the
            // correspondence should be 1:1.
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(timestamp !== undefined);
            sample.setTimestamp(timestamp);
            this.finalizeAndEmitSample(sample);
        }
    }
    finalizeAndEmitSample(sample) {
        // Round the timestamps to the time resolution
        sample.setTimestamp(Math.round(sample.timestamp * this.timeResolution) / this.timeResolution);
        sample.setDuration(Math.round(sample.duration * this.timeResolution) / this.timeResolution);
        sample.setRotation(this.rotation);
        this.onSample(sample);
    }
    mergeAlpha(color, alpha) {
        if (!alpha) {
            // Nothing needs to be merged
            const finalSample = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VideoSample"](color);
            this.sampleHandler(finalSample);
            return;
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.merger);
        this.merger.update(color, alpha);
        color.close();
        alpha.close();
        const finalFrame = new VideoFrame(this.merger.canvas, {
            timestamp: color.timestamp,
            duration: color.duration ?? undefined
        });
        const finalSample = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VideoSample"](finalFrame);
        this.sampleHandler(finalSample);
    }
    async flush() {
        if (this.customDecoder) {
            await this.customDecoderCallSerializer.call(()=>this.customDecoder.flush());
        } else {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.decoder);
            await Promise.all([
                this.decoder.flush(),
                this.alphaDecoder?.flush()
            ]);
            this.colorQueue.forEach((x)=>x.close());
            this.colorQueue.length = 0;
            this.alphaQueue.forEach((x)=>x?.close());
            this.alphaQueue.length = 0;
            this.alphaHadKeyframe = false;
            this.decodedAlphaChunkCount = 0;
            this.alphaDecoderQueueSize = 0;
            this.nullAlphaFrameQueue.length = 0;
            this.currentAlphaPacketIndex = 0;
            this.alphaRaslSkipped = false;
        }
        if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isWebKit"])()) {
            for (const sample of this.sampleQueue){
                this.finalizeAndEmitSample(sample);
            }
            this.sampleQueue.length = 0;
        }
        this.currentPacketIndex = 0;
        this.raslSkipped = false;
    }
    close() {
        if (this.customDecoder) {
            void this.customDecoderCallSerializer.call(()=>this.customDecoder.close());
        } else {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.decoder);
            this.decoder.close();
            this.alphaDecoder?.close();
            this.colorQueue.forEach((x)=>x.close());
            this.colorQueue.length = 0;
            this.alphaQueue.forEach((x)=>x?.close());
            this.alphaQueue.length = 0;
            this.merger?.close();
        }
        for (const sample of this.sampleQueue){
            sample.close();
        }
        this.sampleQueue.length = 0;
    }
}
/** Utility class that merges together color and alpha information using simple WebGL 2 shaders. */ class ColorAlphaMerger {
    constructor(){
        // Canvas will be resized later
        if (typeof OffscreenCanvas !== 'undefined') {
            // Prefer OffscreenCanvas for Worker environments
            this.canvas = new OffscreenCanvas(300, 150);
        } else {
            this.canvas = document.createElement('canvas');
        }
        const gl = this.canvas.getContext('webgl2', {
            premultipliedAlpha: false
        }); // Casting because of some TypeScript weirdness
        if (!gl) {
            throw new Error('Couldn\'t acquire WebGL 2 context.');
        }
        this.gl = gl;
        this.program = this.createProgram();
        this.vao = this.createVAO();
        this.colorTexture = this.createTexture();
        this.alphaTexture = this.createTexture();
        this.gl.useProgram(this.program);
        this.gl.uniform1i(this.gl.getUniformLocation(this.program, 'u_colorTexture'), 0);
        this.gl.uniform1i(this.gl.getUniformLocation(this.program, 'u_alphaTexture'), 1);
    }
    createProgram() {
        const vertexShader = this.createShader(this.gl.VERTEX_SHADER, `#version 300 es
			in vec2 a_position;
			in vec2 a_texCoord;
			out vec2 v_texCoord;
			
			void main() {
				gl_Position = vec4(a_position, 0.0, 1.0);
				v_texCoord = a_texCoord;
			}
		`);
        const fragmentShader = this.createShader(this.gl.FRAGMENT_SHADER, `#version 300 es
			precision highp float;
			
			uniform sampler2D u_colorTexture;
			uniform sampler2D u_alphaTexture;
			in vec2 v_texCoord;
			out vec4 fragColor;
			
			void main() {
				vec3 color = texture(u_colorTexture, v_texCoord).rgb;
				float alpha = texture(u_alphaTexture, v_texCoord).r;
				fragColor = vec4(color, alpha);
			}
		`);
        const program = this.gl.createProgram();
        this.gl.attachShader(program, vertexShader);
        this.gl.attachShader(program, fragmentShader);
        this.gl.linkProgram(program);
        return program;
    }
    createShader(type, source) {
        const shader = this.gl.createShader(type);
        this.gl.shaderSource(shader, source);
        this.gl.compileShader(shader);
        return shader;
    }
    createVAO() {
        const vao = this.gl.createVertexArray();
        this.gl.bindVertexArray(vao);
        const vertices = new Float32Array([
            -1,
            -1,
            0,
            1,
            1,
            -1,
            1,
            1,
            -1,
            1,
            0,
            0,
            1,
            1,
            1,
            0
        ]);
        const buffer = this.gl.createBuffer();
        this.gl.bindBuffer(this.gl.ARRAY_BUFFER, buffer);
        this.gl.bufferData(this.gl.ARRAY_BUFFER, vertices, this.gl.STATIC_DRAW);
        const positionLocation = this.gl.getAttribLocation(this.program, 'a_position');
        const texCoordLocation = this.gl.getAttribLocation(this.program, 'a_texCoord');
        this.gl.enableVertexAttribArray(positionLocation);
        this.gl.vertexAttribPointer(positionLocation, 2, this.gl.FLOAT, false, 16, 0);
        this.gl.enableVertexAttribArray(texCoordLocation);
        this.gl.vertexAttribPointer(texCoordLocation, 2, this.gl.FLOAT, false, 16, 8);
        return vao;
    }
    createTexture() {
        const texture = this.gl.createTexture();
        this.gl.bindTexture(this.gl.TEXTURE_2D, texture);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR);
        return texture;
    }
    update(color, alpha) {
        if (color.displayWidth !== this.canvas.width || color.displayHeight !== this.canvas.height) {
            this.canvas.width = color.displayWidth;
            this.canvas.height = color.displayHeight;
        }
        this.gl.activeTexture(this.gl.TEXTURE0);
        this.gl.bindTexture(this.gl.TEXTURE_2D, this.colorTexture);
        this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, color);
        this.gl.activeTexture(this.gl.TEXTURE1);
        this.gl.bindTexture(this.gl.TEXTURE_2D, this.alphaTexture);
        this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, alpha);
        this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);
        this.gl.clear(this.gl.COLOR_BUFFER_BIT);
        this.gl.bindVertexArray(this.vao);
        this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);
    }
    close() {
        this.gl.getExtension('WEBGL_lose_context')?.loseContext();
        this.gl = null;
    }
}
class VideoSampleSink extends BaseMediaSampleSink {
    /** Creates a new {@link VideoSampleSink} for the given {@link InputVideoTrack}. */ constructor(videoTrack){
        if (!(videoTrack instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputVideoTrack"])) {
            throw new TypeError('videoTrack must be an InputVideoTrack.');
        }
        super();
        this._track = videoTrack;
    }
    /** @internal */ async _createDecoder(onSample, onError) {
        if (!await this._track.canDecode()) {
            throw new Error('This video track cannot be decoded by this browser. Make sure to check decodability before using' + ' a track.');
        }
        const codec = this._track.codec;
        const rotation = this._track.rotation;
        const decoderConfig = await this._track.getDecoderConfig();
        const timeResolution = this._track.timeResolution;
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(codec && decoderConfig);
        return new VideoDecoderWrapper(onSample, onError, codec, decoderConfig, rotation, timeResolution);
    }
    /** @internal */ _createPacketSink() {
        return new EncodedPacketSink(this._track);
    }
    /**
     * Retrieves the video sample (frame) corresponding to the given timestamp, in seconds. More specifically, returns
     * the last video sample (in presentation order) with a start timestamp less than or equal to the given timestamp.
     * Returns null if the timestamp is before the track's first timestamp.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */ async getSample(timestamp) {
        validateTimestamp(timestamp);
        for await (const sample of this.mediaSamplesAtTimestamps([
            timestamp
        ])){
            return sample;
        }
        throw new Error('Internal error: Iterator returned nothing.');
    }
    /**
     * Creates an async iterator that yields the video samples (frames) of this track in presentation order. This method
     * will intelligently pre-decode a few frames ahead to enable fast iteration.
     *
     * @param startTimestamp - The timestamp in seconds at which to start yielding samples (inclusive).
     * @param endTimestamp - The timestamp in seconds at which to stop yielding samples (exclusive).
     */ samples(startTimestamp = 0, endTimestamp = Infinity) {
        return this.mediaSamplesInRange(startTimestamp, endTimestamp);
    }
    /**
     * Creates an async iterator that yields a video sample (frame) for each timestamp in the argument. This method
     * uses an optimized decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most
     * once, and is therefore more efficient than manually getting the sample for every timestamp. The iterator may
     * yield null if no frame is available for a given timestamp.
     *
     * @param timestamps - An iterable or async iterable of timestamps in seconds.
     */ samplesAtTimestamps(timestamps) {
        return this.mediaSamplesAtTimestamps(timestamps);
    }
}
class CanvasSink {
    /** Creates a new {@link CanvasSink} for the given {@link InputVideoTrack}. */ constructor(videoTrack, options = {}){
        /** @internal */ this._nextCanvasIndex = 0;
        if (!(videoTrack instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputVideoTrack"])) {
            throw new TypeError('videoTrack must be an InputVideoTrack.');
        }
        if (options && typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (options.alpha !== undefined && typeof options.alpha !== 'boolean') {
            throw new TypeError('options.alpha, when provided, must be a boolean.');
        }
        if (options.width !== undefined && (!Number.isInteger(options.width) || options.width <= 0)) {
            throw new TypeError('options.width, when defined, must be a positive integer.');
        }
        if (options.height !== undefined && (!Number.isInteger(options.height) || options.height <= 0)) {
            throw new TypeError('options.height, when defined, must be a positive integer.');
        }
        if (options.fit !== undefined && ![
            'fill',
            'contain',
            'cover'
        ].includes(options.fit)) {
            throw new TypeError('options.fit, when provided, must be one of "fill", "contain", or "cover".');
        }
        if (options.width !== undefined && options.height !== undefined && options.fit === undefined) {
            throw new TypeError('When both options.width and options.height are provided, options.fit must also be provided.');
        }
        if (options.rotation !== undefined && ![
            0,
            90,
            180,
            270
        ].includes(options.rotation)) {
            throw new TypeError('options.rotation, when provided, must be 0, 90, 180 or 270.');
        }
        if (options.crop !== undefined) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateCropRectangle"])(options.crop, 'options.');
        }
        if (options.poolSize !== undefined && (typeof options.poolSize !== 'number' || !Number.isInteger(options.poolSize) || options.poolSize < 0)) {
            throw new TypeError('poolSize must be a non-negative integer.');
        }
        const rotation = options.rotation ?? videoTrack.rotation;
        const [rotatedWidth, rotatedHeight] = rotation % 180 === 0 ? [
            videoTrack.codedWidth,
            videoTrack.codedHeight
        ] : [
            videoTrack.codedHeight,
            videoTrack.codedWidth
        ];
        const crop = options.crop;
        if (crop) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clampCropRectangle"])(crop, rotatedWidth, rotatedHeight);
        }
        let [width, height] = crop ? [
            crop.width,
            crop.height
        ] : [
            rotatedWidth,
            rotatedHeight
        ];
        const originalAspectRatio = width / height;
        // If width and height aren't defined together, deduce the missing value using the aspect ratio
        if (options.width !== undefined && options.height === undefined) {
            width = options.width;
            height = Math.round(width / originalAspectRatio);
        } else if (options.width === undefined && options.height !== undefined) {
            height = options.height;
            width = Math.round(height * originalAspectRatio);
        } else if (options.width !== undefined && options.height !== undefined) {
            width = options.width;
            height = options.height;
        }
        this._videoTrack = videoTrack;
        this._alpha = options.alpha ?? false;
        this._width = width;
        this._height = height;
        this._rotation = rotation;
        this._crop = crop;
        this._fit = options.fit ?? 'fill';
        this._videoSampleSink = new VideoSampleSink(videoTrack);
        this._canvasPool = Array.from({
            length: options.poolSize ?? 0
        }, ()=>null);
    }
    /** @internal */ _videoSampleToWrappedCanvas(sample) {
        let canvas = this._canvasPool[this._nextCanvasIndex];
        let canvasIsNew = false;
        if (!canvas) {
            if (typeof document !== 'undefined') {
                // Prefer an HTMLCanvasElement
                canvas = document.createElement('canvas');
                canvas.width = this._width;
                canvas.height = this._height;
            } else {
                canvas = new OffscreenCanvas(this._width, this._height);
            }
            if (this._canvasPool.length > 0) {
                this._canvasPool[this._nextCanvasIndex] = canvas;
            }
            canvasIsNew = true;
        }
        if (this._canvasPool.length > 0) {
            this._nextCanvasIndex = (this._nextCanvasIndex + 1) % this._canvasPool.length;
        }
        const context = canvas.getContext('2d', {
            alpha: this._alpha || (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isFirefox"])()
        });
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(context);
        context.resetTransform();
        if (!canvasIsNew) {
            if (!this._alpha && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isFirefox"])()) {
                context.fillStyle = 'black';
                context.fillRect(0, 0, this._width, this._height);
            } else {
                context.clearRect(0, 0, this._width, this._height);
            }
        }
        sample.drawWithFit(context, {
            fit: this._fit,
            rotation: this._rotation,
            crop: this._crop
        });
        const result = {
            canvas,
            timestamp: sample.timestamp,
            duration: sample.duration
        };
        sample.close();
        return result;
    }
    /**
     * Retrieves a canvas with the video frame corresponding to the given timestamp, in seconds. More specifically,
     * returns the last video frame (in presentation order) with a start timestamp less than or equal to the given
     * timestamp. Returns null if the timestamp is before the track's first timestamp.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */ async getCanvas(timestamp) {
        validateTimestamp(timestamp);
        const sample = await this._videoSampleSink.getSample(timestamp);
        return sample && this._videoSampleToWrappedCanvas(sample);
    }
    /**
     * Creates an async iterator that yields canvases with the video frames of this track in presentation order. This
     * method will intelligently pre-decode a few frames ahead to enable fast iteration.
     *
     * @param startTimestamp - The timestamp in seconds at which to start yielding canvases (inclusive).
     * @param endTimestamp - The timestamp in seconds at which to stop yielding canvases (exclusive).
     */ canvases(startTimestamp = 0, endTimestamp = Infinity) {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["mapAsyncGenerator"])(this._videoSampleSink.samples(startTimestamp, endTimestamp), (sample)=>this._videoSampleToWrappedCanvas(sample));
    }
    /**
     * Creates an async iterator that yields a canvas for each timestamp in the argument. This method uses an optimized
     * decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most once, and is
     * therefore more efficient than manually getting the canvas for every timestamp. The iterator may yield null if
     * no frame is available for a given timestamp.
     *
     * @param timestamps - An iterable or async iterable of timestamps in seconds.
     */ canvasesAtTimestamps(timestamps) {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["mapAsyncGenerator"])(this._videoSampleSink.samplesAtTimestamps(timestamps), (sample)=>sample && this._videoSampleToWrappedCanvas(sample));
    }
}
class AudioDecoderWrapper extends DecoderWrapper {
    constructor(onSample, onError, codec, decoderConfig){
        super(onSample, onError);
        this.decoder = null;
        this.customDecoder = null;
        this.customDecoderCallSerializer = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["CallSerializer"]();
        this.customDecoderQueueSize = 0;
        // Internal state to accumulate a precise current timestamp based on audio durations, not the (potentially
        // inaccurate) packet timestamps.
        this.currentTimestamp = null;
        const sampleHandler = (sample)=>{
            if (this.currentTimestamp === null || Math.abs(sample.timestamp - this.currentTimestamp) >= sample.duration) {
                // We need to sync with the sample timestamp again
                this.currentTimestamp = sample.timestamp;
            }
            const preciseTimestamp = this.currentTimestamp;
            this.currentTimestamp += sample.duration;
            if (sample.numberOfFrames === 0) {
                // We skip zero-data (empty) AudioSamples. These are sometimes emitted, for example, by Firefox when it
                // decodes Vorbis (at the start).
                sample.close();
                return;
            }
            // Round the timestamp to the sample rate
            const sampleRate = decoderConfig.sampleRate;
            sample.setTimestamp(Math.round(preciseTimestamp * sampleRate) / sampleRate);
            onSample(sample);
        };
        const MatchingCustomDecoder = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["customAudioDecoders"].find((x)=>x.supports(codec, decoderConfig));
        if (MatchingCustomDecoder) {
            // @ts-expect-error "Can't create instance of abstract class "
            this.customDecoder = new MatchingCustomDecoder();
            // @ts-expect-error It's technically readonly
            this.customDecoder.codec = codec;
            // @ts-expect-error It's technically readonly
            this.customDecoder.config = decoderConfig;
            // @ts-expect-error It's technically readonly
            this.customDecoder.onSample = (sample)=>{
                if (!(sample instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AudioSample"])) {
                    throw new TypeError('The argument passed to onSample must be an AudioSample.');
                }
                sampleHandler(sample);
            };
            void this.customDecoderCallSerializer.call(()=>this.customDecoder.init());
        } else {
            const stack = new Error('Decoding error').stack;
            this.decoder = new AudioDecoder({
                output: (data)=>{
                    try {
                        sampleHandler(new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AudioSample"](data));
                    } catch (error) {
                        this.onError(error);
                    }
                },
                error: (error)=>{
                    error.stack = stack; // Provide a more useful stack trace, the default one sucks
                    this.onError(error);
                }
            });
            this.decoder.configure(decoderConfig);
        }
    }
    getDecodeQueueSize() {
        if (this.customDecoder) {
            return this.customDecoderQueueSize;
        } else {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.decoder);
            return this.decoder.decodeQueueSize;
        }
    }
    decode(packet) {
        if (this.customDecoder) {
            this.customDecoderQueueSize++;
            void this.customDecoderCallSerializer.call(()=>this.customDecoder.decode(packet)).then(()=>this.customDecoderQueueSize--);
        } else {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.decoder);
            this.decoder.decode(packet.toEncodedAudioChunk());
        }
    }
    flush() {
        if (this.customDecoder) {
            return this.customDecoderCallSerializer.call(()=>this.customDecoder.flush());
        } else {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.decoder);
            return this.decoder.flush();
        }
    }
    close() {
        if (this.customDecoder) {
            void this.customDecoderCallSerializer.call(()=>this.customDecoder.close());
        } else {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.decoder);
            this.decoder.close();
        }
    }
}
// There are a lot of PCM variants not natively supported by the browser and by AudioData. Therefore we need a simple
// decoder that maps any input PCM format into a PCM format supported by the browser.
class PcmAudioDecoderWrapper extends DecoderWrapper {
    constructor(onSample, onError, decoderConfig){
        super(onSample, onError);
        this.decoderConfig = decoderConfig;
        // Internal state to accumulate a precise current timestamp based on audio durations, not the (potentially
        // inaccurate) packet timestamps.
        this.currentTimestamp = null;
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PCM_AUDIO_CODECS"].includes(decoderConfig.codec));
        this.codec = decoderConfig.codec;
        const { dataType, sampleSize, littleEndian } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parsePcmCodec"])(this.codec);
        this.inputSampleSize = sampleSize;
        switch(sampleSize){
            case 1:
                {
                    if (dataType === 'unsigned') {
                        this.readInputValue = (view, byteOffset)=>view.getUint8(byteOffset) - 2 ** 7;
                    } else if (dataType === 'signed') {
                        this.readInputValue = (view, byteOffset)=>view.getInt8(byteOffset);
                    } else if (dataType === 'ulaw') {
                        this.readInputValue = (view, byteOffset)=>(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$pcm$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["fromUlaw"])(view.getUint8(byteOffset));
                    } else if (dataType === 'alaw') {
                        this.readInputValue = (view, byteOffset)=>(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$pcm$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["fromAlaw"])(view.getUint8(byteOffset));
                    } else {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                    }
                }
                ;
                break;
            case 2:
                {
                    if (dataType === 'unsigned') {
                        this.readInputValue = (view, byteOffset)=>view.getUint16(byteOffset, littleEndian) - 2 ** 15;
                    } else if (dataType === 'signed') {
                        this.readInputValue = (view, byteOffset)=>view.getInt16(byteOffset, littleEndian);
                    } else {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                    }
                }
                ;
                break;
            case 3:
                {
                    if (dataType === 'unsigned') {
                        this.readInputValue = (view, byteOffset)=>(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getUint24"])(view, byteOffset, littleEndian) - 2 ** 23;
                    } else if (dataType === 'signed') {
                        this.readInputValue = (view, byteOffset)=>(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getInt24"])(view, byteOffset, littleEndian);
                    } else {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                    }
                }
                ;
                break;
            case 4:
                {
                    if (dataType === 'unsigned') {
                        this.readInputValue = (view, byteOffset)=>view.getUint32(byteOffset, littleEndian) - 2 ** 31;
                    } else if (dataType === 'signed') {
                        this.readInputValue = (view, byteOffset)=>view.getInt32(byteOffset, littleEndian);
                    } else if (dataType === 'float') {
                        this.readInputValue = (view, byteOffset)=>view.getFloat32(byteOffset, littleEndian);
                    } else {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                    }
                }
                ;
                break;
            case 8:
                {
                    if (dataType === 'float') {
                        this.readInputValue = (view, byteOffset)=>view.getFloat64(byteOffset, littleEndian);
                    } else {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                    }
                }
                ;
                break;
            default:
                {
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(sampleSize);
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                }
                ;
        }
        switch(sampleSize){
            case 1:
                {
                    if (dataType === 'ulaw' || dataType === 'alaw') {
                        this.outputSampleSize = 2;
                        this.outputFormat = 's16';
                        this.writeOutputValue = (view, byteOffset, value)=>view.setInt16(byteOffset, value, true);
                    } else {
                        this.outputSampleSize = 1;
                        this.outputFormat = 'u8';
                        this.writeOutputValue = (view, byteOffset, value)=>view.setUint8(byteOffset, value + 2 ** 7);
                    }
                }
                ;
                break;
            case 2:
                {
                    this.outputSampleSize = 2;
                    this.outputFormat = 's16';
                    this.writeOutputValue = (view, byteOffset, value)=>view.setInt16(byteOffset, value, true);
                }
                ;
                break;
            case 3:
                {
                    this.outputSampleSize = 4;
                    this.outputFormat = 's32';
                    // From https://www.w3.org/TR/webcodecs:
                    // AudioData containing 24-bit samples SHOULD store those samples in s32 or f32. When samples are
                    // stored in s32, each sample MUST be left-shifted by 8 bits.
                    this.writeOutputValue = (view, byteOffset, value)=>view.setInt32(byteOffset, value << 8, true);
                }
                ;
                break;
            case 4:
                {
                    this.outputSampleSize = 4;
                    if (dataType === 'float') {
                        this.outputFormat = 'f32';
                        this.writeOutputValue = (view, byteOffset, value)=>view.setFloat32(byteOffset, value, true);
                    } else {
                        this.outputFormat = 's32';
                        this.writeOutputValue = (view, byteOffset, value)=>view.setInt32(byteOffset, value, true);
                    }
                }
                ;
                break;
            case 8:
                {
                    this.outputSampleSize = 4;
                    this.outputFormat = 'f32';
                    this.writeOutputValue = (view, byteOffset, value)=>view.setFloat32(byteOffset, value, true);
                }
                ;
                break;
            default:
                {
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(sampleSize);
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
                }
                ;
        }
        ;
    }
    getDecodeQueueSize() {
        return 0;
    }
    decode(packet) {
        const inputView = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(packet.data);
        const numberOfFrames = packet.byteLength / this.decoderConfig.numberOfChannels / this.inputSampleSize;
        const outputBufferSize = numberOfFrames * this.decoderConfig.numberOfChannels * this.outputSampleSize;
        const outputBuffer = new ArrayBuffer(outputBufferSize);
        const outputView = new DataView(outputBuffer);
        for(let i = 0; i < numberOfFrames * this.decoderConfig.numberOfChannels; i++){
            const inputIndex = i * this.inputSampleSize;
            const outputIndex = i * this.outputSampleSize;
            const value = this.readInputValue(inputView, inputIndex);
            this.writeOutputValue(outputView, outputIndex, value);
        }
        const preciseDuration = numberOfFrames / this.decoderConfig.sampleRate;
        if (this.currentTimestamp === null || Math.abs(packet.timestamp - this.currentTimestamp) >= preciseDuration) {
            // We need to sync with the packet timestamp again
            this.currentTimestamp = packet.timestamp;
        }
        const preciseTimestamp = this.currentTimestamp;
        this.currentTimestamp += preciseDuration;
        const audioSample = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$sample$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AudioSample"]({
            format: this.outputFormat,
            data: outputBuffer,
            numberOfChannels: this.decoderConfig.numberOfChannels,
            sampleRate: this.decoderConfig.sampleRate,
            numberOfFrames,
            timestamp: preciseTimestamp
        });
        this.onSample(audioSample);
    }
    async flush() {
    // Do nothing
    }
    close() {
    // Do nothing
    }
}
class AudioSampleSink extends BaseMediaSampleSink {
    /** Creates a new {@link AudioSampleSink} for the given {@link InputAudioTrack}. */ constructor(audioTrack){
        if (!(audioTrack instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputAudioTrack"])) {
            throw new TypeError('audioTrack must be an InputAudioTrack.');
        }
        super();
        this._track = audioTrack;
    }
    /** @internal */ async _createDecoder(onSample, onError) {
        if (!await this._track.canDecode()) {
            throw new Error('This audio track cannot be decoded by this browser. Make sure to check decodability before using' + ' a track.');
        }
        const codec = this._track.codec;
        const decoderConfig = await this._track.getDecoderConfig();
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(codec && decoderConfig);
        if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PCM_AUDIO_CODECS"].includes(decoderConfig.codec)) {
            return new PcmAudioDecoderWrapper(onSample, onError, decoderConfig);
        } else {
            return new AudioDecoderWrapper(onSample, onError, codec, decoderConfig);
        }
    }
    /** @internal */ _createPacketSink() {
        return new EncodedPacketSink(this._track);
    }
    /**
     * Retrieves the audio sample corresponding to the given timestamp, in seconds. More specifically, returns
     * the last audio sample (in presentation order) with a start timestamp less than or equal to the given timestamp.
     * Returns null if the timestamp is before the track's first timestamp.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */ async getSample(timestamp) {
        validateTimestamp(timestamp);
        for await (const sample of this.mediaSamplesAtTimestamps([
            timestamp
        ])){
            return sample;
        }
        throw new Error('Internal error: Iterator returned nothing.');
    }
    /**
     * Creates an async iterator that yields the audio samples of this track in presentation order. This method
     * will intelligently pre-decode a few samples ahead to enable fast iteration.
     *
     * @param startTimestamp - The timestamp in seconds at which to start yielding samples (inclusive).
     * @param endTimestamp - The timestamp in seconds at which to stop yielding samples (exclusive).
     */ samples(startTimestamp = 0, endTimestamp = Infinity) {
        return this.mediaSamplesInRange(startTimestamp, endTimestamp);
    }
    /**
     * Creates an async iterator that yields an audio sample for each timestamp in the argument. This method
     * uses an optimized decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most
     * once, and is therefore more efficient than manually getting the sample for every timestamp. The iterator may
     * yield null if no sample is available for a given timestamp.
     *
     * @param timestamps - An iterable or async iterable of timestamps in seconds.
     */ samplesAtTimestamps(timestamps) {
        return this.mediaSamplesAtTimestamps(timestamps);
    }
}
class AudioBufferSink {
    /** Creates a new {@link AudioBufferSink} for the given {@link InputAudioTrack}. */ constructor(audioTrack){
        if (!(audioTrack instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputAudioTrack"])) {
            throw new TypeError('audioTrack must be an InputAudioTrack.');
        }
        this._audioSampleSink = new AudioSampleSink(audioTrack);
    }
    /** @internal */ _audioSampleToWrappedArrayBuffer(sample) {
        const result = {
            buffer: sample.toAudioBuffer(),
            timestamp: sample.timestamp,
            duration: sample.duration
        };
        sample.close();
        return result;
    }
    /**
     * Retrieves the audio buffer corresponding to the given timestamp, in seconds. More specifically, returns
     * the last audio buffer (in presentation order) with a start timestamp less than or equal to the given timestamp.
     * Returns null if the timestamp is before the track's first timestamp.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */ async getBuffer(timestamp) {
        validateTimestamp(timestamp);
        const data = await this._audioSampleSink.getSample(timestamp);
        return data && this._audioSampleToWrappedArrayBuffer(data);
    }
    /**
     * Creates an async iterator that yields audio buffers of this track in presentation order. This method
     * will intelligently pre-decode a few buffers ahead to enable fast iteration.
     *
     * @param startTimestamp - The timestamp in seconds at which to start yielding buffers (inclusive).
     * @param endTimestamp - The timestamp in seconds at which to stop yielding buffers (exclusive).
     */ buffers(startTimestamp = 0, endTimestamp = Infinity) {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["mapAsyncGenerator"])(this._audioSampleSink.samples(startTimestamp, endTimestamp), (data)=>this._audioSampleToWrappedArrayBuffer(data));
    }
    /**
     * Creates an async iterator that yields an audio buffer for each timestamp in the argument. This method
     * uses an optimized decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most
     * once, and is therefore more efficient than manually getting the buffer for every timestamp. The iterator may
     * yield null if no buffer is available for a given timestamp.
     *
     * @param timestamps - An iterable or async iterable of timestamps in seconds.
     */ buffersAtTimestamps(timestamps) {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["mapAsyncGenerator"])(this._audioSampleSink.samplesAtTimestamps(timestamps), (data)=>data && this._audioSampleToWrappedArrayBuffer(data));
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/input-track.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "InputAudioTrack",
    ()=>InputAudioTrack,
    "InputTrack",
    ()=>InputTrack,
    "InputVideoTrack",
    ()=>InputVideoTrack
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec-data.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/custom-coder.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$media$2d$sink$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/media-sink.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/packet.js [app-route] (ecmascript)");
;
;
;
;
;
class InputTrack {
    /** @internal */ constructor(input, backing){
        this.input = input;
        this._backing = backing;
    }
    /** Returns true if and only if this track is a video track. */ isVideoTrack() {
        return this instanceof InputVideoTrack;
    }
    /** Returns true if and only if this track is an audio track. */ isAudioTrack() {
        return this instanceof InputAudioTrack;
    }
    /** The unique ID of this track in the input file. */ get id() {
        return this._backing.getId();
    }
    /**
     * The identifier of the codec used internally by the container. It is not homogenized by Mediabunny
     * and depends entirely on the container format.
     *
     * This field can be used to determine the codec of a track in case Mediabunny doesn't know that codec.
     *
     * - For ISOBMFF files, this field returns the name of the Sample Description Box (e.g. `'avc1'`).
     * - For Matroska files, this field returns the value of the `CodecID` element.
     * - For WAVE files, this field returns the value of the format tag in the `'fmt '` chunk.
     * - For ADTS files, this field contains the `MPEG-4 Audio Object Type`.
     * - In all other cases, this field is `null`.
     */ get internalCodecId() {
        return this._backing.getInternalCodecId();
    }
    /**
     * The ISO 639-2/T language code for this track. If the language is unknown, this field is `'und'` (undetermined).
     */ get languageCode() {
        return this._backing.getLanguageCode();
    }
    /** A user-defined name for this track. */ get name() {
        return this._backing.getName();
    }
    /**
     * A positive number x such that all timestamps and durations of all packets of this track are
     * integer multiples of 1/x.
     */ get timeResolution() {
        return this._backing.getTimeResolution();
    }
    /** The track's disposition, i.e. information about its intended usage. */ get disposition() {
        return this._backing.getDisposition();
    }
    /**
     * Returns the start timestamp of the first packet of this track, in seconds. While often near zero, this value
     * may be positive or even negative. A negative starting timestamp means the track's timing has been offset. Samples
     * with a negative timestamp should not be presented.
     */ getFirstTimestamp() {
        return this._backing.getFirstTimestamp();
    }
    /** Returns the end timestamp of the last packet of this track, in seconds. */ computeDuration() {
        return this._backing.computeDuration();
    }
    /**
     * Computes aggregate packet statistics for this track, such as average packet rate or bitrate.
     *
     * @param targetPacketCount - This optional parameter sets a target for how many packets this method must have
     * looked at before it can return early; this means, you can use it to aggregate only a subset (prefix) of all
     * packets. This is very useful for getting a great estimate of video frame rate without having to scan through the
     * entire file.
     */ async computePacketStats(targetPacketCount = Infinity) {
        const sink = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$media$2d$sink$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacketSink"](this);
        let startTimestamp = Infinity;
        let endTimestamp = -Infinity;
        let packetCount = 0;
        let totalPacketBytes = 0;
        for await (const packet of sink.packets(undefined, undefined, {
            metadataOnly: true
        })){
            if (packetCount >= targetPacketCount && packet.timestamp >= endTimestamp) {
                break;
            }
            startTimestamp = Math.min(startTimestamp, packet.timestamp);
            endTimestamp = Math.max(endTimestamp, packet.timestamp + packet.duration);
            packetCount++;
            totalPacketBytes += packet.byteLength;
        }
        return {
            packetCount,
            averagePacketRate: packetCount ? Number((packetCount / (endTimestamp - startTimestamp)).toPrecision(16)) : 0,
            averageBitrate: packetCount ? Number((8 * totalPacketBytes / (endTimestamp - startTimestamp)).toPrecision(16)) : 0
        };
    }
}
class InputVideoTrack extends InputTrack {
    /** @internal */ constructor(input, backing){
        super(input, backing);
        this._backing = backing;
    }
    get type() {
        return 'video';
    }
    get codec() {
        return this._backing.getCodec();
    }
    /** The width in pixels of the track's coded samples, before any transformations or rotations. */ get codedWidth() {
        return this._backing.getCodedWidth();
    }
    /** The height in pixels of the track's coded samples, before any transformations or rotations. */ get codedHeight() {
        return this._backing.getCodedHeight();
    }
    /** The angle in degrees by which the track's frames should be rotated (clockwise). */ get rotation() {
        return this._backing.getRotation();
    }
    /** The width in pixels of the track's frames after rotation. */ get displayWidth() {
        const rotation = this._backing.getRotation();
        return rotation % 180 === 0 ? this._backing.getCodedWidth() : this._backing.getCodedHeight();
    }
    /** The height in pixels of the track's frames after rotation. */ get displayHeight() {
        const rotation = this._backing.getRotation();
        return rotation % 180 === 0 ? this._backing.getCodedHeight() : this._backing.getCodedWidth();
    }
    /** Returns the color space of the track's samples. */ getColorSpace() {
        return this._backing.getColorSpace();
    }
    /** If this method returns true, the track's samples use a high dynamic range (HDR). */ async hasHighDynamicRange() {
        const colorSpace = await this._backing.getColorSpace();
        return colorSpace.primaries === 'bt2020' || colorSpace.primaries === 'smpte432' || colorSpace.transfer === 'pg' || colorSpace.transfer === 'hlg' || colorSpace.matrix === 'bt2020-ncl';
    }
    /** Checks if this track may contain transparent samples with alpha data. */ canBeTransparent() {
        return this._backing.canBeTransparent();
    }
    /**
     * Returns the [decoder configuration](https://www.w3.org/TR/webcodecs/#video-decoder-config) for decoding the
     * track's packets using a [`VideoDecoder`](https://developer.mozilla.org/en-US/docs/Web/API/VideoDecoder). Returns
     * null if the track's codec is unknown.
     */ getDecoderConfig() {
        return this._backing.getDecoderConfig();
    }
    async getCodecParameterString() {
        const decoderConfig = await this._backing.getDecoderConfig();
        return decoderConfig?.codec ?? null;
    }
    async canDecode() {
        try {
            const decoderConfig = await this._backing.getDecoderConfig();
            if (!decoderConfig) {
                return false;
            }
            const codec = this._backing.getCodec();
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(codec !== null);
            if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["customVideoDecoders"].some((x)=>x.supports(codec, decoderConfig))) {
                return true;
            }
            if (typeof VideoDecoder === 'undefined') {
                return false;
            }
            const support = await VideoDecoder.isConfigSupported(decoderConfig);
            return support.supported === true;
        } catch (error) {
            console.error('Error during decodability check:', error);
            return false;
        }
    }
    async determinePacketType(packet) {
        if (!(packet instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"])) {
            throw new TypeError('packet must be an EncodedPacket.');
        }
        if (packet.isMetadataOnly) {
            throw new TypeError('packet must not be metadata-only to determine its type.');
        }
        if (this.codec === null) {
            return null;
        }
        const decoderConfig = await this.getDecoderConfig();
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(decoderConfig);
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["determineVideoPacketType"])(this.codec, decoderConfig, packet.data);
    }
}
class InputAudioTrack extends InputTrack {
    /** @internal */ constructor(input, backing){
        super(input, backing);
        this._backing = backing;
    }
    get type() {
        return 'audio';
    }
    get codec() {
        return this._backing.getCodec();
    }
    /** The number of audio channels in the track. */ get numberOfChannels() {
        return this._backing.getNumberOfChannels();
    }
    /** The track's audio sample rate in hertz. */ get sampleRate() {
        return this._backing.getSampleRate();
    }
    /**
     * Returns the [decoder configuration](https://www.w3.org/TR/webcodecs/#audio-decoder-config) for decoding the
     * track's packets using an [`AudioDecoder`](https://developer.mozilla.org/en-US/docs/Web/API/AudioDecoder). Returns
     * null if the track's codec is unknown.
     */ getDecoderConfig() {
        return this._backing.getDecoderConfig();
    }
    async getCodecParameterString() {
        const decoderConfig = await this._backing.getDecoderConfig();
        return decoderConfig?.codec ?? null;
    }
    async canDecode() {
        try {
            const decoderConfig = await this._backing.getDecoderConfig();
            if (!decoderConfig) {
                return false;
            }
            const codec = this._backing.getCodec();
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(codec !== null);
            if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$custom$2d$coder$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["customAudioDecoders"].some((x)=>x.supports(codec, decoderConfig))) {
                return true;
            }
            if (decoderConfig.codec.startsWith('pcm-')) {
                return true; // Since we decode it ourselves
            } else {
                if (typeof AudioDecoder === 'undefined') {
                    return false;
                }
                const support = await AudioDecoder.isConfigSupported(decoderConfig);
                return support.supported === true;
            }
        } catch (error) {
            console.error('Error during decodability check:', error);
            return false;
        }
    }
    async determinePacketType(packet) {
        if (!(packet instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"])) {
            throw new TypeError('packet must be an EncodedPacket.');
        }
        if (this.codec === null) {
            return null;
        }
        return 'key'; // No audio codec with delta packets
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/id3.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "ID3_V1_GENRES",
    ()=>ID3_V1_GENRES,
    "ID3_V1_TAG_SIZE",
    ()=>ID3_V1_TAG_SIZE,
    "ID3_V2_HEADER_SIZE",
    ()=>ID3_V2_HEADER_SIZE,
    "Id3V2HeaderFlags",
    ()=>Id3V2HeaderFlags,
    "Id3V2Reader",
    ()=>Id3V2Reader,
    "Id3V2TextEncoding",
    ()=>Id3V2TextEncoding,
    "Id3V2Writer",
    ()=>Id3V2Writer,
    "parseId3V1Tag",
    ()=>parseId3V1Tag,
    "parseId3V2Tag",
    ()=>parseId3V2Tag,
    "readId3V1String",
    ()=>readId3V1String,
    "readId3V2Header",
    ()=>readId3V2Header
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/shared/mp3-misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
;
;
;
var Id3V2HeaderFlags;
(function(Id3V2HeaderFlags) {
    Id3V2HeaderFlags[Id3V2HeaderFlags["Unsynchronisation"] = 128] = "Unsynchronisation";
    Id3V2HeaderFlags[Id3V2HeaderFlags["ExtendedHeader"] = 64] = "ExtendedHeader";
    Id3V2HeaderFlags[Id3V2HeaderFlags["ExperimentalIndicator"] = 32] = "ExperimentalIndicator";
    Id3V2HeaderFlags[Id3V2HeaderFlags["Footer"] = 16] = "Footer";
})(Id3V2HeaderFlags || (Id3V2HeaderFlags = {}));
var Id3V2TextEncoding;
(function(Id3V2TextEncoding) {
    Id3V2TextEncoding[Id3V2TextEncoding["ISO_8859_1"] = 0] = "ISO_8859_1";
    Id3V2TextEncoding[Id3V2TextEncoding["UTF_16_WITH_BOM"] = 1] = "UTF_16_WITH_BOM";
    Id3V2TextEncoding[Id3V2TextEncoding["UTF_16_BE_NO_BOM"] = 2] = "UTF_16_BE_NO_BOM";
    Id3V2TextEncoding[Id3V2TextEncoding["UTF_8"] = 3] = "UTF_8";
})(Id3V2TextEncoding || (Id3V2TextEncoding = {}));
const ID3_V1_TAG_SIZE = 128;
const ID3_V2_HEADER_SIZE = 10;
const ID3_V1_GENRES = [
    'Blues',
    'Classic rock',
    'Country',
    'Dance',
    'Disco',
    'Funk',
    'Grunge',
    'Hip-hop',
    'Jazz',
    'Metal',
    'New age',
    'Oldies',
    'Other',
    'Pop',
    'Rhythm and blues',
    'Rap',
    'Reggae',
    'Rock',
    'Techno',
    'Industrial',
    'Alternative',
    'Ska',
    'Death metal',
    'Pranks',
    'Soundtrack',
    'Euro-techno',
    'Ambient',
    'Trip-hop',
    'Vocal',
    'Jazz & funk',
    'Fusion',
    'Trance',
    'Classical',
    'Instrumental',
    'Acid',
    'House',
    'Game',
    'Sound clip',
    'Gospel',
    'Noise',
    'Alternative rock',
    'Bass',
    'Soul',
    'Punk',
    'Space',
    'Meditative',
    'Instrumental pop',
    'Instrumental rock',
    'Ethnic',
    'Gothic',
    'Darkwave',
    'Techno-industrial',
    'Electronic',
    'Pop-folk',
    'Eurodance',
    'Dream',
    'Southern rock',
    'Comedy',
    'Cult',
    'Gangsta',
    'Top 40',
    'Christian rap',
    'Pop/funk',
    'Jungle music',
    'Native US',
    'Cabaret',
    'New wave',
    'Psychedelic',
    'Rave',
    'Showtunes',
    'Trailer',
    'Lo-fi',
    'Tribal',
    'Acid punk',
    'Acid jazz',
    'Polka',
    'Retro',
    'Musical',
    'Rock \'n\' roll',
    'Hard rock',
    'Folk',
    'Folk rock',
    'National folk',
    'Swing',
    'Fast fusion',
    'Bebop',
    'Latin',
    'Revival',
    'Celtic',
    'Bluegrass',
    'Avantgarde',
    'Gothic rock',
    'Progressive rock',
    'Psychedelic rock',
    'Symphonic rock',
    'Slow rock',
    'Big band',
    'Chorus',
    'Easy listening',
    'Acoustic',
    'Humour',
    'Speech',
    'Chanson',
    'Opera',
    'Chamber music',
    'Sonata',
    'Symphony',
    'Booty bass',
    'Primus',
    'Porn groove',
    'Satire',
    'Slow jam',
    'Club',
    'Tango',
    'Samba',
    'Folklore',
    'Ballad',
    'Power ballad',
    'Rhythmic Soul',
    'Freestyle',
    'Duet',
    'Punk rock',
    'Drum solo',
    'A cappella',
    'Euro-house',
    'Dance hall',
    'Goa music',
    'Drum & bass',
    'Club-house',
    'Hardcore techno',
    'Terror',
    'Indie',
    'Britpop',
    'Negerpunk',
    'Polsk punk',
    'Beat',
    'Christian gangsta rap',
    'Heavy metal',
    'Black metal',
    'Crossover',
    'Contemporary Christian',
    'Christian rock',
    'Merengue',
    'Salsa',
    'Thrash metal',
    'Anime',
    'Jpop',
    'Synthpop',
    'Christmas',
    'Art rock',
    'Baroque',
    'Bhangra',
    'Big beat',
    'Breakbeat',
    'Chillout',
    'Downtempo',
    'Dub',
    'EBM',
    'Eclectic',
    'Electro',
    'Electroclash',
    'Emo',
    'Experimental',
    'Garage',
    'Global',
    'IDM',
    'Illbient',
    'Industro-Goth',
    'Jam Band',
    'Krautrock',
    'Leftfield',
    'Lounge',
    'Math rock',
    'New romantic',
    'Nu-breakz',
    'Post-punk',
    'Post-rock',
    'Psytrance',
    'Shoegaze',
    'Space rock',
    'Trop rock',
    'World music',
    'Neoclassical',
    'Audiobook',
    'Audio theatre',
    'Neue Deutsche Welle',
    'Podcast',
    'Indie rock',
    'G-Funk',
    'Dubstep',
    'Garage rock',
    'Psybient'
];
const parseId3V1Tag = (slice, tags)=>{
    const startPos = slice.filePos;
    tags.raw ??= {};
    tags.raw['TAG'] ??= (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, ID3_V1_TAG_SIZE - 3); // Dump the whole tag into the raw metadata
    slice.filePos = startPos;
    const title = readId3V1String(slice, 30);
    if (title) tags.title ??= title;
    const artist = readId3V1String(slice, 30);
    if (artist) tags.artist ??= artist;
    const album = readId3V1String(slice, 30);
    if (album) tags.album ??= album;
    const yearText = readId3V1String(slice, 4);
    const year = Number.parseInt(yearText, 10);
    if (Number.isInteger(year) && year > 0) {
        tags.date ??= new Date(year, 0, 1);
    }
    const commentBytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, 30);
    let comment;
    // Check for the ID3v1.1 track number format:
    // The 29th byte (index 28) is a null terminator, and the 30th byte is the track number.
    if (commentBytes[28] === 0 && commentBytes[29] !== 0) {
        const trackNum = commentBytes[29];
        if (trackNum > 0) {
            tags.trackNumber ??= trackNum;
        }
        slice.skip(-30);
        comment = readId3V1String(slice, 28);
        slice.skip(2);
    } else {
        slice.skip(-30);
        comment = readId3V1String(slice, 30);
    }
    if (comment) tags.comment ??= comment;
    const genreIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice);
    if (genreIndex < ID3_V1_GENRES.length) {
        tags.genre ??= ID3_V1_GENRES[genreIndex];
    }
};
const readId3V1String = (slice, length)=>{
    const bytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, length);
    const endIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["coalesceIndex"])(bytes.indexOf(0), bytes.length);
    const relevantBytes = bytes.subarray(0, endIndex);
    // Decode as ISO-8859-1
    let str = '';
    for(let i = 0; i < relevantBytes.length; i++){
        str += String.fromCharCode(relevantBytes[i]);
    }
    return str.trimEnd(); // String also may be padded with spaces
};
const readId3V2Header = (slice)=>{
    const startPos = slice.filePos;
    const tag = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 3);
    const majorVersion = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice);
    const revision = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice);
    const flags = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice);
    const sizeRaw = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Be"])(slice);
    if (tag !== 'ID3' || majorVersion === 0xff || revision === 0xff || (sizeRaw & 0x80808080) !== 0) {
        slice.filePos = startPos;
        return null;
    }
    const size = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["decodeSynchsafe"])(sizeRaw);
    return {
        majorVersion,
        revision,
        flags,
        size
    };
};
const parseId3V2Tag = (slice, header, tags)=>{
    // https://id3.org/id3v2.3.0
    if (![
        2,
        3,
        4
    ].includes(header.majorVersion)) {
        console.warn(`Unsupported ID3v2 major version: ${header.majorVersion}`);
        return;
    }
    const bytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, header.size);
    const reader = new Id3V2Reader(header, bytes);
    if (header.flags & Id3V2HeaderFlags.Footer) {
        reader.removeFooter();
    }
    if (header.flags & Id3V2HeaderFlags.Unsynchronisation && header.majorVersion === 3) {
        reader.ununsynchronizeAll();
    }
    if (header.flags & Id3V2HeaderFlags.ExtendedHeader) {
        const extendedHeaderSize = reader.readU32();
        if (header.majorVersion === 3) {
            reader.pos += extendedHeaderSize; // The extended header size excludes itself
        } else {
            reader.pos += extendedHeaderSize - 4; // The extended header size includes itself
        }
    }
    while(reader.pos <= reader.bytes.length - reader.frameHeaderSize()){
        const frame = reader.readId3V2Frame();
        if (!frame) {
            break;
        }
        const frameStartPos = reader.pos;
        const frameEndPos = reader.pos + frame.size;
        let frameEncrypted = false;
        let frameCompressed = false;
        let frameUnsynchronized = false;
        if (header.majorVersion === 3) {
            frameEncrypted = !!(frame.flags & 1 << 6);
            frameCompressed = !!(frame.flags & 1 << 7);
        } else if (header.majorVersion === 4) {
            frameEncrypted = !!(frame.flags & 1 << 2);
            frameCompressed = !!(frame.flags & 1 << 3);
            frameUnsynchronized = !!(frame.flags & 1 << 1) || !!(header.flags & Id3V2HeaderFlags.Unsynchronisation);
        }
        if (frameEncrypted) {
            console.warn(`Skipping encrypted ID3v2 frame ${frame.id}`);
            reader.pos = frameEndPos;
            continue;
        }
        if (frameCompressed) {
            console.warn(`Skipping compressed ID3v2 frame ${frame.id}`); // Maybe someday? Idk
            reader.pos = frameEndPos;
            continue;
        }
        if (frameUnsynchronized) {
            reader.ununsynchronizeRegion(reader.pos, frameEndPos);
        }
        tags.raw ??= {};
        if (frame.id[0] === 'T') {
            // It's a text frame, let's decode as text
            tags.raw[frame.id] ??= reader.readId3V2EncodingAndText(frameEndPos);
        } else {
            // For the others, let's just get the bytes
            tags.raw[frame.id] ??= reader.readBytes(frame.size);
        }
        reader.pos = frameStartPos;
        switch(frame.id){
            case 'TIT2':
            case 'TT2':
                {
                    tags.title ??= reader.readId3V2EncodingAndText(frameEndPos);
                }
                ;
                break;
            case 'TIT3':
            case 'TT3':
                {
                    tags.description ??= reader.readId3V2EncodingAndText(frameEndPos);
                }
                ;
                break;
            case 'TPE1':
            case 'TP1':
                {
                    tags.artist ??= reader.readId3V2EncodingAndText(frameEndPos);
                }
                ;
                break;
            case 'TALB':
            case 'TAL':
                {
                    tags.album ??= reader.readId3V2EncodingAndText(frameEndPos);
                }
                ;
                break;
            case 'TPE2':
            case 'TP2':
                {
                    tags.albumArtist ??= reader.readId3V2EncodingAndText(frameEndPos);
                }
                ;
                break;
            case 'TRCK':
            case 'TRK':
                {
                    const trackText = reader.readId3V2EncodingAndText(frameEndPos);
                    const parts = trackText.split('/');
                    const trackNum = Number.parseInt(parts[0], 10);
                    const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);
                    if (Number.isInteger(trackNum) && trackNum > 0) {
                        tags.trackNumber ??= trackNum;
                    }
                    if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {
                        tags.tracksTotal ??= tracksTotal;
                    }
                }
                ;
                break;
            case 'TPOS':
            case 'TPA':
                {
                    const discText = reader.readId3V2EncodingAndText(frameEndPos);
                    const parts = discText.split('/');
                    const discNum = Number.parseInt(parts[0], 10);
                    const discsTotal = parts[1] && Number.parseInt(parts[1], 10);
                    if (Number.isInteger(discNum) && discNum > 0) {
                        tags.discNumber ??= discNum;
                    }
                    if (discsTotal && Number.isInteger(discsTotal) && discsTotal > 0) {
                        tags.discsTotal ??= discsTotal;
                    }
                }
                ;
                break;
            case 'TCON':
            case 'TCO':
                {
                    const genreText = reader.readId3V2EncodingAndText(frameEndPos);
                    let match = /^\((\d+)\)/.exec(genreText);
                    if (match) {
                        const genreNumber = Number.parseInt(match[1]);
                        if (ID3_V1_GENRES[genreNumber] !== undefined) {
                            tags.genre ??= ID3_V1_GENRES[genreNumber];
                            break;
                        }
                    }
                    match = /^\d+$/.exec(genreText);
                    if (match) {
                        const genreNumber = Number.parseInt(match[0]);
                        if (ID3_V1_GENRES[genreNumber] !== undefined) {
                            tags.genre ??= ID3_V1_GENRES[genreNumber];
                            break;
                        }
                    }
                    tags.genre ??= genreText;
                }
                ;
                break;
            case 'TDRC':
            case 'TDAT':
                {
                    const dateText = reader.readId3V2EncodingAndText(frameEndPos);
                    const date = new Date(dateText);
                    if (!Number.isNaN(date.getTime())) {
                        tags.date ??= date;
                    }
                }
                ;
                break;
            case 'TYER':
            case 'TYE':
                {
                    const yearText = reader.readId3V2EncodingAndText(frameEndPos);
                    const year = Number.parseInt(yearText, 10);
                    if (Number.isInteger(year)) {
                        tags.date ??= new Date(year, 0, 1);
                    }
                }
                ;
                break;
            case 'USLT':
            case 'ULT':
                {
                    const encoding = reader.readU8();
                    reader.pos += 3; // Skip language
                    reader.readId3V2Text(encoding, frameEndPos); // Short content description
                    tags.lyrics ??= reader.readId3V2Text(encoding, frameEndPos);
                }
                ;
                break;
            case 'COMM':
            case 'COM':
                {
                    const encoding = reader.readU8();
                    reader.pos += 3; // Skip language
                    reader.readId3V2Text(encoding, frameEndPos); // Short content description
                    tags.comment ??= reader.readId3V2Text(encoding, frameEndPos);
                }
                ;
                break;
            case 'APIC':
            case 'PIC':
                {
                    const encoding = reader.readId3V2TextEncoding();
                    let mimeType;
                    if (header.majorVersion === 2) {
                        const imageFormat = reader.readAscii(3);
                        mimeType = imageFormat === 'PNG' ? 'image/png' : imageFormat === 'JPG' ? 'image/jpeg' : 'image/*';
                    } else {
                        mimeType = reader.readId3V2Text(encoding, frameEndPos);
                    }
                    const pictureType = reader.readU8();
                    const description = reader.readId3V2Text(encoding, frameEndPos).trimEnd(); // Trim ending spaces
                    const imageDataSize = frameEndPos - reader.pos;
                    if (imageDataSize >= 0) {
                        const imageData = reader.readBytes(imageDataSize);
                        if (!tags.images) tags.images = [];
                        tags.images.push({
                            data: imageData,
                            mimeType,
                            kind: pictureType === 3 ? 'coverFront' : pictureType === 4 ? 'coverBack' : 'unknown',
                            description
                        });
                    }
                }
                ;
                break;
            default:
                {
                    reader.pos += frame.size;
                }
                ;
                break;
        }
        reader.pos = frameEndPos;
    }
};
class Id3V2Reader {
    constructor(header, bytes){
        this.header = header;
        this.bytes = bytes;
        this.pos = 0;
        this.view = new DataView(bytes.buffer, bytes.byteOffset, bytes.byteLength);
    }
    frameHeaderSize() {
        return this.header.majorVersion === 2 ? 6 : 10;
    }
    ununsynchronizeAll() {
        const newBytes = [];
        for(let i = 0; i < this.bytes.length; i++){
            const value1 = this.bytes[i];
            newBytes.push(value1);
            if (value1 === 0xff && i !== this.bytes.length - 1) {
                const value2 = this.bytes[i];
                if (value2 === 0x00) {
                    i++;
                }
            }
        }
        this.bytes = new Uint8Array(newBytes);
        this.view = new DataView(this.bytes.buffer);
    }
    ununsynchronizeRegion(start, end) {
        const newBytes = [];
        for(let i = start; i < end; i++){
            const value1 = this.bytes[i];
            newBytes.push(value1);
            if (value1 === 0xff && i !== end - 1) {
                const value2 = this.bytes[i + 1];
                if (value2 === 0x00) {
                    i++;
                }
            }
        }
        const before = this.bytes.subarray(0, start);
        const after = this.bytes.subarray(end);
        this.bytes = new Uint8Array(before.length + newBytes.length + after.length);
        this.bytes.set(before, 0);
        this.bytes.set(newBytes, before.length);
        this.bytes.set(after, before.length + newBytes.length);
        this.view = new DataView(this.bytes.buffer);
    }
    removeFooter() {
        this.bytes = this.bytes.subarray(0, this.bytes.length - ID3_V2_HEADER_SIZE);
        this.view = new DataView(this.bytes.buffer);
    }
    readBytes(length) {
        const slice = this.bytes.subarray(this.pos, this.pos + length);
        this.pos += length;
        return slice;
    }
    readU8() {
        const value = this.view.getUint8(this.pos);
        this.pos += 1;
        return value;
    }
    readU16() {
        const value = this.view.getUint16(this.pos, false);
        this.pos += 2;
        return value;
    }
    readU24() {
        const high = this.view.getUint16(this.pos, false);
        const low = this.view.getUint8(this.pos + 1);
        this.pos += 3;
        return high * 0x100 + low;
    }
    readU32() {
        const value = this.view.getUint32(this.pos, false);
        this.pos += 4;
        return value;
    }
    readAscii(length) {
        let str = '';
        for(let i = 0; i < length; i++){
            str += String.fromCharCode(this.view.getUint8(this.pos + i));
        }
        this.pos += length;
        return str;
    }
    readId3V2Frame() {
        if (this.header.majorVersion === 2) {
            const id = this.readAscii(3);
            if (id === '\x00\x00\x00') {
                return null;
            }
            const size = this.readU24();
            return {
                id,
                size,
                flags: 0
            };
        } else {
            const id = this.readAscii(4);
            if (id === '\x00\x00\x00\x00') {
                // We've landed in the padding section
                return null;
            }
            const sizeRaw = this.readU32();
            let size = this.header.majorVersion === 4 ? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["decodeSynchsafe"])(sizeRaw) : sizeRaw;
            const flags = this.readU16();
            const headerEndPos = this.pos;
            // Some files may have incorrectly synchsafed/unsynchsafed sizes. To validate which interpretation is valid,
            // we validate a size by skipping ahead and seeing if we land at a valid frame header (or at the end of the
            // tag.
            const isSizeValid = (size)=>{
                const nextPos = this.pos + size;
                if (nextPos > this.bytes.length) {
                    return false;
                }
                if (nextPos <= this.bytes.length - this.frameHeaderSize()) {
                    this.pos += size;
                    const nextId = this.readAscii(4);
                    if (nextId !== '\x00\x00\x00\x00' && !/[0-9A-Z]{4}/.test(nextId)) {
                        return false;
                    }
                }
                return true;
            };
            if (!isSizeValid(size)) {
                // Flip the synchsafing, and try if this one makes more sense
                const otherSize = this.header.majorVersion === 4 ? sizeRaw : (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["decodeSynchsafe"])(sizeRaw);
                if (isSizeValid(otherSize)) {
                    size = otherSize;
                }
            }
            this.pos = headerEndPos;
            return {
                id,
                size,
                flags
            };
        }
    }
    readId3V2TextEncoding() {
        const number = this.readU8();
        if (number > 3) {
            throw new Error(`Unsupported text encoding: ${number}`);
        }
        return number;
    }
    readId3V2Text(encoding, until) {
        const startPos = this.pos;
        const data = this.readBytes(until - this.pos);
        switch(encoding){
            case Id3V2TextEncoding.ISO_8859_1:
                {
                    let str = '';
                    for(let i = 0; i < data.length; i++){
                        const value = data[i];
                        if (value === 0) {
                            this.pos = startPos + i + 1;
                            break;
                        }
                        str += String.fromCharCode(value);
                    }
                    return str;
                }
            case Id3V2TextEncoding.UTF_16_WITH_BOM:
                {
                    if (data[0] === 0xff && data[1] === 0xfe) {
                        const decoder = new TextDecoder('utf-16le');
                        const endIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["coalesceIndex"])(data.findIndex((x, i)=>x === 0 && data[i + 1] === 0 && i % 2 === 0), data.length);
                        this.pos = startPos + Math.min(endIndex + 2, data.length);
                        return decoder.decode(data.subarray(2, endIndex));
                    } else if (data[0] === 0xfe && data[1] === 0xff) {
                        const decoder = new TextDecoder('utf-16be');
                        const endIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["coalesceIndex"])(data.findIndex((x, i)=>x === 0 && data[i + 1] === 0 && i % 2 === 0), data.length);
                        this.pos = startPos + Math.min(endIndex + 2, data.length);
                        return decoder.decode(data.subarray(2, endIndex));
                    } else {
                        // Treat it like UTF-8, some files do this
                        const endIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["coalesceIndex"])(data.findIndex((x)=>x === 0), data.length);
                        this.pos = startPos + Math.min(endIndex + 1, data.length);
                        return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textDecoder"].decode(data.subarray(0, endIndex));
                    }
                }
            case Id3V2TextEncoding.UTF_16_BE_NO_BOM:
                {
                    const decoder = new TextDecoder('utf-16be');
                    const endIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["coalesceIndex"])(data.findIndex((x, i)=>x === 0 && data[i + 1] === 0 && i % 2 === 0), data.length);
                    this.pos = startPos + Math.min(endIndex + 2, data.length);
                    return decoder.decode(data.subarray(0, endIndex));
                }
            case Id3V2TextEncoding.UTF_8:
                {
                    const endIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["coalesceIndex"])(data.findIndex((x)=>x === 0), data.length);
                    this.pos = startPos + Math.min(endIndex + 1, data.length);
                    return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textDecoder"].decode(data.subarray(0, endIndex));
                }
        }
    }
    readId3V2EncodingAndText(until) {
        if (this.pos >= until) {
            return '';
        }
        const encoding = this.readId3V2TextEncoding();
        return this.readId3V2Text(encoding, until);
    }
}
class Id3V2Writer {
    constructor(writer){
        this.helper = new Uint8Array(8);
        this.helperView = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(this.helper);
        this.writer = writer;
    }
    writeId3V2Tag(metadata) {
        const tagStartPos = this.writer.getPos();
        // Write ID3v2.4 header
        this.writeAscii('ID3');
        this.writeU8(0x04); // Version 2.4
        this.writeU8(0x00); // Revision 0
        this.writeU8(0x00); // Flags
        this.writeSynchsafeU32(0); // Size placeholder
        const framesStartPos = this.writer.getPos();
        const writtenTags = new Set();
        // Write all metadata frames
        for (const { key, value } of (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["keyValueIterator"])(metadata)){
            switch(key){
                case 'title':
                    {
                        this.writeId3V2TextFrame('TIT2', value);
                        writtenTags.add('TIT2');
                    }
                    ;
                    break;
                case 'description':
                    {
                        this.writeId3V2TextFrame('TIT3', value);
                        writtenTags.add('TIT3');
                    }
                    ;
                    break;
                case 'artist':
                    {
                        this.writeId3V2TextFrame('TPE1', value);
                        writtenTags.add('TPE1');
                    }
                    ;
                    break;
                case 'album':
                    {
                        this.writeId3V2TextFrame('TALB', value);
                        writtenTags.add('TALB');
                    }
                    ;
                    break;
                case 'albumArtist':
                    {
                        this.writeId3V2TextFrame('TPE2', value);
                        writtenTags.add('TPE2');
                    }
                    ;
                    break;
                case 'trackNumber':
                    {
                        const string = metadata.tracksTotal !== undefined ? `${value}/${metadata.tracksTotal}` : value.toString();
                        this.writeId3V2TextFrame('TRCK', string);
                        writtenTags.add('TRCK');
                    }
                    ;
                    break;
                case 'discNumber':
                    {
                        const string = metadata.discsTotal !== undefined ? `${value}/${metadata.discsTotal}` : value.toString();
                        this.writeId3V2TextFrame('TPOS', string);
                        writtenTags.add('TPOS');
                    }
                    ;
                    break;
                case 'genre':
                    {
                        this.writeId3V2TextFrame('TCON', value);
                        writtenTags.add('TCON');
                    }
                    ;
                    break;
                case 'date':
                    {
                        this.writeId3V2TextFrame('TDRC', value.toISOString().slice(0, 10));
                        writtenTags.add('TDRC');
                    }
                    ;
                    break;
                case 'lyrics':
                    {
                        this.writeId3V2LyricsFrame(value);
                        writtenTags.add('USLT');
                    }
                    ;
                    break;
                case 'comment':
                    {
                        this.writeId3V2CommentFrame(value);
                        writtenTags.add('COMM');
                    }
                    ;
                    break;
                case 'images':
                    {
                        const pictureTypeMap = {
                            coverFront: 0x03,
                            coverBack: 0x04,
                            unknown: 0x00
                        };
                        for (const image of value){
                            const pictureType = pictureTypeMap[image.kind] ?? 0x00;
                            const description = image.description ?? '';
                            this.writeId3V2ApicFrame(image.mimeType, pictureType, description, image.data);
                        }
                    }
                    ;
                    break;
                case 'tracksTotal':
                case 'discsTotal':
                    {
                    // Handled with trackNumber and discNumber respectively
                    }
                    ;
                    break;
                case 'raw':
                    {
                    // Handled later
                    }
                    ;
                    break;
                default:
                    {
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(key);
                    }
            }
        }
        if (metadata.raw) {
            for(const key in metadata.raw){
                const value = metadata.raw[key];
                if (value == null || key.length !== 4 || writtenTags.has(key)) {
                    continue;
                }
                let bytes;
                if (typeof value === 'string') {
                    const encoded = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textEncoder"].encode(value);
                    bytes = new Uint8Array(encoded.byteLength + 2);
                    bytes[0] = Id3V2TextEncoding.UTF_8;
                    bytes.set(encoded, 1);
                // Last byte is the null terminator
                } else if (value instanceof Uint8Array) {
                    bytes = value;
                } else {
                    continue;
                }
                this.writeAscii(key);
                this.writeSynchsafeU32(bytes.byteLength);
                this.writeU16(0x0000);
                this.writer.write(bytes);
            }
        }
        const framesEndPos = this.writer.getPos();
        const framesSize = framesEndPos - framesStartPos;
        // Update the size field in the header (synchsafe)
        this.writer.seek(tagStartPos + 6); // Skip 'ID3' + version + revision + flags
        this.writeSynchsafeU32(framesSize);
        this.writer.seek(framesEndPos);
        return framesSize + 10; // +10 for the header size
    }
    writeU8(value) {
        this.helper[0] = value;
        this.writer.write(this.helper.subarray(0, 1));
    }
    writeU16(value) {
        this.helperView.setUint16(0, value, false);
        this.writer.write(this.helper.subarray(0, 2));
    }
    writeU32(value) {
        this.helperView.setUint32(0, value, false);
        this.writer.write(this.helper.subarray(0, 4));
    }
    writeAscii(text) {
        for(let i = 0; i < text.length; i++){
            this.helper[i] = text.charCodeAt(i);
        }
        this.writer.write(this.helper.subarray(0, text.length));
    }
    writeSynchsafeU32(value) {
        this.writeU32((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["encodeSynchsafe"])(value));
    }
    writeIsoString(text) {
        const bytes = new Uint8Array(text.length + 1);
        for(let i = 0; i < text.length; i++){
            bytes[i] = text.charCodeAt(i);
        }
        bytes[text.length] = 0x00;
        this.writer.write(bytes);
    }
    writeUtf8String(text) {
        const utf8Data = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textEncoder"].encode(text);
        this.writer.write(utf8Data);
        this.writeU8(0x00);
    }
    writeId3V2TextFrame(frameId, text) {
        const useIso88591 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isIso88591Compatible"])(text);
        const textDataLength = useIso88591 ? text.length : __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textEncoder"].encode(text).byteLength;
        const frameSize = 1 + textDataLength + 1;
        this.writeAscii(frameId);
        this.writeSynchsafeU32(frameSize);
        this.writeU16(0x0000);
        this.writeU8(useIso88591 ? Id3V2TextEncoding.ISO_8859_1 : Id3V2TextEncoding.UTF_8);
        if (useIso88591) {
            this.writeIsoString(text);
        } else {
            this.writeUtf8String(text);
        }
    }
    writeId3V2LyricsFrame(lyrics) {
        const useIso88591 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isIso88591Compatible"])(lyrics);
        const shortDescription = '';
        const frameSize = 1 + 3 + shortDescription.length + 1 + lyrics.length + 1;
        this.writeAscii('USLT');
        this.writeSynchsafeU32(frameSize);
        this.writeU16(0x0000);
        this.writeU8(useIso88591 ? Id3V2TextEncoding.ISO_8859_1 : Id3V2TextEncoding.UTF_8);
        this.writeAscii('und');
        if (useIso88591) {
            this.writeIsoString(shortDescription);
            this.writeIsoString(lyrics);
        } else {
            this.writeUtf8String(shortDescription);
            this.writeUtf8String(lyrics);
        }
    }
    writeId3V2CommentFrame(comment) {
        const useIso88591 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isIso88591Compatible"])(comment);
        const textDataLength = useIso88591 ? comment.length : __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textEncoder"].encode(comment).byteLength;
        const shortDescription = '';
        const frameSize = 1 + 3 + shortDescription.length + 1 + textDataLength + 1;
        this.writeAscii('COMM');
        this.writeSynchsafeU32(frameSize);
        this.writeU16(0x0000);
        this.writeU8(useIso88591 ? Id3V2TextEncoding.ISO_8859_1 : Id3V2TextEncoding.UTF_8);
        this.writeU8(0x75); // 'u'
        this.writeU8(0x6E); // 'n'
        this.writeU8(0x64); // 'd'
        if (useIso88591) {
            this.writeIsoString(shortDescription);
            this.writeIsoString(comment);
        } else {
            this.writeUtf8String(shortDescription);
            this.writeUtf8String(comment);
        }
    }
    writeId3V2ApicFrame(mimeType, pictureType, description, imageData) {
        const useIso88591 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isIso88591Compatible"])(mimeType) && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isIso88591Compatible"])(description);
        const descriptionDataLength = useIso88591 ? description.length : __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textEncoder"].encode(description).byteLength;
        const frameSize = 1 + mimeType.length + 1 + 1 + descriptionDataLength + 1 + imageData.byteLength;
        this.writeAscii('APIC');
        this.writeSynchsafeU32(frameSize);
        this.writeU16(0x0000);
        this.writeU8(useIso88591 ? Id3V2TextEncoding.ISO_8859_1 : Id3V2TextEncoding.UTF_8);
        if (useIso88591) {
            this.writeIsoString(mimeType);
        } else {
            this.writeUtf8String(mimeType);
        }
        this.writeU8(pictureType);
        if (useIso88591) {
            this.writeIsoString(description);
        } else {
            this.writeUtf8String(description);
        }
        this.writer.write(imageData);
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/mp3/mp3-reader.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "readNextFrameHeader",
    ()=>readNextFrameHeader
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/shared/mp3-misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
;
;
const readNextFrameHeader = async (reader, startPos, until)=>{
    let currentPos = startPos;
    while(until === null || currentPos < until){
        let slice = reader.requestSlice(currentPos, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FRAME_HEADER_SIZE"]);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) break;
        const word = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Be"])(slice);
        const result = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readFrameHeader"])(word, reader.fileSize !== null ? reader.fileSize - currentPos : null);
        if (result.header) {
            return {
                header: result.header,
                startPos: currentPos
            };
        }
        currentPos += result.bytesAdvanced;
    }
    return null;
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/mp3/mp3-demuxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "Mp3Demuxer",
    ()=>Mp3Demuxer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/input-track.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/metadata.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/packet.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/shared/mp3-misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/id3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$mp3$2f$mp3$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/mp3/mp3-reader.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
;
class Mp3Demuxer extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Demuxer"] {
    constructor(input){
        super(input);
        this.metadataPromise = null;
        this.firstFrameHeader = null;
        this.loadedSamples = []; // All samples from the start of the file to lastLoadedPos
        this.metadataTags = null;
        this.tracks = [];
        this.readingMutex = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AsyncMutex"]();
        this.lastSampleLoaded = false;
        this.lastLoadedPos = 0;
        this.nextTimestampInSamples = 0;
        this.reader = input._reader;
    }
    async readMetadata() {
        return this.metadataPromise ??= (async ()=>{
            // Keep loading until we find the first frame header
            while(!this.firstFrameHeader && !this.lastSampleLoaded){
                await this.advanceReader();
            }
            if (!this.firstFrameHeader) {
                throw new Error('No valid MP3 frame found.');
            }
            this.tracks = [
                new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputAudioTrack"](this.input, new Mp3AudioTrackBacking(this))
            ];
        })();
    }
    async advanceReader() {
        if (this.lastLoadedPos === 0) {
            // Let's skip all ID3v2 tags at the start of the file
            while(true){
                let slice = this.reader.requestSlice(this.lastLoadedPos, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ID3_V2_HEADER_SIZE"]);
                if (slice instanceof Promise) slice = await slice;
                if (!slice) {
                    this.lastSampleLoaded = true;
                    return;
                }
                const id3V2Header = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readId3V2Header"])(slice);
                if (!id3V2Header) {
                    break;
                }
                this.lastLoadedPos = slice.filePos + id3V2Header.size;
            }
        }
        const result = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$mp3$2f$mp3$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readNextFrameHeader"])(this.reader, this.lastLoadedPos, this.reader.fileSize);
        if (!result) {
            this.lastSampleLoaded = true;
            return;
        }
        const header = result.header;
        this.lastLoadedPos = result.startPos + header.totalSize - 1; // -1 in case the frame is 1 byte too short
        const xingOffset = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getXingOffset"])(header.mpegVersionId, header.channel);
        let slice = this.reader.requestSlice(result.startPos + xingOffset, 4);
        if (slice instanceof Promise) slice = await slice;
        if (slice) {
            const word = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Be"])(slice);
            const isXing = word === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["XING"] || word === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["INFO"];
            if (isXing) {
                // There's no actual audio data in this frame, so let's skip it
                return;
            }
        }
        if (!this.firstFrameHeader) {
            this.firstFrameHeader = header;
        }
        if (header.sampleRate !== this.firstFrameHeader.sampleRate) {
            console.warn(`MP3 changed sample rate mid-file: ${this.firstFrameHeader.sampleRate} Hz to ${header.sampleRate} Hz.` + ` Might be a bug, so please report this file.`);
        }
        const sampleDuration = header.audioSamplesInFrame / this.firstFrameHeader.sampleRate;
        const sample = {
            timestamp: this.nextTimestampInSamples / this.firstFrameHeader.sampleRate,
            duration: sampleDuration,
            dataStart: result.startPos,
            dataSize: header.totalSize
        };
        this.loadedSamples.push(sample);
        this.nextTimestampInSamples += header.audioSamplesInFrame;
        return;
    }
    async getMimeType() {
        return 'audio/mpeg';
    }
    async getTracks() {
        await this.readMetadata();
        return this.tracks;
    }
    async computeDuration() {
        await this.readMetadata();
        const track = this.tracks[0];
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(track);
        return track.computeDuration();
    }
    async getMetadataTags() {
        const release = await this.readingMutex.acquire();
        try {
            await this.readMetadata();
            if (this.metadataTags) {
                return this.metadataTags;
            }
            this.metadataTags = {};
            let currentPos = 0;
            let id3V2HeaderFound = false;
            while(true){
                let headerSlice = this.reader.requestSlice(currentPos, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ID3_V2_HEADER_SIZE"]);
                if (headerSlice instanceof Promise) headerSlice = await headerSlice;
                if (!headerSlice) break;
                const id3V2Header = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readId3V2Header"])(headerSlice);
                if (!id3V2Header) {
                    break;
                }
                id3V2HeaderFound = true;
                let contentSlice = this.reader.requestSlice(headerSlice.filePos, id3V2Header.size);
                if (contentSlice instanceof Promise) contentSlice = await contentSlice;
                if (!contentSlice) break;
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseId3V2Tag"])(contentSlice, id3V2Header, this.metadataTags);
                currentPos = headerSlice.filePos + id3V2Header.size;
            }
            if (!id3V2HeaderFound && this.reader.fileSize !== null && this.reader.fileSize >= __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ID3_V1_TAG_SIZE"]) {
                // Try reading an ID3v1 tag at the end of the file
                let slice = this.reader.requestSlice(this.reader.fileSize - __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ID3_V1_TAG_SIZE"], __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ID3_V1_TAG_SIZE"]);
                if (slice instanceof Promise) slice = await slice;
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(slice);
                const tag = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 3);
                if (tag === 'TAG') {
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseId3V1Tag"])(slice, this.metadataTags);
                }
            }
            return this.metadataTags;
        } finally{
            release();
        }
    }
}
class Mp3AudioTrackBacking {
    constructor(demuxer){
        this.demuxer = demuxer;
    }
    getId() {
        return 1;
    }
    async getFirstTimestamp() {
        return 0;
    }
    getTimeResolution() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.firstFrameHeader);
        return this.demuxer.firstFrameHeader.sampleRate / this.demuxer.firstFrameHeader.audioSamplesInFrame;
    }
    async computeDuration() {
        const lastPacket = await this.getPacket(Infinity, {
            metadataOnly: true
        });
        return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);
    }
    getName() {
        return null;
    }
    getLanguageCode() {
        return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["UNDETERMINED_LANGUAGE"];
    }
    getCodec() {
        return 'mp3';
    }
    getInternalCodecId() {
        return null;
    }
    getNumberOfChannels() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.firstFrameHeader);
        return this.demuxer.firstFrameHeader.channel === 3 ? 1 : 2;
    }
    getSampleRate() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.firstFrameHeader);
        return this.demuxer.firstFrameHeader.sampleRate;
    }
    getDisposition() {
        return {
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["DEFAULT_TRACK_DISPOSITION"]
        };
    }
    async getDecoderConfig() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.firstFrameHeader);
        return {
            codec: 'mp3',
            numberOfChannels: this.demuxer.firstFrameHeader.channel === 3 ? 1 : 2,
            sampleRate: this.demuxer.firstFrameHeader.sampleRate
        };
    }
    async getPacketAtIndex(sampleIndex, options) {
        if (sampleIndex === -1) {
            return null;
        }
        const rawSample = this.demuxer.loadedSamples[sampleIndex];
        if (!rawSample) {
            return null;
        }
        let data;
        if (options.metadataOnly) {
            data = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PLACEHOLDER_DATA"];
        } else {
            let slice = this.demuxer.reader.requestSlice(rawSample.dataStart, rawSample.dataSize);
            if (slice instanceof Promise) slice = await slice;
            if (!slice) {
                return null; // Data didn't fit into the rest of the file
            }
            data = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, rawSample.dataSize);
        }
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"](data, 'key', rawSample.timestamp, rawSample.duration, sampleIndex, rawSample.dataSize);
    }
    getFirstPacket(options) {
        return this.getPacketAtIndex(0, options);
    }
    async getNextPacket(packet, options) {
        const release = await this.demuxer.readingMutex.acquire();
        try {
            const sampleIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["binarySearchExact"])(this.demuxer.loadedSamples, packet.timestamp, (x)=>x.timestamp);
            if (sampleIndex === -1) {
                throw new Error('Packet was not created from this track.');
            }
            const nextIndex = sampleIndex + 1;
            // Ensure the next sample exists
            while(nextIndex >= this.demuxer.loadedSamples.length && !this.demuxer.lastSampleLoaded){
                await this.demuxer.advanceReader();
            }
            return this.getPacketAtIndex(nextIndex, options);
        } finally{
            release();
        }
    }
    async getPacket(timestamp, options) {
        const release = await this.demuxer.readingMutex.acquire();
        try {
            while(true){
                const index = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["binarySearchLessOrEqual"])(this.demuxer.loadedSamples, timestamp, (x)=>x.timestamp);
                if (index === -1 && this.demuxer.loadedSamples.length > 0) {
                    // We're before the first sample
                    return null;
                }
                if (this.demuxer.lastSampleLoaded) {
                    // All data is loaded, return what we found
                    return this.getPacketAtIndex(index, options);
                }
                if (index >= 0 && index + 1 < this.demuxer.loadedSamples.length) {
                    // The next packet also exists, we're done
                    return this.getPacketAtIndex(index, options);
                }
                // Otherwise, keep loading data
                await this.demuxer.advanceReader();
            }
        } finally{
            release();
        }
    }
    getKeyPacket(timestamp, options) {
        return this.getPacket(timestamp, options);
    }
    getNextKeyPacket(packet, options) {
        return this.getNextPacket(packet, options);
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/mp3/mp3-writer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "Mp3Writer",
    ()=>Mp3Writer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/shared/mp3-misc.js [app-route] (ecmascript)");
;
class Mp3Writer {
    constructor(writer){
        this.writer = writer;
        this.helper = new Uint8Array(8);
        this.helperView = new DataView(this.helper.buffer);
    }
    writeU32(value) {
        this.helperView.setUint32(0, value, false);
        this.writer.write(this.helper.subarray(0, 4));
    }
    writeXingFrame(data) {
        const startPos = this.writer.getPos();
        const firstByte = 0xff;
        const secondByte = 0xe0 | data.mpegVersionId << 3 | data.layer << 1;
        let lowSamplingFrequency;
        if (data.mpegVersionId & 2) {
            lowSamplingFrequency = data.mpegVersionId & 1 ? 0 : 1;
        } else {
            lowSamplingFrequency = 1;
        }
        const padding = 0;
        const neededBytes = 155;
        let bitrateIndex = -1;
        const bitrateOffset = lowSamplingFrequency * 16 * 4 + data.layer * 16;
        // Let's find the lowest bitrate for which the frame size is sufficiently large to fit all the data
        for(let i = 0; i < 16; i++){
            const kbr = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["KILOBIT_RATES"][bitrateOffset + i];
            const size = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["computeMp3FrameSize"])(lowSamplingFrequency, data.layer, 1000 * kbr, data.sampleRate, padding);
            if (size >= neededBytes) {
                bitrateIndex = i;
                break;
            }
        }
        if (bitrateIndex === -1) {
            throw new Error('No suitable bitrate found.');
        }
        const thirdByte = bitrateIndex << 4 | data.frequencyIndex << 2 | padding << 1;
        const fourthByte = data.channel << 6 | data.modeExtension << 4 | data.copyright << 3 | data.original << 2 | data.emphasis;
        this.helper[0] = firstByte;
        this.helper[1] = secondByte;
        this.helper[2] = thirdByte;
        this.helper[3] = fourthByte;
        this.writer.write(this.helper.subarray(0, 4));
        const xingOffset = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getXingOffset"])(data.mpegVersionId, data.channel);
        this.writer.seek(startPos + xingOffset);
        this.writeU32(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["XING"]);
        let flags = 0;
        if (data.frameCount !== null) {
            flags |= 1;
        }
        if (data.fileSize !== null) {
            flags |= 2;
        }
        if (data.toc !== null) {
            flags |= 4;
        }
        this.writeU32(flags);
        this.writeU32(data.frameCount ?? 0);
        this.writeU32(data.fileSize ?? 0);
        this.writer.write(data.toc ?? new Uint8Array(100));
        const kilobitRate = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["KILOBIT_RATES"][bitrateOffset + bitrateIndex];
        const frameSize = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["computeMp3FrameSize"])(lowSamplingFrequency, data.layer, 1000 * kilobitRate, data.sampleRate, padding);
        this.writer.seek(startPos + frameSize);
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/mp3/mp3-muxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "Mp3Muxer",
    ()=>Mp3Muxer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/metadata.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/muxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/shared/mp3-misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$mp3$2f$mp3$2d$writer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/mp3/mp3-writer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/id3.js [app-route] (ecmascript)");
;
;
;
;
;
;
class Mp3Muxer extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Muxer"] {
    constructor(output, format){
        super(output);
        this.xingFrameData = null;
        this.frameCount = 0;
        this.framePositions = [];
        this.xingFramePos = null;
        this.format = format;
        this.writer = output._writer;
        this.mp3Writer = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$mp3$2f$mp3$2d$writer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Mp3Writer"](output._writer);
    }
    async start() {
        if (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["metadataTagsAreEmpty"])(this.output._metadataTags)) {
            const id3Writer = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Id3V2Writer"](this.writer);
            id3Writer.writeId3V2Tag(this.output._metadataTags);
        }
    }
    async getMimeType() {
        return 'audio/mpeg';
    }
    async addEncodedVideoPacket() {
        throw new Error('MP3 does not support video.');
    }
    async addEncodedAudioPacket(track, packet) {
        const release = await this.mutex.acquire();
        try {
            const writeXingHeader = this.format._options.xingHeader !== false;
            if (!this.xingFrameData && writeXingHeader) {
                const view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(packet.data);
                if (view.byteLength < 4) {
                    throw new Error('Invalid MP3 header in sample.');
                }
                const word = view.getUint32(0, false);
                const header = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readFrameHeader"])(word, null).header;
                if (!header) {
                    throw new Error('Invalid MP3 header in sample.');
                }
                const xingOffset = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getXingOffset"])(header.mpegVersionId, header.channel);
                if (view.byteLength >= xingOffset + 4) {
                    const word = view.getUint32(xingOffset, false);
                    const isXing = word === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["XING"] || word === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["INFO"];
                    if (isXing) {
                        // This is not a data frame, so let's completely ignore this sample
                        return;
                    }
                }
                this.xingFrameData = {
                    mpegVersionId: header.mpegVersionId,
                    layer: header.layer,
                    frequencyIndex: header.frequencyIndex,
                    sampleRate: header.sampleRate,
                    channel: header.channel,
                    modeExtension: header.modeExtension,
                    copyright: header.copyright,
                    original: header.original,
                    emphasis: header.emphasis,
                    frameCount: null,
                    fileSize: null,
                    toc: null
                };
                // Write a Xing frame because this muxer doesn't make any bitrate constraints, meaning we don't know if
                // this will be a constant or variable bitrate file. Therefore, always write the Xing frame.
                this.xingFramePos = this.writer.getPos();
                this.mp3Writer.writeXingFrame(this.xingFrameData);
                this.frameCount++;
            }
            this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === 'key');
            this.writer.write(packet.data);
            this.frameCount++;
            await this.writer.flush();
            if (writeXingHeader) {
                this.framePositions.push(this.writer.getPos());
            }
        } finally{
            release();
        }
    }
    async addSubtitleCue() {
        throw new Error('MP3 does not support subtitles.');
    }
    async finalize() {
        if (!this.xingFrameData || this.xingFramePos === null) {
            return;
        }
        const release = await this.mutex.acquire();
        const endPos = this.writer.getPos();
        this.writer.seek(this.xingFramePos);
        const toc = new Uint8Array(100);
        for(let i = 0; i < 100; i++){
            const index = Math.floor(this.framePositions.length * (i / 100));
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(index !== -1 && index < this.framePositions.length);
            const byteOffset = this.framePositions[index];
            toc[i] = 256 * (byteOffset / endPos);
        }
        this.xingFrameData.frameCount = this.frameCount;
        this.xingFrameData.fileSize = endPos;
        this.xingFrameData.toc = toc;
        if (this.format._options.onXingFrame) {
            this.writer.startTrackingWrites();
        }
        this.mp3Writer.writeXingFrame(this.xingFrameData);
        if (this.format._options.onXingFrame) {
            const { data, start } = this.writer.stopTrackingWrites();
            this.format._options.onXingFrame(data, start);
        }
        this.writer.seek(endPos);
        release();
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/ogg/ogg-misc.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "OGGS",
    ()=>OGGS,
    "buildOggMimeType",
    ()=>buildOggMimeType,
    "computeOggPageCrc",
    ()=>computeOggPageCrc,
    "extractSampleMetadata",
    ()=>extractSampleMetadata
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec-data.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
;
;
const OGGS = 0x5367674f; // 'OggS'
const OGG_CRC_POLYNOMIAL = 0x04c11db7;
const OGG_CRC_TABLE = new Uint32Array(256);
for(let n = 0; n < 256; n++){
    let crc = n << 24;
    for(let k = 0; k < 8; k++){
        crc = crc & 0x80000000 ? crc << 1 ^ OGG_CRC_POLYNOMIAL : crc << 1;
    }
    OGG_CRC_TABLE[n] = crc >>> 0 & 0xffffffff;
}
const computeOggPageCrc = (bytes)=>{
    const view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(bytes);
    const originalChecksum = view.getUint32(22, true);
    view.setUint32(22, 0, true); // Zero out checksum field
    let crc = 0;
    for(let i = 0; i < bytes.length; i++){
        const byte = bytes[i];
        crc = (crc << 8 ^ OGG_CRC_TABLE[crc >>> 24 ^ byte]) >>> 0;
    }
    view.setUint32(22, originalChecksum, true); // Restore checksum field
    return crc;
};
const extractSampleMetadata = (data, codecInfo, vorbisLastBlocksize)=>{
    let durationInSamples = 0;
    let currentBlocksize = null;
    if (data.length > 0) {
        // To know sample duration, we'll need to peak inside the packet
        if (codecInfo.codec === 'vorbis') {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(codecInfo.vorbisInfo);
            const vorbisModeCount = codecInfo.vorbisInfo.modeBlockflags.length;
            const bitCount = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ilog"])(vorbisModeCount - 1);
            const modeMask = (1 << bitCount) - 1 << 1;
            const modeNumber = (data[0] & modeMask) >> 1;
            if (modeNumber >= codecInfo.vorbisInfo.modeBlockflags.length) {
                throw new Error('Invalid mode number.');
            }
            // In Vorbis, packet duration also depends on the blocksize of the previous packet
            let prevBlocksize = vorbisLastBlocksize;
            const blockflag = codecInfo.vorbisInfo.modeBlockflags[modeNumber];
            currentBlocksize = codecInfo.vorbisInfo.blocksizes[blockflag];
            if (blockflag === 1) {
                const prevMask = (modeMask | 0x1) + 1;
                const flag = data[0] & prevMask ? 1 : 0;
                prevBlocksize = codecInfo.vorbisInfo.blocksizes[flag];
            }
            durationInSamples = prevBlocksize !== null ? prevBlocksize + currentBlocksize >> 2 : 0; // The first sample outputs no audio data and therefore has a duration of 0
        } else if (codecInfo.codec === 'opus') {
            const toc = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseOpusTocByte"])(data);
            durationInSamples = toc.durationInSamples;
        }
    }
    return {
        durationInSamples,
        vorbisBlockSize: currentBlocksize
    };
};
const buildOggMimeType = (info)=>{
    let string = 'audio/ogg';
    if (info.codecStrings) {
        const uniqueCodecMimeTypes = [
            ...new Set(info.codecStrings)
        ];
        string += `; codecs="${uniqueCodecMimeTypes.join(', ')}"`;
    }
    return string;
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/ogg/ogg-reader.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "MAX_PAGE_HEADER_SIZE",
    ()=>MAX_PAGE_HEADER_SIZE,
    "MAX_PAGE_SIZE",
    ()=>MAX_PAGE_SIZE,
    "MIN_PAGE_HEADER_SIZE",
    ()=>MIN_PAGE_HEADER_SIZE,
    "findNextPageHeader",
    ()=>findNextPageHeader,
    "readPageHeader",
    ()=>readPageHeader
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/ogg/ogg-misc.js [app-route] (ecmascript)");
;
;
const MIN_PAGE_HEADER_SIZE = 27;
const MAX_PAGE_HEADER_SIZE = 27 + 255;
const MAX_PAGE_SIZE = MAX_PAGE_HEADER_SIZE + 255 * 255;
const readPageHeader = (slice)=>{
    const startPos = slice.filePos;
    const capturePattern = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Le"])(slice);
    if (capturePattern !== __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OGGS"]) {
        return null;
    }
    slice.skip(1); // Version
    const headerType = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice);
    const granulePosition = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readI64Le"])(slice);
    const serialNumber = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Le"])(slice);
    const sequenceNumber = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Le"])(slice);
    const checksum = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Le"])(slice);
    const numberPageSegments = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice);
    const lacingValues = new Uint8Array(numberPageSegments);
    for(let i = 0; i < numberPageSegments; i++){
        lacingValues[i] = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice);
    }
    const headerSize = 27 + numberPageSegments;
    const dataSize = lacingValues.reduce((a, b)=>a + b, 0);
    const totalSize = headerSize + dataSize;
    return {
        headerStartPos: startPos,
        totalSize,
        dataStartPos: startPos + headerSize,
        dataSize,
        headerType,
        granulePosition,
        serialNumber,
        sequenceNumber,
        checksum,
        lacingValues
    };
};
const findNextPageHeader = (slice, until)=>{
    while(slice.filePos < until - (4 - 1)){
        const word = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Le"])(slice);
        const firstByte = word & 0xff;
        const secondByte = word >>> 8 & 0xff;
        const thirdByte = word >>> 16 & 0xff;
        const fourthByte = word >>> 24 & 0xff;
        const O = 0x4f; // 'O'
        if (firstByte !== O && secondByte !== O && thirdByte !== O && fourthByte !== O) {
            continue;
        }
        slice.skip(-4);
        if (word === __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OGGS"]) {
            // We have found the capture pattern
            return true;
        }
        slice.skip(1);
    }
    return false;
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/ogg/ogg-demuxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "OggDemuxer",
    ()=>OggDemuxer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec-data.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/input-track.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/metadata.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/packet.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/ogg/ogg-misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/ogg/ogg-reader.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
;
;
class OggDemuxer extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Demuxer"] {
    constructor(input){
        super(input);
        this.metadataPromise = null;
        this.bitstreams = [];
        this.tracks = [];
        this.metadataTags = {};
        this.reader = input._reader;
    }
    async readMetadata() {
        return this.metadataPromise ??= (async ()=>{
            let currentPos = 0;
            while(true){
                let slice = this.reader.requestSliceRange(currentPos, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_PAGE_HEADER_SIZE"], __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_PAGE_HEADER_SIZE"]);
                if (slice instanceof Promise) slice = await slice;
                if (!slice) break;
                const page = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readPageHeader"])(slice);
                if (!page) {
                    break;
                }
                const isBos = !!(page.headerType & 0x02);
                if (!isBos) {
                    break;
                }
                this.bitstreams.push({
                    serialNumber: page.serialNumber,
                    bosPage: page,
                    description: null,
                    numberOfChannels: -1,
                    sampleRate: -1,
                    codecInfo: {
                        codec: null,
                        vorbisInfo: null,
                        opusInfo: null
                    },
                    lastMetadataPacket: null
                });
                currentPos = page.headerStartPos + page.totalSize;
            }
            for (const bitstream of this.bitstreams){
                const firstPacket = await this.readPacket(bitstream.bosPage, 0);
                if (!firstPacket) {
                    continue;
                }
                if (// Check for Vorbis
                firstPacket.data.byteLength >= 7 && firstPacket.data[0] === 0x01 // Packet type 1 = identification header
                 && firstPacket.data[1] === 0x76 // 'v'
                 && firstPacket.data[2] === 0x6f // 'o'
                 && firstPacket.data[3] === 0x72 // 'r'
                 && firstPacket.data[4] === 0x62 // 'b'
                 && firstPacket.data[5] === 0x69 // 'i'
                 && firstPacket.data[6] === 0x73 // 's'
                ) {
                    await this.readVorbisMetadata(firstPacket, bitstream);
                } else if (// Check for Opus
                firstPacket.data.byteLength >= 8 && firstPacket.data[0] === 0x4f // 'O'
                 && firstPacket.data[1] === 0x70 // 'p'
                 && firstPacket.data[2] === 0x75 // 'u'
                 && firstPacket.data[3] === 0x73 // 's'
                 && firstPacket.data[4] === 0x48 // 'H'
                 && firstPacket.data[5] === 0x65 // 'e'
                 && firstPacket.data[6] === 0x61 // 'a'
                 && firstPacket.data[7] === 0x64 // 'd'
                ) {
                    await this.readOpusMetadata(firstPacket, bitstream);
                }
                if (bitstream.codecInfo.codec !== null) {
                    this.tracks.push(new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputAudioTrack"](this.input, new OggAudioTrackBacking(bitstream, this)));
                }
            }
        })();
    }
    async readVorbisMetadata(firstPacket, bitstream) {
        let nextPacketPosition = await this.findNextPacketStart(firstPacket);
        if (!nextPacketPosition) {
            return;
        }
        const secondPacket = await this.readPacket(nextPacketPosition.startPage, nextPacketPosition.startSegmentIndex);
        if (!secondPacket) {
            return;
        }
        nextPacketPosition = await this.findNextPacketStart(secondPacket);
        if (!nextPacketPosition) {
            return;
        }
        const thirdPacket = await this.readPacket(nextPacketPosition.startPage, nextPacketPosition.startSegmentIndex);
        if (!thirdPacket) {
            return;
        }
        if (secondPacket.data[0] !== 0x03 || thirdPacket.data[0] !== 0x05) {
            return;
        }
        const lacingValues = [];
        const addBytesToSegmentTable = (bytes)=>{
            while(true){
                lacingValues.push(Math.min(255, bytes));
                if (bytes < 255) {
                    break;
                }
                bytes -= 255;
            }
        };
        addBytesToSegmentTable(firstPacket.data.length);
        addBytesToSegmentTable(secondPacket.data.length);
        // We don't add the last packet to the segment table, as it is assumed to be whatever bytes remain
        const description = new Uint8Array(1 + lacingValues.length + firstPacket.data.length + secondPacket.data.length + thirdPacket.data.length);
        description[0] = 2; // Num entries in the segment table
        description.set(lacingValues, 1);
        description.set(firstPacket.data, 1 + lacingValues.length);
        description.set(secondPacket.data, 1 + lacingValues.length + firstPacket.data.length);
        description.set(thirdPacket.data, 1 + lacingValues.length + firstPacket.data.length + secondPacket.data.length);
        bitstream.codecInfo.codec = 'vorbis';
        bitstream.description = description;
        bitstream.lastMetadataPacket = thirdPacket;
        const view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(firstPacket.data);
        bitstream.numberOfChannels = view.getUint8(11);
        bitstream.sampleRate = view.getUint32(12, true);
        const blockSizeByte = view.getUint8(28);
        bitstream.codecInfo.vorbisInfo = {
            blocksizes: [
                1 << (blockSizeByte & 0xf),
                1 << (blockSizeByte >> 4)
            ],
            modeBlockflags: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseModesFromVorbisSetupPacket"])(thirdPacket.data).modeBlockflags
        };
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readVorbisComments"])(secondPacket.data.subarray(7), this.metadataTags); // Skip header type and 'vorbis'
    }
    async readOpusMetadata(firstPacket, bitstream) {
        // From https://datatracker.ietf.org/doc/html/rfc7845#section-5:
        // "An Ogg Opus logical stream contains exactly two mandatory header packets: an identification header and a
        // comment header."
        const nextPacketPosition = await this.findNextPacketStart(firstPacket);
        if (!nextPacketPosition) {
            return;
        }
        const secondPacket = await this.readPacket(nextPacketPosition.startPage, nextPacketPosition.startSegmentIndex);
        if (!secondPacket) {
            return;
        }
        bitstream.codecInfo.codec = 'opus';
        bitstream.description = firstPacket.data;
        bitstream.lastMetadataPacket = secondPacket;
        const header = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseOpusIdentificationHeader"])(firstPacket.data);
        bitstream.numberOfChannels = header.outputChannelCount;
        bitstream.sampleRate = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OPUS_SAMPLE_RATE"]; // Always the same
        bitstream.codecInfo.opusInfo = {
            preSkip: header.preSkip
        };
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readVorbisComments"])(secondPacket.data.subarray(8), this.metadataTags); // Skip 'OpusTags'
    }
    async readPacket(startPage, startSegmentIndex) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(startSegmentIndex < startPage.lacingValues.length);
        let startDataOffset = 0;
        for(let i = 0; i < startSegmentIndex; i++){
            startDataOffset += startPage.lacingValues[i];
        }
        let currentPage = startPage;
        let currentDataOffset = startDataOffset;
        let currentSegmentIndex = startSegmentIndex;
        const chunks = [];
        outer: while(true){
            // Load the entire page data
            let pageSlice = this.reader.requestSlice(currentPage.dataStartPos, currentPage.dataSize);
            if (pageSlice instanceof Promise) pageSlice = await pageSlice;
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(pageSlice);
            const pageData = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(pageSlice, currentPage.dataSize);
            while(true){
                if (currentSegmentIndex === currentPage.lacingValues.length) {
                    chunks.push(pageData.subarray(startDataOffset, currentDataOffset));
                    break;
                }
                const lacingValue = currentPage.lacingValues[currentSegmentIndex];
                currentDataOffset += lacingValue;
                if (lacingValue < 255) {
                    chunks.push(pageData.subarray(startDataOffset, currentDataOffset));
                    break outer;
                }
                currentSegmentIndex++;
            }
            // The packet extends to the next page; let's find it
            let currentPos = currentPage.headerStartPos + currentPage.totalSize;
            while(true){
                let headerSlice = this.reader.requestSliceRange(currentPos, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_PAGE_HEADER_SIZE"], __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_PAGE_HEADER_SIZE"]);
                if (headerSlice instanceof Promise) headerSlice = await headerSlice;
                if (!headerSlice) {
                    return null;
                }
                const nextPage = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readPageHeader"])(headerSlice);
                if (!nextPage) {
                    return null;
                }
                currentPage = nextPage;
                if (currentPage.serialNumber === startPage.serialNumber) {
                    break;
                }
                currentPos = currentPage.headerStartPos + currentPage.totalSize;
            }
            startDataOffset = 0;
            currentDataOffset = 0;
            currentSegmentIndex = 0;
        }
        const totalPacketSize = chunks.reduce((sum, chunk)=>sum + chunk.length, 0);
        const packetData = new Uint8Array(totalPacketSize);
        let offset = 0;
        for(let i = 0; i < chunks.length; i++){
            const chunk = chunks[i];
            packetData.set(chunk, offset);
            offset += chunk.length;
        }
        return {
            data: packetData,
            endPage: currentPage,
            endSegmentIndex: currentSegmentIndex
        };
    }
    async findNextPacketStart(lastPacket) {
        // If there's another segment in the same page, return it
        if (lastPacket.endSegmentIndex < lastPacket.endPage.lacingValues.length - 1) {
            return {
                startPage: lastPacket.endPage,
                startSegmentIndex: lastPacket.endSegmentIndex + 1
            };
        }
        const isEos = !!(lastPacket.endPage.headerType & 0x04);
        if (isEos) {
            // The page is marked as the last page of the logical bitstream, so we won't find anything beyond it
            return null;
        }
        // Otherwise, search for the next page belonging to the same bitstream
        let currentPos = lastPacket.endPage.headerStartPos + lastPacket.endPage.totalSize;
        while(true){
            let slice = this.reader.requestSliceRange(currentPos, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_PAGE_HEADER_SIZE"], __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_PAGE_HEADER_SIZE"]);
            if (slice instanceof Promise) slice = await slice;
            if (!slice) {
                return null;
            }
            const nextPage = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readPageHeader"])(slice);
            if (!nextPage) {
                return null;
            }
            if (nextPage.serialNumber === lastPacket.endPage.serialNumber) {
                return {
                    startPage: nextPage,
                    startSegmentIndex: 0
                };
            }
            currentPos = nextPage.headerStartPos + nextPage.totalSize;
        }
    }
    async getMimeType() {
        await this.readMetadata();
        const codecStrings = await Promise.all(this.tracks.map((x)=>x.getCodecParameterString()));
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["buildOggMimeType"])({
            codecStrings: codecStrings.filter(Boolean)
        });
    }
    async getTracks() {
        await this.readMetadata();
        return this.tracks;
    }
    async computeDuration() {
        const tracks = await this.getTracks();
        const trackDurations = await Promise.all(tracks.map((x)=>x.computeDuration()));
        return Math.max(0, ...trackDurations);
    }
    async getMetadataTags() {
        await this.readMetadata();
        return this.metadataTags;
    }
}
class OggAudioTrackBacking {
    constructor(bitstream, demuxer){
        this.bitstream = bitstream;
        this.demuxer = demuxer;
        this.encodedPacketToMetadata = new WeakMap();
        this.sequentialScanCache = [];
        this.sequentialScanMutex = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AsyncMutex"]();
        // Opus always uses a fixed sample rate for its internal calculations, even if the actual rate is different
        this.internalSampleRate = bitstream.codecInfo.codec === 'opus' ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OPUS_SAMPLE_RATE"] : bitstream.sampleRate;
    }
    getId() {
        return this.bitstream.serialNumber;
    }
    getNumberOfChannels() {
        return this.bitstream.numberOfChannels;
    }
    getSampleRate() {
        return this.bitstream.sampleRate;
    }
    getTimeResolution() {
        return this.bitstream.sampleRate;
    }
    getCodec() {
        return this.bitstream.codecInfo.codec;
    }
    getInternalCodecId() {
        return null;
    }
    async getDecoderConfig() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.bitstream.codecInfo.codec);
        return {
            codec: this.bitstream.codecInfo.codec,
            numberOfChannels: this.bitstream.numberOfChannels,
            sampleRate: this.bitstream.sampleRate,
            description: this.bitstream.description ?? undefined
        };
    }
    getName() {
        return null;
    }
    getLanguageCode() {
        return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["UNDETERMINED_LANGUAGE"];
    }
    getDisposition() {
        return {
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["DEFAULT_TRACK_DISPOSITION"]
        };
    }
    async getFirstTimestamp() {
        return 0;
    }
    async computeDuration() {
        const lastPacket = await this.getPacket(Infinity, {
            metadataOnly: true
        });
        return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);
    }
    granulePositionToTimestampInSamples(granulePosition) {
        if (this.bitstream.codecInfo.codec === 'opus') {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.bitstream.codecInfo.opusInfo);
            return granulePosition - this.bitstream.codecInfo.opusInfo.preSkip;
        }
        return granulePosition;
    }
    createEncodedPacketFromOggPacket(packet, additional, options) {
        if (!packet) {
            return null;
        }
        const { durationInSamples, vorbisBlockSize } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["extractSampleMetadata"])(packet.data, this.bitstream.codecInfo, additional.vorbisLastBlocksize);
        const encodedPacket = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"](options.metadataOnly ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PLACEHOLDER_DATA"] : packet.data, 'key', Math.max(0, additional.timestampInSamples) / this.internalSampleRate, durationInSamples / this.internalSampleRate, packet.endPage.headerStartPos + packet.endSegmentIndex, packet.data.byteLength);
        this.encodedPacketToMetadata.set(encodedPacket, {
            packet,
            timestampInSamples: additional.timestampInSamples,
            durationInSamples,
            vorbisLastBlockSize: additional.vorbisLastBlocksize,
            vorbisBlockSize
        });
        return encodedPacket;
    }
    async getFirstPacket(options) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.bitstream.lastMetadataPacket);
        const packetPosition = await this.demuxer.findNextPacketStart(this.bitstream.lastMetadataPacket);
        if (!packetPosition) {
            return null;
        }
        let timestampInSamples = 0;
        if (this.bitstream.codecInfo.codec === 'opus') {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.bitstream.codecInfo.opusInfo);
            timestampInSamples -= this.bitstream.codecInfo.opusInfo.preSkip;
        }
        const packet = await this.demuxer.readPacket(packetPosition.startPage, packetPosition.startSegmentIndex);
        return this.createEncodedPacketFromOggPacket(packet, {
            timestampInSamples,
            vorbisLastBlocksize: null
        }, options);
    }
    async getNextPacket(prevPacket, options) {
        const prevMetadata = this.encodedPacketToMetadata.get(prevPacket);
        if (!prevMetadata) {
            throw new Error('Packet was not created from this track.');
        }
        const packetPosition = await this.demuxer.findNextPacketStart(prevMetadata.packet);
        if (!packetPosition) {
            return null;
        }
        const timestampInSamples = prevMetadata.timestampInSamples + prevMetadata.durationInSamples;
        const packet = await this.demuxer.readPacket(packetPosition.startPage, packetPosition.startSegmentIndex);
        return this.createEncodedPacketFromOggPacket(packet, {
            timestampInSamples,
            vorbisLastBlocksize: prevMetadata.vorbisBlockSize
        }, options);
    }
    async getPacket(timestamp, options) {
        if (this.demuxer.reader.fileSize === null) {
            // No file size known, can't do binary search, but fall back to sequential algo instead
            return this.getPacketSequential(timestamp, options);
        }
        const timestampInSamples = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["roundIfAlmostInteger"])(timestamp * this.internalSampleRate);
        if (timestampInSamples === 0) {
            // Fast path for timestamp 0 - avoids binary search when playing back from the start
            return this.getFirstPacket(options);
        }
        if (timestampInSamples < 0) {
            // There's nothing here
            return null;
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.bitstream.lastMetadataPacket);
        const startPosition = await this.demuxer.findNextPacketStart(this.bitstream.lastMetadataPacket);
        if (!startPosition) {
            return null;
        }
        let lowPage = startPosition.startPage;
        let high = this.demuxer.reader.fileSize;
        const lowPages = [
            lowPage
        ];
        // First, let's perform a binary serach (bisection search) on the file to find the approximate page where
        // we'll find the packet. We want to find a page whose end packet position is less than or equal to the
        // packet position we're searching for.
        // Outer loop: Does the binary serach
        outer: while(lowPage.headerStartPos + lowPage.totalSize < high){
            const low = lowPage.headerStartPos;
            const mid = Math.floor((low + high) / 2);
            let searchStartPos = mid;
            // Inner loop: Does a linear forward scan if the page cannot be found immediately
            while(true){
                const until = Math.min(searchStartPos + __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_PAGE_SIZE"], high - __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_PAGE_HEADER_SIZE"]);
                let searchSlice = this.demuxer.reader.requestSlice(searchStartPos, until - searchStartPos);
                if (searchSlice instanceof Promise) searchSlice = await searchSlice;
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(searchSlice);
                const found = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["findNextPageHeader"])(searchSlice, until);
                if (!found) {
                    high = mid + __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_PAGE_HEADER_SIZE"];
                    continue outer;
                }
                let headerSlice = this.demuxer.reader.requestSliceRange(searchSlice.filePos, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_PAGE_HEADER_SIZE"], __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_PAGE_HEADER_SIZE"]);
                if (headerSlice instanceof Promise) headerSlice = await headerSlice;
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(headerSlice);
                const page = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readPageHeader"])(headerSlice);
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(page);
                let pageValid = false;
                if (page.serialNumber === this.bitstream.serialNumber) {
                    // Serial numbers are basically random numbers, and the chance of finding a fake page with
                    // matching serial number is astronomically low, so we can be pretty sure this page is legit.
                    pageValid = true;
                } else {
                    let pageSlice = this.demuxer.reader.requestSlice(page.headerStartPos, page.totalSize);
                    if (pageSlice instanceof Promise) pageSlice = await pageSlice;
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(pageSlice);
                    // Validate the page by checking checksum
                    const bytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(pageSlice, page.totalSize);
                    const crc = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["computeOggPageCrc"])(bytes);
                    pageValid = crc === page.checksum;
                }
                if (!pageValid) {
                    // Keep searching for a valid page
                    searchStartPos = page.headerStartPos + 4; // 'OggS' is 4 bytes
                    continue;
                }
                if (pageValid && page.serialNumber !== this.bitstream.serialNumber) {
                    // Page is valid but from a different bitstream, so keep searching forward until we find one
                    // belonging to the our bitstream
                    searchStartPos = page.headerStartPos + page.totalSize;
                    continue;
                }
                const isContinuationPage = page.granulePosition === -1;
                if (isContinuationPage) {
                    // No packet ends on this page - keep looking
                    searchStartPos = page.headerStartPos + page.totalSize;
                    continue;
                }
                // The page is valid and belongs to our bitstream; let's check its granule position to see where we
                // need to take the bisection search.
                if (this.granulePositionToTimestampInSamples(page.granulePosition) > timestampInSamples) {
                    high = page.headerStartPos;
                } else {
                    lowPage = page;
                    lowPages.push(page);
                }
                continue outer;
            }
        }
        // Now we have the last page with a packet position <= the packet position we're looking for, but there
        // might be multiple pages with the packet position, in which case we actually need to find the first of
        // such pages. We'll do this in two steps: First, let's find the latest page we know with an earlier packet
        // position, and then linear scan ourselves forward until we find the correct page.
        let lowerPage = startPosition.startPage;
        for (const otherLowPage of lowPages){
            if (otherLowPage.granulePosition === lowPage.granulePosition) {
                break;
            }
            if (!lowerPage || otherLowPage.headerStartPos > lowerPage.headerStartPos) {
                lowerPage = otherLowPage;
            }
        }
        let currentPage = lowerPage;
        // Keep track of the pages we traversed, we need these later for backwards seeking
        const previousPages = [
            currentPage
        ];
        while(true){
            // This loop must terminate as we'll eventually reach lowPage
            if (currentPage.serialNumber === this.bitstream.serialNumber && currentPage.granulePosition === lowPage.granulePosition) {
                break;
            }
            const nextPos = currentPage.headerStartPos + currentPage.totalSize;
            let slice = this.demuxer.reader.requestSliceRange(nextPos, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_PAGE_HEADER_SIZE"], __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_PAGE_HEADER_SIZE"]);
            if (slice instanceof Promise) slice = await slice;
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(slice);
            const nextPage = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readPageHeader"])(slice);
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(nextPage);
            currentPage = nextPage;
            if (currentPage.serialNumber === this.bitstream.serialNumber) {
                previousPages.push(currentPage);
            }
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(currentPage.granulePosition !== -1);
        let currentSegmentIndex = null;
        let currentTimestampInSamples;
        let currentTimestampIsCorrect;
        // These indicate the end position of the packet that the granule position belongs to
        let endPage = currentPage;
        let endSegmentIndex = 0;
        if (currentPage.headerStartPos === startPosition.startPage.headerStartPos) {
            currentTimestampInSamples = this.granulePositionToTimestampInSamples(0);
            currentTimestampIsCorrect = true;
            currentSegmentIndex = 0;
        } else {
            currentTimestampInSamples = 0; // Placeholder value! We'll refine it once we can
            currentTimestampIsCorrect = false;
            // Find the segment index of the next packet
            for(let i = currentPage.lacingValues.length - 1; i >= 0; i--){
                const value = currentPage.lacingValues[i];
                if (value < 255) {
                    // We know the last packet ended at i, so the next one starts at i + 1
                    currentSegmentIndex = i + 1;
                    break;
                }
            }
            // This must hold: Since this page has a granule position set, that means there must be a packet that
            // ends in this page.
            if (currentSegmentIndex === null) {
                throw new Error('Invalid page with granule position: no packets end on this page.');
            }
            endSegmentIndex = currentSegmentIndex - 1;
            const pseudopacket = {
                data: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PLACEHOLDER_DATA"],
                endPage,
                endSegmentIndex
            };
            const nextPosition = await this.demuxer.findNextPacketStart(pseudopacket);
            if (nextPosition) {
                // Let's rewind a single step (packet) - this previous packet ensures that we'll correctly compute
                // the duration for the packet we're looking for.
                const endPosition = findPreviousPacketEndPosition(previousPages, currentPage, currentSegmentIndex);
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(endPosition);
                const startPosition = findPacketStartPosition(previousPages, endPosition.page, endPosition.segmentIndex);
                if (startPosition) {
                    currentPage = startPosition.page;
                    currentSegmentIndex = startPosition.segmentIndex;
                }
            } else {
                // There is no next position, which means we're looking for the last packet in the bitstream. The
                // granule position on the last page tends to be fucky, so let's instead start the search on the
                // page before that. So let's loop until we find a packet that ends in a previous page.
                while(true){
                    const endPosition = findPreviousPacketEndPosition(previousPages, currentPage, currentSegmentIndex);
                    if (!endPosition) {
                        break;
                    }
                    const startPosition = findPacketStartPosition(previousPages, endPosition.page, endPosition.segmentIndex);
                    if (!startPosition) {
                        break;
                    }
                    currentPage = startPosition.page;
                    currentSegmentIndex = startPosition.segmentIndex;
                    if (endPosition.page.headerStartPos !== endPage.headerStartPos) {
                        endPage = endPosition.page;
                        endSegmentIndex = endPosition.segmentIndex;
                        break;
                    }
                }
            }
        }
        let lastEncodedPacket = null;
        let lastEncodedPacketMetadata = null;
        // Alright, now it's time for the final, granular seek: We keep iterating over packets until we've found the
        // one with the correct timestamp - i.e., the last one with a timestamp <= the timestamp we're looking for.
        while(currentPage !== null){
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(currentSegmentIndex !== null);
            const packet = await this.demuxer.readPacket(currentPage, currentSegmentIndex);
            if (!packet) {
                break;
            }
            // We might need to skip the packet if it's a metadata one
            const skipPacket = currentPage.headerStartPos === startPosition.startPage.headerStartPos && currentSegmentIndex < startPosition.startSegmentIndex;
            if (!skipPacket) {
                let encodedPacket = this.createEncodedPacketFromOggPacket(packet, {
                    timestampInSamples: currentTimestampInSamples,
                    vorbisLastBlocksize: lastEncodedPacketMetadata?.vorbisBlockSize ?? null
                }, options);
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(encodedPacket);
                let encodedPacketMetadata = this.encodedPacketToMetadata.get(encodedPacket);
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(encodedPacketMetadata);
                if (!currentTimestampIsCorrect && packet.endPage.headerStartPos === endPage.headerStartPos && packet.endSegmentIndex === endSegmentIndex) {
                    // We know this packet end timestamp can be derived from the page's granule position
                    currentTimestampInSamples = this.granulePositionToTimestampInSamples(currentPage.granulePosition);
                    currentTimestampIsCorrect = true;
                    // Let's backpatch the packet we just created with the correct timestamp
                    encodedPacket = this.createEncodedPacketFromOggPacket(packet, {
                        timestampInSamples: currentTimestampInSamples - encodedPacketMetadata.durationInSamples,
                        vorbisLastBlocksize: lastEncodedPacketMetadata?.vorbisBlockSize ?? null
                    }, options);
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(encodedPacket);
                    encodedPacketMetadata = this.encodedPacketToMetadata.get(encodedPacket);
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(encodedPacketMetadata);
                } else {
                    currentTimestampInSamples += encodedPacketMetadata.durationInSamples;
                }
                lastEncodedPacket = encodedPacket;
                lastEncodedPacketMetadata = encodedPacketMetadata;
                if (currentTimestampIsCorrect && (// Next timestamp will be too late
                Math.max(currentTimestampInSamples, 0) > timestampInSamples || Math.max(encodedPacketMetadata.timestampInSamples, 0) === timestampInSamples)) {
                    break;
                }
            }
            const nextPosition = await this.demuxer.findNextPacketStart(packet);
            if (!nextPosition) {
                break;
            }
            currentPage = nextPosition.startPage;
            currentSegmentIndex = nextPosition.startSegmentIndex;
        }
        return lastEncodedPacket;
    }
    // A slower but simpler and sequential algorithm for finding a packet in a file
    async getPacketSequential(timestamp, options) {
        const release = await this.sequentialScanMutex.acquire(); // Requires exclusivity because we write to a cache
        try {
            const timestampInSamples = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["roundIfAlmostInteger"])(timestamp * this.internalSampleRate);
            timestamp = timestampInSamples / this.internalSampleRate;
            const index = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["binarySearchLessOrEqual"])(this.sequentialScanCache, timestampInSamples, (x)=>x.timestampInSamples);
            let currentPacket;
            if (index !== -1) {
                // We don't need to start from the beginning, we can start at a previous scan point
                const cacheEntry = this.sequentialScanCache[index];
                currentPacket = this.createEncodedPacketFromOggPacket(cacheEntry.packet, {
                    timestampInSamples: cacheEntry.timestampInSamples,
                    vorbisLastBlocksize: cacheEntry.vorbisLastBlockSize
                }, options);
            } else {
                currentPacket = await this.getFirstPacket(options);
            }
            let i = 0;
            while(currentPacket && currentPacket.timestamp < timestamp){
                const nextPacket = await this.getNextPacket(currentPacket, options);
                if (!nextPacket || nextPacket.timestamp > timestamp) {
                    break;
                }
                currentPacket = nextPacket;
                i++;
                if (i === 100) {
                    // Add "checkpoints" every once in a while to speed up subsequent random accesses
                    i = 0;
                    const metadata = this.encodedPacketToMetadata.get(currentPacket);
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(metadata);
                    if (this.sequentialScanCache.length > 0) {
                        // If we reach this case, we must be at the end of the cache
                        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["last"])(this.sequentialScanCache).timestampInSamples <= metadata.timestampInSamples);
                    }
                    this.sequentialScanCache.push(metadata);
                }
            }
            return currentPacket;
        } finally{
            release();
        }
    }
    getKeyPacket(timestamp, options) {
        return this.getPacket(timestamp, options);
    }
    getNextKeyPacket(packet, options) {
        return this.getNextPacket(packet, options);
    }
}
/** Finds the start position of a packet given its end position. */ const findPacketStartPosition = (pageList, endPage, endSegmentIndex)=>{
    let page = endPage;
    let segmentIndex = endSegmentIndex;
    outer: while(true){
        segmentIndex--;
        for(segmentIndex; segmentIndex >= 0; segmentIndex--){
            const lacingValue = page.lacingValues[segmentIndex];
            if (lacingValue < 255) {
                segmentIndex++; // We know the last packet starts here
                break outer;
            }
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(segmentIndex === -1);
        const pageStartsWithFreshPacket = !(page.headerType & 0x01);
        if (pageStartsWithFreshPacket) {
            // Fast exit: We know we don't need to look in the previous page
            segmentIndex = 0;
            break;
        }
        const previousPage = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["findLast"])(pageList, (x)=>x.headerStartPos < page.headerStartPos);
        if (!previousPage) {
            return null;
        }
        page = previousPage;
        segmentIndex = page.lacingValues.length;
    }
    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(segmentIndex !== -1);
    if (segmentIndex === page.lacingValues.length) {
        // Wrap back around to the first segment of the next page
        const nextPage = pageList[pageList.indexOf(page) + 1];
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(nextPage);
        page = nextPage;
        segmentIndex = 0;
    }
    return {
        page,
        segmentIndex
    };
};
/** Finds the end position of a packet given the start position of the following packet. */ const findPreviousPacketEndPosition = (pageList, startPage, startSegmentIndex)=>{
    if (startSegmentIndex > 0) {
        // Easy
        return {
            page: startPage,
            segmentIndex: startSegmentIndex - 1
        };
    }
    const previousPage = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["findLast"])(pageList, (x)=>x.headerStartPos < startPage.headerStartPos);
    if (!previousPage) {
        return null;
    }
    return {
        page: previousPage,
        segmentIndex: previousPage.lacingValues.length - 1
    };
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/ogg/ogg-muxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "OggMuxer",
    ()=>OggMuxer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec-data.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/muxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/ogg/ogg-misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/ogg/ogg-reader.js [app-route] (ecmascript)");
;
;
;
;
;
;
const PAGE_SIZE_TARGET = 8192;
class OggMuxer extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Muxer"] {
    constructor(output, format){
        super(output);
        this.trackDatas = [];
        this.bosPagesWritten = false;
        this.allTracksKnown = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])();
        this.pageBytes = new Uint8Array(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_PAGE_SIZE"]);
        this.pageView = new DataView(this.pageBytes.buffer);
        this.format = format;
        this.writer = output._writer;
        this.writer.ensureMonotonicity = true; // Ogg is always monotonically written!
    }
    async start() {
    // Nothin'
    }
    async getMimeType() {
        await this.allTracksKnown.promise;
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["buildOggMimeType"])({
            codecStrings: this.trackDatas.map((x)=>x.codecInfo.codec)
        });
    }
    addEncodedVideoPacket() {
        throw new Error('Video tracks are not supported.');
    }
    getTrackData(track, meta) {
        const existingTrackData = this.trackDatas.find((td)=>td.track === track);
        if (existingTrackData) {
            return existingTrackData;
        }
        // Give the track a unique random serial number
        let serialNumber;
        do {
            serialNumber = Math.floor(2 ** 32 * Math.random());
        }while (this.trackDatas.some((td)=>td.serialNumber === serialNumber))
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(track.source._codec === 'vorbis' || track.source._codec === 'opus');
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateAudioChunkMetadata"])(meta);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(meta);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(meta.decoderConfig);
        const newTrackData = {
            track,
            serialNumber,
            internalSampleRate: track.source._codec === 'opus' ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OPUS_SAMPLE_RATE"] : meta.decoderConfig.sampleRate,
            codecInfo: {
                codec: track.source._codec,
                vorbisInfo: null,
                opusInfo: null
            },
            vorbisLastBlocksize: null,
            packetQueue: [],
            currentTimestampInSamples: 0,
            pagesWritten: 0,
            currentGranulePosition: 0,
            currentLacingValues: [],
            currentPageData: [],
            currentPageSize: 27,
            currentPageStartsWithFreshPacket: true
        };
        this.queueHeaderPackets(newTrackData, meta);
        this.trackDatas.push(newTrackData);
        if (this.allTracksAreKnown()) {
            this.allTracksKnown.resolve();
        }
        return newTrackData;
    }
    queueHeaderPackets(trackData, meta) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(meta.decoderConfig);
        if (trackData.track.source._codec === 'vorbis') {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(meta.decoderConfig.description);
            const bytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(meta.decoderConfig.description);
            if (bytes[0] !== 2) {
                throw new TypeError('First byte of Vorbis decoder description must be 2.');
            }
            let pos = 1;
            const readPacketLength = ()=>{
                let length = 0;
                while(true){
                    const value = bytes[pos++];
                    if (value === undefined) {
                        throw new TypeError('Vorbis decoder description is too short.');
                    }
                    length += value;
                    if (value < 255) {
                        return length;
                    }
                }
            };
            const identificationHeaderLength = readPacketLength();
            const commentHeaderLength = readPacketLength();
            const setupHeaderLength = bytes.length - pos; // Setup header fills the remaining bytes
            if (setupHeaderLength <= 0) {
                throw new TypeError('Vorbis decoder description is too short.');
            }
            const identificationHeader = bytes.subarray(pos, pos += identificationHeaderLength);
            pos += commentHeaderLength; // Skip the comment header, we'll build our own
            const setupHeader = bytes.subarray(pos);
            const commentHeaderHeader = new Uint8Array(7);
            commentHeaderHeader[0] = 3; // Packet type
            commentHeaderHeader[1] = 0x76; // 'v'
            commentHeaderHeader[2] = 0x6f; // 'o'
            commentHeaderHeader[3] = 0x72; // 'r'
            commentHeaderHeader[4] = 0x62; // 'b'
            commentHeaderHeader[5] = 0x69; // 'i'
            commentHeaderHeader[6] = 0x73; // 's'
            const commentHeader = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["createVorbisComments"])(commentHeaderHeader, this.output._metadataTags, true);
            trackData.packetQueue.push({
                data: identificationHeader,
                endGranulePosition: 0,
                timestamp: 0,
                forcePageFlush: true
            }, {
                data: commentHeader,
                endGranulePosition: 0,
                timestamp: 0,
                forcePageFlush: false
            }, {
                data: setupHeader,
                endGranulePosition: 0,
                timestamp: 0,
                forcePageFlush: true
            });
            const view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(identificationHeader);
            const blockSizeByte = view.getUint8(28);
            trackData.codecInfo.vorbisInfo = {
                blocksizes: [
                    1 << (blockSizeByte & 0xf),
                    1 << (blockSizeByte >> 4)
                ],
                modeBlockflags: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseModesFromVorbisSetupPacket"])(setupHeader).modeBlockflags
            };
        } else if (trackData.track.source._codec === 'opus') {
            if (!meta.decoderConfig.description) {
                throw new TypeError('For Ogg, Opus decoder description is required.');
            }
            const identificationHeader = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(meta.decoderConfig.description);
            const commentHeaderHeader = new Uint8Array(8);
            const commentHeaderHeaderView = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(commentHeaderHeader);
            commentHeaderHeaderView.setUint32(0, 0x4f707573, false); // 'Opus'
            commentHeaderHeaderView.setUint32(4, 0x54616773, false); // 'Tags'
            const commentHeader = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["createVorbisComments"])(commentHeaderHeader, this.output._metadataTags, true);
            trackData.packetQueue.push({
                data: identificationHeader,
                endGranulePosition: 0,
                timestamp: 0,
                forcePageFlush: true
            }, {
                data: commentHeader,
                endGranulePosition: 0,
                timestamp: 0,
                forcePageFlush: true
            });
            trackData.codecInfo.opusInfo = {
                preSkip: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseOpusIdentificationHeader"])(identificationHeader).preSkip
            };
        }
    }
    async addEncodedAudioPacket(track, packet, meta) {
        const release = await this.mutex.acquire();
        try {
            const trackData = this.getTrackData(track, meta);
            this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, packet.type === 'key');
            const currentTimestampInSamples = trackData.currentTimestampInSamples;
            const { durationInSamples, vorbisBlockSize } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["extractSampleMetadata"])(packet.data, trackData.codecInfo, trackData.vorbisLastBlocksize);
            trackData.currentTimestampInSamples += durationInSamples;
            trackData.vorbisLastBlocksize = vorbisBlockSize;
            trackData.packetQueue.push({
                data: packet.data,
                endGranulePosition: trackData.currentTimestampInSamples,
                timestamp: currentTimestampInSamples / trackData.internalSampleRate,
                forcePageFlush: false
            });
            await this.interleavePages();
        } finally{
            release();
        }
    }
    addSubtitleCue() {
        throw new Error('Subtitle tracks are not supported.');
    }
    allTracksAreKnown() {
        for (const track of this.output._tracks){
            if (!track.source._closed && !this.trackDatas.some((x)=>x.track === track)) {
                return false; // We haven't seen a sample from this open track yet
            }
        }
        return true;
    }
    async interleavePages(isFinalCall = false) {
        if (!this.bosPagesWritten) {
            if (!this.allTracksAreKnown()) {
                return; // We can't interleave yet as we don't yet know how many tracks we'll truly have
            }
            // Write the header page for all bitstreams
            for (const trackData of this.trackDatas){
                while(trackData.packetQueue.length > 0){
                    const packet = trackData.packetQueue.shift();
                    this.writePacket(trackData, packet, false);
                    if (packet.forcePageFlush) {
                        break;
                    }
                }
            }
            this.bosPagesWritten = true;
        }
        outer: while(true){
            let trackWithMinTimestamp = null;
            let minTimestamp = Infinity;
            for (const trackData of this.trackDatas){
                if (!isFinalCall && trackData.packetQueue.length <= 1 // Limit is 1, not 0, for correct EOS flag logic
                 && !trackData.track.source._closed) {
                    break outer;
                }
                if (trackData.packetQueue.length > 0 && trackData.packetQueue[0].timestamp < minTimestamp) {
                    trackWithMinTimestamp = trackData;
                    minTimestamp = trackData.packetQueue[0].timestamp;
                }
            }
            if (!trackWithMinTimestamp) {
                break;
            }
            const packet = trackWithMinTimestamp.packetQueue.shift();
            const isFinalPacket = trackWithMinTimestamp.packetQueue.length === 0;
            this.writePacket(trackWithMinTimestamp, packet, isFinalPacket);
        }
        if (!isFinalCall) {
            await this.writer.flush();
        }
    }
    writePacket(trackData, packet, isFinalPacket) {
        let remainingLength = packet.data.length;
        let dataStartOffset = 0;
        let dataOffset = 0;
        while(true){
            if (trackData.currentLacingValues.length === 0 && dataStartOffset > 0) {
                // This is a packet spanning multiple pages
                trackData.currentPageStartsWithFreshPacket = false;
            }
            const segmentSize = Math.min(255, remainingLength);
            trackData.currentLacingValues.push(segmentSize);
            trackData.currentPageSize++;
            dataOffset += segmentSize;
            const segmentIsLastOfPacket = remainingLength < 255;
            if (trackData.currentLacingValues.length === 255) {
                // The page is full, we need to add part of the packet data and then flush the page
                const slice = packet.data.subarray(dataStartOffset, dataOffset);
                dataStartOffset = dataOffset;
                trackData.currentPageData.push(slice);
                trackData.currentPageSize += slice.length;
                this.writePage(trackData, isFinalPacket && segmentIsLastOfPacket);
                if (segmentIsLastOfPacket) {
                    return;
                }
            }
            if (segmentIsLastOfPacket) {
                break;
            }
            remainingLength -= 255;
        }
        const slice = packet.data.subarray(dataStartOffset);
        trackData.currentPageData.push(slice);
        trackData.currentPageSize += slice.length;
        trackData.currentGranulePosition = packet.endGranulePosition;
        if (trackData.currentPageSize >= PAGE_SIZE_TARGET || packet.forcePageFlush) {
            this.writePage(trackData, isFinalPacket);
        }
    }
    writePage(trackData, isEos) {
        this.pageView.setUint32(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OGGS"], true); // Capture pattern
        this.pageView.setUint8(4, 0); // Version
        let headerType = 0;
        if (!trackData.currentPageStartsWithFreshPacket) {
            headerType |= 1;
        }
        if (trackData.pagesWritten === 0) {
            headerType |= 2; // Beginning of stream
        }
        if (isEos) {
            headerType |= 4; // End of stream
        }
        this.pageView.setUint8(5, headerType); // Header type
        const granulePosition = trackData.currentLacingValues.every((x)=>x === 255) ? -1 // No packets end on this page
         : trackData.currentGranulePosition;
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["setInt64"])(this.pageView, 6, granulePosition, true); // Granule position
        this.pageView.setUint32(14, trackData.serialNumber, true); // Serial number
        this.pageView.setUint32(18, trackData.pagesWritten, true); // Page sequence number
        this.pageView.setUint32(22, 0, true); // Checksum placeholder
        this.pageView.setUint8(26, trackData.currentLacingValues.length); // Number of page segments
        this.pageBytes.set(trackData.currentLacingValues, 27);
        let pos = 27 + trackData.currentLacingValues.length;
        for (const data of trackData.currentPageData){
            this.pageBytes.set(data, pos);
            pos += data.length;
        }
        const slice = this.pageBytes.subarray(0, pos);
        const crc = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["computeOggPageCrc"])(slice);
        this.pageView.setUint32(22, crc, true); // Checksum
        trackData.pagesWritten++;
        trackData.currentLacingValues.length = 0;
        trackData.currentPageData.length = 0;
        trackData.currentPageSize = 27;
        trackData.currentPageStartsWithFreshPacket = true;
        if (this.format._options.onPage) {
            this.writer.startTrackingWrites();
        }
        this.writer.write(slice);
        if (this.format._options.onPage) {
            const { data, start } = this.writer.stopTrackingWrites();
            this.format._options.onPage(data, start, trackData.track.source);
        }
    }
    // eslint-disable-next-line @typescript-eslint/no-misused-promises
    async onTrackClose() {
        const release = await this.mutex.acquire();
        if (this.allTracksAreKnown()) {
            this.allTracksKnown.resolve();
        }
        // Since a track is now closed, we may be able to write out chunks that were previously waiting
        await this.interleavePages();
        release();
    }
    async finalize() {
        const release = await this.mutex.acquire();
        this.allTracksKnown.resolve();
        await this.interleavePages(true);
        for (const trackData of this.trackDatas){
            if (trackData.currentLacingValues.length > 0) {
                this.writePage(trackData, true);
            }
        }
        release();
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/wave/wave-demuxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "WaveDemuxer",
    ()=>WaveDemuxer,
    "WaveFormat",
    ()=>WaveFormat
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/input-track.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/metadata.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/packet.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/id3.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
var WaveFormat;
(function(WaveFormat) {
    WaveFormat[WaveFormat["PCM"] = 1] = "PCM";
    WaveFormat[WaveFormat["IEEE_FLOAT"] = 3] = "IEEE_FLOAT";
    WaveFormat[WaveFormat["ALAW"] = 6] = "ALAW";
    WaveFormat[WaveFormat["MULAW"] = 7] = "MULAW";
    WaveFormat[WaveFormat["EXTENSIBLE"] = 65534] = "EXTENSIBLE";
})(WaveFormat || (WaveFormat = {}));
class WaveDemuxer extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Demuxer"] {
    constructor(input){
        super(input);
        this.metadataPromise = null;
        this.dataStart = -1;
        this.dataSize = -1;
        this.audioInfo = null;
        this.tracks = [];
        this.lastKnownPacketIndex = 0;
        this.metadataTags = {};
        this.reader = input._reader;
    }
    async readMetadata() {
        return this.metadataPromise ??= (async ()=>{
            let slice = this.reader.requestSlice(0, 12);
            if (slice instanceof Promise) slice = await slice;
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(slice);
            const riffType = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 4);
            const littleEndian = riffType !== 'RIFX';
            const isRf64 = riffType === 'RF64';
            const outerChunkSize = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32"])(slice, littleEndian);
            let totalFileSize = isRf64 ? this.reader.fileSize : Math.min(outerChunkSize + 8, this.reader.fileSize ?? Infinity);
            const format = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 4);
            if (format !== 'WAVE') {
                throw new Error('Invalid WAVE file - wrong format');
            }
            let chunksRead = 0;
            let dataChunkSize = null;
            let currentPos = slice.filePos;
            while(totalFileSize === null || currentPos < totalFileSize){
                let slice = this.reader.requestSlice(currentPos, 8);
                if (slice instanceof Promise) slice = await slice;
                if (!slice) break;
                const chunkId = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 4);
                const chunkSize = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32"])(slice, littleEndian);
                const startPos = slice.filePos;
                if (isRf64 && chunksRead === 0 && chunkId !== 'ds64') {
                    throw new Error('Invalid RF64 file: First chunk must be "ds64".');
                }
                if (chunkId === 'fmt ') {
                    await this.parseFmtChunk(startPos, chunkSize, littleEndian);
                } else if (chunkId === 'data') {
                    dataChunkSize ??= chunkSize;
                    this.dataStart = slice.filePos;
                    this.dataSize = Math.min(dataChunkSize, (totalFileSize ?? Infinity) - this.dataStart);
                    if (this.reader.fileSize === null) {
                        break; // Stop once we hit the data chunk
                    }
                } else if (chunkId === 'ds64') {
                    // File and data chunk sizes are defined in here instead
                    let ds64Slice = this.reader.requestSlice(startPos, chunkSize);
                    if (ds64Slice instanceof Promise) ds64Slice = await ds64Slice;
                    if (!ds64Slice) break;
                    const riffChunkSize = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU64"])(ds64Slice, littleEndian);
                    dataChunkSize = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU64"])(ds64Slice, littleEndian);
                    totalFileSize = Math.min(riffChunkSize + 8, this.reader.fileSize ?? Infinity);
                } else if (chunkId === 'LIST') {
                    await this.parseListChunk(startPos, chunkSize, littleEndian);
                } else if (chunkId === 'ID3 ' || chunkId === 'id3 ') {
                    await this.parseId3Chunk(startPos, chunkSize);
                }
                currentPos = startPos + chunkSize + (chunkSize & 1); // Handle padding
                chunksRead++;
            }
            if (!this.audioInfo) {
                throw new Error('Invalid WAVE file - missing "fmt " chunk');
            }
            if (this.dataStart === -1) {
                throw new Error('Invalid WAVE file - missing "data" chunk');
            }
            const blockSize = this.audioInfo.blockSizeInBytes;
            this.dataSize = Math.floor(this.dataSize / blockSize) * blockSize;
            this.tracks.push(new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputAudioTrack"](this.input, new WaveAudioTrackBacking(this)));
        })();
    }
    async parseFmtChunk(startPos, size, littleEndian) {
        let slice = this.reader.requestSlice(startPos, size);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) return; // File too short
        let formatTag = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU16"])(slice, littleEndian);
        const numChannels = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU16"])(slice, littleEndian);
        const sampleRate = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32"])(slice, littleEndian);
        slice.skip(4); // Bytes per second
        const blockAlign = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU16"])(slice, littleEndian);
        let bitsPerSample;
        if (size === 14) {
            bitsPerSample = 8;
        } else {
            bitsPerSample = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU16"])(slice, littleEndian);
        }
        // Handle WAVEFORMATEXTENSIBLE
        if (size >= 18 && formatTag !== 0x0165) {
            const cbSize = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU16"])(slice, littleEndian);
            const remainingSize = size - 18;
            const extensionSize = Math.min(remainingSize, cbSize);
            if (extensionSize >= 22 && formatTag === WaveFormat.EXTENSIBLE) {
                // Parse WAVEFORMATEXTENSIBLE
                slice.skip(2 + 4);
                const subFormat = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, 16);
                // Get actual format from subFormat GUID
                formatTag = subFormat[0] | subFormat[1] << 8;
            }
        }
        if (formatTag === WaveFormat.MULAW || formatTag === WaveFormat.ALAW) {
            bitsPerSample = 8;
        }
        this.audioInfo = {
            format: formatTag,
            numberOfChannels: numChannels,
            sampleRate,
            sampleSizeInBytes: Math.ceil(bitsPerSample / 8),
            blockSizeInBytes: blockAlign
        };
    }
    async parseListChunk(startPos, size, littleEndian) {
        let slice = this.reader.requestSlice(startPos, size);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) return; // File too short
        const infoType = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 4);
        if (infoType !== 'INFO' && infoType !== 'INF0') {
            return; // Not an INFO chunk
        }
        let currentPos = slice.filePos;
        while(currentPos <= startPos + size - 8){
            slice.filePos = currentPos;
            const chunkName = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 4);
            const chunkSize = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32"])(slice, littleEndian);
            const bytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, chunkSize);
            let stringLength = 0;
            for(let i = 0; i < bytes.length; i++){
                if (bytes[i] === 0) {
                    break;
                }
                stringLength++;
            }
            const value = String.fromCharCode(...bytes.subarray(0, stringLength));
            this.metadataTags.raw ??= {};
            this.metadataTags.raw[chunkName] = value;
            switch(chunkName){
                case 'INAM':
                case 'TITL':
                    {
                        this.metadataTags.title ??= value;
                    }
                    ;
                    break;
                case 'TIT3':
                    {
                        this.metadataTags.description ??= value;
                    }
                    ;
                    break;
                case 'IART':
                    {
                        this.metadataTags.artist ??= value;
                    }
                    ;
                    break;
                case 'IPRD':
                    {
                        this.metadataTags.album ??= value;
                    }
                    ;
                    break;
                case 'IPRT':
                case 'ITRK':
                case 'TRCK':
                    {
                        const parts = value.split('/');
                        const trackNum = Number.parseInt(parts[0], 10);
                        const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);
                        if (Number.isInteger(trackNum) && trackNum > 0) {
                            this.metadataTags.trackNumber ??= trackNum;
                        }
                        if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {
                            this.metadataTags.tracksTotal ??= tracksTotal;
                        }
                    }
                    ;
                    break;
                case 'ICRD':
                case 'IDIT':
                    {
                        const date = new Date(value);
                        if (!Number.isNaN(date.getTime())) {
                            this.metadataTags.date ??= date;
                        }
                    }
                    ;
                    break;
                case 'YEAR':
                    {
                        const year = Number.parseInt(value, 10);
                        if (Number.isInteger(year) && year > 0) {
                            this.metadataTags.date ??= new Date(year, 0, 1);
                        }
                    }
                    ;
                    break;
                case 'IGNR':
                case 'GENR':
                    {
                        this.metadataTags.genre ??= value;
                    }
                    ;
                    break;
                case 'ICMT':
                case 'CMNT':
                case 'COMM':
                    {
                        this.metadataTags.comment ??= value;
                    }
                    ;
                    break;
            }
            currentPos += 8 + chunkSize + (chunkSize & 1); // Handle padding
        }
    }
    async parseId3Chunk(startPos, size) {
        // Parse ID3 tag embedded in WAV file (non-default, but used a lot in practice anyway)
        let slice = this.reader.requestSlice(startPos, size);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) return; // File too short
        const id3V2Header = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readId3V2Header"])(slice);
        if (id3V2Header) {
            // Extract the content portion (skip the 10-byte header)
            const contentSlice = slice.slice(startPos + 10, id3V2Header.size);
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parseId3V2Tag"])(contentSlice, id3V2Header, this.metadataTags);
        }
    }
    getCodec() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.audioInfo);
        if (this.audioInfo.format === WaveFormat.MULAW) {
            return 'ulaw';
        }
        if (this.audioInfo.format === WaveFormat.ALAW) {
            return 'alaw';
        }
        if (this.audioInfo.format === WaveFormat.PCM) {
            // All formats are little-endian
            if (this.audioInfo.sampleSizeInBytes === 1) {
                return 'pcm-u8';
            } else if (this.audioInfo.sampleSizeInBytes === 2) {
                return 'pcm-s16';
            } else if (this.audioInfo.sampleSizeInBytes === 3) {
                return 'pcm-s24';
            } else if (this.audioInfo.sampleSizeInBytes === 4) {
                return 'pcm-s32';
            }
        }
        if (this.audioInfo.format === WaveFormat.IEEE_FLOAT) {
            if (this.audioInfo.sampleSizeInBytes === 4) {
                return 'pcm-f32';
            }
        }
        return null;
    }
    async getMimeType() {
        return 'audio/wav';
    }
    async computeDuration() {
        await this.readMetadata();
        const track = this.tracks[0];
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(track);
        return track.computeDuration();
    }
    async getTracks() {
        await this.readMetadata();
        return this.tracks;
    }
    async getMetadataTags() {
        await this.readMetadata();
        return this.metadataTags;
    }
}
const PACKET_SIZE_IN_FRAMES = 2048;
class WaveAudioTrackBacking {
    constructor(demuxer){
        this.demuxer = demuxer;
    }
    getId() {
        return 1;
    }
    getCodec() {
        return this.demuxer.getCodec();
    }
    getInternalCodecId() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        return this.demuxer.audioInfo.format;
    }
    async getDecoderConfig() {
        const codec = this.demuxer.getCodec();
        if (!codec) {
            return null;
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        return {
            codec,
            numberOfChannels: this.demuxer.audioInfo.numberOfChannels,
            sampleRate: this.demuxer.audioInfo.sampleRate
        };
    }
    async computeDuration() {
        const lastPacket = await this.getPacket(Infinity, {
            metadataOnly: true
        });
        return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);
    }
    getNumberOfChannels() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        return this.demuxer.audioInfo.numberOfChannels;
    }
    getSampleRate() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        return this.demuxer.audioInfo.sampleRate;
    }
    getTimeResolution() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        return this.demuxer.audioInfo.sampleRate;
    }
    getName() {
        return null;
    }
    getLanguageCode() {
        return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["UNDETERMINED_LANGUAGE"];
    }
    getDisposition() {
        return {
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["DEFAULT_TRACK_DISPOSITION"]
        };
    }
    async getFirstTimestamp() {
        return 0;
    }
    async getPacketAtIndex(packetIndex, options) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        const startOffset = packetIndex * PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes;
        if (startOffset >= this.demuxer.dataSize) {
            return null;
        }
        const sizeInBytes = Math.min(PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes, this.demuxer.dataSize - startOffset);
        if (this.demuxer.reader.fileSize === null) {
            // If the file size is unknown, we weren't able to cap the dataSize in the init logic and we instead have to
            // rely on the headers telling us how large the file is. But, these might be wrong, so let's check if the
            // requested slice actually exists.
            let slice = this.demuxer.reader.requestSlice(this.demuxer.dataStart + startOffset, sizeInBytes);
            if (slice instanceof Promise) slice = await slice;
            if (!slice) {
                return null;
            }
        }
        let data;
        if (options.metadataOnly) {
            data = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PLACEHOLDER_DATA"];
        } else {
            let slice = this.demuxer.reader.requestSlice(this.demuxer.dataStart + startOffset, sizeInBytes);
            if (slice instanceof Promise) slice = await slice;
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(slice);
            data = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, sizeInBytes);
        }
        const timestamp = packetIndex * PACKET_SIZE_IN_FRAMES / this.demuxer.audioInfo.sampleRate;
        const duration = sizeInBytes / this.demuxer.audioInfo.blockSizeInBytes / this.demuxer.audioInfo.sampleRate;
        this.demuxer.lastKnownPacketIndex = Math.max(packetIndex, timestamp);
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"](data, 'key', timestamp, duration, packetIndex, sizeInBytes);
    }
    getFirstPacket(options) {
        return this.getPacketAtIndex(0, options);
    }
    async getPacket(timestamp, options) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        const packetIndex = Math.floor(Math.min(timestamp * this.demuxer.audioInfo.sampleRate / PACKET_SIZE_IN_FRAMES, (this.demuxer.dataSize - 1) / (PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes)));
        const packet = await this.getPacketAtIndex(packetIndex, options);
        if (packet) {
            return packet;
        }
        if (packetIndex === 0) {
            return null; // Empty data chunk
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.reader.fileSize === null);
        // The file is shorter than we thought, meaning the packet we were looking for doesn't exist. So, let's find
        // the last packet by doing a sequential scan, instead.
        let currentPacket = await this.getPacketAtIndex(this.demuxer.lastKnownPacketIndex, options);
        while(currentPacket){
            const nextPacket = await this.getNextPacket(currentPacket, options);
            if (!nextPacket) {
                break;
            }
            currentPacket = nextPacket;
        }
        return currentPacket;
    }
    getNextPacket(packet, options) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        const packetIndex = Math.round(packet.timestamp * this.demuxer.audioInfo.sampleRate / PACKET_SIZE_IN_FRAMES);
        return this.getPacketAtIndex(packetIndex + 1, options);
    }
    getKeyPacket(timestamp, options) {
        return this.getPacket(timestamp, options);
    }
    getNextKeyPacket(packet, options) {
        return this.getNextPacket(packet, options);
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/wave/riff-writer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "RiffWriter",
    ()=>RiffWriter
]);
class RiffWriter {
    constructor(writer){
        this.writer = writer;
        this.helper = new Uint8Array(8);
        this.helperView = new DataView(this.helper.buffer);
    }
    writeU16(value) {
        this.helperView.setUint16(0, value, true);
        this.writer.write(this.helper.subarray(0, 2));
    }
    writeU32(value) {
        this.helperView.setUint32(0, value, true);
        this.writer.write(this.helper.subarray(0, 4));
    }
    writeU64(value) {
        this.helperView.setUint32(0, value, true);
        this.helperView.setUint32(4, Math.floor(value / 2 ** 32), true);
        this.writer.write(this.helper);
    }
    writeAscii(text) {
        this.writer.write(new TextEncoder().encode(text));
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/wave/wave-muxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "WaveMuxer",
    ()=>WaveMuxer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/muxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$wave$2f$wave$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/wave/wave-demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$wave$2f$riff$2d$writer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/wave/riff-writer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/metadata.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/id3.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
class WaveMuxer extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Muxer"] {
    constructor(output, format){
        super(output);
        this.headerWritten = false;
        this.dataSize = 0;
        this.sampleRate = null;
        this.sampleCount = 0;
        this.riffSizePos = null;
        this.dataSizePos = null;
        this.ds64RiffSizePos = null;
        this.ds64DataSizePos = null;
        this.ds64SampleCountPos = null;
        this.format = format;
        this.writer = output._writer;
        this.riffWriter = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$wave$2f$riff$2d$writer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["RiffWriter"](output._writer);
        this.isRf64 = !!format._options.large;
    }
    async start() {
    // Nothing needed here - we'll write the header with the first sample
    }
    async getMimeType() {
        return 'audio/wav';
    }
    async addEncodedVideoPacket() {
        throw new Error('WAVE does not support video.');
    }
    async addEncodedAudioPacket(track, packet, meta) {
        const release = await this.mutex.acquire();
        try {
            if (!this.headerWritten) {
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateAudioChunkMetadata"])(meta);
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(meta);
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(meta.decoderConfig);
                this.writeHeader(track, meta.decoderConfig);
                this.sampleRate = meta.decoderConfig.sampleRate;
                this.headerWritten = true;
            }
            this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === 'key');
            if (!this.isRf64 && this.writer.getPos() + packet.data.byteLength >= 2 ** 32) {
                throw new Error('Adding more audio data would exceed the maximum RIFF size of 4 GiB. To write larger files, use' + ' RF64 by setting `large: true` in the WavOutputFormatOptions.');
            }
            this.writer.write(packet.data);
            this.dataSize += packet.data.byteLength;
            this.sampleCount += Math.round(packet.duration * this.sampleRate);
            await this.writer.flush();
        } finally{
            release();
        }
    }
    async addSubtitleCue() {
        throw new Error('WAVE does not support subtitles.');
    }
    writeHeader(track, config) {
        if (this.format._options.onHeader) {
            this.writer.startTrackingWrites();
        }
        let format;
        const codec = track.source._codec;
        const pcmInfo = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["parsePcmCodec"])(codec);
        if (pcmInfo.dataType === 'ulaw') {
            format = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$wave$2f$wave$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["WaveFormat"].MULAW;
        } else if (pcmInfo.dataType === 'alaw') {
            format = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$wave$2f$wave$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["WaveFormat"].ALAW;
        } else if (pcmInfo.dataType === 'float') {
            format = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$wave$2f$wave$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["WaveFormat"].IEEE_FLOAT;
        } else {
            format = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$wave$2f$wave$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["WaveFormat"].PCM;
        }
        const channels = config.numberOfChannels;
        const sampleRate = config.sampleRate;
        const blockSize = pcmInfo.sampleSize * channels;
        // RIFF header
        this.riffWriter.writeAscii(this.isRf64 ? 'RF64' : 'RIFF');
        if (this.isRf64) {
            this.riffWriter.writeU32(0xffffffff); // Not used in RF64
        } else {
            this.riffSizePos = this.writer.getPos();
            this.riffWriter.writeU32(0); // File size placeholder
        }
        this.riffWriter.writeAscii('WAVE');
        if (this.isRf64) {
            this.riffWriter.writeAscii('ds64');
            this.riffWriter.writeU32(28); // Chunk size
            this.ds64RiffSizePos = this.writer.getPos();
            this.riffWriter.writeU64(0); // RIFF size placeholder
            this.ds64DataSizePos = this.writer.getPos();
            this.riffWriter.writeU64(0); // Data size placeholder
            this.ds64SampleCountPos = this.writer.getPos();
            this.riffWriter.writeU64(0); // Sample count placeholder
            this.riffWriter.writeU32(0); // Table length
        // Empty table
        }
        // fmt chunk
        this.riffWriter.writeAscii('fmt ');
        this.riffWriter.writeU32(16); // Chunk size
        this.riffWriter.writeU16(format);
        this.riffWriter.writeU16(channels);
        this.riffWriter.writeU32(sampleRate);
        this.riffWriter.writeU32(sampleRate * blockSize); // Bytes per second
        this.riffWriter.writeU16(blockSize);
        this.riffWriter.writeU16(8 * pcmInfo.sampleSize);
        // Metadata tags
        if (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["metadataTagsAreEmpty"])(this.output._metadataTags)) {
            const metadataFormat = this.format._options.metadataFormat ?? 'info';
            if (metadataFormat === 'info') {
                this.writeInfoChunk(this.output._metadataTags);
            } else if (metadataFormat === 'id3') {
                this.writeId3Chunk(this.output._metadataTags);
            } else {
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(metadataFormat);
            }
        }
        // data chunk
        this.riffWriter.writeAscii('data');
        if (this.isRf64) {
            this.riffWriter.writeU32(0xffffffff); // Not used in RF64
        } else {
            this.dataSizePos = this.writer.getPos();
            this.riffWriter.writeU32(0); // Data size placeholder
        }
        if (this.format._options.onHeader) {
            const { data, start } = this.writer.stopTrackingWrites();
            this.format._options.onHeader(data, start);
        }
    }
    writeInfoChunk(metadata) {
        const startPos = this.writer.getPos();
        this.riffWriter.writeAscii('LIST');
        this.riffWriter.writeU32(0); // Size placeholder
        this.riffWriter.writeAscii('INFO');
        const writtenTags = new Set();
        const writeInfoTag = (tag, value)=>{
            if (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isIso88591Compatible"])(value)) {
                // No Unicode supported here
                console.warn(`Didn't write tag '${tag}' because '${value}' is not ISO 8859-1-compatible.`);
                return;
            }
            const size = value.length + 1; // +1 for null terminator
            const bytes = new Uint8Array(size);
            for(let i = 0; i < value.length; i++){
                bytes[i] = value.charCodeAt(i);
            }
            this.riffWriter.writeAscii(tag);
            this.riffWriter.writeU32(size);
            this.writer.write(bytes);
            // Add padding byte if size is odd
            if (size & 1) {
                this.writer.write(new Uint8Array(1));
            }
            writtenTags.add(tag);
        };
        for (const { key, value } of (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["keyValueIterator"])(metadata)){
            switch(key){
                case 'title':
                    {
                        writeInfoTag('INAM', value);
                        writtenTags.add('INAM');
                    }
                    ;
                    break;
                case 'artist':
                    {
                        writeInfoTag('IART', value);
                        writtenTags.add('IART');
                    }
                    ;
                    break;
                case 'album':
                    {
                        writeInfoTag('IPRD', value);
                        writtenTags.add('IPRD');
                    }
                    ;
                    break;
                case 'trackNumber':
                    {
                        const string = metadata.tracksTotal !== undefined ? `${value}/${metadata.tracksTotal}` : value.toString();
                        writeInfoTag('ITRK', string);
                        writtenTags.add('ITRK');
                    }
                    ;
                    break;
                case 'genre':
                    {
                        writeInfoTag('IGNR', value);
                        writtenTags.add('IGNR');
                    }
                    ;
                    break;
                case 'date':
                    {
                        writeInfoTag('ICRD', value.toISOString().slice(0, 10));
                        writtenTags.add('ICRD');
                    }
                    ;
                    break;
                case 'comment':
                    {
                        writeInfoTag('ICMT', value);
                        writtenTags.add('ICMT');
                    }
                    ;
                    break;
                case 'albumArtist':
                case 'discNumber':
                case 'tracksTotal':
                case 'discsTotal':
                case 'description':
                case 'lyrics':
                case 'images':
                    {
                    // Not supported in RIFF INFO
                    }
                    ;
                    break;
                case 'raw':
                    {
                    // Handled later
                    }
                    ;
                    break;
                default:
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(key);
            }
        }
        if (metadata.raw) {
            for(const key in metadata.raw){
                const value = metadata.raw[key];
                if (value == null || key.length !== 4 || writtenTags.has(key)) {
                    continue;
                }
                if (typeof value === 'string') {
                    writeInfoTag(key, value);
                }
            }
        }
        const endPos = this.writer.getPos();
        const chunkSize = endPos - startPos - 8;
        this.writer.seek(startPos + 4);
        this.riffWriter.writeU32(chunkSize);
        this.writer.seek(endPos);
        // Add padding byte if chunk size is odd
        if (chunkSize & 1) {
            this.writer.write(new Uint8Array(1));
        }
    }
    writeId3Chunk(metadata) {
        const startPos = this.writer.getPos();
        // Write RIFF chunk header
        this.riffWriter.writeAscii('ID3 ');
        this.riffWriter.writeU32(0); // Size placeholder
        const id3Writer = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Id3V2Writer"](this.writer);
        const id3TagSize = id3Writer.writeId3V2Tag(metadata);
        const endPos = this.writer.getPos();
        // Update RIFF chunk size
        this.writer.seek(startPos + 4);
        this.riffWriter.writeU32(id3TagSize);
        this.writer.seek(endPos);
        // Add padding byte if chunk size is odd
        if (id3TagSize & 1) {
            this.writer.write(new Uint8Array(1));
        }
    }
    async finalize() {
        const release = await this.mutex.acquire();
        const endPos = this.writer.getPos();
        if (this.isRf64) {
            // Write riff size
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.ds64RiffSizePos !== null);
            this.writer.seek(this.ds64RiffSizePos);
            this.riffWriter.writeU64(endPos - 8);
            // Write data size
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.ds64DataSizePos !== null);
            this.writer.seek(this.ds64DataSizePos);
            this.riffWriter.writeU64(this.dataSize);
            // Write sample count
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.ds64SampleCountPos !== null);
            this.writer.seek(this.ds64SampleCountPos);
            this.riffWriter.writeU64(this.sampleCount);
        } else {
            // Write file size
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.riffSizePos !== null);
            this.writer.seek(this.riffSizePos);
            this.riffWriter.writeU32(endPos - 8);
            // Write data chunk size
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.dataSizePos !== null);
            this.writer.seek(this.dataSizePos);
            this.riffWriter.writeU32(this.dataSize);
        }
        this.writer.seek(endPos);
        release();
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/flac/flac-misc.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "calculateCrc8",
    ()=>calculateCrc8,
    "getBlockSizeOrUncommon",
    ()=>getBlockSizeOrUncommon,
    "getSampleRateOrUncommon",
    ()=>getSampleRateOrUncommon,
    "readBlockSize",
    ()=>readBlockSize,
    "readCodedNumber",
    ()=>readCodedNumber,
    "readSampleRate",
    ()=>readSampleRate
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
;
;
const getBlockSizeOrUncommon = (bits)=>{
    if (bits === 0b0000) {
        return null;
    } else if (bits === 0b0001) {
        return 192;
    } else if (bits >= 0b0010 && bits <= 0b0101) {
        return 144 * 2 ** bits;
    } else if (bits === 0b0110) {
        return 'uncommon-u8';
    } else if (bits === 0b0111) {
        return 'uncommon-u16';
    } else if (bits >= 0b1000 && bits <= 0b1111) {
        return 2 ** bits;
    } else {
        return null;
    }
};
const getSampleRateOrUncommon = (sampleRateBits, streamInfoSampleRate)=>{
    switch(sampleRateBits){
        case 0b0000:
            return streamInfoSampleRate;
        case 0b0001:
            return 88200;
        case 0b0010:
            return 176400;
        case 0b0011:
            return 192000;
        case 0b0100:
            return 8000;
        case 0b0101:
            return 16000;
        case 0b0110:
            return 22050;
        case 0b0111:
            return 24000;
        case 0b1000:
            return 32000;
        case 0b1001:
            return 44100;
        case 0b1010:
            return 48000;
        case 0b1011:
            return 96000;
        case 0b1100:
            return 'uncommon-u8';
        case 0b1101:
            return 'uncommon-u16';
        case 0b1110:
            return 'uncommon-u16-10';
        default:
            return null;
    }
};
const readCodedNumber = (fileSlice)=>{
    let ones = 0;
    const bitstream1 = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"]((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(fileSlice, 1));
    while(bitstream1.readBits(1) === 1){
        ones++;
    }
    if (ones === 0) {
        return bitstream1.readBits(7);
    }
    const bitArray = [];
    const extraBytes = ones - 1;
    const bitstream2 = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"]((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(fileSlice, extraBytes));
    const firstByteBits = 8 - ones - 1;
    for(let i = 0; i < firstByteBits; i++){
        bitArray.unshift(bitstream1.readBits(1));
    }
    for(let i = 0; i < extraBytes; i++){
        for(let j = 0; j < 8; j++){
            const val = bitstream2.readBits(1);
            if (j < 2) {
                continue;
            }
            bitArray.unshift(val);
        }
    }
    const encoded = bitArray.reduce((acc, bit, index)=>{
        return acc | bit << index;
    }, 0);
    return encoded;
};
const readBlockSize = (slice, blockSizeBits)=>{
    if (blockSizeBits === 'uncommon-u16') {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU16Be"])(slice) + 1;
    } else if (blockSizeBits === 'uncommon-u8') {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice) + 1;
    } else if (typeof blockSizeBits === 'number') {
        return blockSizeBits;
    } else {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assertNever"])(blockSizeBits);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(false);
    }
};
const readSampleRate = (slice, sampleRateOrUncommon)=>{
    if (sampleRateOrUncommon === 'uncommon-u16') {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU16Be"])(slice);
    }
    if (sampleRateOrUncommon === 'uncommon-u16-10') {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU16Be"])(slice) * 10;
    }
    if (sampleRateOrUncommon === 'uncommon-u8') {
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice);
    }
    if (typeof sampleRateOrUncommon === 'number') {
        return sampleRateOrUncommon;
    }
    return null;
};
const calculateCrc8 = (data)=>{
    const polynomial = 0x07; // x^8 + x^2 + x^1 + x^0
    let crc = 0x00; // Initialize CRC to 0
    for (const byte of data){
        crc ^= byte; // XOR byte into least significant byte of crc
        for(let i = 0; i < 8; i++){
            // For each bit in the byte
            if ((crc & 0x80) !== 0) {
                // If the leftmost bit (MSB) is set
                crc = crc << 1 ^ polynomial; // Shift left and XOR with polynomial
            } else {
                crc <<= 1; // Just shift left
            }
            crc &= 0xff; // Ensure CRC remains 8-bit
        }
    }
    return crc;
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/flac/flac-demuxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "FlacDemuxer",
    ()=>FlacDemuxer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec-data.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/input-track.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/packet.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/metadata.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/flac/flac-misc.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
class FlacDemuxer extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Demuxer"] {
    constructor(input){
        super(input);
        this.loadedSamples = []; // All samples from the start of the file to lastLoadedPos
        this.metadataPromise = null;
        this.track = null;
        this.metadataTags = {};
        this.audioInfo = null;
        this.lastLoadedPos = null;
        this.blockingBit = null;
        this.readingMutex = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AsyncMutex"]();
        this.lastSampleLoaded = false;
        this.reader = input._reader;
    }
    async computeDuration() {
        await this.readMetadata();
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.track);
        return this.track.computeDuration();
    }
    async getMetadataTags() {
        await this.readMetadata();
        return this.metadataTags;
    }
    async getTracks() {
        await this.readMetadata();
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.track);
        return [
            this.track
        ];
    }
    async getMimeType() {
        return 'audio/flac';
    }
    async readMetadata() {
        let currentPos = 4; // Skip 'fLaC'
        return this.metadataPromise ??= (async ()=>{
            while(this.reader.fileSize === null || currentPos < this.reader.fileSize){
                let sizeSlice = this.reader.requestSlice(currentPos, 4);
                if (sizeSlice instanceof Promise) sizeSlice = await sizeSlice;
                currentPos += 4;
                if (sizeSlice === null) {
                    throw new Error(`Metadata block at position ${currentPos} is too small! Corrupted file.`);
                }
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(sizeSlice);
                const byte = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(sizeSlice); // first bit: isLastMetadata, remaining 7 bits: metaBlockType
                const size = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU24Be"])(sizeSlice);
                const isLastMetadata = (byte & 0x80) !== 0;
                const metaBlockType = byte & 0x7f;
                switch(metaBlockType){
                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FlacBlockType"].STREAMINFO:
                        {
                            // Parse streaminfo block
                            // https://www.rfc-editor.org/rfc/rfc9639.html#section-8.2
                            let streamInfoBlock = this.reader.requestSlice(currentPos, size);
                            if (streamInfoBlock instanceof Promise) streamInfoBlock = await streamInfoBlock;
                            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(streamInfoBlock);
                            if (streamInfoBlock === null) {
                                throw new Error(`StreamInfo block at position ${currentPos} is too small! Corrupted file.`);
                            }
                            const streamInfoBytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(streamInfoBlock, 34);
                            const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](streamInfoBytes);
                            const minimumBlockSize = bitstream.readBits(16);
                            const maximumBlockSize = bitstream.readBits(16);
                            const minimumFrameSize = bitstream.readBits(24);
                            const maximumFrameSize = bitstream.readBits(24);
                            const sampleRate = bitstream.readBits(20);
                            const numberOfChannels = bitstream.readBits(3) + 1;
                            bitstream.readBits(5); // bitsPerSample - 1
                            const totalSamples = bitstream.readBits(36);
                            // https://www.w3.org/TR/webcodecs-flac-codec-registration/#audiodecoderconfig-description
                            // description is required, and has to be the following:
                            // 1. The bytes 0x66 0x4C 0x61 0x43 ("fLaC" in ASCII)
                            // 2. A metadata block (called the STREAMINFO block) as described in section 7 of [FLAC]
                            // 3. Optionaly (sic) other metadata blocks, that are not used by the specification
                            bitstream.skipBits(16 * 8); // md5 hash
                            const description = new Uint8Array(42);
                            // 1. "fLaC"
                            description.set(new Uint8Array([
                                0x66,
                                0x4c,
                                0x61,
                                0x43
                            ]), 0);
                            // 2. STREAMINFO block
                            description.set(new Uint8Array([
                                128,
                                0,
                                0,
                                34
                            ]), 4);
                            // 3. Other metadata blocks
                            description.set(streamInfoBytes, 8);
                            this.audioInfo = {
                                numberOfChannels,
                                sampleRate,
                                totalSamples,
                                minimumBlockSize,
                                maximumBlockSize,
                                minimumFrameSize,
                                maximumFrameSize,
                                description
                            };
                            this.track = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$track$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputAudioTrack"](this.input, new FlacAudioTrackBacking(this));
                            break;
                        }
                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FlacBlockType"].VORBIS_COMMENT:
                        {
                            // Parse vorbis comment block
                            // https://www.rfc-editor.org/rfc/rfc9639.html#name-vorbis-comment
                            let vorbisCommentBlock = this.reader.requestSlice(currentPos, size);
                            if (vorbisCommentBlock instanceof Promise) vorbisCommentBlock = await vorbisCommentBlock;
                            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(vorbisCommentBlock);
                            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readVorbisComments"])((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(vorbisCommentBlock, size), this.metadataTags);
                            break;
                        }
                    case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FlacBlockType"].PICTURE:
                        {
                            // Parse picture block
                            // https://www.rfc-editor.org/rfc/rfc9639.html#name-picture
                            let pictureBlock = this.reader.requestSlice(currentPos, size);
                            if (pictureBlock instanceof Promise) pictureBlock = await pictureBlock;
                            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(pictureBlock);
                            const pictureType = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Be"])(pictureBlock);
                            const mediaTypeLength = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Be"])(pictureBlock);
                            const mediaType = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textDecoder"].decode((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(pictureBlock, mediaTypeLength));
                            const descriptionLength = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Be"])(pictureBlock);
                            const description = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textDecoder"].decode((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(pictureBlock, descriptionLength));
                            pictureBlock.skip(4 + 4 + 4 + 4); // Skip width, height, color depth, number of indexed colors
                            const dataLength = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU32Be"])(pictureBlock);
                            const data = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(pictureBlock, dataLength);
                            this.metadataTags.images ??= [];
                            this.metadataTags.images.push({
                                data,
                                mimeType: mediaType,
                                // https://www.rfc-editor.org/rfc/rfc9639.html#table13
                                kind: pictureType === 3 ? 'coverFront' : pictureType === 4 ? 'coverBack' : 'unknown',
                                description
                            });
                            break;
                        }
                    default:
                        break;
                }
                currentPos += size;
                if (isLastMetadata) {
                    this.lastLoadedPos = currentPos;
                    break;
                }
            }
        })();
    }
    async readNextFlacFrame({ startPos, isFirstPacket }) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.audioInfo);
        // we expect that there are at least `minimumFrameSize` bytes left in the file
        // Ideally we also want to validate the next header is valid
        // to throw out an accidential sync word
        // The shortest valid FLAC header I can think of, based off the code
        // of readFlacFrameHeader:
        // 4 bytes used for bitstream from syncword to bit depth
        // 1 byte coded number
        // (uncommon values, no bytes read)
        // 1 byte crc
        // --> 6 bytes
        const minimumHeaderLength = 6;
        // If we read everything in readFlacFrameHeader, we read 16 bytes
        const maximumHeaderSize = 16;
        const maximumSliceLength = this.audioInfo.maximumFrameSize + maximumHeaderSize;
        const slice = await this.reader.requestSliceRange(startPos, this.audioInfo.minimumFrameSize, maximumSliceLength);
        if (!slice) {
            return null;
        }
        const frameHeader = this.readFlacFrameHeader({
            slice,
            isFirstPacket: isFirstPacket
        });
        if (!frameHeader) {
            return null;
        }
        // We don't know exactly how long the packet is, we only know the `minimumFrameSize` and `maximumFrameSize`
        // The packet is over if the next 2 bytes are the sync word followed by a valid header
        // or the end of the file is reached
        // The next sync word is expected at earliest when `minimumFrameSize` is reached,
        // we can skip over anything before that
        slice.filePos = startPos + this.audioInfo.minimumFrameSize;
        while(true){
            // Reached end of the file, packet is over
            if (slice.filePos > slice.end - minimumHeaderLength) {
                return {
                    num: frameHeader.num,
                    blockSize: frameHeader.blockSize,
                    sampleRate: frameHeader.sampleRate,
                    size: slice.end - startPos,
                    isLastFrame: true
                };
            }
            const nextByte = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice);
            if (nextByte === 0xff) {
                const positionBeforeReading = slice.filePos;
                const byteAfterNextByte = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice);
                const expected = this.blockingBit === 1 ? 0b1111_1001 : 0b1111_1000;
                if (byteAfterNextByte !== expected) {
                    slice.filePos = positionBeforeReading;
                    continue;
                }
                slice.skip(-2);
                const lengthIfNextFlacFrameHeaderIsLegit = slice.filePos - startPos;
                const nextFrameHeader = this.readFlacFrameHeader({
                    slice,
                    isFirstPacket: false
                });
                if (!nextFrameHeader) {
                    slice.filePos = positionBeforeReading;
                    continue;
                }
                // Ensure the frameOrSampleNum is consecutive.
                // https://github.com/Vanilagy/mediabunny/issues/194
                if (this.blockingBit === 0) {
                    // Case A: If the stream is fixed block size, this is the frame number, which increments by 1
                    if (nextFrameHeader.num - frameHeader.num !== 1) {
                        slice.filePos = positionBeforeReading;
                        continue;
                    }
                } else {
                    // Case B: If the stream is variable block size, this is the sample number, which increments by
                    // amount of samples in a frame.
                    if (nextFrameHeader.num - frameHeader.num !== frameHeader.blockSize) {
                        slice.filePos = positionBeforeReading;
                        continue;
                    }
                }
                return {
                    num: frameHeader.num,
                    blockSize: frameHeader.blockSize,
                    sampleRate: frameHeader.sampleRate,
                    size: lengthIfNextFlacFrameHeaderIsLegit,
                    isLastFrame: false
                };
            }
        }
    }
    readFlacFrameHeader({ slice, isFirstPacket }) {
        // In this function, generally it is not safe to throw errors.
        // We might end up here because we stumbled upon a syncword,
        // but the data might not actually be a FLAC frame, it might be random bitstream
        // data, in that case we should return null and continue.
        const startOffset = slice.filePos;
        // https://www.rfc-editor.org/rfc/rfc9639.html#section-9.1
        // Each frame MUST start on a byte boundary and start with the 15-bit frame
        // sync code 0b111111111111100. Following the sync code is the blocking strategy
        // bit, which MUST NOT change during the audio stream.
        const bytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, 4);
        const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](bytes);
        const bits = bitstream.readBits(15);
        if (bits !== 0b111111111111100) {
            // This cannot be a valid FLAC frame, must start with the syncword
            return null;
        }
        if (this.blockingBit === null) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(isFirstPacket);
            const newBlockingBit = bitstream.readBits(1);
            this.blockingBit = newBlockingBit;
        } else if (this.blockingBit === 1) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(!isFirstPacket);
            const newBlockingBit = bitstream.readBits(1);
            if (newBlockingBit !== 1) {
                // This cannot be a valid FLAC frame, expected 1 but got 0
                return null;
            }
        } else if (this.blockingBit === 0) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(!isFirstPacket);
            const newBlockingBit = bitstream.readBits(1);
            if (newBlockingBit !== 0) {
                // This cannot be a valid FLAC frame, expected 0 but got 1
                return null;
            }
        } else {
            throw new Error('Invalid blocking bit');
        }
        const blockSizeOrUncommon = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getBlockSizeOrUncommon"])(bitstream.readBits(4));
        if (!blockSizeOrUncommon) {
            // This cannot be a valid FLAC frame, the syncword was just coincidental
            return null;
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.audioInfo);
        const sampleRateOrUncommon = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getSampleRateOrUncommon"])(bitstream.readBits(4), this.audioInfo.sampleRate);
        if (!sampleRateOrUncommon) {
            // This cannot be a valid FLAC frame, the syncword was just coincidental
            return null;
        }
        bitstream.readBits(4); // channel count
        bitstream.readBits(3); // bit depth
        const reservedZero = bitstream.readBits(1); // reserved zero
        if (reservedZero !== 0) {
            // This cannot be a valid FLAC frame, the syncword was just coincidental
            return null;
        }
        const num = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readCodedNumber"])(slice);
        const blockSize = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBlockSize"])(slice, blockSizeOrUncommon);
        const sampleRate = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readSampleRate"])(slice, sampleRateOrUncommon);
        if (sampleRate === null) {
            // This cannot be a valid FLAC frame, the syncword was just coincidental
            return null;
        }
        if (sampleRate !== this.audioInfo.sampleRate) {
            // This cannot be a valid FLAC frame, the sample rate is not the same as in the stream info
            return null;
        }
        const size = slice.filePos - startOffset;
        const crc = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readU8"])(slice);
        slice.skip(-size);
        slice.skip(-1);
        const crcCalculated = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["calculateCrc8"])((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, size));
        if (crc !== crcCalculated) {
            // Maybe this wasn't a FLAC frame at all, the syncword was just coincidentally
            // in the bitstream
            return null;
        }
        return {
            num,
            blockSize,
            sampleRate
        };
    }
    async advanceReader() {
        await this.readMetadata();
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.lastLoadedPos !== null);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.audioInfo);
        const startPos = this.lastLoadedPos;
        const frame = await this.readNextFlacFrame({
            startPos,
            isFirstPacket: this.loadedSamples.length === 0
        });
        if (!frame) {
            // Unexpected case, failed to read next FLAC frame
            // handling gracefully
            this.lastSampleLoaded = true;
            return;
        }
        const lastSample = this.loadedSamples[this.loadedSamples.length - 1];
        const blockOffset = lastSample ? lastSample.blockOffset + lastSample.blockSize : 0;
        const sample = {
            blockOffset,
            blockSize: frame.blockSize,
            byteOffset: startPos,
            byteSize: frame.size
        };
        this.lastLoadedPos = this.lastLoadedPos + frame.size;
        this.loadedSamples.push(sample);
        if (frame.isLastFrame) {
            this.lastSampleLoaded = true;
            return;
        }
    }
}
class FlacAudioTrackBacking {
    constructor(demuxer){
        this.demuxer = demuxer;
    }
    getId() {
        return 1;
    }
    getCodec() {
        return 'flac';
    }
    getInternalCodecId() {
        return null;
    }
    getNumberOfChannels() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        return this.demuxer.audioInfo.numberOfChannels;
    }
    async computeDuration() {
        const lastPacket = await this.getPacket(Infinity, {
            metadataOnly: true
        });
        return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);
    }
    getSampleRate() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        return this.demuxer.audioInfo.sampleRate;
    }
    getName() {
        return null;
    }
    getLanguageCode() {
        return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["UNDETERMINED_LANGUAGE"];
    }
    getTimeResolution() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        return this.demuxer.audioInfo.sampleRate;
    }
    getDisposition() {
        return {
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["DEFAULT_TRACK_DISPOSITION"]
        };
    }
    async getFirstTimestamp() {
        return 0;
    }
    async getDecoderConfig() {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        return {
            codec: 'flac',
            numberOfChannels: this.demuxer.audioInfo.numberOfChannels,
            sampleRate: this.demuxer.audioInfo.sampleRate,
            description: this.demuxer.audioInfo.description
        };
    }
    async getPacket(timestamp, options) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        if (timestamp < 0) {
            throw new Error('Timestamp cannot be negative');
        }
        const release = await this.demuxer.readingMutex.acquire();
        try {
            while(true){
                const packetIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["binarySearchLessOrEqual"])(this.demuxer.loadedSamples, timestamp, (x)=>x.blockOffset / this.demuxer.audioInfo.sampleRate);
                if (packetIndex === -1) {
                    await this.demuxer.advanceReader();
                    continue;
                }
                const packet = this.demuxer.loadedSamples[packetIndex];
                const sampleTimestamp = packet.blockOffset / this.demuxer.audioInfo.sampleRate;
                const sampleDuration = packet.blockSize / this.demuxer.audioInfo.sampleRate;
                if (sampleTimestamp + sampleDuration <= timestamp) {
                    if (this.demuxer.lastSampleLoaded) {
                        return this.getPacketAtIndex(this.demuxer.loadedSamples.length - 1, options);
                    }
                    await this.demuxer.advanceReader();
                    continue;
                }
                return this.getPacketAtIndex(packetIndex, options);
            }
        } finally{
            release();
        }
    }
    async getNextPacket(packet, options) {
        const release = await this.demuxer.readingMutex.acquire();
        try {
            const nextIndex = packet.sequenceNumber + 1;
            if (this.demuxer.lastSampleLoaded && nextIndex >= this.demuxer.loadedSamples.length) {
                return null;
            }
            // Ensure the next sample exists
            while(nextIndex >= this.demuxer.loadedSamples.length && !this.demuxer.lastSampleLoaded){
                await this.demuxer.advanceReader();
            }
            return this.getPacketAtIndex(nextIndex, options);
        } finally{
            release();
        }
    }
    getKeyPacket(timestamp, options) {
        return this.getPacket(timestamp, options);
    }
    getNextKeyPacket(packet, options) {
        return this.getNextPacket(packet, options);
    }
    async getPacketAtIndex(sampleIndex, options) {
        const rawSample = this.demuxer.loadedSamples[sampleIndex];
        if (!rawSample) {
            return null;
        }
        let data;
        if (options.metadataOnly) {
            data = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PLACEHOLDER_DATA"];
        } else {
            let slice = this.demuxer.reader.requestSlice(rawSample.byteOffset, rawSample.byteSize);
            if (slice instanceof Promise) slice = await slice;
            if (!slice) {
                return null; // Data didn't fit into the rest of the file
            }
            data = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, rawSample.byteSize);
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.demuxer.audioInfo);
        const timestamp = rawSample.blockOffset / this.demuxer.audioInfo.sampleRate;
        const duration = rawSample.blockSize / this.demuxer.audioInfo.sampleRate;
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$packet$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EncodedPacket"](data, 'key', timestamp, duration, sampleIndex, rawSample.byteSize);
    }
    async getFirstPacket(options) {
        // Ensure the next sample exists
        while(this.demuxer.loadedSamples.length === 0 && !this.demuxer.lastSampleLoaded){
            await this.demuxer.advanceReader();
        }
        return this.getPacketAtIndex(0, options);
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/flac/flac-muxer.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "FlacMuxer",
    ()=>FlacMuxer
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec-data.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/muxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/metadata.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/flac/flac-misc.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
const FLAC_HEADER = /* #__PURE__ */ new Uint8Array([
    0x66,
    0x4c,
    0x61,
    0x43
]); // 'fLaC'
const STREAMINFO_SIZE = 38;
const STREAMINFO_BLOCK_SIZE = 34;
class FlacMuxer extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Muxer"] {
    constructor(output, format){
        super(output);
        this.metadataWritten = false;
        this.blockSizes = [];
        this.frameSizes = [];
        this.sampleRate = null;
        this.channels = null;
        this.bitsPerSample = null;
        this.writer = output._writer;
        this.format = format;
    }
    async start() {
        this.writer.write(FLAC_HEADER);
    }
    writeHeader({ bitsPerSample, minimumBlockSize, maximumBlockSize, minimumFrameSize, maximumFrameSize, sampleRate, channels, totalSamples }) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.writer.getPos() === 4);
        const hasMetadata = !(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["metadataTagsAreEmpty"])(this.output._metadataTags);
        const headerBitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](new Uint8Array(4));
        headerBitstream.writeBits(1, Number(!hasMetadata)); // isLastMetadata
        headerBitstream.writeBits(7, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FlacBlockType"].STREAMINFO); // metaBlockType = streaminfo
        headerBitstream.writeBits(24, STREAMINFO_BLOCK_SIZE); // size
        this.writer.write(headerBitstream.bytes);
        const contentBitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](new Uint8Array(18));
        contentBitstream.writeBits(16, minimumBlockSize);
        contentBitstream.writeBits(16, maximumBlockSize);
        contentBitstream.writeBits(24, minimumFrameSize);
        contentBitstream.writeBits(24, maximumFrameSize);
        contentBitstream.writeBits(20, sampleRate);
        contentBitstream.writeBits(3, channels - 1);
        contentBitstream.writeBits(5, bitsPerSample - 1);
        // Bitstream operations are only safe until 32bit, breaks when using 36 bits
        // Splitting up into writing 4 0 bits and then 32 bits is safe
        // This is safe for audio up to (2 ** 32 / 44100 / 3600) -> 27 hours
        // Not implementing support for more than 32 bits now
        if (totalSamples >= 2 ** 32) {
            throw new Error('This muxer only supports writing up to 2 ** 32 samples');
        }
        contentBitstream.writeBits(4, 0);
        contentBitstream.writeBits(32, totalSamples);
        this.writer.write(contentBitstream.bytes);
        // The MD5 hash is calculated from decoded audio data, but we do not have access
        // to it here. We are allowed to set 0:
        // "A value of 0 signifies that the value is not known."
        // https://www.rfc-editor.org/rfc/rfc9639.html#name-streaminfo
        this.writer.write(new Uint8Array(16));
    }
    writePictureBlock(picture) {
        // Header size:
        // 4 bytes: picture type
        // 4 bytes: media type length
        // x bytes: media type
        // 4 bytes: description length
        // y bytes: description
        // 1 bytes: width
        // 1 bytes: height
        // 1 bytes: color depth
        // 1 bytes: number of indexed colors
        // 4 bytes: picture data length
        // z bytes: picture data
        // Total: 20 + x + y + z
        const headerSize = 32 + picture.mimeType.length + (picture.description?.length ?? 0) + picture.data.length;
        const header = new Uint8Array(headerSize);
        let offset = 0;
        const dataView = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(header);
        dataView.setUint32(offset, picture.kind === 'coverFront' ? 3 : picture.kind === 'coverBack' ? 4 : 0);
        offset += 4;
        dataView.setUint32(offset, picture.mimeType.length);
        offset += 4;
        header.set(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textEncoder"].encode(picture.mimeType), 8);
        offset += picture.mimeType.length;
        dataView.setUint32(offset, picture.description?.length ?? 0);
        offset += 4;
        header.set(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textEncoder"].encode(picture.description ?? ''), offset);
        offset += picture.description?.length ?? 0;
        offset += 4 + 4 + 4 + 4; // setting width, height, color depth, number of indexed colors to 0
        dataView.setUint32(offset, picture.data.length);
        offset += 4;
        header.set(picture.data, offset);
        offset += picture.data.length;
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(offset === headerSize);
        const headerBitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](new Uint8Array(4));
        headerBitstream.writeBits(1, 0); // Last metadata block -> false, will be continued by vorbis comment
        headerBitstream.writeBits(7, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FlacBlockType"].PICTURE); // Type -> Picture
        headerBitstream.writeBits(24, headerSize);
        this.writer.write(headerBitstream.bytes);
        this.writer.write(header);
    }
    writeVorbisCommentAndPictureBlock() {
        this.writer.seek(STREAMINFO_SIZE + FLAC_HEADER.byteLength);
        if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["metadataTagsAreEmpty"])(this.output._metadataTags)) {
            this.metadataWritten = true;
            return;
        }
        const pictures = this.output._metadataTags.images ?? [];
        for (const picture of pictures){
            this.writePictureBlock(picture);
        }
        const vorbisComment = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["createVorbisComments"])(new Uint8Array(0), this.output._metadataTags, false);
        const headerBitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](new Uint8Array(4));
        headerBitstream.writeBits(1, 1); // Last metadata block -> true
        headerBitstream.writeBits(7, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2d$data$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FlacBlockType"].VORBIS_COMMENT); // Type -> Vorbis comment
        headerBitstream.writeBits(24, vorbisComment.length);
        this.writer.write(headerBitstream.bytes);
        this.writer.write(vorbisComment);
        this.metadataWritten = true;
    }
    async getMimeType() {
        return 'audio/flac';
    }
    async addEncodedVideoPacket() {
        throw new Error('FLAC does not support video.');
    }
    async addEncodedAudioPacket(track, packet, meta) {
        const release = await this.mutex.acquire();
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateAudioChunkMetadata"])(meta);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(meta);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(meta.decoderConfig);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(meta.decoderConfig.description);
        try {
            this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === 'key');
            if (this.sampleRate === null) {
                this.sampleRate = meta.decoderConfig.sampleRate;
            }
            if (this.channels === null) {
                this.channels = meta.decoderConfig.numberOfChannels;
            }
            if (this.bitsPerSample === null) {
                const descriptionBitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"]((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(meta.decoderConfig.description));
                // skip 'fLaC' + block size + frame size + sample rate + number of channels
                // See demuxer for the exact structure
                descriptionBitstream.skipBits(103 + 64);
                const bitsPerSample = descriptionBitstream.readBits(5) + 1;
                this.bitsPerSample = bitsPerSample;
            }
            if (!this.metadataWritten) {
                this.writeVorbisCommentAndPictureBlock();
            }
            const slice = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FileSlice"].tempFromBytes(packet.data);
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, 2);
            const bytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBytes"])(slice, 2);
            const bitstream = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Bitstream"](bytes);
            const blockSizeOrUncommon = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getBlockSizeOrUncommon"])(bitstream.readBits(4));
            if (blockSizeOrUncommon === null) {
                throw new Error('Invalid FLAC frame: Invalid block size.');
            }
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readCodedNumber"])(slice); // num
            const blockSize = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readBlockSize"])(slice, blockSizeOrUncommon);
            this.blockSizes.push(blockSize);
            this.frameSizes.push(packet.data.length);
            const startPos = this.writer.getPos();
            this.writer.write(packet.data);
            if (this.format._options.onFrame) {
                this.format._options.onFrame(packet.data, startPos);
            }
            await this.writer.flush();
        } finally{
            release();
        }
    }
    addSubtitleCue() {
        throw new Error('FLAC does not support subtitles.');
    }
    async finalize() {
        const release = await this.mutex.acquire();
        let minimumBlockSize = Infinity;
        let maximumBlockSize = 0;
        let minimumFrameSize = Infinity;
        let maximumFrameSize = 0;
        let totalSamples = 0;
        for(let i = 0; i < this.blockSizes.length; i++){
            minimumFrameSize = Math.min(minimumFrameSize, this.frameSizes[i]);
            maximumFrameSize = Math.max(maximumFrameSize, this.frameSizes[i]);
            maximumBlockSize = Math.max(maximumBlockSize, this.blockSizes[i]);
            totalSamples += this.blockSizes[i];
            // Excluding the last frame from block size calculation
            // https://www.rfc-editor.org/rfc/rfc9639.html#name-streaminfo
            // "The minimum block size (in samples) used in the stream, excluding the last block."
            const isLastFrame = i === this.blockSizes.length - 1;
            if (isLastFrame) {
                continue;
            }
            minimumBlockSize = Math.min(minimumBlockSize, this.blockSizes[i]);
        }
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.sampleRate !== null);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.channels !== null);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.bitsPerSample !== null);
        this.writer.seek(4);
        this.writeHeader({
            minimumBlockSize,
            maximumBlockSize,
            minimumFrameSize,
            maximumFrameSize,
            sampleRate: this.sampleRate,
            channels: this.channels,
            bitsPerSample: this.bitsPerSample,
            totalSamples
        });
        release();
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/input-format.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "ADTS",
    ()=>ADTS,
    "ALL_FORMATS",
    ()=>ALL_FORMATS,
    "AdtsInputFormat",
    ()=>AdtsInputFormat,
    "FLAC",
    ()=>FLAC,
    "FlacInputFormat",
    ()=>FlacInputFormat,
    "InputFormat",
    ()=>InputFormat,
    "IsobmffInputFormat",
    ()=>IsobmffInputFormat,
    "MATROSKA",
    ()=>MATROSKA,
    "MP3",
    ()=>MP3,
    "MP4",
    ()=>MP4,
    "MatroskaInputFormat",
    ()=>MatroskaInputFormat,
    "Mp3InputFormat",
    ()=>Mp3InputFormat,
    "Mp4InputFormat",
    ()=>Mp4InputFormat,
    "OGG",
    ()=>OGG,
    "OggInputFormat",
    ()=>OggInputFormat,
    "QTFF",
    ()=>QTFF,
    "QuickTimeInputFormat",
    ()=>QuickTimeInputFormat,
    "WAVE",
    ()=>WAVE,
    "WEBM",
    ()=>WEBM,
    "WaveInputFormat",
    ()=>WaveInputFormat,
    "WebMInputFormat",
    ()=>WebMInputFormat
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$isobmff$2f$isobmff$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/isobmff/isobmff-demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/matroska/ebml.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$matroska$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/matroska/matroska-demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$mp3$2f$mp3$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/mp3/mp3-demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/shared/mp3-misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/id3.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$mp3$2f$mp3$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/mp3/mp3-reader.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/ogg/ogg-demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$wave$2f$wave$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/wave/wave-demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/adts/adts-reader.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/adts/adts-demuxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/flac/flac-demuxer.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
;
;
;
;
;
class InputFormat {
}
class IsobmffInputFormat extends InputFormat {
    /** @internal */ async _getMajorBrand(input) {
        let slice = input._reader.requestSlice(0, 12);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) return null;
        slice.skip(4);
        const fourCc = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 4);
        if (fourCc !== 'ftyp') {
            return null;
        }
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 4);
    }
    /** @internal */ _createDemuxer(input) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$isobmff$2f$isobmff$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["IsobmffDemuxer"](input);
    }
}
class Mp4InputFormat extends IsobmffInputFormat {
    /** @internal */ async _canReadInput(input) {
        const majorBrand = await this._getMajorBrand(input);
        return !!majorBrand && majorBrand !== 'qt  ';
    }
    get name() {
        return 'MP4';
    }
    get mimeType() {
        return 'video/mp4';
    }
}
class QuickTimeInputFormat extends IsobmffInputFormat {
    /** @internal */ async _canReadInput(input) {
        const majorBrand = await this._getMajorBrand(input);
        return majorBrand === 'qt  ';
    }
    get name() {
        return 'QuickTime File Format';
    }
    get mimeType() {
        return 'video/quicktime';
    }
}
class MatroskaInputFormat extends InputFormat {
    /** @internal */ async isSupportedEBMLOfDocType(input, desiredDocType) {
        let headerSlice = input._reader.requestSlice(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_HEADER_SIZE"]);
        if (headerSlice instanceof Promise) headerSlice = await headerSlice;
        if (!headerSlice) return false;
        const varIntSize = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readVarIntSize"])(headerSlice);
        if (varIntSize === null) {
            return false;
        }
        if (varIntSize < 1 || varIntSize > 8) {
            return false;
        }
        const id = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readUnsignedInt"])(headerSlice, varIntSize);
        if (id !== __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EBMLId"].EBML) {
            return false;
        }
        const dataSize = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readElementSize"])(headerSlice);
        if (dataSize === null) {
            return false; // Miss me with that shit
        }
        let dataSlice = input._reader.requestSlice(headerSlice.filePos, dataSize);
        if (dataSlice instanceof Promise) dataSlice = await dataSlice;
        if (!dataSlice) return false;
        const startPos = headerSlice.filePos;
        while(dataSlice.filePos <= startPos + dataSize - __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_HEADER_SIZE"]){
            const header = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readElementHeader"])(dataSlice);
            if (!header) break;
            const { id, size } = header;
            const dataStartPos = dataSlice.filePos;
            if (size === null) return false;
            switch(id){
                case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EBMLId"].EBMLVersion:
                    {
                        const ebmlVersion = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readUnsignedInt"])(dataSlice, size);
                        if (ebmlVersion !== 1) {
                            return false;
                        }
                    }
                    ;
                    break;
                case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EBMLId"].EBMLReadVersion:
                    {
                        const ebmlReadVersion = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readUnsignedInt"])(dataSlice, size);
                        if (ebmlReadVersion !== 1) {
                            return false;
                        }
                    }
                    ;
                    break;
                case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EBMLId"].DocType:
                    {
                        const docType = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAsciiString"])(dataSlice, size);
                        if (docType !== desiredDocType) {
                            return false;
                        }
                    }
                    ;
                    break;
                case __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EBMLId"].DocTypeVersion:
                    {
                        const docTypeVersion = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$ebml$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readUnsignedInt"])(dataSlice, size);
                        if (docTypeVersion > 4) {
                            return false;
                        }
                    }
                    ;
                    break;
            }
            dataSlice.filePos = dataStartPos + size;
        }
        return true;
    }
    /** @internal */ _canReadInput(input) {
        return this.isSupportedEBMLOfDocType(input, 'matroska');
    }
    /** @internal */ _createDemuxer(input) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$matroska$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MatroskaDemuxer"](input);
    }
    get name() {
        return 'Matroska';
    }
    get mimeType() {
        return 'video/x-matroska';
    }
}
class WebMInputFormat extends MatroskaInputFormat {
    /** @internal */ _canReadInput(input) {
        return this.isSupportedEBMLOfDocType(input, 'webm');
    }
    get name() {
        return 'WebM';
    }
    get mimeType() {
        return 'video/webm';
    }
}
class Mp3InputFormat extends InputFormat {
    /** @internal */ async _canReadInput(input) {
        let slice = input._reader.requestSlice(0, 10);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) return false;
        let currentPos = 0;
        let id3V2HeaderFound = false;
        while(true){
            let slice = input._reader.requestSlice(currentPos, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ID3_V2_HEADER_SIZE"]);
            if (slice instanceof Promise) slice = await slice;
            if (!slice) break;
            const id3V2Header = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$id3$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readId3V2Header"])(slice);
            if (!id3V2Header) {
                break;
            }
            id3V2HeaderFound = true;
            currentPos = slice.filePos + id3V2Header.size;
        }
        const firstResult = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$mp3$2f$mp3$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readNextFrameHeader"])(input._reader, currentPos, currentPos + 4096);
        if (!firstResult) {
            return false;
        }
        if (id3V2HeaderFound) {
            // If there was an ID3v2 tag at the start, we can be pretty sure this is MP3 by now
            return true;
        }
        currentPos = firstResult.startPos + firstResult.header.totalSize;
        // Fine, we found one frame header, but we're still not entirely sure this is MP3. Let's check if we can find
        // another header right after it:
        const secondResult = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$mp3$2f$mp3$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readNextFrameHeader"])(input._reader, currentPos, currentPos + __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$shared$2f$mp3$2d$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FRAME_HEADER_SIZE"]);
        if (!secondResult) {
            return false;
        }
        const firstHeader = firstResult.header;
        const secondHeader = secondResult.header;
        // In a well-formed MP3 file, we'd expect these two frames to share some similarities:
        if (firstHeader.channel !== secondHeader.channel || firstHeader.sampleRate !== secondHeader.sampleRate) {
            return false;
        }
        // We have found two matching consecutive MP3 frames, a strong indicator that this is an MP3 file
        return true;
    }
    /** @internal */ _createDemuxer(input) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$mp3$2f$mp3$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Mp3Demuxer"](input);
    }
    get name() {
        return 'MP3';
    }
    get mimeType() {
        return 'audio/mpeg';
    }
}
class WaveInputFormat extends InputFormat {
    /** @internal */ async _canReadInput(input) {
        let slice = input._reader.requestSlice(0, 12);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) return false;
        const riffType = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 4);
        if (riffType !== 'RIFF' && riffType !== 'RIFX' && riffType !== 'RF64') {
            return false;
        }
        slice.skip(4);
        const format = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 4);
        return format === 'WAVE';
    }
    /** @internal */ _createDemuxer(input) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$wave$2f$wave$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["WaveDemuxer"](input);
    }
    get name() {
        return 'WAVE';
    }
    get mimeType() {
        return 'audio/wav';
    }
}
class OggInputFormat extends InputFormat {
    /** @internal */ async _canReadInput(input) {
        let slice = input._reader.requestSlice(0, 4);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) return false;
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 4) === 'OggS';
    }
    /** @internal */ _createDemuxer(input) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OggDemuxer"](input);
    }
    get name() {
        return 'Ogg';
    }
    get mimeType() {
        return 'application/ogg';
    }
}
class FlacInputFormat extends InputFormat {
    /** @internal */ async _canReadInput(input) {
        let slice = input._reader.requestSlice(0, 4);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) return false;
        return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readAscii"])(slice, 4) === 'fLaC';
    }
    get name() {
        return 'FLAC';
    }
    get mimeType() {
        return 'audio/flac';
    }
    /** @internal */ _createDemuxer(input) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FlacDemuxer"](input);
    }
}
class AdtsInputFormat extends InputFormat {
    /** @internal */ async _canReadInput(input) {
        let slice = input._reader.requestSliceRange(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_FRAME_HEADER_SIZE"], __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_FRAME_HEADER_SIZE"]);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) return false;
        const firstHeader = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readFrameHeader"])(slice);
        if (!firstHeader) {
            return false;
        }
        slice = input._reader.requestSliceRange(firstHeader.frameLength, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MIN_FRAME_HEADER_SIZE"], __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MAX_FRAME_HEADER_SIZE"]);
        if (slice instanceof Promise) slice = await slice;
        if (!slice) return false;
        const secondHeader = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["readFrameHeader"])(slice);
        if (!secondHeader) {
            return false;
        }
        return firstHeader.objectType === secondHeader.objectType && firstHeader.samplingFrequencyIndex === secondHeader.samplingFrequencyIndex && firstHeader.channelConfiguration === secondHeader.channelConfiguration;
    }
    /** @internal */ _createDemuxer(input) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$demuxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AdtsDemuxer"](input);
    }
    get name() {
        return 'ADTS';
    }
    get mimeType() {
        return 'audio/aac';
    }
}
const MP4 = /* #__PURE__ */ new Mp4InputFormat();
const QTFF = /* #__PURE__ */ new QuickTimeInputFormat();
const MATROSKA = /* #__PURE__ */ new MatroskaInputFormat();
const WEBM = /* #__PURE__ */ new WebMInputFormat();
const MP3 = /* #__PURE__ */ new Mp3InputFormat();
const WAVE = /* #__PURE__ */ new WaveInputFormat();
const OGG = /* #__PURE__ */ new OggInputFormat();
const ADTS = /* #__PURE__ */ new AdtsInputFormat();
const FLAC = /* #__PURE__ */ new FlacInputFormat();
const ALL_FORMATS = [
    MP4,
    QTFF,
    MATROSKA,
    WEBM,
    WAVE,
    OGG,
    FLAC,
    MP3,
    ADTS
];
}),
"[project]/node_modules/mediabunny/dist/modules/src/source.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "BlobSource",
    ()=>BlobSource,
    "BufferSource",
    ()=>BufferSource,
    "FilePathSource",
    ()=>FilePathSource,
    "ReadableStreamSource",
    ()=>ReadableStreamSource,
    "Source",
    ()=>Source,
    "StreamSource",
    ()=>StreamSource,
    "UrlSource",
    ()=>UrlSource
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$node$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/node.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/input.js [app-route] (ecmascript)");
;
;
;
const node = typeof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$node$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ !== 'undefined' ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$node$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ // Aliasing it prevents some bundler warnings
 : undefined;
class Source {
    constructor(){
        /** @internal */ this._disposed = false;
        /** @internal */ this._sizePromise = null;
        /** Called each time data is retrieved from the source. Will be called with the retrieved range (end exclusive). */ this.onread = null;
    }
    /**
     * Resolves with the total size of the file in bytes. This function is memoized, meaning only the first call
     * will retrieve the size.
     *
     * Returns null if the source is unsized.
     */ async getSizeOrNull() {
        if (this._disposed) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
        }
        return this._sizePromise ??= Promise.resolve(this._retrieveSize());
    }
    /**
     * Resolves with the total size of the file in bytes. This function is memoized, meaning only the first call
     * will retrieve the size.
     *
     * Throws an error if the source is unsized.
     */ async getSize() {
        if (this._disposed) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
        }
        const result = await this.getSizeOrNull();
        if (result === null) {
            throw new Error('Cannot determine the size of an unsized source.');
        }
        return result;
    }
}
class BufferSource extends Source {
    /**
     * Creates a new {@link BufferSource} backed by the specified `ArrayBuffer`, `SharedArrayBuffer`,
     * or `ArrayBufferView`.
     */ constructor(buffer){
        if (!(buffer instanceof ArrayBuffer) && !(typeof SharedArrayBuffer !== 'undefined' && buffer instanceof SharedArrayBuffer) && !ArrayBuffer.isView(buffer)) {
            throw new TypeError('buffer must be an ArrayBuffer, SharedArrayBuffer, or ArrayBufferView.');
        }
        super();
        /** @internal */ this._onreadCalled = false;
        this._bytes = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(buffer);
        this._view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(buffer);
    }
    /** @internal */ _retrieveSize() {
        return this._bytes.byteLength;
    }
    /** @internal */ _read() {
        if (!this._onreadCalled) {
            // We just say the first read retrives all bytes from the source (which, I mean, it does)
            this.onread?.(0, this._bytes.byteLength);
            this._onreadCalled = true;
        }
        return {
            bytes: this._bytes,
            view: this._view,
            offset: 0
        };
    }
    /** @internal */ _dispose() {}
}
class BlobSource extends Source {
    /**
     * Creates a new {@link BlobSource} backed by the specified
     * [`Blob`](https://developer.mozilla.org/en-US/docs/Web/API/Blob).
     */ constructor(blob, options = {}){
        if (!(blob instanceof Blob)) {
            throw new TypeError('blob must be a Blob.');
        }
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (options.maxCacheSize !== undefined && (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isNumber"])(options.maxCacheSize) || options.maxCacheSize < 0)) {
            throw new TypeError('options.maxCacheSize, when provided, must be a non-negative number.');
        }
        super();
        /** @internal */ this._readers = new WeakMap();
        this._blob = blob;
        this._orchestrator = new ReadOrchestrator({
            maxCacheSize: options.maxCacheSize ?? 8 * 2 ** 20 /* 8 MiB */ ,
            maxWorkerCount: 4,
            runWorker: this._runWorker.bind(this),
            prefetchProfile: PREFETCH_PROFILES.fileSystem
        });
    }
    /** @internal */ _retrieveSize() {
        const size = this._blob.size;
        this._orchestrator.fileSize = size;
        return size;
    }
    /** @internal */ _read(start, end) {
        return this._orchestrator.read(start, end);
    }
    /** @internal */ async _runWorker(worker) {
        let reader = this._readers.get(worker);
        if (reader === undefined) {
            // https://github.com/Vanilagy/mediabunny/issues/184
            // WebKit has critical bugs with blob.stream():
            // - WebKitBlobResource error 1 when streaming large files
            // - Memory buildup and reload loops on iOS (network process crashes)
            // - ReadableStream stalls under backpressure (especially video)
            // Affects Safari and all iOS browsers (Chrome, Firefox, etc.).
            // Use arrayBuffer() fallback for WebKit browsers.
            if ('stream' in this._blob && !(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isWebKit"])()) {
                // Get a reader of the blob starting at the required offset, and then keep it around
                const slice = this._blob.slice(worker.currentPos);
                reader = slice.stream().getReader();
            } else {
                // We'll need to use more primitive ways
                reader = null;
            }
            this._readers.set(worker, reader);
        }
        while(worker.currentPos < worker.targetPos && !worker.aborted){
            if (reader) {
                const { done, value } = await reader.read();
                if (done) {
                    this._orchestrator.forgetWorker(worker);
                    throw new Error('Blob reader stopped unexpectedly before all requested data was read.');
                }
                if (worker.aborted) {
                    break;
                }
                this.onread?.(worker.currentPos, worker.currentPos + value.length);
                this._orchestrator.supplyWorkerData(worker, value);
            } else {
                const data = await this._blob.slice(worker.currentPos, worker.targetPos).arrayBuffer();
                if (worker.aborted) {
                    break;
                }
                this.onread?.(worker.currentPos, worker.currentPos + data.byteLength);
                this._orchestrator.supplyWorkerData(worker, new Uint8Array(data));
            }
        }
        worker.running = false;
    }
    /** @internal */ _dispose() {
        this._orchestrator.dispose();
    }
}
const URL_SOURCE_MIN_LOAD_AMOUNT = 0.5 * 2 ** 20; // 0.5 MiB
const DEFAULT_RETRY_DELAY = (previousAttempts, error, src)=>{
    // Check if this could be a CORS error. If so, we cannot recover from it and
    // should not attempt to retry.
    // CORS errors are intentionally not opaque, so we need to rely on heuristics.
    const couldBeCorsError = error instanceof Error && (error.message.includes('Failed to fetch') // Chrome
     || error.message.includes('Load failed') // Safari
     || error.message.includes('NetworkError when attempting to fetch resource') // Firefox
    );
    if (couldBeCorsError) {
        let originOfSrc = null;
        // Checking if the origin is different, because only then a CORS error could originate
        try {
            if ("TURBOPACK compile-time falsy", 0) //TURBOPACK unreachable
            ;
        } catch  {
        // URL parse failed
        }
        // If user is offline, it is probably not a CORS error.
        const isOnline = typeof navigator !== 'undefined' && typeof navigator.onLine === 'boolean' ? navigator.onLine : true;
        if (isOnline && originOfSrc !== null && originOfSrc !== window.location.origin) {
            console.warn(`Request will not be retried because a CORS error was suspected due to different origins. You can` + ` modify this behavior by providing your own function for the 'getRetryDelay' option.`);
            return null;
        }
    }
    return Math.min(2 ** (previousAttempts - 2), 16);
};
class UrlSource extends Source {
    /** Creates a new {@link UrlSource} backed by the resource at the specified URL. */ constructor(url, options = {}){
        if (typeof url !== 'string' && !(url instanceof URL) && !(typeof Request !== 'undefined' && url instanceof Request)) {
            throw new TypeError('url must be a string, URL or Request.');
        }
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (options.requestInit !== undefined && (!options.requestInit || typeof options.requestInit !== 'object')) {
            throw new TypeError('options.requestInit, when provided, must be an object.');
        }
        if (options.getRetryDelay !== undefined && typeof options.getRetryDelay !== 'function') {
            throw new TypeError('options.getRetryDelay, when provided, must be a function.');
        }
        if (options.maxCacheSize !== undefined && (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isNumber"])(options.maxCacheSize) || options.maxCacheSize < 0)) {
            throw new TypeError('options.maxCacheSize, when provided, must be a non-negative number.');
        }
        if (options.fetchFn !== undefined && typeof options.fetchFn !== 'function') {
            throw new TypeError('options.fetchFn, when provided, must be a function.');
        // Won't bother validating this function beyond this
        }
        super();
        /** @internal */ this._existingResponses = new WeakMap();
        this._url = url;
        this._options = options;
        this._getRetryDelay = options.getRetryDelay ?? DEFAULT_RETRY_DELAY;
        this._orchestrator = new ReadOrchestrator({
            maxCacheSize: options.maxCacheSize ?? 64 * 2 ** 20 /* 64 MiB */ ,
            // Most files in the real-world have a single sequential access pattern, but having two in parallel can
            // also happen
            maxWorkerCount: 2,
            runWorker: this._runWorker.bind(this),
            prefetchProfile: PREFETCH_PROFILES.network
        });
    }
    /** @internal */ async _retrieveSize() {
        // Retrieving the resource size for UrlSource is optimized: Almost always (= always), the first bytes we have to
        // read are the start of the file. This means it's smart to combine size fetching with fetching the start of the
        // file. We additionally use this step to probe if the server supports range requests, killing three birds with
        // one stone.
        const abortController = new AbortController();
        const response = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["retriedFetch"])(this._options.fetchFn ?? fetch, this._url, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["mergeRequestInit"])(this._options.requestInit ?? {}, {
            headers: {
                // We could also send a non-range request to request the same bytes (all of them), but doing it like
                // this is an easy way to check if the server supports range requests in the first place
                Range: 'bytes=0-'
            },
            signal: abortController.signal
        }), this._getRetryDelay, ()=>this._disposed);
        if (!response.ok) {
            // eslint-disable-next-line @typescript-eslint/no-base-to-string
            throw new Error(`Error fetching ${String(this._url)}: ${response.status} ${response.statusText}`);
        }
        let worker;
        let fileSize;
        if (response.status === 206) {
            fileSize = this._getTotalLengthFromRangeResponse(response);
            worker = this._orchestrator.createWorker(0, Math.min(fileSize, URL_SOURCE_MIN_LOAD_AMOUNT));
        } else {
            // Server probably returned a 200.
            const contentLength = response.headers.get('Content-Length');
            if (contentLength) {
                fileSize = Number(contentLength);
                worker = this._orchestrator.createWorker(0, fileSize);
                this._orchestrator.options.maxCacheSize = Infinity; // 
                console.warn('HTTP server did not respond with 206 Partial Content, meaning the entire remote resource now has' + ' to be downloaded. For efficient media file streaming across a network, please make sure your' + ' server supports range requests.');
            } else {
                throw new Error(`HTTP response (status ${response.status}) must surface Content-Length header.`);
            }
        }
        this._orchestrator.fileSize = fileSize;
        this._existingResponses.set(worker, {
            response,
            abortController
        });
        this._orchestrator.runWorker(worker);
        return fileSize;
    }
    /** @internal */ _read(start, end) {
        return this._orchestrator.read(start, end);
    }
    /** @internal */ async _runWorker(worker) {
        // The outer loop is for resuming a request if it dies mid-response
        while(true){
            const existing = this._existingResponses.get(worker);
            this._existingResponses.delete(worker);
            let abortController = existing?.abortController;
            let response = existing?.response;
            if (!abortController) {
                abortController = new AbortController();
                response = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["retriedFetch"])(this._options.fetchFn ?? fetch, this._url, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["mergeRequestInit"])(this._options.requestInit ?? {}, {
                    headers: {
                        Range: `bytes=${worker.currentPos}-`
                    },
                    signal: abortController.signal
                }), this._getRetryDelay, ()=>this._disposed);
            }
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(response);
            if (!response.ok) {
                // eslint-disable-next-line @typescript-eslint/no-base-to-string
                throw new Error(`Error fetching ${String(this._url)}: ${response.status} ${response.statusText}`);
            }
            if (worker.currentPos > 0 && response.status !== 206) {
                throw new Error('HTTP server did not respond with 206 Partial Content to a range request. To enable efficient media' + ' file streaming across a network, please make sure your server supports range requests.');
            }
            if (!response.body) {
                throw new Error('Missing HTTP response body stream. The used fetch function must provide the response body as a' + ' ReadableStream.');
            }
            const reader = response.body.getReader();
            while(true){
                if (worker.currentPos >= worker.targetPos || worker.aborted) {
                    abortController.abort();
                    worker.running = false;
                    return;
                }
                let readResult;
                try {
                    readResult = await reader.read();
                } catch (error) {
                    if (this._disposed) {
                        // No need to try to retry
                        throw error;
                    }
                    const retryDelayInSeconds = this._getRetryDelay(1, error, this._url);
                    if (retryDelayInSeconds !== null) {
                        console.error('Error while reading response stream. Attempting to resume.', error);
                        await new Promise((resolve)=>setTimeout(resolve, 1000 * retryDelayInSeconds));
                        break;
                    } else {
                        throw error;
                    }
                }
                if (worker.aborted) {
                    break;
                }
                const { done, value } = readResult;
                if (done) {
                    if (worker.currentPos >= worker.targetPos) {
                        // All data was delivered, we're good
                        this._orchestrator.forgetWorker(worker);
                        worker.running = false;
                        return;
                    }
                    break;
                }
                this.onread?.(worker.currentPos, worker.currentPos + value.length);
                this._orchestrator.supplyWorkerData(worker, value);
            }
            if (worker.aborted) {
                break;
            }
        }
        worker.running = false;
    // The previous UrlSource had logic for circumventing https://issues.chromium.org/issues/436025873; I haven't
    // been able to observe this bug with the new UrlSource (maybe because we're using response streaming), so the
    // logic for that has vanished for now. Leaving a comment here if this becomes relevant again.
    }
    /** @internal */ _getTotalLengthFromRangeResponse(response) {
        const contentRange = response.headers.get('Content-Range');
        if (contentRange) {
            const match = /\/(\d+)/.exec(contentRange);
            if (match) {
                return Number(match[1]);
            }
        }
        const contentLength = response.headers.get('Content-Length');
        if (contentLength) {
            return Number(contentLength);
        } else {
            throw new Error('Partial HTTP response (status 206) must surface either Content-Range or' + ' Content-Length header.');
        }
    }
    /** @internal */ _dispose() {
        this._orchestrator.dispose();
    }
}
class FilePathSource extends Source {
    /** Creates a new {@link FilePathSource} backed by the file at the specified file path. */ constructor(filePath, options = {}){
        if (typeof filePath !== 'string') {
            throw new TypeError('filePath must be a string.');
        }
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (options.maxCacheSize !== undefined && (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isNumber"])(options.maxCacheSize) || options.maxCacheSize < 0)) {
            throw new TypeError('options.maxCacheSize, when provided, must be a non-negative number.');
        }
        super();
        /** @internal */ this._fileHandle = null;
        // Let's back this source with a StreamSource, makes the implementation very simple
        this._streamSource = new StreamSource({
            getSize: async ()=>{
                this._fileHandle = await node.fs.open(filePath, 'r');
                const stats = await this._fileHandle.stat();
                return stats.size;
            },
            read: async (start, end)=>{
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._fileHandle);
                const buffer = new Uint8Array(end - start);
                await this._fileHandle.read(buffer, 0, end - start, start);
                return buffer;
            },
            maxCacheSize: options.maxCacheSize,
            prefetchProfile: 'fileSystem'
        });
    }
    /** @internal */ _read(start, end) {
        return this._streamSource._read(start, end);
    }
    /** @internal */ _retrieveSize() {
        return this._streamSource._retrieveSize();
    }
    /** @internal */ _dispose() {
        this._streamSource._dispose();
        void this._fileHandle?.close();
        this._fileHandle = null;
    }
}
class StreamSource extends Source {
    /** Creates a new {@link StreamSource} whose behavior is specified by `options`.  */ constructor(options){
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (typeof options.getSize !== 'function') {
            throw new TypeError('options.getSize must be a function.');
        }
        if (typeof options.read !== 'function') {
            throw new TypeError('options.read must be a function.');
        }
        if (options.dispose !== undefined && typeof options.dispose !== 'function') {
            throw new TypeError('options.dispose, when provided, must be a function.');
        }
        if (options.maxCacheSize !== undefined && (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isNumber"])(options.maxCacheSize) || options.maxCacheSize < 0)) {
            throw new TypeError('options.maxCacheSize, when provided, must be a non-negative number.');
        }
        if (options.prefetchProfile && ![
            'none',
            'fileSystem',
            'network'
        ].includes(options.prefetchProfile)) {
            throw new TypeError('options.prefetchProfile, when provided, must be one of \'none\', \'fileSystem\' or \'network\'.');
        }
        super();
        this._options = options;
        this._orchestrator = new ReadOrchestrator({
            maxCacheSize: options.maxCacheSize ?? 8 * 2 ** 20 /* 8 MiB */ ,
            maxWorkerCount: 2,
            prefetchProfile: PREFETCH_PROFILES[options.prefetchProfile ?? 'none'],
            runWorker: this._runWorker.bind(this)
        });
    }
    /** @internal */ _retrieveSize() {
        const result = this._options.getSize();
        if (result instanceof Promise) {
            return result.then((size)=>{
                if (!Number.isInteger(size) || size < 0) {
                    throw new TypeError('options.getSize must return or resolve to a non-negative integer.');
                }
                this._orchestrator.fileSize = size;
                return size;
            });
        } else {
            if (!Number.isInteger(result) || result < 0) {
                throw new TypeError('options.getSize must return or resolve to a non-negative integer.');
            }
            this._orchestrator.fileSize = result;
            return result;
        }
    }
    /** @internal */ _read(start, end) {
        return this._orchestrator.read(start, end);
    }
    /** @internal */ async _runWorker(worker) {
        while(worker.currentPos < worker.targetPos && !worker.aborted){
            const originalCurrentPos = worker.currentPos;
            const originalTargetPos = worker.targetPos;
            let data = this._options.read(worker.currentPos, originalTargetPos);
            if (data instanceof Promise) data = await data;
            if (worker.aborted) {
                break;
            }
            if (data instanceof Uint8Array) {
                data = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(data); // Normalize things like Node.js Buffer to Uint8Array
                if (data.length !== originalTargetPos - worker.currentPos) {
                    // Yes, we're that strict
                    throw new Error(`options.read returned a Uint8Array with unexpected length: Requested ${originalTargetPos - worker.currentPos} bytes, but got ${data.length}.`);
                }
                this.onread?.(worker.currentPos, worker.currentPos + data.length);
                this._orchestrator.supplyWorkerData(worker, data);
            } else if (data instanceof ReadableStream) {
                const reader = data.getReader();
                while(worker.currentPos < originalTargetPos && !worker.aborted){
                    const { done, value } = await reader.read();
                    if (done) {
                        if (worker.currentPos < originalTargetPos) {
                            // Yes, we're *that* strict
                            throw new Error(`ReadableStream returned by options.read ended before supplying enough data.` + ` Requested ${originalTargetPos - originalCurrentPos} bytes, but got ${worker.currentPos - originalCurrentPos}`);
                        }
                        break;
                    }
                    if (!(value instanceof Uint8Array)) {
                        throw new TypeError('ReadableStream returned by options.read must yield Uint8Array chunks.');
                    }
                    if (worker.aborted) {
                        break;
                    }
                    const data = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toUint8Array"])(value); // Normalize things like Node.js Buffer to Uint8Array
                    this.onread?.(worker.currentPos, worker.currentPos + data.length);
                    this._orchestrator.supplyWorkerData(worker, data);
                }
            } else {
                throw new TypeError('options.read must return or resolve to a Uint8Array or a ReadableStream.');
            }
        }
        worker.running = false;
    }
    /** @internal */ _dispose() {
        this._orchestrator.dispose();
        this._options.dispose?.();
    }
}
class ReadableStreamSource extends Source {
    /** Creates a new {@link ReadableStreamSource} backed by the specified `ReadableStream<Uint8Array>`. */ constructor(stream, options = {}){
        if (!(stream instanceof ReadableStream)) {
            throw new TypeError('stream must be a ReadableStream.');
        }
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (options.maxCacheSize !== undefined && (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isNumber"])(options.maxCacheSize) || options.maxCacheSize < 0)) {
            throw new TypeError('options.maxCacheSize, when provided, must be a non-negative number.');
        }
        super();
        /** @internal */ this._reader = null;
        /** @internal */ this._cache = [];
        /** @internal */ this._pendingSlices = [];
        /** @internal */ this._currentIndex = 0;
        /** @internal */ this._targetIndex = 0;
        /** @internal */ this._maxRequestedIndex = 0;
        /** @internal */ this._endIndex = null;
        /** @internal */ this._pulling = false;
        this._stream = stream;
        this._maxCacheSize = options.maxCacheSize ?? 16 * 2 ** 20 /* 16 MiB */ ;
    }
    /** @internal */ _retrieveSize() {
        return this._endIndex; // Starts out as null, meaning this source is unsized
    }
    /** @internal */ _read(start, end) {
        if (this._endIndex !== null && end > this._endIndex) {
            return null;
        }
        this._maxRequestedIndex = Math.max(this._maxRequestedIndex, end);
        const cacheStartIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["binarySearchLessOrEqual"])(this._cache, start, (x)=>x.start);
        const cacheStartEntry = cacheStartIndex !== -1 ? this._cache[cacheStartIndex] : null;
        if (cacheStartEntry && cacheStartEntry.start <= start && end <= cacheStartEntry.end) {
            // The request can be satisfied with a single cache entry
            return {
                bytes: cacheStartEntry.bytes,
                view: cacheStartEntry.view,
                offset: cacheStartEntry.start
            };
        }
        let lastEnd = start;
        const bytes = new Uint8Array(end - start);
        if (cacheStartIndex !== -1) {
            // Walk over the cache to see if we can satisfy the request using multiple cache entries
            for(let i = cacheStartIndex; i < this._cache.length; i++){
                const cacheEntry = this._cache[i];
                if (cacheEntry.start >= end) {
                    break;
                }
                const cappedStart = Math.max(start, cacheEntry.start);
                if (cappedStart > lastEnd) {
                    // We're too far behind
                    this._throwDueToCacheMiss();
                }
                const cappedEnd = Math.min(end, cacheEntry.end);
                if (cappedStart < cappedEnd) {
                    bytes.set(cacheEntry.bytes.subarray(cappedStart - cacheEntry.start, cappedEnd - cacheEntry.start), cappedStart - start);
                    lastEnd = cappedEnd;
                }
            }
        }
        if (lastEnd === end) {
            return {
                bytes,
                view: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(bytes),
                offset: start
            };
        }
        // We need to pull more data
        if (this._currentIndex > lastEnd) {
            // We're too far behind
            this._throwDueToCacheMiss();
        }
        const { promise, resolve, reject } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])();
        this._pendingSlices.push({
            start,
            end,
            bytes,
            resolve,
            reject
        });
        this._targetIndex = Math.max(this._targetIndex, end);
        // Start pulling from the stream if we're not already doing it
        if (!this._pulling) {
            this._pulling = true;
            void this._pull().catch((error)=>{
                this._pulling = false;
                if (this._pendingSlices.length > 0) {
                    this._pendingSlices.forEach((x)=>x.reject(error)); // Make sure to propagate any errors
                    this._pendingSlices.length = 0;
                } else {
                    throw error; // So it doesn't get swallowed
                }
            });
        }
        return promise;
    }
    /** @internal */ _throwDueToCacheMiss() {
        throw new Error('Read is before the cached region. With ReadableStreamSource, you must access the data more' + ' sequentially or increase the size of its cache.');
    }
    /** @internal */ async _pull() {
        this._reader ??= this._stream.getReader();
        // This is the loop that keeps pulling data from the stream until a target index is reached, filling requests
        // in the process
        while(this._currentIndex < this._targetIndex && !this._disposed){
            const { done, value } = await this._reader.read();
            if (done) {
                for (const pendingSlice of this._pendingSlices){
                    pendingSlice.resolve(null);
                }
                this._pendingSlices.length = 0;
                this._endIndex = this._currentIndex; // We know how long the file is now!
                break;
            }
            const startIndex = this._currentIndex;
            const endIndex = this._currentIndex + value.byteLength;
            // Fill the pending slices with the data
            for(let i = 0; i < this._pendingSlices.length; i++){
                const pendingSlice = this._pendingSlices[i];
                const cappedStart = Math.max(startIndex, pendingSlice.start);
                const cappedEnd = Math.min(endIndex, pendingSlice.end);
                if (cappedStart < cappedEnd) {
                    pendingSlice.bytes.set(value.subarray(cappedStart - startIndex, cappedEnd - startIndex), cappedStart - pendingSlice.start);
                    if (cappedEnd === pendingSlice.end) {
                        // Pending slice fully filled
                        pendingSlice.resolve({
                            bytes: pendingSlice.bytes,
                            view: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(pendingSlice.bytes),
                            offset: pendingSlice.start
                        });
                        this._pendingSlices.splice(i, 1);
                        i--;
                    }
                }
            }
            this._cache.push({
                start: startIndex,
                end: endIndex,
                bytes: value,
                view: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(value),
                age: 0
            });
            // Do cache eviction, based on the distance from the last-requested index. It's important that we do it like
            // this and not based on where the reader is at, because if the reader is fast, we'll unnecessarily evict
            // data that we still might need.
            while(this._cache.length > 0){
                const firstEntry = this._cache[0];
                const distance = this._maxRequestedIndex - firstEntry.end;
                if (distance <= this._maxCacheSize) {
                    break;
                }
                this._cache.shift();
            }
            this._currentIndex += value.byteLength;
        }
        this._pulling = false;
    }
    /** @internal */ _dispose() {
        this._pendingSlices.length = 0;
        this._cache.length = 0;
    }
}
const PREFETCH_PROFILES = {
    none: (start, end)=>({
            start,
            end
        }),
    fileSystem: (start, end)=>{
        const padding = 2 ** 16;
        start = Math.floor((start - padding) / padding) * padding;
        end = Math.ceil((end + padding) / padding) * padding;
        return {
            start,
            end
        };
    },
    network: (start, end, workers)=>{
        // Add a slight bit of start padding because backwards reading is painful
        const paddingStart = 2 ** 16;
        start = Math.max(0, Math.floor((start - paddingStart) / paddingStart) * paddingStart);
        // Remote resources have extreme latency (relatively speaking), so the benefit from intelligent
        // prefetching is great. The network prefetch strategy is as follows: When we notice
        // successive reads to a worker's read region, we prefetch more data at the end of that region,
        // growing exponentially (up to a cap). This performs well for real-world use cases: Either we read a
        // small part of the file once and then never need it again, in which case the requested about of data
        // is small. Or, we're repeatedly doing a sequential access pattern (common in media files), in which
        // case we can become more and more confident to prefetch more and more data.
        for (const worker of workers){
            const maxExtensionAmount = 8 * 2 ** 20; // 8 MiB
            // When the read region cross the threshold point, we trigger a prefetch. This point is typically
            // in the middle of the worker's read region, or a fixed offset from the end if the region has grown
            // really large.
            const thresholdPoint = Math.max((worker.startPos + worker.targetPos) / 2, worker.targetPos - maxExtensionAmount);
            if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["closedIntervalsOverlap"])(start, end, thresholdPoint, worker.targetPos)) {
                const size = worker.targetPos - worker.startPos;
                // If we extend by maxExtensionAmount
                const a = Math.ceil((size + 1) / maxExtensionAmount) * maxExtensionAmount;
                // If we extend to the next power of 2
                const b = 2 ** Math.ceil(Math.log2(size + 1));
                const extent = Math.min(b, a);
                end = Math.max(end, worker.startPos + extent);
            }
        }
        end = Math.max(end, start + URL_SOURCE_MIN_LOAD_AMOUNT);
        return {
            start,
            end
        };
    }
};
/**
 * Godclass for orchestrating complex, cached read operations. The reading model is as follows: Any reading task is
 * delegated to a *worker*, which is a sequential reader positioned somewhere along the file. All workers run in
 * parallel and can be stopped and resumed in their forward movement. When read requests come in, this orchestrator will
 * first try to satisfy the request with only the cached data. If this isn't possible, workers are spun up for all
 * missing parts (or existing workers are repurposed), and these workers will then fill the holes in the data as they
 * march along the file.
 */ class ReadOrchestrator {
    constructor(options){
        this.options = options;
        this.fileSize = null;
        this.nextAge = 0; // Used for LRU eviction of both cache entries and workers
        this.workers = [];
        this.cache = [];
        this.currentCacheSize = 0;
        this.disposed = false;
    }
    read(innerStart, innerEnd) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this.fileSize !== null);
        const prefetchRange = this.options.prefetchProfile(innerStart, innerEnd, this.workers);
        const outerStart = Math.max(prefetchRange.start, 0);
        const outerEnd = Math.min(prefetchRange.end, this.fileSize);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(outerStart <= innerStart && innerEnd <= outerEnd);
        let result = null;
        const innerCacheStartIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["binarySearchLessOrEqual"])(this.cache, innerStart, (x)=>x.start);
        const innerStartEntry = innerCacheStartIndex !== -1 ? this.cache[innerCacheStartIndex] : null;
        // See if the read request can be satisfied by a single cache entry
        if (innerStartEntry && innerStartEntry.start <= innerStart && innerEnd <= innerStartEntry.end) {
            innerStartEntry.age = this.nextAge++;
            result = {
                bytes: innerStartEntry.bytes,
                view: innerStartEntry.view,
                offset: innerStartEntry.start
            };
        // Can't return yet though, still need to check if the prefetch range might lie outside the cached area
        }
        const outerCacheStartIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["binarySearchLessOrEqual"])(this.cache, outerStart, (x)=>x.start);
        const bytes = result ? null : new Uint8Array(innerEnd - innerStart);
        let contiguousBytesWriteEnd = 0; // Used to track if the cache is able to completely cover the bytes
        let lastEnd = outerStart;
        // The "holes" in the cache (the parts we need to load)
        const outerHoles = [];
        // Loop over the cache and build up the list of holes
        if (outerCacheStartIndex !== -1) {
            for(let i = outerCacheStartIndex; i < this.cache.length; i++){
                const entry = this.cache[i];
                if (entry.start >= outerEnd) {
                    break;
                }
                if (entry.end <= outerStart) {
                    continue;
                }
                const cappedOuterStart = Math.max(outerStart, entry.start);
                const cappedOuterEnd = Math.min(outerEnd, entry.end);
                (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(cappedOuterStart <= cappedOuterEnd);
                if (lastEnd < cappedOuterStart) {
                    outerHoles.push({
                        start: lastEnd,
                        end: cappedOuterStart
                    });
                }
                lastEnd = cappedOuterEnd;
                if (bytes) {
                    const cappedInnerStart = Math.max(innerStart, entry.start);
                    const cappedInnerEnd = Math.min(innerEnd, entry.end);
                    if (cappedInnerStart < cappedInnerEnd) {
                        const relativeOffset = cappedInnerStart - innerStart;
                        // Fill the relevant section of the bytes with the cached data
                        bytes.set(entry.bytes.subarray(cappedInnerStart - entry.start, cappedInnerEnd - entry.start), relativeOffset);
                        if (relativeOffset === contiguousBytesWriteEnd) {
                            contiguousBytesWriteEnd = cappedInnerEnd - innerStart;
                        }
                    }
                }
                entry.age = this.nextAge++;
            }
            if (lastEnd < outerEnd) {
                outerHoles.push({
                    start: lastEnd,
                    end: outerEnd
                });
            }
        } else {
            outerHoles.push({
                start: outerStart,
                end: outerEnd
            });
        }
        if (bytes && contiguousBytesWriteEnd >= bytes.length) {
            // Multiple cache entries were able to completely cover the requested bytes!
            result = {
                bytes,
                view: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(bytes),
                offset: innerStart
            };
        }
        if (outerHoles.length === 0) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(result);
            return result;
        }
        // We need to read more data, so now we're in async land
        const { promise, resolve, reject } = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["promiseWithResolvers"])();
        const innerHoles = [];
        for (const outerHole of outerHoles){
            const cappedStart = Math.max(innerStart, outerHole.start);
            const cappedEnd = Math.min(innerEnd, outerHole.end);
            if (cappedStart === outerHole.start && cappedEnd === outerHole.end) {
                innerHoles.push(outerHole); // Can reuse without allocating a new object
            } else if (cappedStart < cappedEnd) {
                innerHoles.push({
                    start: cappedStart,
                    end: cappedEnd
                });
            }
        }
        // Fire off workers to take care of patching the holes
        for (const outerHole of outerHoles){
            const pendingSlice = bytes && {
                start: innerStart,
                bytes,
                holes: innerHoles,
                resolve,
                reject
            };
            let workerFound = false;
            for (const worker of this.workers){
                // A small tolerance in the case that the requested region is *just* after the target position of an
                // existing worker. In that case, it's probably more efficient to repurpose that worker than to spawn
                // another one so close to it
                const gapTolerance = 2 ** 17;
                // This check also implies worker.currentPos <= outerHole.start, a critical condition
                if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["closedIntervalsOverlap"])(outerHole.start - gapTolerance, outerHole.start, worker.currentPos, worker.targetPos)) {
                    worker.targetPos = Math.max(worker.targetPos, outerHole.end); // Update the worker's target position
                    workerFound = true;
                    if (pendingSlice && !worker.pendingSlices.includes(pendingSlice)) {
                        worker.pendingSlices.push(pendingSlice);
                    }
                    if (!worker.running) {
                        // Kick it off if it's idle
                        this.runWorker(worker);
                    }
                    break;
                }
            }
            if (!workerFound) {
                // We need to spawn a new worker
                const newWorker = this.createWorker(outerHole.start, outerHole.end);
                if (pendingSlice) {
                    newWorker.pendingSlices = [
                        pendingSlice
                    ];
                }
                this.runWorker(newWorker);
            }
        }
        if (!result) {
            (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(bytes);
            result = promise.then((bytes)=>({
                    bytes,
                    view: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(bytes),
                    offset: innerStart
                }));
        } else {
        // The requested region was satisfied by the cache, but the entire prefetch region was not
        }
        return result;
    }
    createWorker(startPos, targetPos) {
        const worker = {
            startPos,
            currentPos: startPos,
            targetPos,
            running: false,
            // Due to async shenanigans, it can happen that workers are started after disposal. In this case, instead of
            // simply not creating the worker, we allow it to run but immediately label it as aborted, so it can then
            // shut itself down.
            aborted: this.disposed,
            pendingSlices: [],
            age: this.nextAge++
        };
        this.workers.push(worker);
        // LRU eviction of the other workers
        while(this.workers.length > this.options.maxWorkerCount){
            let oldestIndex = 0;
            let oldestWorker = this.workers[0];
            for(let i = 1; i < this.workers.length; i++){
                const worker = this.workers[i];
                if (worker.age < oldestWorker.age) {
                    oldestIndex = i;
                    oldestWorker = worker;
                }
            }
            if (oldestWorker.running && oldestWorker.pendingSlices.length > 0) {
                break;
            }
            oldestWorker.aborted = true;
            this.workers.splice(oldestIndex, 1);
        }
        return worker;
    }
    runWorker(worker) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(!worker.running);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(worker.currentPos < worker.targetPos);
        worker.running = true;
        worker.age = this.nextAge++;
        void this.options.runWorker(worker).catch((error)=>{
            worker.running = false;
            if (worker.pendingSlices.length > 0) {
                worker.pendingSlices.forEach((x)=>x.reject(error)); // Make sure to propagate any errors
                worker.pendingSlices.length = 0;
            } else {
                throw error; // So it doesn't get swallowed
            }
        });
    }
    /** Called by a worker when it has read some data. */ supplyWorkerData(worker, bytes) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(!worker.aborted);
        const start = worker.currentPos;
        const end = start + bytes.length;
        this.insertIntoCache({
            start,
            end,
            bytes,
            view: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(bytes),
            age: this.nextAge++
        });
        worker.currentPos += bytes.length;
        worker.targetPos = Math.max(worker.targetPos, worker.currentPos); // In case it overshoots
        // Now, let's see if we can use the read bytes to fill any pending slice
        for(let i = 0; i < worker.pendingSlices.length; i++){
            const pendingSlice = worker.pendingSlices[i];
            const clampedStart = Math.max(start, pendingSlice.start);
            const clampedEnd = Math.min(end, pendingSlice.start + pendingSlice.bytes.length);
            if (clampedStart < clampedEnd) {
                pendingSlice.bytes.set(bytes.subarray(clampedStart - start, clampedEnd - start), clampedStart - pendingSlice.start);
            }
            for(let j = 0; j < pendingSlice.holes.length; j++){
                // The hole is intentionally not modified here if the read section starts somewhere in the middle of
                // the hole. We don't need to do "hole splitting", since the workers are spawned *by* the holes,
                // meaning there's always a worker which will consume the hole left to right.
                const hole = pendingSlice.holes[j];
                if (start <= hole.start && end > hole.start) {
                    hole.start = end;
                }
                if (hole.end <= hole.start) {
                    pendingSlice.holes.splice(j, 1);
                    j--;
                }
            }
            if (pendingSlice.holes.length === 0) {
                // The slice has been fulfilled, everything has been read. Let's resolve the promise
                pendingSlice.resolve(pendingSlice.bytes);
                worker.pendingSlices.splice(i, 1);
                i--;
            }
        }
        // Remove other idle workers if we "ate" into their territory
        for(let i = 0; i < this.workers.length; i++){
            const otherWorker = this.workers[i];
            if (worker === otherWorker || otherWorker.running) {
                continue;
            }
            if ((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["closedIntervalsOverlap"])(start, end, otherWorker.currentPos, otherWorker.targetPos)) {
                this.workers.splice(i, 1);
                i--;
            }
        }
    }
    forgetWorker(worker) {
        const index = this.workers.indexOf(worker);
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(index !== -1);
        this.workers.splice(index, 1);
    }
    insertIntoCache(entry) {
        if (this.options.maxCacheSize === 0) {
            return; // No caching
        }
        let insertionIndex = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["binarySearchLessOrEqual"])(this.cache, entry.start, (x)=>x.start) + 1;
        if (insertionIndex > 0) {
            const previous = this.cache[insertionIndex - 1];
            if (previous.end >= entry.end) {
                // Previous entry swallows the one to be inserted; we don't need to do anything
                return;
            }
            if (previous.end > entry.start) {
                // Partial overlap with the previous entry, let's join
                const joined = new Uint8Array(entry.end - previous.start);
                joined.set(previous.bytes, 0);
                joined.set(entry.bytes, entry.start - previous.start);
                this.currentCacheSize += entry.end - previous.end;
                previous.bytes = joined;
                previous.view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(joined);
                previous.end = entry.end;
                // Do the rest of the logic with the previous entry instead
                insertionIndex--;
                entry = previous;
            } else {
                this.cache.splice(insertionIndex, 0, entry);
                this.currentCacheSize += entry.bytes.length;
            }
        } else {
            this.cache.splice(insertionIndex, 0, entry);
            this.currentCacheSize += entry.bytes.length;
        }
        for(let i = insertionIndex + 1; i < this.cache.length; i++){
            const next = this.cache[i];
            if (entry.end <= next.start) {
                break;
            }
            if (entry.end >= next.end) {
                // The inserted entry completely swallows the next entry
                this.cache.splice(i, 1);
                this.currentCacheSize -= next.bytes.length;
                i--;
                continue;
            }
            // Partial overlap, let's join
            const joined = new Uint8Array(next.end - entry.start);
            joined.set(entry.bytes, 0);
            joined.set(next.bytes, next.start - entry.start);
            this.currentCacheSize -= entry.end - next.start; // Subtract the overlap
            entry.bytes = joined;
            entry.view = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(joined);
            entry.end = next.end;
            this.cache.splice(i, 1);
            break; // After the join case, we're done: the next entry cannot possibly overlap with the inserted one.
        }
        // LRU eviction of cache entries
        while(this.currentCacheSize > this.options.maxCacheSize){
            let oldestIndex = 0;
            let oldestEntry = this.cache[0];
            for(let i = 1; i < this.cache.length; i++){
                const entry = this.cache[i];
                if (entry.age < oldestEntry.age) {
                    oldestIndex = i;
                    oldestEntry = entry;
                }
            }
            if (this.currentCacheSize - oldestEntry.bytes.length <= this.options.maxCacheSize) {
                break;
            }
            this.cache.splice(oldestIndex, 1);
            this.currentCacheSize -= oldestEntry.bytes.length;
        }
    }
    dispose() {
        for (const worker of this.workers){
            worker.aborted = true;
        }
        this.workers.length = 0;
        this.cache.length = 0;
        this.disposed = true;
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/input.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "Input",
    ()=>Input,
    "InputDisposedError",
    ()=>InputDisposedError
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$format$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/input-format.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$source$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/source.js [app-route] (ecmascript)");
;
;
;
;
(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["polyfillSymbolDispose"])();
class Input {
    /** True if the input has been disposed. */ get disposed() {
        return this._disposed;
    }
    /**
     * Creates a new input file from the specified options. No reading operations will be performed until methods are
     * called on this instance.
     */ constructor(options){
        /** @internal */ this._demuxerPromise = null;
        /** @internal */ this._format = null;
        /** @internal */ this._disposed = false;
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (!Array.isArray(options.formats) || options.formats.some((x)=>!(x instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2d$format$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputFormat"]))) {
            throw new TypeError('options.formats must be an array of InputFormat.');
        }
        if (!(options.source instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$source$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Source"])) {
            throw new TypeError('options.source must be a Source.');
        }
        if (options.source._disposed) {
            throw new Error('options.source must not be disposed.');
        }
        this._formats = options.formats;
        this._source = options.source;
        this._reader = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$reader$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Reader"](options.source);
    }
    /** @internal */ _getDemuxer() {
        return this._demuxerPromise ??= (async ()=>{
            this._reader.fileSize = await this._source.getSizeOrNull();
            for (const format of this._formats){
                const canRead = await format._canReadInput(this);
                if (canRead) {
                    this._format = format;
                    return format._createDemuxer(this);
                }
            }
            throw new Error('Input has an unsupported or unrecognizable format.');
        })();
    }
    /**
     * Returns the source from which this input file reads its data. This is the same source that was passed to the
     * constructor.
     */ get source() {
        return this._source;
    }
    /**
     * Returns the format of the input file. You can compare this result directly to the {@link InputFormat} singletons
     * or use `instanceof` checks for subset-aware logic (for example, `format instanceof MatroskaInputFormat` is true
     * for both MKV and WebM).
     */ async getFormat() {
        await this._getDemuxer();
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(this._format);
        return this._format;
    }
    /**
     * Computes the duration of the input file, in seconds. More precisely, returns the largest end timestamp among
     * all tracks.
     */ async computeDuration() {
        const demuxer = await this._getDemuxer();
        return demuxer.computeDuration();
    }
    /** Returns the list of all tracks of this input file. */ async getTracks() {
        const demuxer = await this._getDemuxer();
        return demuxer.getTracks();
    }
    /** Returns the list of all video tracks of this input file. */ async getVideoTracks() {
        const tracks = await this.getTracks();
        return tracks.filter((x)=>x.isVideoTrack());
    }
    /** Returns the list of all audio tracks of this input file. */ async getAudioTracks() {
        const tracks = await this.getTracks();
        return tracks.filter((x)=>x.isAudioTrack());
    }
    /** Returns the primary video track of this input file, or null if there are no video tracks. */ async getPrimaryVideoTrack() {
        const tracks = await this.getTracks();
        return tracks.find((x)=>x.isVideoTrack()) ?? null;
    }
    /** Returns the primary audio track of this input file, or null if there are no audio tracks. */ async getPrimaryAudioTrack() {
        const tracks = await this.getTracks();
        return tracks.find((x)=>x.isAudioTrack()) ?? null;
    }
    /** Returns the full MIME type of this input file, including track codecs. */ async getMimeType() {
        const demuxer = await this._getDemuxer();
        return demuxer.getMimeType();
    }
    /**
     * Returns descriptive metadata tags about the media file, such as title, author, date, cover art, or other
     * attached files.
     */ async getMetadataTags() {
        const demuxer = await this._getDemuxer();
        return demuxer.getMetadataTags();
    }
    /**
     * Disposes this input and frees connected resources. When an input is disposed, ongoing read operations will be
     * canceled, all future read operations will fail, any open decoders will be closed, and all ongoing media sink
     * operations will be canceled. Disallowed and canceled operations will throw an {@link InputDisposedError}.
     *
     * You are expected not to use an input after disposing it. While some operations may still work, it is not
     * specified and may change in any future update.
     */ dispose() {
        if (this._disposed) {
            return;
        }
        this._disposed = true;
        this._source._disposed = true;
        this._source._dispose();
    }
    /**
     * Calls `.dispose()` on the input, implementing the `Disposable` interface for use with
     * JavaScript Explicit Resource Management features.
     */ [Symbol.dispose]() {
        this.dispose();
    }
}
class InputDisposedError extends Error {
    /** Creates a new {@link InputDisposedError}. */ constructor(message = 'Input has been disposed.'){
        super(message);
        this.name = 'InputDisposedError';
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/reader.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "FileSlice",
    ()=>FileSlice,
    "Reader",
    ()=>Reader,
    "readAscii",
    ()=>readAscii,
    "readBytes",
    ()=>readBytes,
    "readF32Be",
    ()=>readF32Be,
    "readF64Be",
    ()=>readF64Be,
    "readI16Be",
    ()=>readI16Be,
    "readI32Be",
    ()=>readI32Be,
    "readI32Le",
    ()=>readI32Le,
    "readI64Be",
    ()=>readI64Be,
    "readI64Le",
    ()=>readI64Le,
    "readU16",
    ()=>readU16,
    "readU16Be",
    ()=>readU16Be,
    "readU24Be",
    ()=>readU24Be,
    "readU32",
    ()=>readU32,
    "readU32Be",
    ()=>readU32Be,
    "readU32Le",
    ()=>readU32Le,
    "readU64",
    ()=>readU64,
    "readU64Be",
    ()=>readU64Be,
    "readU8",
    ()=>readU8
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/input.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
;
;
class Reader {
    constructor(source){
        this.source = source;
    }
    requestSlice(start, length) {
        if (this.source._disposed) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
        }
        if (this.fileSize !== null && start + length > this.fileSize) {
            return null;
        }
        const end = start + length;
        const result = this.source._read(start, end);
        if (result instanceof Promise) {
            return result.then((x)=>{
                if (!x) {
                    return null;
                }
                return new FileSlice(x.bytes, x.view, x.offset, start, end);
            });
        } else {
            if (!result) {
                return null;
            }
            return new FileSlice(result.bytes, result.view, result.offset, start, end);
        }
    }
    requestSliceRange(start, minLength, maxLength) {
        if (this.source._disposed) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$input$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InputDisposedError"]();
        }
        if (this.fileSize !== null) {
            return this.requestSlice(start, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])(this.fileSize - start, minLength, maxLength));
        } else {
            const promisedAttempt = this.requestSlice(start, maxLength);
            const handleAttempt = (attempt)=>{
                if (attempt) {
                    return attempt;
                }
                const handleFileSize = (fileSize)=>{
                    (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["assert"])(fileSize !== null); // The slice couldn't fit, meaning we must know the file size now
                    return this.requestSlice(start, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["clamp"])(fileSize - start, minLength, maxLength));
                };
                const promisedFileSize = this.source._retrieveSize();
                if (promisedFileSize instanceof Promise) {
                    return promisedFileSize.then(handleFileSize);
                } else {
                    return handleFileSize(promisedFileSize);
                }
            };
            if (promisedAttempt instanceof Promise) {
                return promisedAttempt.then(handleAttempt);
            } else {
                return handleAttempt(promisedAttempt);
            }
        }
    }
}
class FileSlice {
    constructor(/** The underlying bytes backing this slice. Avoid using this directly and prefer reader functions instead. */ bytes, /** A view into the bytes backing this slice. Avoid using this directly and prefer reader functions instead. */ view, /** The offset in "file bytes" at which `bytes` begins in the file. */ offset, /** The offset in "file bytes" where this slice begins. */ start, /** The offset in "file bytes" where this slice ends (exclusive). */ end){
        this.bytes = bytes;
        this.view = view;
        this.offset = offset;
        this.start = start;
        this.end = end;
        this.bufferPos = start - offset;
    }
    static tempFromBytes(bytes) {
        return new FileSlice(bytes, (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toDataView"])(bytes), 0, 0, bytes.length);
    }
    get length() {
        return this.end - this.start;
    }
    get filePos() {
        return this.offset + this.bufferPos;
    }
    set filePos(value) {
        this.bufferPos = value - this.offset;
    }
    /** The number of bytes left from the current pos to the end of the slice. */ get remainingLength() {
        return Math.max(this.end - this.filePos, 0);
    }
    skip(byteCount) {
        this.bufferPos += byteCount;
    }
    /** Creates a new subslice of this slice whose byte range must be contained within this slice. */ slice(filePos, length = this.end - filePos) {
        if (filePos < this.start || filePos + length > this.end) {
            throw new RangeError('Slicing outside of original slice.');
        }
        return new FileSlice(this.bytes, this.view, this.offset, filePos, filePos + length);
    }
}
const checkIsInRange = (slice, bytesToRead)=>{
    if (slice.filePos < slice.start || slice.filePos + bytesToRead > slice.end) {
        throw new RangeError(`Tried reading [${slice.filePos}, ${slice.filePos + bytesToRead}), but slice is` + ` [${slice.start}, ${slice.end}). This is likely an internal error, please report it alongside the file` + ` that caused it.`);
    }
};
const readBytes = (slice, length)=>{
    checkIsInRange(slice, length);
    const bytes = slice.bytes.subarray(slice.bufferPos, slice.bufferPos + length);
    slice.bufferPos += length;
    return bytes;
};
const readU8 = (slice)=>{
    checkIsInRange(slice, 1);
    return slice.view.getUint8(slice.bufferPos++);
};
const readU16 = (slice, littleEndian)=>{
    checkIsInRange(slice, 2);
    const value = slice.view.getUint16(slice.bufferPos, littleEndian);
    slice.bufferPos += 2;
    return value;
};
const readU16Be = (slice)=>{
    checkIsInRange(slice, 2);
    const value = slice.view.getUint16(slice.bufferPos, false);
    slice.bufferPos += 2;
    return value;
};
const readU24Be = (slice)=>{
    checkIsInRange(slice, 3);
    const value = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getUint24"])(slice.view, slice.bufferPos, false);
    slice.bufferPos += 3;
    return value;
};
const readI16Be = (slice)=>{
    checkIsInRange(slice, 2);
    const value = slice.view.getInt16(slice.bufferPos, false);
    slice.bufferPos += 2;
    return value;
};
const readU32 = (slice, littleEndian)=>{
    checkIsInRange(slice, 4);
    const value = slice.view.getUint32(slice.bufferPos, littleEndian);
    slice.bufferPos += 4;
    return value;
};
const readU32Be = (slice)=>{
    checkIsInRange(slice, 4);
    const value = slice.view.getUint32(slice.bufferPos, false);
    slice.bufferPos += 4;
    return value;
};
const readU32Le = (slice)=>{
    checkIsInRange(slice, 4);
    const value = slice.view.getUint32(slice.bufferPos, true);
    slice.bufferPos += 4;
    return value;
};
const readI32Be = (slice)=>{
    checkIsInRange(slice, 4);
    const value = slice.view.getInt32(slice.bufferPos, false);
    slice.bufferPos += 4;
    return value;
};
const readI32Le = (slice)=>{
    checkIsInRange(slice, 4);
    const value = slice.view.getInt32(slice.bufferPos, true);
    slice.bufferPos += 4;
    return value;
};
const readU64 = (slice, littleEndian)=>{
    let low;
    let high;
    if (littleEndian) {
        low = readU32(slice, true);
        high = readU32(slice, true);
    } else {
        high = readU32(slice, false);
        low = readU32(slice, false);
    }
    return high * 0x100000000 + low;
};
const readU64Be = (slice)=>{
    const high = readU32Be(slice);
    const low = readU32Be(slice);
    return high * 0x100000000 + low;
};
const readI64Be = (slice)=>{
    const high = readI32Be(slice);
    const low = readU32Be(slice);
    return high * 0x100000000 + low;
};
const readI64Le = (slice)=>{
    const low = readU32Le(slice);
    const high = readI32Le(slice);
    return high * 0x100000000 + low;
};
const readF32Be = (slice)=>{
    checkIsInRange(slice, 4);
    const value = slice.view.getFloat32(slice.bufferPos, false);
    slice.bufferPos += 4;
    return value;
};
const readF64Be = (slice)=>{
    checkIsInRange(slice, 8);
    const value = slice.view.getFloat64(slice.bufferPos, false);
    slice.bufferPos += 8;
    return value;
};
const readAscii = (slice, length)=>{
    checkIsInRange(slice, length);
    let str = '';
    for(let i = 0; i < length; i++){
        str += String.fromCharCode(slice.bytes[slice.bufferPos++]);
    }
    return str;
};
}),
"[project]/node_modules/mediabunny/dist/modules/src/output-format.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "AdtsOutputFormat",
    ()=>AdtsOutputFormat,
    "FlacOutputFormat",
    ()=>FlacOutputFormat,
    "IsobmffOutputFormat",
    ()=>IsobmffOutputFormat,
    "MkvOutputFormat",
    ()=>MkvOutputFormat,
    "MovOutputFormat",
    ()=>MovOutputFormat,
    "Mp3OutputFormat",
    ()=>Mp3OutputFormat,
    "Mp4OutputFormat",
    ()=>Mp4OutputFormat,
    "OggOutputFormat",
    ()=>OggOutputFormat,
    "OutputFormat",
    ()=>OutputFormat,
    "WavOutputFormat",
    ()=>WavOutputFormat,
    "WebMOutputFormat",
    ()=>WebMOutputFormat
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/adts/adts-muxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/codec.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/flac/flac-muxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$isobmff$2f$isobmff$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/isobmff/isobmff-muxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$matroska$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/matroska/matroska-muxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$mp3$2f$mp3$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/mp3/mp3-muxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/ogg/ogg-muxer.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$wave$2f$wave$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/wave/wave-muxer.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
class OutputFormat {
    /** Returns a list of video codecs that this output format can contain. */ getSupportedVideoCodecs() {
        return this.getSupportedCodecs().filter((codec)=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"].includes(codec));
    }
    /** Returns a list of audio codecs that this output format can contain. */ getSupportedAudioCodecs() {
        return this.getSupportedCodecs().filter((codec)=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AUDIO_CODECS"].includes(codec));
    }
    /** Returns a list of subtitle codecs that this output format can contain. */ getSupportedSubtitleCodecs() {
        return this.getSupportedCodecs().filter((codec)=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SUBTITLE_CODECS"].includes(codec));
    }
    /** @internal */ // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _codecUnsupportedHint(codec) {
        return '';
    }
}
class IsobmffOutputFormat extends OutputFormat {
    /** Internal constructor. */ constructor(options = {}){
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (options.fastStart !== undefined && ![
            false,
            'in-memory',
            'reserve',
            'fragmented'
        ].includes(options.fastStart)) {
            throw new TypeError('options.fastStart, when provided, must be false, \'in-memory\', \'reserve\', or \'fragmented\'.');
        }
        if (options.minimumFragmentDuration !== undefined && (!Number.isFinite(options.minimumFragmentDuration) || options.minimumFragmentDuration < 0)) {
            throw new TypeError('options.minimumFragmentDuration, when provided, must be a non-negative number.');
        }
        if (options.onFtyp !== undefined && typeof options.onFtyp !== 'function') {
            throw new TypeError('options.onFtyp, when provided, must be a function.');
        }
        if (options.onMoov !== undefined && typeof options.onMoov !== 'function') {
            throw new TypeError('options.onMoov, when provided, must be a function.');
        }
        if (options.onMdat !== undefined && typeof options.onMdat !== 'function') {
            throw new TypeError('options.onMdat, when provided, must be a function.');
        }
        if (options.onMoof !== undefined && typeof options.onMoof !== 'function') {
            throw new TypeError('options.onMoof, when provided, must be a function.');
        }
        if (options.metadataFormat !== undefined && ![
            'mdir',
            'mdta',
            'udta',
            'auto'
        ].includes(options.metadataFormat)) {
            throw new TypeError('options.metadataFormat, when provided, must be either \'auto\', \'mdir\', \'mdta\', or \'udta\'.');
        }
        super();
        this._options = options;
    }
    getSupportedTrackCounts() {
        return {
            video: {
                min: 0,
                max: Infinity
            },
            audio: {
                min: 0,
                max: Infinity
            },
            subtitle: {
                min: 0,
                max: Infinity
            },
            total: {
                min: 1,
                max: 2 ** 32 - 1
            }
        };
    }
    get supportsVideoRotationMetadata() {
        return true;
    }
    /** @internal */ _createMuxer(output) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$isobmff$2f$isobmff$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["IsobmffMuxer"](output, this);
    }
}
class Mp4OutputFormat extends IsobmffOutputFormat {
    /** Creates a new {@link Mp4OutputFormat} configured with the specified `options`. */ constructor(options){
        super(options);
    }
    /** @internal */ get _name() {
        return 'MP4';
    }
    get fileExtension() {
        return '.mp4';
    }
    get mimeType() {
        return 'video/mp4';
    }
    getSupportedCodecs() {
        return [
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"],
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NON_PCM_AUDIO_CODECS"],
            // These are supported via ISO/IEC 23003-5
            'pcm-s16',
            'pcm-s16be',
            'pcm-s24',
            'pcm-s24be',
            'pcm-s32',
            'pcm-s32be',
            'pcm-f32',
            'pcm-f32be',
            'pcm-f64',
            'pcm-f64be',
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SUBTITLE_CODECS"]
        ];
    }
    /** @internal */ _codecUnsupportedHint(codec) {
        if (new MovOutputFormat().getSupportedCodecs().includes(codec)) {
            return ' Switching to MOV will grant support for this codec.';
        }
        return '';
    }
}
class MovOutputFormat extends IsobmffOutputFormat {
    /** Creates a new {@link MovOutputFormat} configured with the specified `options`. */ constructor(options){
        super(options);
    }
    /** @internal */ get _name() {
        return 'MOV';
    }
    get fileExtension() {
        return '.mov';
    }
    get mimeType() {
        return 'video/quicktime';
    }
    getSupportedCodecs() {
        return [
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"],
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AUDIO_CODECS"]
        ];
    }
    /** @internal */ _codecUnsupportedHint(codec) {
        if (new Mp4OutputFormat().getSupportedCodecs().includes(codec)) {
            return ' Switching to MP4 will grant support for this codec.';
        }
        return '';
    }
}
class MkvOutputFormat extends OutputFormat {
    /** Creates a new {@link MkvOutputFormat} configured with the specified `options`. */ constructor(options = {}){
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (options.appendOnly !== undefined && typeof options.appendOnly !== 'boolean') {
            throw new TypeError('options.appendOnly, when provided, must be a boolean.');
        }
        if (options.minimumClusterDuration !== undefined && (!Number.isFinite(options.minimumClusterDuration) || options.minimumClusterDuration < 0)) {
            throw new TypeError('options.minimumClusterDuration, when provided, must be a non-negative number.');
        }
        if (options.onEbmlHeader !== undefined && typeof options.onEbmlHeader !== 'function') {
            throw new TypeError('options.onEbmlHeader, when provided, must be a function.');
        }
        if (options.onSegmentHeader !== undefined && typeof options.onSegmentHeader !== 'function') {
            throw new TypeError('options.onHeader, when provided, must be a function.');
        }
        if (options.onCluster !== undefined && typeof options.onCluster !== 'function') {
            throw new TypeError('options.onCluster, when provided, must be a function.');
        }
        super();
        this._options = options;
    }
    /** @internal */ _createMuxer(output) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$matroska$2f$matroska$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["MatroskaMuxer"](output, this);
    }
    /** @internal */ get _name() {
        return 'Matroska';
    }
    getSupportedTrackCounts() {
        return {
            video: {
                min: 0,
                max: Infinity
            },
            audio: {
                min: 0,
                max: Infinity
            },
            subtitle: {
                min: 0,
                max: Infinity
            },
            total: {
                min: 1,
                max: 127
            }
        };
    }
    get fileExtension() {
        return '.mkv';
    }
    get mimeType() {
        return 'video/x-matroska';
    }
    getSupportedCodecs() {
        return [
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"],
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NON_PCM_AUDIO_CODECS"],
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PCM_AUDIO_CODECS"].filter((codec)=>![
                    'pcm-s8',
                    'pcm-f32be',
                    'pcm-f64be',
                    'ulaw',
                    'alaw'
                ].includes(codec)),
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SUBTITLE_CODECS"]
        ];
    }
    get supportsVideoRotationMetadata() {
        // While it technically does support it with ProjectionPoseRoll, many players appear to ignore this value
        return false;
    }
}
class WebMOutputFormat extends MkvOutputFormat {
    /** Creates a new {@link WebMOutputFormat} configured with the specified `options`. */ constructor(options){
        super(options);
    }
    getSupportedCodecs() {
        return [
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VIDEO_CODECS"].filter((codec)=>[
                    'vp8',
                    'vp9',
                    'av1'
                ].includes(codec)),
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AUDIO_CODECS"].filter((codec)=>[
                    'opus',
                    'vorbis'
                ].includes(codec)),
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SUBTITLE_CODECS"]
        ];
    }
    /** @internal */ get _name() {
        return 'WebM';
    }
    get fileExtension() {
        return '.webm';
    }
    get mimeType() {
        return 'video/webm';
    }
    /** @internal */ _codecUnsupportedHint(codec) {
        if (new MkvOutputFormat().getSupportedCodecs().includes(codec)) {
            return ' Switching to MKV will grant support for this codec.';
        }
        return '';
    }
}
class Mp3OutputFormat extends OutputFormat {
    /** Creates a new {@link Mp3OutputFormat} configured with the specified `options`. */ constructor(options = {}){
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (options.xingHeader !== undefined && typeof options.xingHeader !== 'boolean') {
            throw new TypeError('options.xingHeader, when provided, must be a boolean.');
        }
        if (options.onXingFrame !== undefined && typeof options.onXingFrame !== 'function') {
            throw new TypeError('options.onXingFrame, when provided, must be a function.');
        }
        super();
        this._options = options;
    }
    /** @internal */ _createMuxer(output) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$mp3$2f$mp3$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Mp3Muxer"](output, this);
    }
    /** @internal */ get _name() {
        return 'MP3';
    }
    getSupportedTrackCounts() {
        return {
            video: {
                min: 0,
                max: 0
            },
            audio: {
                min: 1,
                max: 1
            },
            subtitle: {
                min: 0,
                max: 0
            },
            total: {
                min: 1,
                max: 1
            }
        };
    }
    get fileExtension() {
        return '.mp3';
    }
    get mimeType() {
        return 'audio/mpeg';
    }
    getSupportedCodecs() {
        return [
            'mp3'
        ];
    }
    get supportsVideoRotationMetadata() {
        return false;
    }
}
class WavOutputFormat extends OutputFormat {
    /** Creates a new {@link WavOutputFormat} configured with the specified `options`. */ constructor(options = {}){
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (options.large !== undefined && typeof options.large !== 'boolean') {
            throw new TypeError('options.large, when provided, must be a boolean.');
        }
        if (options.metadataFormat !== undefined && ![
            'info',
            'id3'
        ].includes(options.metadataFormat)) {
            throw new TypeError('options.metadataFormat, when provided, must be either \'info\' or \'id3\'.');
        }
        if (options.onHeader !== undefined && typeof options.onHeader !== 'function') {
            throw new TypeError('options.onHeader, when provided, must be a function.');
        }
        super();
        this._options = options;
    }
    /** @internal */ _createMuxer(output) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$wave$2f$wave$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["WaveMuxer"](output, this);
    }
    /** @internal */ get _name() {
        return 'WAVE';
    }
    getSupportedTrackCounts() {
        return {
            video: {
                min: 0,
                max: 0
            },
            audio: {
                min: 1,
                max: 1
            },
            subtitle: {
                min: 0,
                max: 0
            },
            total: {
                min: 1,
                max: 1
            }
        };
    }
    get fileExtension() {
        return '.wav';
    }
    get mimeType() {
        return 'audio/wav';
    }
    getSupportedCodecs() {
        return [
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PCM_AUDIO_CODECS"].filter((codec)=>[
                    'pcm-s16',
                    'pcm-s24',
                    'pcm-s32',
                    'pcm-f32',
                    'pcm-u8',
                    'ulaw',
                    'alaw'
                ].includes(codec))
        ];
    }
    get supportsVideoRotationMetadata() {
        return false;
    }
}
class OggOutputFormat extends OutputFormat {
    /** Creates a new {@link OggOutputFormat} configured with the specified `options`. */ constructor(options = {}){
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (options.onPage !== undefined && typeof options.onPage !== 'function') {
            throw new TypeError('options.onPage, when provided, must be a function.');
        }
        super();
        this._options = options;
    }
    /** @internal */ _createMuxer(output) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$ogg$2f$ogg$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OggMuxer"](output, this);
    }
    /** @internal */ get _name() {
        return 'Ogg';
    }
    getSupportedTrackCounts() {
        return {
            video: {
                min: 0,
                max: 0
            },
            audio: {
                min: 0,
                max: Infinity
            },
            subtitle: {
                min: 0,
                max: 0
            },
            total: {
                min: 1,
                max: 2 ** 32
            }
        };
    }
    get fileExtension() {
        return '.ogg';
    }
    get mimeType() {
        return 'application/ogg';
    }
    getSupportedCodecs() {
        return [
            ...__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$codec$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AUDIO_CODECS"].filter((codec)=>[
                    'vorbis',
                    'opus'
                ].includes(codec))
        ];
    }
    get supportsVideoRotationMetadata() {
        return false;
    }
}
class AdtsOutputFormat extends OutputFormat {
    /** Creates a new {@link AdtsOutputFormat} configured with the specified `options`. */ constructor(options = {}){
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (options.onFrame !== undefined && typeof options.onFrame !== 'function') {
            throw new TypeError('options.onFrame, when provided, must be a function.');
        }
        super();
        this._options = options;
    }
    /** @internal */ _createMuxer(output) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$adts$2f$adts$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AdtsMuxer"](output, this);
    }
    /** @internal */ get _name() {
        return 'ADTS';
    }
    getSupportedTrackCounts() {
        return {
            video: {
                min: 0,
                max: 0
            },
            audio: {
                min: 1,
                max: 1
            },
            subtitle: {
                min: 0,
                max: 0
            },
            total: {
                min: 1,
                max: 1
            }
        };
    }
    get fileExtension() {
        return '.aac';
    }
    get mimeType() {
        return 'audio/aac';
    }
    getSupportedCodecs() {
        return [
            'aac'
        ];
    }
    get supportsVideoRotationMetadata() {
        return false;
    }
}
class FlacOutputFormat extends OutputFormat {
    /** Creates a new {@link FlacOutputFormat} configured with the specified `options`. */ constructor(options = {}){
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        super();
        this._options = options;
    }
    /** @internal */ _createMuxer(output) {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$flac$2f$flac$2d$muxer$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FlacMuxer"](output, this);
    }
    /** @internal */ get _name() {
        return 'FLAC';
    }
    getSupportedTrackCounts() {
        return {
            video: {
                min: 0,
                max: 0
            },
            audio: {
                min: 1,
                max: 1
            },
            subtitle: {
                min: 0,
                max: 0
            },
            total: {
                min: 1,
                max: 1
            }
        };
    }
    get fileExtension() {
        return '.flac';
    }
    get mimeType() {
        return 'audio/flac';
    }
    getSupportedCodecs() {
        return [
            'flac'
        ];
    }
    get supportsVideoRotationMetadata() {
        return false;
    }
}
}),
"[project]/node_modules/mediabunny/dist/modules/src/output.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */ __turbopack_context__.s([
    "ALL_TRACK_TYPES",
    ()=>ALL_TRACK_TYPES,
    "Output",
    ()=>Output
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/misc.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/metadata.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$output$2d$format$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/output-format.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$media$2d$source$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/media-source.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$target$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/mediabunny/dist/modules/src/target.js [app-route] (ecmascript)");
;
;
;
;
;
const ALL_TRACK_TYPES = [
    'video',
    'audio',
    'subtitle'
];
const validateBaseTrackMetadata = (metadata)=>{
    if (!metadata || typeof metadata !== 'object') {
        throw new TypeError('metadata must be an object.');
    }
    if (metadata.languageCode !== undefined && !(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isIso639Dash2LanguageCode"])(metadata.languageCode)) {
        throw new TypeError('metadata.languageCode, when provided, must be a three-letter, ISO 639-2/T language code.');
    }
    if (metadata.name !== undefined && typeof metadata.name !== 'string') {
        throw new TypeError('metadata.name, when provided, must be a string.');
    }
    if (metadata.disposition !== undefined) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateTrackDisposition"])(metadata.disposition);
    }
    if (metadata.maximumPacketCount !== undefined && (!Number.isInteger(metadata.maximumPacketCount) || metadata.maximumPacketCount < 0)) {
        throw new TypeError('metadata.maximumPacketCount, when provided, must be a non-negative integer.');
    }
};
class Output {
    /**
     * Creates a new instance of {@link Output} which can then be used to create a new media file according to the
     * specified {@link OutputOptions}.
     */ constructor(options){
        /** The current state of the output. */ this.state = 'pending';
        /** @internal */ this._tracks = [];
        /** @internal */ this._startPromise = null;
        /** @internal */ this._cancelPromise = null;
        /** @internal */ this._finalizePromise = null;
        /** @internal */ this._mutex = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$misc$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AsyncMutex"]();
        /** @internal */ this._metadataTags = {};
        if (!options || typeof options !== 'object') {
            throw new TypeError('options must be an object.');
        }
        if (!(options.format instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$output$2d$format$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OutputFormat"])) {
            throw new TypeError('options.format must be an OutputFormat.');
        }
        if (!(options.target instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$target$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Target"])) {
            throw new TypeError('options.target must be a Target.');
        }
        if (options.target._output) {
            throw new Error('Target is already used for another output.');
        }
        options.target._output = this;
        this.format = options.format;
        this.target = options.target;
        this._writer = options.target._createWriter();
        this._muxer = options.format._createMuxer(this);
    }
    /** Adds a video track to the output with the given source. Can only be called before the output is started. */ addVideoTrack(source, metadata = {}) {
        if (!(source instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$media$2d$source$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["VideoSource"])) {
            throw new TypeError('source must be a VideoSource.');
        }
        validateBaseTrackMetadata(metadata);
        if (metadata.rotation !== undefined && ![
            0,
            90,
            180,
            270
        ].includes(metadata.rotation)) {
            throw new TypeError(`Invalid video rotation: ${metadata.rotation}. Has to be 0, 90, 180 or 270.`);
        }
        if (!this.format.supportsVideoRotationMetadata && metadata.rotation) {
            throw new Error(`${this.format._name} does not support video rotation metadata.`);
        }
        if (metadata.frameRate !== undefined && (!Number.isFinite(metadata.frameRate) || metadata.frameRate <= 0)) {
            throw new TypeError(`Invalid video frame rate: ${metadata.frameRate}. Must be a positive number.`);
        }
        this._addTrack('video', source, metadata);
    }
    /** Adds an audio track to the output with the given source. Can only be called before the output is started. */ addAudioTrack(source, metadata = {}) {
        if (!(source instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$media$2d$source$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["AudioSource"])) {
            throw new TypeError('source must be an AudioSource.');
        }
        validateBaseTrackMetadata(metadata);
        this._addTrack('audio', source, metadata);
    }
    /** Adds a subtitle track to the output with the given source. Can only be called before the output is started. */ addSubtitleTrack(source, metadata = {}) {
        if (!(source instanceof __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$media$2d$source$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SubtitleSource"])) {
            throw new TypeError('source must be a SubtitleSource.');
        }
        validateBaseTrackMetadata(metadata);
        this._addTrack('subtitle', source, metadata);
    }
    /**
     * Sets descriptive metadata tags about the media file, such as title, author, date, or cover art. When called
     * multiple times, only the metadata from the last call will be used.
     *
     * Can only be called before the output is started.
     */ setMetadataTags(tags) {
        (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f$mediabunny$2f$dist$2f$modules$2f$src$2f$metadata$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["validateMetadataTags"])(tags);
        if (this.state !== 'pending') {
            throw new Error('Cannot set metadata tags after output has been started or canceled.');
        }
        this._metadataTags = tags;
    }
    /** @internal */ _addTrack(type, source, metadata) {
        if (this.state !== 'pending') {
            throw new Error('Cannot add track after output has been started or canceled.');
        }
        if (source._connectedTrack) {
            throw new Error('Source is already used for a track.');
        }
        // Verify maximum track count constraints
        const supportedTrackCounts = this.format.getSupportedTrackCounts();
        const presentTracksOfThisType = this._tracks.reduce((count, track)=>count + (track.type === type ? 1 : 0), 0);
        const maxCount = supportedTrackCounts[type].max;
        if (presentTracksOfThisType === maxCount) {
            throw new Error(maxCount === 0 ? `${this.format._name} does not support ${type} tracks.` : `${this.format._name} does not support more than ${maxCount} ${type} track` + `${maxCount === 1 ? '' : 's'}.`);
        }
        const maxTotalCount = supportedTrackCounts.total.max;
        if (this._tracks.length === maxTotalCount) {
            throw new Error(`${this.format._name} does not support more than ${maxTotalCount} tracks` + `${maxTotalCount === 1 ? '' : 's'} in total.`);
        }
        const track = {
            id: this._tracks.length + 1,
            output: this,
            type,
            source: source,
            metadata
        };
        if (track.type === 'video') {
            const supportedVideoCodecs = this.format.getSupportedVideoCodecs();
            if (supportedVideoCodecs.length === 0) {
                throw new Error(`${this.format._name} does not support video tracks.` + this.format._codecUnsupportedHint(track.source._codec));
            } else if (!supportedVideoCodecs.includes(track.source._codec)) {
                throw new Error(`Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported` + ` video codecs are: ${supportedVideoCodecs.map((codec)=>`'${codec}'`).join(', ')}.` + this.format._codecUnsupportedHint(track.source._codec));
            }
        } else if (track.type === 'audio') {
            const supportedAudioCodecs = this.format.getSupportedAudioCodecs();
            if (supportedAudioCodecs.length === 0) {
                throw new Error(`${this.format._name} does not support audio tracks.` + this.format._codecUnsupportedHint(track.source._codec));
            } else if (!supportedAudioCodecs.includes(track.source._codec)) {
                throw new Error(`Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported` + ` audio codecs are: ${supportedAudioCodecs.map((codec)=>`'${codec}'`).join(', ')}.` + this.format._codecUnsupportedHint(track.source._codec));
            }
        } else if (track.type === 'subtitle') {
            const supportedSubtitleCodecs = this.format.getSupportedSubtitleCodecs();
            if (supportedSubtitleCodecs.length === 0) {
                throw new Error(`${this.format._name} does not support subtitle tracks.` + this.format._codecUnsupportedHint(track.source._codec));
            } else if (!supportedSubtitleCodecs.includes(track.source._codec)) {
                throw new Error(`Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported` + ` subtitle codecs are: ${supportedSubtitleCodecs.map((codec)=>`'${codec}'`).join(', ')}.` + this.format._codecUnsupportedHint(track.source._codec));
            }
        }
        this._tracks.push(track);
        source._connectedTrack = track;
    }
    /**
     * Starts the creation of the output file. This method should be called after all tracks have been added. Only after
     * the output has started can media samples be added to the tracks.
     *
     * @returns A promise that resolves when the output has successfully started and is ready to receive media samples.
     */ async start() {
        // Verify minimum track count constraints
        const supportedTrackCounts = this.format.getSupportedTrackCounts();
        for (const trackType of ALL_TRACK_TYPES){
            const presentTracksOfThisType = this._tracks.reduce((count, track)=>count + (track.type === trackType ? 1 : 0), 0);
            const minCount = supportedTrackCounts[trackType].min;
            if (presentTracksOfThisType < minCount) {
                throw new Error(minCount === supportedTrackCounts[trackType].max ? `${this.format._name} requires exactly ${minCount} ${trackType}` + ` track${minCount === 1 ? '' : 's'}.` : `${this.format._name} requires at least ${minCount} ${trackType}` + ` track${minCount === 1 ? '' : 's'}.`);
            }
        }
        const totalMinCount = supportedTrackCounts.total.min;
        if (this._tracks.length < totalMinCount) {
            throw new Error(totalMinCount === supportedTrackCounts.total.max ? `${this.format._name} requires exactly ${totalMinCount} track` + `${totalMinCount === 1 ? '' : 's'}.` : `${this.format._name} requires at least ${totalMinCount} track` + `${totalMinCount === 1 ? '' : 's'}.`);
        }
        if (this.state === 'canceled') {
            throw new Error('Output has been canceled.');
        }
        if (this._startPromise) {
            console.warn('Output has already been started.');
            return this._startPromise;
        }
        return this._startPromise = (async ()=>{
            this.state = 'started';
            this._writer.start();
            const release = await this._mutex.acquire();
            await this._muxer.start();
            const promises = this._tracks.map((track)=>track.source._start());
            await Promise.all(promises);
            release();
        })();
    }
    /**
     * Resolves with the full MIME type of the output file, including track codecs.
     *
     * The returned promise will resolve only once the precise codec strings of all tracks are known.
     */ getMimeType() {
        return this._muxer.getMimeType();
    }
    /**
     * Cancels the creation of the output file, releasing internal resources like encoders and preventing further
     * samples from being added.
     *
     * @returns A promise that resolves once all internal resources have been released.
     */ async cancel() {
        if (this._cancelPromise) {
            console.warn('Output has already been canceled.');
            return this._cancelPromise;
        } else if (this.state === 'finalizing' || this.state === 'finalized') {
            console.warn('Output has already been finalized.');
            return;
        }
        return this._cancelPromise = (async ()=>{
            this.state = 'canceled';
            const release = await this._mutex.acquire();
            const promises = this._tracks.map((x)=>x.source._flushOrWaitForOngoingClose(true)); // Force close
            await Promise.all(promises);
            await this._writer.close();
            release();
        })();
    }
    /**
     * Finalizes the output file. This method must be called after all media samples across all tracks have been added.
     * Once the Promise returned by this method completes, the output file is ready.
     */ async finalize() {
        if (this.state === 'pending') {
            throw new Error('Cannot finalize before starting.');
        }
        if (this.state === 'canceled') {
            throw new Error('Cannot finalize after canceling.');
        }
        if (this._finalizePromise) {
            console.warn('Output has already been finalized.');
            return this._finalizePromise;
        }
        return this._finalizePromise = (async ()=>{
            this.state = 'finalizing';
            const release = await this._mutex.acquire();
            const promises = this._tracks.map((x)=>x.source._flushOrWaitForOngoingClose(false));
            await Promise.all(promises);
            await this._muxer.finalize();
            await this._writer.flush();
            await this._writer.finalize();
            this.state = 'finalized';
            release();
        })();
    }
}
}),
];

//# sourceMappingURL=node_modules_mediabunny_dist_modules_src_9c59443a._.js.map